{"question":"How did the Brahmo Samaj's social reform agenda relate to broader Indian debates about religious freedom and political rights?","answer":"The Brahmo Samaj, founded by Raja Ram Mohan Roy in 1828, advocated for major social reforms including criticism of the Sati practice, opposition to casteism, and support for widow remarriage. While these reforms were framed in religious terms, they represented part of a larger struggle over religious freedom and political rights in India. The question of religious freedom in India became complex, as shown by debates over whether religious freedom should include the right to proselytize. This complexity is reflected in how many progressive Indians supported restrictions on proselytizing, following a tradition of Indian secularist thought first articulated in the 1920s. The Indian secularist imagination developed as an intervention in these politics of religious freedom, emphasizing equal respect for all religions while questioning certain Western conceptions of religious liberty.","context":["Social and Cultural Uprisings\nSocial and Cultural Uprisings :: Tribal & Peasant Uprisings in India\n- Founded by Raja Ram Mohan Roy in 1828.\n- He earlier started Atmiya Sabha in 1814.\n- Criticized Sati Pratha, casteism and advocated widow remarriage.\n- He gave enthusiastic assistance to David Hare, who founded the famous Hindu College in Calcutta.\n- Established a Vedanta College in which courses both in Indian and Western social and physical sciences were offered.\n- He was a gifted linguist. He knew more than dozen languages including Sanskrit, Persian, Arabic, English, French, Latin, Greek and Hebrew.\n- He was opposed to Sanskrit system of education; because he thought it would keep the country in darkness.\n- Other important leaders were Devendranath Tagore (father of Rabindranath Tagore) and Keshab Chandra Sen.\n- Tagore dismissed Keshab Chandra in 1865.\n- Keshab started Sangat Sabha, Prarthana Samaj and Brahmo Samaj of India.\n- Tagore’s organization came to be known as Tattvabodhini Sabha and Adi Brahmo Samaj.\n- Anand Mohan Bose started the Sadharana Brahmo Samaj.\n- Justice M.G. Ranade founded the Prarthana Sabha.\nArya Samaj India :\n- Founded by Swami Dayanand (or, Moolshankar) in 1875.\n- His motto was ‘Go back to the Vedas’ & ‘India for the Indians’. He disregarded Puranas, idol worship, casteism and untouchability. He advocated widow remarriage.\n- Dayanand’s views were published in his famous work, Satyarth Prakash. He also wrote Veda Bhashya Bhumika and Veda Bhashya.\n- Established a large number of educational institutions in India, viz., Gurukuls, DAV schools, etc.\n- Also started the ‘Siddhi’ movement to convert non – Hindus to Hinduism.\n- Other prominent persons of Arya Samaj were Lala Hans Raj, Pt. Guru Dutt, Lala Lajpat Rai, Swami Shraddhanand.\nHistory of Ramakrishna Mission :\n- Founded by Vivekanand (earlier, Narendranath Dutta) (1863 – 1902) in 1897, 11 years after the death of his guru Ram Krishna Paramhans.\n- Vivekanand attended the Parliament of Religion at Chicago in 1893.\n- He published two papers : Prabhudha Bharat in English and Udbodhana in Bengali.\n- Vivekanand’s Quotes :\n- No social progress is possible without improving condition of women, who were most important instrument of social change.\n- So long as millions live in hunger and ignorance I hold every man a traitor who, having been educated at their expense, pays not the least heed to them.\n- All power is within you, you can do anything and everything. Believe in that; do not believe that you are weak. You can do anything and everything, without even the guidance of any one. All power is there. Stand up and express the divinity with you. Arise, awake, sleep no more. With each of you there is the power to remove all wants and all miseries. Believe in this, that power will be manifested.\n- Irish woman Margaret Noble (Known as sister Nivedita) popularized Ramakrishna Mission after Vivekanand’s death.\nYoung Bengal Movement :\n- During the late 1820 and early 1830, there emerged a radical intellectual trend among the youth in Bengal, which came to be known as the ‘Young Bengal Movement’.\n- Founded by Henry Louis Vivian Derozio (1809 – 31). He was a teacher in Hindu College in Calcutta.\n- He also edited the papers, Hesperus and Calcutta Literary Gazette and was connected with the India Gazette.\n- He urged the students to live and die for truth. He also supported women’s education and their rights.\nHistory of Veda Samaj :\n- Called Brahmo Samaj of South. Started by Sridharalu Naidu.\n- He translated books of Brahmo Dharma into Tamil and Telegu.\nDharma Sabha :\n- Initiated by Radhakant Deb in 1830.\n- Was opposed to reforms and protected orthodoxy, but played an active role in promoting western education even to girls.\nDrain of Wealth Theory India :\n- R.C. Dutta and Dadabhai Naoroji first cited the drain of wealth theory. Naoroji brought it to light in his book titled “Poverty and Unbritish Rule in India”. R C Dutt blamed the British policies for economic ills in his book “Economic History of India”.\n- Drain of wealth refers to the portion of national product of India, which was not available for consumption of Indians.\n- Drain of wealth began in 1757 after the Battle of Plassey when the Company’s servants began to extort fortunes from Indian rulers, zamindars, merchants and common people and send home.\n- In 1765, the Company acquired the Diwani of Bengal and began to purchase the Indian goods out of the revenue of Bengal and exported them. These purchases were known as Company’s investments.\n- Duty free inland trade provided British merchants a competitive edge over their Indian counterparts.\n- The actual drain, as a part of the salaries and other incomes of the English officials and the trading fortunes of English merchants, was even more.\n- The drain of wealth stunted the growth of Indian enterprise and checked and retarded capital formation in India.\n- Started by Gopal Hari Deshmukh. Advocated western education and a rational outlook. He advocated female education for the upliftment of women.\n- As a vptary of national self – reliance, he attended Delhi durbar in 1876, wearing handspun khadi cloth.\nIndian (National) Social Conference :\n- Founded by M.G. Ranade and Raghunath Rao. It held its first session in 1887.\n- Its main focus was on abolition of polygamy and kulinism and it encouraged intercaste marriages. It also pledged to fight child marriages.\n- The Conference is sometimes referred as the social reform cell of the Indian National Congress.\nServants of India Society :\n- Formed by Gopal Krishna Gokhale in 1915.\n- It did notable work in providing famine relief and in improving the condition of the tribal.\nSeva Samiti : Hridayanath Kunzru, a member of the Servants of India Society, organized the Samiti at Allahabad in 1914, to improve the status of the suffering classes, reform criminals and to rescue those suffering in society.\nRadhaswami Movement :\n- Founded in 1861 by a banker of Agra, Tulsi Ram, popularly known as Shiv Dayal Saheb or Swami Maharaj.\n- The sect preached belief in one Supreme Being, the Guru’s supreme position and a simple social life for the believers (the Satsangis).\n- Founded by Shiv Narain Agnihotri in 1887. it preached high moral and social conduct like, for instance, keeping oneself away from gambling and intoxicants.\n- Deva Shastra tells us about the ideals of Deva Samaj.\nTheosophical Society Annie Besant :\n- Founded by Westerners who drew inspiration from Indian thought and culture.\n- Madam H P Blavatsky laid the foundation of the movement in US in 1875. Later, Col. M S Olcott of the US Army joined her.\n- In 1882, it was shifted to India at Adyar (Tamil Nadu).\n- Annie Besant was elected its President in 1907. She founded the Central Hindu College in 1898, which became Banaras Hindu University in 1916.\n- The society accepted Hindu beliefs like re – incarnation, Karma and draws inspiration from Upanishads, Sankhya, Yoga and Vedanta schools.\nThe Aligarh Movement :\n- Started by Sir Syyed Ahmed Khan. He encouraged Muslims to accept the virtues of western education and urged them to apply the principle of enquiry to religion.\n- For a rational and scientific order in society, he founded a scientific society in 1864, an Urdu journal, Tahzib – al – akhlaq in 1870, and the Aligarh school in 1875. The school was made into the Muhammadan Anglo – Oriental College in 1877. The college grew into the Aligarh Muslim University.\nThe Ahmedia Movement in Islam :\n- Started by Mirza Ghulam Ahmed in 1889.\n- His movement embraced the belief in a universal religion, opposed sacred wars and encouraged fraternal relations among all.\nThe Deobandi Movement :\n- In 1866, the Deoband School of Islamic Theology was set up at Deoband by Rashid Ahmed Gangohi and Muhammad Qasim Nanautavi to promote studies in classical Islam and moral and religious regeneration of the Muslims. The school did not support western education and. culture.\n- Its liberal interpretations of Islam earned it a high reputation.\nSatyashodhak Samaj :\n- Founded by Jyotiba Phule in 1873 to fight Brahmanic domination and to liberate low castes by educating them and teaching them their rights. He advocated the cause of untouchables.\n- Jyotiba also started a school for untouchables and an orphanage for widows.\n- His books, Ghulamgiri and Sarvajanik Satyadharma Pustak questioned the traditional customs and beliefs of society.\n- Met the Duke of York as the representative of poverty stricken Indian peasant.\nThe Justice Party Movement :\n- Dr. T.M. Nair, Sir Pitti Theagaraja Chettiar and the Raja of Panagal formed the South Indian Liberal Federation (SILF) in 1916 to protest against the domination of Brahmins in government service, education and in the political field.\n- The newspaper, Justice, was their main organ for expressing views and opinions.\n- The SILF came to be called the Justice Party later on.\nSelf Respect Movement in Tamil Nadu :\n- The radical movement was launched by Periyar or E.V. Ramaswamy Naicker in Tamil Nadu in 1925, to awaken non – brahmins for overthrowing Brahmanic superiority.\n- The movement organized weddings without involving the Brahmins and temple entry.\nSelf Respect Movement in India :\n- Dr. Bhimrao Ramji Ambedkar’s movement worked for the upliftment of the untouchables by fighting for their educational, legal and political rights and encouraging them to throw off the traditional caste duties imposed on them.\n- Ambedkar founded the Depressed Classes Institute (Bahishkrit Hitkarini Sabha) in Bombay in 1924, a Marathi fortnightly Bahishkrit Bharat in 1927 and the Sarnaj Samata Sangha in 1927. He also founded the Independent Labour Party.\n- The Scheduled Caste Federation, a political party, was formed by him in 1942.\nSocial and Cultural Uprisings – Brahmo Samaj Movement – Arya Samaj India – History of Ramakrishna Mission – Young Bengal Movement\nHistory Related : Social and Cultural Uprising , Raja Ram Mohan Roy Brahmo Samaj , Brahmo Samaj Founder , Social and Cultural Uprisings, Arya Samaj , Ramakrishna Mission Vivekanand , Narendranath Dutta , RamKrishna Paramhans , Margaret Noble , Young Bengal Movement , Veda Samaj , Dharma Sabha , Social Uprisings , Hindu Dharma Sabha , Lokahitawadi , Lokahitawadi Gopal Hari Deshmukh , Uprisings in History , Indian National Conference , Servants of India Society , Gopal Krishna Gokhale , Swami Maharaj , Deva Samaj , Theosophical Society , Annie Besant , Annie Besant Freedom Fighter , Aligarh Movement , Sir Syyed Ahmed Khan , E V Ramaswamy Naicker , Radical Movement , Ahmedia Movement , Deobandi Movement , Satya Shodhak Samaj , Jyotiba Phule , Self Respect Movement in Tamil Nadu , Bhimrao Ramji Ambedkar , General Knowledge Today , GK about Indian History , GK about History , General Knowledge Indian History , General Knowledge about Current Affairs , General Knowledge about History , General Knowledge in Indian History , General Knowledge in History , General Knowledge , GK , GK in India , General Knowledge Questions , General Knowledge India , General Knowledge Test , GK Quiz ,\nPosted In general knowledge : history : Leave a response for social and cultural uprisings by jayaraj","What is the politics of religious freedom? For the past decade and more, those who would like to see the active promotion of religious freedom at the “core” of foreign policy in the U.S. and now in Canada would have us understand that religious freedom is the foundation of democracy, the basis for political stability and first step to all other freedoms. The mission statement of the Office of International Religious Freedom in the U.S. Department of State links its promotion of religious freedom to human rights and to political “stability” for “all countries.” Referring to the establishment of a new Office of Religious Freedom within his government’s Department of Foreign Affairs and International Trade in a statement to the United Nations last year, the Canadian UN Ambassador declared, “History has shown us that where religious freedom is strong, democratic freedom is strong.”\nThese are strong claims with powerful appeal. In India too, national narratives would trace today’s secular democracy to the foundational moment when religious freedom—taken in a broad sense, at least—was established as a political ideal. Many regard Indian secularism to be deeply rooted in an ideal of equal respect for all religions. The annual reports issued by the U.S. Office of International Religious Freedom over the past several years credit the Indian achievement by noting that the constitution protects religious freedom. But they also observe that laws at the state level have restricted this freedom. The 2010 Report cites legislation restricting religious proselytizing, which it describes as “‘anticonversion’ laws,” but which are properly known as Freedom of Religion acts.\nThe Report’s choice of nomenclature glosses over an important debate about the meaning of religious freedom in India. Many critical observers of Indian debates over conversion argue that to interpret religious freedom to include a right to proselytize, as is normative in American foreign policy and human rights law, is to impose “a Western conception of religion and religious freedom on the rest of the world.” They argue that religious freedom so construed favors “proselytizing religions,” like Christianity, over “non-proselytizing religion,” which is more typical to India.\nI will not dwell on this line of argument here except to note that it has a long and respectable pedigree. Far from confined to the Hindu Right, it is integral to a prominent tradition of Indian secularist thought: the Gandhian tradition, first articulated during the 1920s. This explains the fact, also glossed over in the Annual Report on International Religious Freedom, that many “progressive” Indians support restrictions on proselytizing. In an important sense, the Indian secularist imagination took shape as an intervention in the politics of religious freedom.\nWhat is the politics of religious freedom? As others in this series have remarked, the question hinges on what we take religion to be. Critical reflection has called into question whether it is possible to produce a sufficiently neutral definition of religion to allow religious freedom to be administered to all persons equally. But this is more than a question of majority bias—important as this question is, more is at stake than whether religious freedom is interpreted in such a way as to privilege Christians over Hindus, or Hindus over Christian and Muslim minorities. We must ask what is foregrounded when we speak of religion and what forms of politics our talk of religion might exclude. This is particularly true when we consider the politics of religious freedom outside Europe and North America.\nThe International Religious Freedom Reports on India only hint at this larger story. Untouchability is illegal in India, but members of the Scheduled Castes or Dalits—castes formerly referred to as “untouchable”—continue to face discrimination and violence regardless of their religious affiliations as Muslim, Hindu, Christian, or Buddhist. Their struggles for equality make their appearance in the State Department reports only briefly, when they involve religious conversion: “some Dalits who sought to convert out of a desire to escape discrimination and violence encountered hostility and backlash from upper castes.” But Dalits are subject to discrimination, even by their co-religionists, regardless of whether they are Hindu, Christian, or Muslim. A mere change of religious affiliation does not bring escape from caste-based discrimination. So just what kinds of practice are we talking about, using this imprecise language of “religious conversion”? What forms of political practice does our attention to religious freedom conceal?\nI want to draw attention to the different forms of political struggle that have come to be sheltered under the language of religious freedom in India, but that are also obscured by it. By considering the Indian case from the vantage point of caste, I also hope to provoke a rethinking of the truism that religious freedom is the basis for all other freedoms. Critical reflections have taught us that the category religion is neither natural nor universal, but derives from a modern, European history. The history of religious freedom in India is therefore a history of (partial, incomplete) translations. I cannot do justice to this complex history in this brief post (see more in my contribution to this volume). Instead my aim is to highlight the problem of translation.\nFrom the eighteenth century through the twentieth, the category of religion organized the colonial policy of the British government in India. It informed the colonial policy of religious toleration, and it informed the practice of extending political representation to Indians as members of communities. Indian political elites learned to speak this language of religion, and to invoke their right to religious freedom against the intrusions of the colonial state.\nBut in India the English-language discourse of religion was specific to the civic arena of colonial politics. Scholars have often remarked upon the divided or “bilingual” quality to colonial politics: the civic arena, which was organized by a quasi-liberal political idiom, was confined to a relatively small circle of social actors—the English-educated elites—particularly when they addressed their British rulers. Outside this narrow arena, political effort in colonial India was organized by vernacular idioms that reached deeper into Indian society and drew upon a longer history on the subcontinent. Scholars often resort to using a religious vocabulary to describe the vernacular idioms of politics outside the civic arena. But to do so obscures the labor of translation that was required when Indian actors represented their political struggles before the state.\nBeginning in the last decades of the nineteenth century, those judged to belong to low or “untouchable” castes took part in what I refer to as “ritual-political” struggles for dignity, respectability, and equality of treatment with (Muslim, Sikh, or Hindu) upper castes. Ritual-politics targeted the “meticulous rituals of power” that constituted certain caste groups as subordinate. Low castes were prevented from adopting the dress or ceremonial of superior castes, were required to show prescribed forms of deference in their postures and their forms of greeting, and were often excluded from equal access to common spaces. In the ritual-political initiatives of the low castes, these distinctions were loci of resistance, together with restriction from use of common wells and vessels, exclusion from common schools or education, debarment from owning land, forced obligations to perform demeaning tasks, and unpaid labor.\nSome of these ritual-political initiatives—I have in mind the shuddhi activities associated with the Hindu reform organization, the Arya Samaj—came to be identified as “religious conversion” and, during the 1920s, became the focus of national debates over religious freedom. For the members of “untouchable” castes who actively pursued shuddhi into the first half of this decade, shuddhi was important not because of any nominal change of religious identity it brought about, but because of the way it could be made to serve the ritual-political struggle against caste oppression. But in the 1920s, Indian elites translated this politics of shuddhi into the language of religious freedom: they debated whether religious freedom should protect shuddhi “proselytizing,” or whether “proselytizing” posed an intolerable threat to peaceable relations between (in this case, Hindu and Muslim) religious communities in India. As elites translated shuddhi into the language of religion and religious freedom, the struggle against caste inequality dropped out of sight.\nA great deal has changed in the politics of caste and in the politics of “conversion” between the 1920s and today. As this brief history of religious freedom in India suggests, we must ask not only what kinds of politics the active promotion of religious freedom in India might facilitate, but also what forms of politics and modes of collective action it might foreclose."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:a8994b5e-03d4-4a96-9004-606d11a75e8a>","<urn:uuid:9422647b-a3dd-42ac-8032-86b74830a157>"],"error":null}
{"question":"What are the three Gunas in yoga philosophy and how do they manifest?","answer":"The three Gunas are Tamas, Rajas, and Sattva. Tamas manifests as darkness, inertia, lethargy, and dullness. Rajas manifests as the energy of passion, emotion, desire, and activity. Sattva is associated with harmony, knowledge, happiness, and goodness.","context":["What can we learn about balance from Yoga Philosophy? Esther Ekhart explains the interplay of the three Gunas.\nThe Three Gunas\nThe ancient teachings of yoga, like the Samkhya Philosophy and also the Bhagavad Gita, talk about three essential aspects of nature. These are called the Gunas.\nGunas in Sanskrit means a strand or a rope. All of creation (Prakriti or universal nature) is made up of these three qualities called :\nTamas, which manifests as darkness, inertia, lethargy, dullness, illusion, heaviness. Tamas can be seen as the past, your lot in life, the given.\nRajas, which manifests as the energy of passion, emotion, desire, activity, sorrow. Rajas can be seen as the future, desire, externalisation.\nSattva, which is associated with the principles of harmony, knowledge, happiness and goodness. Sattva is the present, awakening, the process of consciousness unfolding. It transcends tension between the two above, and it is the desirable quality of the three.\nAll Levels of Manifestation\nAccording to the ancient teachings, everything, on all levels of manifestation is made up of different combinations of these three strands or qualities. They underlie matter, life and mind.\nEvery experience we have is composed of the three gunas in different proportions. These three qualities are in a constantly changing relationship with each other.\nWhen one of the gunas is dominant, this is what happens:\nWhen we feel mostly sattvic we feel clear, calm and harmonious\nA rajasic state means you feel passionate, hyper active, the mind keeps going, not being able to stop.\nWhen we feel tamasic we can’t get out of bed, feeling unmotivated, dragging ourselves through the day.\nWe need all three qualities in our life. Tamas makes us stop and rest, we need rajas to get us going in the morning, we need sattva to understand and get clarity and wisdom.\nThe Full Circle\nNow here is an example of how the three gunas act with each other with regards to how we feel and our moods.\nSay we have a sattvic mood, we are content with life as it unfolds, being present. This may last for a while, but then it tends to become over ripe and the contentment turns into becoming a bit lazy and you take it for granted. This then has turned into a tamasic mood, and turns into your being unmotivated and heavy. The rajas mood will then in turn break up the tamasic state. You will get sick of your heaviness and start doing something to get going, through ambition and passion. But then of course it’s excess – hyperactivity, anxiety lie around the corner. The state of chaos that rajas will get you into will make you stop and contemplate and we come back into the sattvic state of understanding and clarity.\nThis will keep repeating itself through life – it is just the three gunas acting with each other, the nature of life.\nFinding Balance with the Wisdom of the Gunas\nIf we don’t know that this is just what happens, we can get very attached to the different states, believing that the sattvic state is where we are supposed to be all the time, or at least doing what you need to do to get there. But this is already rajas kicking in, so it will never work!\nThe practice of yoga is not to make you sattvic – because you now know, tamas will naturally follow, so you will be disappointed! What you want, is to be OK with it all! That is balance.\nWhen we are not attached to a sattvic state, or for example to a good meditation, this will transform it into sattvic state. When the mind creates an ideal, you will become rajasic etc…\nReally it is humorous. Mystical experiences occur when we clearly see that all experience is the three gunas acting on the three gunas… we don’t identify when we are sattvic. Then when we move into a tamasic state, we observe it as the natural pattern of change, and then when passions arise, bringing ideas to stir things up, again it is just the gunas acting on the gunas.\nIt is about appreciating the process of life as it unfolds. If we don’t understand, we become attached, obsessed and ultimately disappointed.\nYoga master B.K.S. Iyengar writes that stability is something we can practise and, ultimately, master. The path to cultivating that stability is through balance, which he defines as being present in the here and now.\nBeing present in the here and now transcends needing to be in a particular state or mood to make that happen. You can be present feeling tamasic, rajasic and sattvic!\nKnowing all these states will follow each other, will make it easier to step back and enjoy seeing life unfolding itself and do its thing.\nSo observe and be present rather than getting caught up believing you need to be a certain way.\nI hope this brings some perspective to the search for balance / happiness 🙂"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:c6d7a6c0-8692-405b-9253-9cc5b68ad52d>"],"error":null}
{"question":"How do both Liebherr-Aerospace and MTU Aero Engines approach future manufacturing challenges in the aerospace industry?","answer":"Liebherr-Aerospace is focusing on integrating additive manufacturing into their established automated workflow to enhance manufacturing efficiency and reduce production surplus, particularly through precise atmosphere control for aluminium components. Meanwhile, MTU Aero Engines has designed their new test center with future expansion capabilities in mind, preparing for testing new materials, designs, and larger structures for next-generation commercial engines, with the ultimate goal of developing emission-free air traffic and innovative green propulsion technologies.","context":["Linde and Liebherr-Aerospace collaborate to optimise additively manufactured aluminium aircraft components\nMay 16, 2019\nThe Linde Group, a leading industrial gases and engineering company has collaborated with Liebherr-Aerospace Toulouse SAS, France, part of the Liebherr Group, Switzerland, in a project set to optimise the benefits of Additive Manufacturing for aluminium aircraft components. To date, the project has reportedly delivered definitive results in terms of improvement of product quality and production repeatability, with Linde’s ADDvance® O2 precision solution gas analysis technology reported to play a central role in the research.\nAccording to Liebherr-Aerospace, it is keen to integrate the fabrication of additively manufactured parts into its established automated workflow to enhance manufacturing efficiency and reduce production surplus. As AM represented a new manufacturing approach for the company, a pilot project was launched in collaboration with Linde to develop aluminium components, including bleed air valves.\nLiebherr-Aerospace installed its first metal AM system at its manufacturing centre in France, but initial tests indicated that oxygen levels fluctuated during the AM process. The variation in oxygen levels were seen to negatively impact the quality of the printed parts – particularly those made from aluminium alloys. Linde states that the solution was to implement its ADDvance O2 precision technology to provide continuous analysis of the gas atmosphere. This technology can reportedly detect O2 concentrations with high precision – as low as 10 parts per million (ppm) – without cross-sensitivity, the unit automatically initiates a purging process to maintain the atmosphere to the required purity.\nAfter the atmosphere in the Additive Manufacturing chamber is purged, impurities can remain due to incomplete purging, via access through loose connections or within the metal powder itself. Small variations in oxygen content can impair the mechanical or chemical properties of alloys sensitive to oxygen like titanium or aluminium. This can affect the composition of the end product, resulting in discolouration and even poor fatigue resistance.\n“Linde has always played a pioneering role in the development of atmospheric gas technologies,” stated, Pierre Forêt, Senior Expert Manufacturing, Linde. “That we were selected by Liebherr-Aerospace Toulouse to collaborate in this important project to advance the understanding of the role atmospheric gases play in Additive Manufacturing of critical aerospace parts, is further testament to our innovative capabilities.”\nThe ADDvance O2 precision has reportedly provided Liebherr-Aerospace with precise, granular control over oxygen concentrations in its printer chamber, allowing them to test different levels to assess how it impacts AM components. It is said to significantly improve monitoring and control through a feedback loop with dynamic adaptation, meaning operators can define a setpoint value and maintain purity levels. In addition, an unexpected benefit was the ability to also measure humidity within the chamber, another critical variable in the production process and a capability unique to ADDvance O2 precision.\nFrédéric Letrange, AM Project Leader, Liebherr-Aerospace Toulouse, commented, “We know that gas purity during fusion has a direct impact on the mechanical and metallurgical properties we can expect to achieve – especially with aluminium alloys. So, we needed a dedicated solution to help us improve atmosphere control in the printer. Having looked at the various oxygen measurement and control systems available on the market, it quickly became clear to us that ADDvance O2 precision was the most mature so it was a natural step for us to expand our partnership with Linde into the Additive Manufacturing space.”","Latest Press Releases\nMTU Aero Engines opens new high-tech test center for engine parts in Munich\n- 25-million-euro investment to grow the company’s capabilities\n- Centerpiece of the test facility is a multifunctional rotation test stand\nMunich, October 15, 2019 – High-tech at its best: MTU Aero Engines has built a new test center for engine parts on its Munich premises, investing an amount of more than 25 million euros in a new building and the most advanced test equipment. After two years of construction, the test center is now operational. This afternoon, Judith Gerlach, Bavarian State Minister for Digital Affairs, and MTU’s Chief Operating Officer (COO) Lars Wagner inaugurated the facility in a ceremony attended by around 100 guests from business, politics and science as well as company employees.\nJudith Gerlach, Bavarian State Minister for Digital Affairs, said: “Like no other state government in Germany, the Bavarian State Government is investing heavily in the aerospace industry. As part of the high-tech agenda recently adopted, we will be providing additional funds in the amount of 90 million euros. ‘Made in Bavaria’ stands for quality and high-tech, and digital transformation is a key driver of innovation. Digitalization has a huge impact not only on product development and production, but also on test methods and quality management.” And she added: “With this highly advanced component test center MTU Aero Engines impressively underscores that it is and will stay committed to the Free State of Bavaria. This is good news for this state as a high-tech region and home to aerospace companies that enjoy an excellent reputation worldwide.”\nMTU’s COO Lars Wagner emphasized the importance of the new test center: “MTU is renowned worldwide for its unique testing expertise. Our new component test center is yet another impressive proof that we have rightly earned our reputation for excellence in this field.” MTU’s testing capabilities comprise parts, components and complete engines. The company performs development tests, certification tests and production acceptance tests. “In our new test center, we will be testing parts that make up compressors and turbines, that is, for example, blades and vanes, disks, casings, rings, and tubing.” Since safety is the number one priority in the aviation industry, the company’s products must undergo rigorous testing and meet the highest safety standards – right down to detail part level.\nTesting of new materials and designs\nWith the new test center MTU not only satisfies its current testing needs - the company has also set its sights on the future. Dr. Jörg Henne, Senior Vice President Engineering and Technology, explained in his speech: “We’ve built up the testing capacities we need for our current engine programs – but not without bearing upcoming future requirements in mind.” Plans are to test new materials, new designs and larger structures. Henne also talked about entirely new propulsion systems just emerging on the horizon: commercial engines of the next and next-but-one generation which will have to meet even more stringent requirements. “Our ultimate goal is emission-free air traffic, and MTU is already pushing the development of innovative green propulsion technologies systematically forward,” Henne said.\nAn emerging program in the military segment is the Next European Fighter Engine, or NEFE for short. This propulsion system will be developed jointly by MTU and European partners, and its parts will be put through their paces in the new test center in Munich, according to Henne. The facility has been designed such that it can easily be expanded when needed, for example to add floor space or to accommodate new technologies.\nExcellent testing capabilities\nMTU has the requisite equipment for as many as 65 different test types – among them spin tests, air flow measurements, structural tests, vibration, wear, ballistic and fatigue tests. MTU created some excellent new testing capabilities that constitute a unique selling point for MTU and make the company clearly stand out among its competitors. Testing will be performed on the company’s existing three vertical test stands, which have been relocated to the new building, and on other test facilities. The company is confident that the integration of all component test facilities into one test center will bring about a marked increase in efficiency. The centerpiece of the new test facility is a multifunctional rotation test stand. It was built up in a separate enclosure – a twin-wall reinforced concrete structure – and rests on a special soundproof base plate weighing as much as 90 tons.\nSmooth operation of all facilities is ensured by highly advanced and sophisticated systems supplying water, electricity, argon, cooling air and hot air and dissipating the heat generated by the test stands. The equipment of the high-tech test center is rounded off with innovative rigging systems, the finest of computing technology as well as office and meeting rooms on the upper floors. 14 employees will work here in an environment that meets the highest standards in terms of ergonomics and environmental protection. The high-tech building was erected on a surface area of 40 meters by 40 meters and is 20 meters high. A total of 1,000 tons of steel went into the building’s construction.\nFurther investments for the sustained development of the site\nLars Wagner said: “MTU has for years been investing heavily in the expansion of its sites – worldwide and especially here in Munich.” Over the last few years, MTU has invested more than 100 million euros in its Munich plant and built a new blisk production shop, a new logistics center and a final assembly line for geared turbofan engines. The opening of the new test center for engine parts now marks another important milestone for the company’s future growth. And there still is more in the pipeline, according to Wagner: “We have many ideas and plans as to how we can further develop the Munich location, our company headquarters, and also all other sites in the world. By the year 2040, our investments all over the world will have increased to around one billion Euros.”\nAbout MTU Aero Engines\nMTU Aero Engines AG is Germany’s leading engine manufacturer. The company is a technological leader in low-pressure turbines, high-pressure compressors, turbine center frames as well as manufacturing processes and repair techniques. In the commercial OEM business, the company plays a key role in the development, manufacturing and marketing of high-tech components together with international partners. Some 30 percent of today’s active aircraft in service worldwide have MTU components on board. In the commercial maintenance sector the company ranks among the top 5 service providers for commercial aircraft engines and industrial gas turbines. The activities are combined under the roof of MTU Maintenance. In the military arena, MTU Aero Engines is Germany’s industrial lead company for practically all engines operated by the country’s military. MTU operates a network of locations around the globe; Munich is home to its corporate headquarters. In fiscal 2018, the company had a workforce of some 10,000 employees and posted consolidated sales of 4.6 billion euros."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:c9a5c148-f212-4c49-b2fb-2b2047a41e2f>","<urn:uuid:ffdb679e-911b-457b-b97f-704a1f514263>"],"error":null}
{"question":"What economic challenges are affecting both urban development and remote work security in the post-pandemic era?","answer":"In urban development, years of disinvestment have led to real estate values too low for traditional financing in historically Black neighborhoods, while affordable housing projects face delays due to fluctuating tax credit values. The URA is addressing this through specialized lending programs and community-driven development initiatives. Meanwhile, the shift to remote work has created economic pressures in cybersecurity, as companies must allocate precious resources and talent to secure their expanded digital footprint. Organizations need to invest in security training, continuous authentication systems, and protection against ransomware attacks, which have become more prevalent during the pandemic. Both situations require significant financial investment and strategic planning to address effectively.","context":["URA Approves New Support For Lending Program In Pittsburgh's Historically Black Neighborhoods\nOn Thursday, the board of Pittsburgh’s Urban Redevelopment Authority greenlit a lending program for Avenues of Hope, which aims to revitalize business corridors in seven historically Black city neighborhoods.\nThe new program is intended to help businesses buy time and build wealth: Applicants will be able to borrow up to $200,000, with no payments for the first 20 years, to acquire commercial real estate.\nJennifer Wilhelm is the URA’s director of commercial lending. As the agency started exploring loans for Avenues of Hope projects, Wilhelm said it became apparent that years of disinvestment in these communities led to real estate values too low to allow for traditional financing.\n“We believe that as the economic development entity … part of our role is to figure out, how do we make up for those years of disinvestment,” she said. “We want them to start to see the same vitality that other areas of Pittsburgh are seeing.”\nFunding for the program will come from one of three sources: the Pittsburgh Business Fund, the Enterprise Zone Revolving Loan Fund, or the Urban Development Fund.\nURA board member Lindsay Powell said the agency is pushing hard to build out Avenues of Hope.\n“We are trying to target, trying to attract, trying to support [minority- and women-owned] firms, and particularly Black firms, to come back to these spaces,” she said.\nBusinesses may still be eligible for the program if they are near the targeted avenues but not directly on them.\nThe board also announced Thursday that it will soon begin work to create strategic plans for two of the corridors, Chartiers and Perrysville Avenues.\nFor the Centre Avenue corridor in the Hill District, the board approved development plans for six townhomes on Rose Street, as well as a 45,000-square-foot commercial development on Centre called Sankofa Square. Both projects stem from an initiative begun in 2019 to foster community-driven development in the Hill; this was before the city announced the Avenues of Hope initiative in 2020.\nWhile most development projects in the Hill, including the Rose Street townhomes, go through a community review process known as the Development Review Panel. Sankofa Square has not, according to the Hill Community Development Corporation.\nCity councilor and URA board member Daniel Lavelle said that’s due to a legal grey area dating from 2019. At the time, it was unclear whether the Hill CDC would apply as a developer for Centre Avenue parcels. If so, coordinating approval for other Centre Avenue projects would create a conflict of interest, Lavelle said. He added four community meetings had been held about Sankofa Square.\nMeanwhile, officials are trying to move ahead on the construction of 12 affordable homes in Hazelwood — a project that has been delayed by the coronavirus and the fluctuating value of tax credits. Action taken by the board will allow City of Bridges Community Land Trust to break ground on four of the homes next spring.\nThe land trust’s director, Ed Nusser, said affordable housing has never been more important, nor harder to finance. He hopes that will change with federal help.\n“We’re finally beginning to hear this idea of housing as infrastructure, housing as life-sustaining investments, which it is,” he said. He expressed cautious optimism about prospects for a $3.5 trillion spending measure approved by Senate Democrats.\nURA board members said existing federal COVID-19 relief money could be used to grow the land trust’s work in Pittsburgh.\nThe city’s budget for the American Rescue Plan funds set aside roughly $70 million for the URA. Some activists have expressed concern that such plans were devised without adequate public input. But executive director Greg Flisram promised full transparency for how that money will be used, noting that “every dollar budgeted to us must be allocated to a specific purpose,” and will be discussed in public meetings.\nIn other housing matters, emergency housing assistance funded by the city will be administered by Allegheny County’s Department of Human Services starting Sept. 1. The Housing Stabilization Program offers up to three months of housing costs to families at risk of losing their homes. It was created by Pittsburgh’s Housing Opportunity Fund, but officials said moving it to the county will help people get what they need with less bureaucracy. In addition, the county can connect applicants to other services they may need.","Employees who work from their homes may be putting their companies’ systems at risk.\n“Many employees do company work from personally managed and owned systems and these machines are often the ‘Wild, Wild West’ in terms of how they are secured,” said Mike Gentile, the chief executive of San Clemente-based cybersecurity company Cisoshare.\n“The majority of complex attacks, such as ransomware, etc., right now are still often caused by a simple phishing attack or an employee mistake like clicking on a bad link.”\nCisoshare is one of several cybersecurity firms that are emerging in Orange County, which is carving a strong position in internet security due to the proliferation of hackers from Russia, China and North Korea who demand eye-popping sums in ransomware.\nCrowdStrike Holdings Inc. (Nasdaq: CRWD), a Sunnyvale-based firm that now has a $55 billion market cap, started in Orange County where it still has a large local presence. Irvine’s Cylance sold for about $1.4 billion to BlackBerry in 2019 and also counts a base of operations here.\nIn Newport Beach, the ioXt Alliance started by Mobilitie founder Gary Jabara, wants to make sure the interconnections among the various devices used each day—such as cellphones, smart home lighting controls and automotive technology—are also secure.\nUC Irvine’s Cybersecurity Policy & Research Institute studies ways to make the internet and networks safer, including running mock attack drills. Cybercriminals\nIrvine-based Netwrix Corp. is expanding so quickly that it’s made four acquisitions since January.\n“Most organizations did not have time to prepare a transition plan and provide security training to the employees” when they started working from home last year, said Ilia Sotnikov, security strategist and vice president at Netwrix.\n“Hence the increase in reported incidents that included data loss or oversharing.”\nAttackers know that ransomware is arguably the quickest way to get money from a company without breaking into its system, he said.\n“The cybercriminals took advantage of the global pandemic and highly divisive political scene in the U.S. last year,” Sotnikov said. “We’ve seen considerable changes in how the threat landscape evolved over the last couple years with ransomware as a service, more specialized groups.”\nThe Coronavirus Chaos\n“There was so much chaos during the first few months of the lockdown that every CISO will need to go back and review all of the access and changes that happened,” said Bil Harmer, who is the chief information security officer (CISO) and chief evangelist at computer identity security software maker SecureAuth.\n“When there is chaos and change, the threat actors will be there looking for ways in.”\nHe predicted that companies “will begin putting more and more focus on digital identities and a continuous authentication methodology that will allow them to adjust access on the fly as the landscape or the user behavior changes.”\nCisoshare, founded by Gentile, placed No. 21 on this year’s Business Journal list of Best Places to Work in Orange County and No. 2 on last year’s list of fastest-growing companies, both in the small-firm category.\nCompanies who let employees work from their homes face an increasing threat level similar to that of an apartment owner who adds more apartments to a portfolio: the more units there are, the greater the business risks, Gentile said.\n“When employees are working from home, it expands the digital footprint and perimeter of the organization,” Gentile said during a recent interview.\nProviding security also requires using precious resources and talent—both of which are in short supply at plenty of companies, Gentile said.\n“The majority of security risk lives in the cracks when people don’t effectively collaborate and ‘cover all the bases’ when building something,” he said.\nTraining on workstations from which a network is accessed can reduce the risks when employees work from home in a decentralized environment, Gentile said.\nCompanies that opt for a “hybrid” model combining both work-from-home and the office should be wary.\n“Hybrid can be risky due to any time rules change, there is a higher likelihood of mistakes,” Kevin McDonald, the chief operating officer and chief information security officer of Alvaka Networks in Irvine lists 16 points of vulnerability. They include use of bootlegged software, browsing illicit sites, opening infected files that would otherwise be blocked, communicating with unverified individuals and illegal sharing of various contraband such as movies, images, and games.\n“Gambling, pornography, sports, gaming sites, alternative bulletin boards, messengers, even terrorism and extremist sites lead to infections of the host that then connects to the company,” he said.\n“We all suffer from a bit of that-won’t-happen-to-me syndrome. We’re not a target, we don’t have anything they want, we’re not that rich of a company.”\nHe says ransomware attackers are well aware of the potential payoffs: “One hit and you can retire.”\nCompanies are starting to nudge employees into coming to their offices though the daily back-and-forth from the COVID-19 Delta variant makes it difficult to set firm guidelines.\nFor example, data analytics software maker Alteryx Inc. has “voluntarily opened a number of our offices, including our Irvine location for those who are comfortable coming in,” Chief Financial Officer Kevin Rubin said on Aug. 5. “There’s no mandate that they do.”\n“We will more officially begin asking associates to start coming back no sooner than January,” he added.\nSotnikov sees some bright spots.\n“I think many of the WFH (work-from-home) specific dangers were mitigated over the last 12 months, as organizations had a chance to catch their breath, get new budgets in 2021, catch up on trainings for both admins and employees,” he said.\nThe Senate included more than $1.9 billion in cybersecurity funds as part of the roughly $1 trillion bipartisan infrastructure package, The Hill website said on Aug. 10.\nThe funds will go toward securing critical infrastructure against attacks, helping vulnerable organizations defend themselves and providing funding for a key federal cyber office, among other initiatives.\nExperts point to the targeting of Colonial Pipeline and JBS meat packers earlier this year as examples of the dangers of ransomware demands.\nThe picture is acute on the international front, with both Sotnikov and McDonald noting President Joe Biden’s warning last month that a significant cyber-attack on the U.S. could lead to “a real shooting war” with a major power, highlighting the growing threats posed by Russia and China.\n“That is a very aggressive and provocative statement,” McDonald said. He points to China in particular as he surveys global cybersecurity threats to the U.S.\n“I should be worried about China finally deciding it’s time to become the sole world power and using its understanding of our weak infrastructure to show us how much we don’t really have control of the world anymore,” McDonald said.\nAnd the ultimate piece of bad news?\n“Replacements are made in China,” he said.\nDangers, Positive Signs: OC Cybersecurity Experts Look at Internet Risks\nOC Cybersecurity Experts Give the Business Journal These Tips:\nKEVIN MCDONALD, chief operating officer/chief information security officer, Alvaka Networks in Irvine\nSome dangers are “removed or reduced” if the equipment is owned by the employer.\n“Employee-owned computers are far less likely to be patched and kept up-to-date against vulnerability. This includes the operating systems, office applications, third party applications such as Adobe, Internet browsers, etc.\n“Having a system shared with non-employees (of unknown behavior tendency, character, education, intent) means that there is a high potential for risky behaviors that can result in a compromised local computer.\n“Big time execs and powerful people are targets and they’re the most reticent to participate in this whole process.\n“Cryptocurrency is the “primary reason” for the rise in ransomware in which hackers hijack a computer system and demand payment to release it.”\nMIKE GENTILE, founder/chief executive, Cisoshare in San Clemente\nThe biggest risk to work from home or hybrid for security “is that collaboration and effective small team dynamics are hindered when people can’t work together in person.”\n“The good news is that some of the strongest safeguards when a workforce is decentralized is a strong security training and awareness program, as well as a communication system so employees know how to get in touch with the security team and vice versa. Both of these items are highly effective, but also much more inexpensive than almost all technical safeguards.”\nBIL HARMER, chief information security officer/chief evangelist, SecureAuth in Irvine\n“The hybrid model will not go away, there is far too much upside for companies in it. From 48 extra minutes per day per employee in productivity to reduced footprints in the office (desks, power, coffee, etc), this is a model that will continue.\n“Companies will begin moving to Secure Identity as the first line of defense. They will begin putting more and more focus on digital identities and a continuous authentication methodology that will allow them to adjust access on the fly as the landscape or the user behavior changes.\n“This will allow the user to move around the physical world and have their authentication and authorization adjust as they do to keep them within the acceptable risk profile.”"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:8ac26df9-dc46-4807-85c4-00e0f4e7cd18>","<urn:uuid:ad45c4f6-8fbd-4d17-b17d-404d81708d47>"],"error":null}
{"question":"As an electrical engineering student, what are the key differences between DC and AC current measurements using a multimeter, and what are the main sources of measurement error to watch out for?","answer":"DC current measurement requires opening the circuit and inserting the multimeter in series, with proper range selection (like using 100mA or 200mA settings for a 50mA current). For AC current, while some multimeters can measure it similarly to DC, clamp ammeters are typically used. Regarding errors, AC measurements face additional challenges due to temperature changes inside the multimeter from self-heating, which can cause measurement errors. The burden voltage for AC current is also larger due to the multimeter's series inductance and measurement connections. For both types, selecting the appropriate range is crucial - using too high a range reduces accuracy, while too low a range risks damaging the instrument.","context":["A few ceramic resistors (100, 200, or 300 ohms), a rheostat (variable resistor), a dc power source,\n2 multi-meters, a calculator, and a few connecting wires with alligator clips\nOhm’s law simply states that the ratio of voltage across an electric device to the current through that device is a constant called the electric resistance of that device.\nIn SI units, V is in volts, I is in amperes, and R is in ohms.\nOhm’s “law” is not actually a law of physics. It applies to some devices, and does not apply to others. Ohm’s law applies when the ratio V/I is independent of the current I.\nMulti-meters can at least read potential difference (voltage), current, and electric resistance. In addition, multi-meters may be capable of other functions, but for now, we will concentrate on the measurement of these three physical quantities. In this experiment, we will learn how to read a multi-meter when it is on the following settings:\n- Resistance setting\n- dc Voltage setting (Battery)\n- ac Voltage setting (City electric outlet)\n- dc Current setting (Battery)\n- ac Current setting (City electric outlet current type)\nNote that “dc” stands for direct current (a current that does not change direction), and “ac” stands for alternating current (a current whose direction changes).\n(a) Resistance Measurement:\nPlace the meter on its highest Resistance setting. Then connect each of its terminals to one end of a ceramic resistor. For reading a resistance, it does not matter which terminal is connected to which end of the resistor. If no reading is displayed, lower the setting until a reading is obtained. It is possible to read a value on more than one setting in the ohm range. Use the one with the best number of significant figures. Repeat this procedure until all resistances are measured and the values of the resistances are written down. Next, use a Color Codes Chart to determine the resistances of the same resistors. Compare the results for each resistor and calculate a percent difference using the following formula:\n(b) DC Voltage Measurement:\nTo read a fixed voltage such as that across the terminals of a battery, a voltmeter must be set in an appropriate range in its “--V” settings. This is a symbol for dc voltage. Set the multi-meter at the appropriate safe range for measuring the voltage across the dc power source. The appropriate safe range is determined by looking at the maximum voltage a power supply or a battery can offer. For example, a 12 V car battery can supply at most 14 volts and the appropriate range on the meter is the 20 V setting. If we choose the 2 V setting of the meter, the meter can get damaged.\nConnect the terminals of the power source to the appropriate terminals of the multi-meter (Positive to Positive, and Negative to Negative). The Negative on the meter is also labeled as “COM” for common. Increase and decrease the voltage of the source, and observe how the readings on its meter as well as those on the multi-meter change. Try to adjust the voltage, as read from the meter on the power supply, to 2 V, 4 V, and 7 V, as closely as you can. Each time, read the same voltages from the multi-meter. For each, calculate a percent difference by using equation (2).\n(c) AC Voltage Measurement:\nUnder the supervision of your lab instructor, set the multi-meter to its 200 V ac setting. The ac setting on the multi-meter is shown as “~V”. Make sure that one wire is connected to COM and the other to POS on the multi-meter. Next, insert the wires (with needle-like metal endings) into a city electrical outlet. (For ac measurements, it does not matter which wire goes into which terminal.) Write down the ac voltage you read. If you see some fluctuations, it is because of the changes in demand by all users. Users keep turning off and on different electric devices.\n(d) Direct Current Measurement:\nMeasuring current is different from measuring voltage. For voltage, we say “voltage across a power source or a resistor,” but for current, we say “current through a source or a resistor.” Suppose you want to measure the voltage across R1 in the following circuit:\nTo do this, you need to first set the multi-meter to the appropriate dc voltage setting and then connect its terminals to points a and b (across the resistor) as shown in the following figure:\nWe say that the voltmeter is connected across the resistor.\nIn order to measure the current, the circuit must be opened (disconnected) first (Fig. 3), and then the multi-meter must be placed into the circuit as shown in Fig. 4. Note that an appropriate (safe) current setting must be selected because the multi-meter is now being used as an ammeter. First, the circuit is opened.\nNext, the ammeter is placed into the circuit.\nNow that you have paid attention to the way a multi-meter measures current, connect the power source (turned off), a 100 Ω resistor, and a multi-meter (set at an appropriate current setting) in series as shown above (Fig. 4).\nThe appropriate current setting can be determined by estimating the amount of current, in amperes, that goes through R1, by dividing the voltage (5 V) by the resistance (100 Ω). The result is 0.05 A. Multiply by 1000 to convert to milliamperes (mA). We get 50 mA. Any range on the multi-meter that can measure more that 50 mA will be safe. Some multi-meters may have 100 mA or 200 mA settings. Choose the appropriate one. Once you are sure of the correct milliamperes setting, and also sure that the power source gives the desired voltage, turn on the power source and read the current displayed by the ammeter. If the displayed current is close to 50 mA, you have done it right.\nCalculate a percent error between the current you read from the ammeter (Measured value) and the calculated value (Accepted value) of 50 mA. The formula for percent error is\nIt is important to always remind yourself of the way current is to be measured. The circuit or branch through which the current is to be measured must be opened first, and then the ammeter must be inserted into that branch.\n(e) Alternating Current Measurement:\nSome multi-meters are capable of measuring alternating currents and some are not. If they are designed to do so, the method of using them for this purpose is similar to measuring dc. However, “clamp ammeters” are used to measure ac. AC measurements are not included in this experiment.\ni) Ohm’s Law (The main experiment)\nArrange a circuit as shown in Fig. 5. Note that the voltmeter reads the voltage across R, and the ammeter reads the current through R. If you change the rheostat setting, the total resistance will change, and with a relatively fixed voltage (supplied by the battery), the current I will change. The change in the current I through R causes the voltage across R to change. However, you will see that the ratio V/ I remains constant.\nMove the slider on the rheostat to five different positions, and for each position, measure the voltage across and current through R, and write down their values in the following table:\n|Current I (A)||Voltage V (volts)||R = V / I (Ω)|\nPlot the results on a V versus I graph. Draw a straight line that best fits the data. Determine the slope of the line.\nTypical values to be used are:\nVb = 5 V\nR = 100 Ω\nRv = 0 to 90 Ω\nThe measured values for I and V at each rheostat setting should be written down in the table.\nCalculate the values of R (=V/ I) and write them in the table. The experimental (measured) value of R is the slope of the graph. This value must be compared with the accepted value of R measured directly by the multi-meter.\nComparison of the Results:\nCalculate a percent error on R.\nConclusion: To be explained by students\nDiscussion: To be explained by students","There is great risk of damaging the instrument and measuring errors occur because there is no warning indication that the maximum amplitude has been exceeded. Temperature changes inside the multimeter due to self–heating may cause additional error on other AC voltage ranges. This can create a significant difference in potential, but this absolute thermoelectric voltage can hardly be measured in practice. View Full Document Company About Us Scholarships Sitemap Standardized Tests Get Course Hero iOS Android Educators Careers Our Team Jobs Internship Help Contact Us FAQ Feedback Legal Copyright Policy Honor Code\nThe only load was the 1MΩ, 16pF input of the oscilloscope. In general, the accuracy is better on the lower range; for the highest accuracy, select the lowest manual range possible for the measurement. E.g.\nTo provide for some control data and to allow for comparison, a 10 W resistor was used to collect one set of 1V results. The input voltage Vin is computed as follows: [equ.2] Z is the impedance formed by the resistance and capacitance to the ground. A. Oscilloscope Error Analysis Another probable source of error was systematic error in measurement due to the precision of the devices used.\nThe same applies for the two copper/aluminium junctions. Oscilloscope Reading Error Circulating currents in the loop create error voltages across any impedances in series with the DMM's input. For example, applying inputs to the 3A terminals while making measurements on the 10A terminals will typically cause errors. References Bell, D A (1978).\nSign up to view the full content. Sources Of Error In Electrical Resistance In Series And Parallel Experiment Fig. 13: Graphical representation of the attenuation of a 25 MHz bandwidth. Atheists, do you think the conclusion of the 'Schrodinger's Cat' thought experiment violates the law of noncontradiction? 20 answers The Pendulum? 7 answers Why do sound waves travel at a speed Update: what are the suggestions for improvement?\nFig. 5: Twisted leads reduce the disturbing effect of external magnetic fields. Different sets of readings were taken on different days, and the ambient temperature thus probably varied a few degrees between different parts of the experiment. Source Of Error In Ohm Law Experiment The input circuit of a conventional multimeter has a low-pass filter. Sources Of Error In Circuit Experiments However, the burden voltage for AC current is larger due to the multimeter's series inductance and your measurement connections.\nThe dependent variables include the voltage across the capacitor, the temperature of the filament, the resistance of the filament, and the current passing through each part of the circuit. 3. http://alignedstrategy.com/of-error/sources-of-error-in-a-lab.php The value of a capacitor is determined purely by its geometry i.e the area of its plates, the distance between them and so on. The larger the surface area of the loop, the greater the induced voltage. This junction generates a thermal-electric voltage of 1026µV. Sources Of Error In Oscilloscope\nAlongside an image of a measurement on a 10MHz square wave. The metal that is highest on the list of the two metals will become the positive one. Sign up to access the rest of the document. check my blog Figure 7 shows a junction of copper and aluminium at room temperature (293K).\nThe magnitude of the error is dependent upon the source's response to this loading. Series And Parallel Circuits Lab Sources Of Error Some further points of theory are covered in the appendix. Every time you make a measurment, the reading you get has a built in error caused by the variations in the readings.\nPlease try the request again. ISBN: 0879093188 University of Bath (1998). Each of the two junctions constantan/copper has a temperature of 60°C (=333K). Ohm Law Experiment Conclusion Only at absolute zero (0K) is the voltage is 0V.\nInitially we assumed that the separation was 1cm per major grid line, however, later, more accurate measurements indicated that the actual separation was about 0.995mm. The system returned: (22) Invalid argument The remote host or network may be down. Though, there were possible sources of errors which are listed above, the first part of the experiment failed i.e. http://alignedstrategy.com/of-error/sources-of-error.php Up to my Academic Projects Page.\nExpand» Details Details Existing questions More Tell us some more Upload in Progress Upload failed. At high frequencies, the impedance Z is so small that its influence is no longer negligible. For accurate measurements and/or measuring small voltages, it's important that the measuring terminals have a good thermal connection to maintain an equal temperature for every junction pair. This is called the tribo-electric effect and is most noticeable on coaxial cables.\nEach junction will therefore generate a voltage of 13820µV. Higher harmonics of non-sinusoidal signals are already weakened long before the fundamental frequency has reached the maximum specified frequency. Fig. 11: 10 MHz square wave measured with a 200 MHz bandwidth limitation. You can only upload files of type PNG, JPG, or JPEG.\nThe peak voltage is much higher than the average or RMS voltage. Yes No Sorry, something has gone wrong. This situation above is relevant for an open circuit consisting of two wires joined by a single weld. The bandwidth of the oscilloscope is 200MHz.\nFor safety reasons never disconnect the earth terminal of an oscilloscope. Correlated noise, while rare, is especially detrimental because it always adds directly to the input signal. Ground Loops Fig. 1: A measurement set-up where a closed ground loop is made. This error is likely to be extremely minor, however, in comparison to some of the more important errors mentioned above. 4."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:577b0b6c-b4b7-4f8a-b565-d0be9169b7e6>","<urn:uuid:a5126df1-b5bb-43dc-b682-dc3d2403cc00>"],"error":null}
{"question":"Between Apache Ignite's partitioned caching and Kudu's write operations, which one provides stronger atomicity guarantees in multi-row operations?","answer":"Apache Ignite's partitioned caching provides stronger atomicity guarantees than Kudu's write operations. In Kudu, multi-row write operations are not fully atomic - the failure of a single write in a batch operation will not roll back the entire operation but produce per-row errors. In contrast, Apache Ignite supports full ACID transactions, including atomicity, which ensures all operations in a transaction either complete successfully or are rolled back entirely.","context":["Getting Started With Apache Ignite (Part 2)\nIn Apache Ignite, a data grid can be thought of as a distributed Key-Value (K-V) store or a distributed HashMap. Learn more about it in this article.\nJoin the DZone community and get the full member experience.Join For Free\nIn the previous article, I discussed my motivation for writing this blog series. Also presented was the high-level component view of Apache® Ignite™, shown in Figure 1.\nFigure 1: Main components of Apache Ignite.\nThe previous article also briefly introduced clustering and deployment. This article will focus on the data grid.\nIn Apache Ignite, a data grid can be thought of as a distributed Key-Value (K-V) store or a distributed HashMap.\nIn Figure 2, we can see an example Apache Ignite cluster, where the entire data set is held in the Ignite Distributed In-Memory Cache.\nFigure 2: Apache Ignite Cluster.\nThe cluster in Figure 2 consists of three servers and the data are distributed evenly across all three servers. Also shown in Figure 2 is that the data can be stored either on-heap or off-heap. On-heap is within the Java heap and off-heap is outside the Java Heap. In on-heap, Java garbage collection passes may cause the cluster to freeze so to avoid this problem, off-heap can be used. Apache Ignite provides its own memory management for off-heap. We can also see in Figure 2 that off-heap memory is larger than on-heap memory, which allows for unlimited scalability.\nApache Ignite can be used to cache data from an underlying data source, such as a relational database system, a NoSQL database system or Hadoop/HDFS. When the data in the cache are updated, these updates can be propagated to the underlying data source. Similarly for read operations, if the cache does not have the data, it will read the data from the underlying data source.\nAnother very important feature is redundancy, where data can be backed-up with one or more in-memory copies. The number of backup copies can be configured. Apache Ignite also supports replicas, so that backup copies are available on other cluster nodes. This is very useful in the case where a node becomes unavailable for some reason, and another node in the grid that contains a backup copy of the data from the unavailable node can be promoted to become the primary source of the data. This failover is automatic and transparent to any applications.\nLet's see some examples of caching strategies. First, we'll start with partitioned caching.\nFigure 3: Partitioned cache.\nIn Figure 3, we have four keys: A, B, C, and D. Apache Ignite automatically distributes these keys across four servers: JVM1, JVM2, JVM3, and JVM4. We can also see that there is a backup of each key and the four backups keys are also distributed across the four servers. So, in this scenario, each server has a small part of the whole data set. The advantage of this approach is that only the primary and backup servers need to be updated if there are key updates.\nThe arrows show possible access patterns for a client JVM. The near cache shown on the client JVM is optional. Suppose the client application wants to access key A and finds that it is not available in the near cache. It then checks JVM1, which holds the primary copy of key A. The key is then fetched to the near cache and then available for use by the client application. Next, the client wants to access key B and finds that it is in the near cache already, so no further work is required in this case. To find the node where a particular key resides, the client uses an affinity function; something we'll discuss in more detail in a future article.\nLet's now look at how replicated caching works.\nFigure 4: Replicated cache,\nIn Figure 4, we can see that every server has the whole data set. So, each server acts as a primary for each of the four keys A, B, C, and D, and also as a backup for all the other keys. In this approach, each server needs to have enough memory to hold the whole data set and any updates need to be propagated to all servers. However, this scenario could be useful for small data sets and where data do not change frequently.\nApache Ignite also supports transactions. These follow the well-known Atomicity, Consistency, Isolation, and Durability (ACID) requirements typically found in database systems. We’ll cover transactions in more detail in a future article.\nIn this article, we have briefly looked at the Apache Ignite Data Grid component. In particular, we have focussed on two caching strategies: partitioned caching and replicated caching.\nNext time, we'll look more closely at the SQL grid and how it can work with the data grid.\nPublished at DZone with permission of Akmal Chaudhri. See the original article here.\nOpinions expressed by DZone contributors are their own.","Apache Kudu Transaction Semantics\nThis is a brief introduction to Kudu’s transaction and consistency semantics. Kudu's core philosophy is to provide transactions with simple, strong semantics, without sacrificing performance or the ability to tune to different requirements. Kudu’s transactional semantics and architecture are inspired by state-of-the-art systems such as Spanner and Calvin. For an in-depth technical exposition of what is mentioned here, see the technical report.\nKudu currently allows the following operations:\nScans are read operations that can traverse multiple tablets and read information with some consistency or correctness guarantees. Scans can also perform time-travel reads. That is, you can set a scan timestamp from the past and get back results that reflect the state of the storage engine at that point in time.\nWrite operations are sets of rows to be inserted, updated, or deleted in the storage engine, in a single tablet with multiple replicas. Write operations do not have separate \"read sets\", that is, they do not scan existing data before performing the write. Each write is only concerned with the previous state of the rows that are about to change. Writes are not \"committed\" explicitly by the user. Instead, they are committed automatically by the system, after completion.\nWhile Kudu is designed to eventually be fully ACID (Atomic, Consistent, Isolated, Durable), multi-tablet transactions have not yet been implemented. As such, the following discussion focuses on single-tablet write operations, and only briefly touches multi-tablet reads.\nSingle Tablet Write Operations\nKudu employs Multiversion Concurrency Control (MVCC) and the Raft consensus algorithm. Each write operation in Kudu must go through the following order of operations:\n- The tablet's leader acquires all locks for the rows that it will change.\n- The leader assigns the write a timestamp before the write is submitted for replication. This timestamp will be the write’s tag in MVCC.\n- After a majority of replicas have acknowledged the write, the rows are changed.\n- After the changes are complete, they are made visible to concurrent writes and reads, atomically.\nAll replicas of a tablet observe the same process. Therefore, if a write operation is assigned timestamp n, and changes row x, a second write operation at timestamp m > n is guaranteed to see the new value of x.\nThis strict ordering of lock acquisition and timestamp assignment is enforced to be consistent across all replicas of a tablet through consensus. Therefore, write operations are ordered with regard to clock-assigned timestamps, relative to other writes in the same tablet. In other words, writes have strict-serializable semantics.\nIn case of multi-row write operations, while they are Isolated and Durable in an ACID sense, they are not yet fully Atomic. The failure of a single write in a batch operation will not roll back the entire operation, but produce per-row errors.\nWriting to Multiple Tablets\nKudu does not support transactions that span multiple tablets. However, consistent snapshot reads are possible (with caveats, as explained below). Writes from a Kudu client are optionally buffered in memory until they are flushed and sent to the tablet server. When a client’s session is flushed, the rows for each tablet are batched together, and sent to the tablet server which hosts the leader replica of the tablet. Since there are no inter-tablet transactions, each of these batches represents a single, independent write operation with its own timestamp. However, the client API provides the option to impose some constraints on the assigned timestamps and on how writes to different tablets are observed by clients.\nKudu was designed to be externally consistent, that is, preserving consistency when operations span multiple tablets and even multiple data centers. In practice this means that if a write operation changes item x at tablet A, and a following write operation changes item y at tablet B, you might want to enforce that if the change to y is observed, the change to x must also be observed. There are many examples where this can be important. For example, if Kudu is storing clickstreams for further analysis, and two clicks follow each other but are stored in different tablets, subsequent clicks should be assigned subsequent timestamps so that the causal relationship between them is captured.\nKudu’s default external consistency mode is called CLIENT_PROPAGATED. This mode causes writes from a single client to be automatically externally consistent. In the clickstream scenario above, if the two clicks are submitted by different client instances, the application must manually propagate timestamps from one client to the other for the causal relationship to be captured. Timestamps between clients a and b can be propagated as follows:\n- Java Client\nCall AsyncKuduClient#getLastPropagatedTimestamp() on client a, propagate the timestamp to client b, and call AsyncKuduClient#setLastPropagatedTimestamp() on client b.\n- C++ Client\nCall KuduClient::GetLatestObservedTimestamp() on client a, propagate the timestamp to client b, and call KuduClient::SetLatestObservedTimestamp() on client b.\nKudu also has an experimental implementation of an external consistency model (used in Google’s Spanner), called COMMIT_WAIT. COMMIT_WAIT works by tightly synchronizing the clocks on all machines in the cluster. Then, when a write occurs, timestamps are assigned and the results of the write are not made visible until enough time has passed so that no other machine in the cluster could possibly assign a lower timestamp to a following write.\nWhen using this mode, the latency of writes is tightly tied to the accuracy of clocks on all the cluster hosts, and using this mode with loose clock synchronization causes writes to either take a long time to complete, or even time out.\nThe COMMIT_WAIT consistency mode may be selected as follows:\n- Java Client\n- C++ Client\nRead Operations (Scans)\nScans are read operations performed by clients that may span one or more rows across one or more tablets. When a server receives a scan request, it takes a snapshot of the MVCC state and then proceeds in one of two ways depending on the read mode selected by the user. The mode may be selected as follows:\n- Java Client\n- C++ Client\nThe following modes are available in both clients:\nThis is the default read mode. The server takes a snapshot of the MVCC state and proceeds with the read immediately. Reads in this mode only yield 'Read Committed' isolation.\nIn this read mode, scans are consistent and repeatable. A timestamp for the snapshot is selected either by the server, or set explicitly by the user through KuduScanner::SetSnapshotMicros(). Explicitly setting the timestamp is recommended.\nThe server waits until this timestamp is 'safe'; that is, until all write operations that have a lower timestamp have completed and are visible). This delay, coupled with an external consistency method, will eventually allow Kudu to have full strict-serializable semantics for reads and writes. However, this is still a work in progress and some anomalies are still possible. Only scans in this mode can be fault-tolerant.\nSelecting between read modes requires balancing the trade-offs and making a choice that fits your workload. For instance, a reporting application that needs to scan the entire database might need to perform careful accounting operations, so that scan may need to be fault-tolerant, but probably doesn’t require a to-the-microsecond up-to-date view of the database. In that case, you might choose READ_AT_SNAPSHOT and select a timestamp that is a few seconds in the past when the scan starts. On the other hand, a machine learning workload that is not ingesting the whole data set and is already statistical in nature might not require the scan to be repeatable, so you might choose READ_LATEST instead for better scan performance.\nKnown Issues and Limitations\nThere are several gaps and corner cases that currently prevent Kudu from being strictly-serializable in certain situations.\nSupport for COMMIT_WAIT is experimental and requires careful tuning of the time-synchronization protocol, such as NTP (Network Time Protocol). Its use in production environments is discouraged.\n- If external consistency is a requirement and you decide to use COMMIT_WAIT, the time-synchronization protocol needs to be tuned carefully. Each\ntransaction will wait 2x the maximum clock error at the time of execution, which is usually in the 100 msec. to 1 sec. range with the default settings, maybe more. Thus, transactions would take at\nleast 200 msec. to 2 sec. to complete when using the default settings and may even time out.\nA local server should be used as a time server. We’ve performed experiments using the default NTP time source available in a Google Compute Engine data center and were able to obtain a reasonable tight max error bound, usually varying between 12-17 milliseconds.\nThe following parameters should be adjusted in /etc/ntp.conf to tighten the maximum error:\nserver my_server.org iburst minpoll 1 maxpoll 8\ntinker dispersion 500\ntinker allan 0\nOn a leader change, READ_AT_SNAPSHOT scans at a snapshot whose timestamp is beyond the last write, may yield non-repeatable reads (see KUDU-1188).\n- If repeatable snapshot reads are a requirement, use READ_AT_SNAPSHOT with a timestamp that is slightly in the past (between 2-5 seconds, ideally). This will circumvent the anomaly described above. Even when the anomaly has been addressed, back-dating the timestamp will always make scans faster, since they are unlikely to block.\nImpala scans are currently performed as READ_LATEST and have no consistency guarantees.\nIn AUTO_BACKGROUND_FLUSH mode, or when using \"async\" flushing mechanisms, writes applied to a single client session may get reordered due to the concurrency of flushing the data to the server. This is particularly noticeable if a single row is quickly updated with different values in succession. This phenomenon affects all client API implementations. Workarounds are described in the respective API documentation for FlushMode or AsyncKuduSession. See KUDU-1767."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:3dc33d2d-7e03-4caf-81f4-670a3429547e>","<urn:uuid:57063ce4-4e18-4c41-a70c-78b7d9f59d67>"],"error":null}
{"question":"How do divine wisdom and King Lemuel's mother's instructions compare in their approach to transforming human behavior?","answer":"Divine wisdom and King Lemuel's mother's instructions both aim to transform behavior, but in different ways. Divine wisdom, according to Lactantius, has immediate and comprehensive effects - it can instantly transform a passionate person into someone gentle, make a covetous person liberal, and change a cruel person into a clement one through a simple divine laver. King Lemuel's mother's approach, on the other hand, focuses on specific behavioral guidelines - warning against immorality, drunkenness, and encouraging aid to the suffering and oppressed. While both approaches seek moral improvement, divine wisdom is described as working instantly and comprehensively, while the mother's instructions provide specific practical guidance for ethical behavior.","context":["Ante-Nicene Fathers, Vol VII:Early Church Fathers Index Previous Next\nLactantius: Chap. XXVI.—It is divine instruction only which bestows wisdom; and of what efficacy the law of God is\nChap. XXVI.—It is Divine Instruction Only Which Bestows Wisdom; And of What Efficacy the Law of God is.\nThat, therefore, which they perceived to be justly required by the demands of nature, but which they were themselves unable to perform, and saw that the philosophers could not effect, is accomplished only by divine instruction; for that only is wisdom. Doubtless they were able to persuade any one who do not even persuade themselves of anything; or they will crush the desires, moderate the anger, and restrain the lusts of any one, when they themselves both yield to vices, and acknowledge that they are overpowered by nature. But what influence is exerted on the souls of men by the precepts of God, because of their simplicity and truth, is shown by daily proofs. Give me a man who is passionate, scurrilous, and unrestrained; with a very few words of God,“I will render him as gentle as a sheep.” 476\nGive me one who is grasping, covetous, and tenacious; I will presently restore him to you liberal, and freely bestowing his money with full hands. Give me a man who is afraid of pain and death; he shall presently despise crosses, and fires, and the bull of Phalaris. 477 Give me one who is lustful, an adulterer, a glutton; you shall presently see him sober, chaste, and temperate. Give me one who is cruel and bloodthirsty: that fury shall presently be changed into true clemency. Give me a man who is unjust, foolish, an evil-doer; forthwith he shall be just, and wise, and innocent: for by one laver 478 all his wickedness shall be taken away. So great is the power of divine wisdom, that, when infused into the breast of man, by one impulse it once for all expels folly, which is the mother of faults, for the effecting of which there is no need of payment, or books, or nightly studies. These results are accomplished gratuitously, easily, and quickly, if only the ears are open and the breast thirsts for wisdom. Let no one fear: we do not sell water, nor offer the sun for a reward. The fountain of God, most abundant and most full, is open to all; and this heavenly light rises for all, 479 as many as have eyes. Did any of the philosophers effect these things, or is he able to effect them if he wishes? For though they spend their lives in the study of philosophy, they are neither able to improve any other person nor themselves (if nature has presented any obstacle). Therefore their wisdom, doing its utmost, does not eradicate, but hide vices. But a few precepts of God so entirely change the whole man, and having put off the old man, render him new, that you would not recognise him as the same.\nTerence, Adelphi, iv. 1.96:477\nPerillus invented the brazen bull, which the tyrant Phalaris used as an instrument of torture. It was so constructed that the groans of the victims appeared to resemble the bellowing of the bull.96:478\nThe baptismal font. [i.e., as signifying Zech. xiii. 1.]96:479\nSee John i. 9.\nNext: Chap. XXVII.—How little the precepts of philosophers contribute to true wisdom, which you will find in religion only\nLike & share St-Takla.org\n© Saint Takla Haymanout Website: Coptic Orthodox Church - Alexandria, Egypt / URL: http://St-Takla.org / Contact us at","June 14, 2020\nThe book of Proverbs is a collection of short sayings in the Old Testament meant to instill wisdom in God’s people. As we read, it is important to remember that a proverb is a statement which is generally true in principle, not a universally true promise. Let’s dig into the Word together and allow the Lord to shape our hearts, our minds, and our lives in his wisdom over the next month!\nThe author of Proverbs 31 is identified as King Lemuel. We do not know who this king was, but his words reveal a great respect and appreciation for his mother and his wife. While he receives the wisdom his mother taught him, and admires the character of his wife, the qualities cited can be characteristics seen in anyperson seeking the heart of God. This means that the example of the “Proverbs 31 woman” is one that you should seek to put into practice too men!\nThe king’s mother gave him three things to practice. First, she warned him against using his authority and power to engage in immorality or to seek the demise of other kings. Secondly, she warned him of the dangers of drunkenness and the inherent risks of trying to rule under the influence of strong drink and the harm and suffering he could cause. Thirdly, she urged him to always come to the aid of those who are suffering or oppressed.\nThe king praises his wife and her noble character. He considers her to be a virtuous woman of excellence who has his heart and deepest trust. She is wise, discreet, industrious, supportive of her husband and cares deeply about his good reputation. She not only rises early to serve her husband and family, but also those who attend to her needs. She has a healthy self-respect and is admired by those who know her. Every day she models a life worthy of imitation!\nThe Words of King Lemuel\n31 The words of King Lemuel. An oracle that his mother taught him:\n2 What are you doing, my son? What are you doing, son of my womb?\nWhat are you doing, son of my vows?\n3 Do not give your strength to women,\nyour ways to those who destroy kings.\n4 It is not for kings, O Lemuel,\nit is not for kings to drink wine,\nor for rulers to take strong drink,\n5 lest they drink and forget what has been decreed\nand pervert the rights of all the afflicted.\n6 Give strong drink to the one who is perishing,\nand wine to those in bitter distress;\n7 let them drink and forget their poverty\nand remember their misery no more.\n8 Open your mouth for the mute,\nfor the rights of all who are destitute.\n9 Open your mouth, judge righteously,\ndefend the rights of the poor and needy.\nThe Woman Who Fears the Lord\n10 An excellent wife who can find?\nShe is far more precious than jewels.\n11 The heart of her husband trusts in her,\nand he will have no lack of gain.\n12 She does him good, and not harm,\nall the days of her life.\n13 She seeks wool and flax,\nand works with willing hands.\n14 She is like the ships of the merchant;\nshe brings her food from afar.\n15 She rises while it is yet night\nand provides food for her household\nand portions for her maidens.\n16 She considers a field and buys it;\nwith the fruit of her hands she plants a vineyard.\n17 She dresses herself with strength\nand makes her arms strong.\n18 She perceives that her merchandise is profitable.\nHer lamp does not go out at night.\n19 She puts her hands to the distaff,\nand her hands hold the spindle.\n20 She opens her hand to the poor\nand reaches out her hands to the needy.\n21 She is not afraid of snow for her household,\nfor all her household are clothed in scarlet.\n22 She makes bed coverings for herself;\nher clothing is fine linen and purple.\n23 Her husband is known in the gates\nwhen he sits among the elders of the land.\n24 She makes linen garments and sells them;\nshe delivers sashes to the merchant.\n25 Strength and dignity are her clothing,\nand she laughs at the time to come.\n26 She opens her mouth with wisdom,\nand the teaching of kindness is on her tongue.\n27 She looks well to the ways of her household\nand does not eat the bread of idleness.\n28 Her children rise up and call her blessed;\nher husband also, and he praises her:\n29 “Many women have done excellently,\nbut you surpass them all.”\n30 Charm is deceitful, and beauty is vain,\nbut a woman who fears the Lord is to be praised.\n31 Give her of the fruit of her hands,\nand let her works praise her in the gates.\nThe Holy Bible, English Standard Version® (ESV®), copyright © 2001 by Crossway, a publishing ministry of Good News Publishers.\nFamily Discussion Question:\n- Do you find the king’s mother’s instructions apply to your life in any way? Do you see any of the character qualities of the king’s wife in your life? What areas of your life do you still need to submit to God?"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:2c803e27-545f-4890-b4cf-4ea72e2259f3>","<urn:uuid:875441ef-9f76-4a72-97dc-cbfaa9ed0463>"],"error":null}
{"question":"As an agricultural researcher, I'm curious about the relationship between global hunger and climate change's impact on farming. What are the key challenges in addressing world hunger, and how is climate change affecting agricultural production?","answer":"The key challenges in addressing world hunger include market priorities favoring profit over food security, lack of solidarity in food distribution, and the 'paradox of plenty' where food exists but not everyone can access it. Meanwhile, climate change is severely impacting agriculture through unpredictable and extreme weather conditions like floods and drought, affecting crop production. Farmers, especially smallholders, face challenges from these weather changes that can devastate entire harvests. They need access to new tools and resources to manage these impacts, such as hybrid seeds that can survive flooding and precision agriculture technologies that help monitor and adapt to changing conditions.","context":["20-11-2014 - Year XXII - Num. 205\n|The Pope at the Conference on Nutrition at the FAO: “the hungry ask for dignity, not charity”|\nVatican City, 20 November 2014 (VIS) – This morning Pope Francis visited the headquarters of the United Nations Food and Agriculture Organisation, on the occasion of the second International Conference on Nutrition, taking place in Rome from 19 to 21 November.\nUpon arrival the Holy Father was received by the director general of the FAO, Jose Graziano da Silva, the adjunct director, Oleg Chestnov and Archbishop Luigi Travaglino, Holy See Permanent Observer at the FAO.\nThe full text of the Pontiff's address, delivered in the Plenary Hall, is published below:\n“I am pleased and honoured to speak here today, at this Second International Conference on Nutrition. I wish to thank you, Mr. President, for your warm greeting and the words of welcome addressed to me. I cordially greet the Director General of the World Health Organisation (WHO), Dr. Margaret Chan, and the Director General of the FAO, Professor José Graziano da Silva, and I rejoice in their decision to convene this conference of representatives of States, international institutions, and organisations of civil society, the world of agriculture and the private sector, with the aim of studying together the forms of intervention necessary in the fight against hunger and malnutrition, as well as the changes that must be made to existing strategies. The overall unity of purpose and of action, and above all the spirit of brotherhood, can be decisive in finding appropriate solutions. The Church, as you know, seeks always to be attentive and watchful regarding the spiritual and material welfare of the people, especially those who are marginalised or excluded, to ensure their safety and dignity.\n“The fates of nations are intertwined, more than ever before; they are like the members of one family who depend upon each other. However, we live in a time in which the relations between nations are too often damaged by mutual suspicion, that at times turns into forms of military and economic aggression, undermining friendship between brothers and rejecting or discarding what is already excluded. He who lacks his daily bread or a decent job is well aware of this. This is a picture of today’s world, in which it is necessary to recognise the limits of approaches based on the sovereignty of each State, intended as absolute, and national interest, frequently conditioned by small power groups. Your working agenda for developing new standards and greater commitments to feed the world shows this well. From this perspective, I hope that, in the formulation of these commitments, the States are inspired by the conviction that the right to food can only be ensured if we care about the actual subject, that is, the person who suffers the effects of hunger and malnutrition.\n“Nowadays there is much talk of rights, frequently neglecting duties; perhaps we have paid too little heed to those who are hungry. It is also painful to see that the struggle against hunger and malnutrition is hindered by “market priorities”, the “primacy of profit”, which have reduced foodstuffs to a commodity like any other, subject to speculation, also of a financial nature. And while we speak of new rights, the hungry remain, at the street corner, and ask to be recognised as citizens, to receive a healthy diet. We ask for dignity, not for charity.\n“These criteria cannot remain in the limbo of theory. Persons and peoples ask for justice to be put into practice: not only in a legal sense, but also in terms of contribution and distribution. Therefore, development plans and the work of international organisations must take into consideration the wish, so frequent among ordinary people, for respect for fundamental human rights and, in this case, the rights of the hungry. When this is achieved, then humanitarian intervention, emergency relief and development operations – in their truest, fullest sense – will attain greater momentum and bring the desired results.\n“Interest in the production, availability and accessibility of foodstuffs, climate change and agricultural trade should certainly inspire rules and technical measures, but the first concern must be the individual as a whole, who lacks daily nourishment and has given up thinking about life, family and social relationships, instead fighting for survival. St. John Paul II, in the inauguration in this hall of the First Conference on Nutrition in 1992, warned the international community against the risk of the “paradox of plenty”, in which there is food for everyone, but not everyone can eat, while waste, excessive consumption and the use of food for other purposes is visible before our very eyes. Unfortunately, this “paradox” remains relevant. There are few subjects about which we find as many fallacies as those related to hunger; few topics as likely to be manipulated by data, statistics, the demands of national security, corruption, or futile lamentation about the economic crisis. This is the first challenge to be overcome.\n“The second challenge to be faced is the lack of solidarity; we suspect that subconsciously we would like to remove this word from the dictionary. Our societies are characterised by growing individualism and division: this ends up depriving the weakest of a decent life, and provokes revolts against institutions. When there is a lack of solidarity in a country, the effects are felt throughout the world. Indeed, solidarity is the attitude that makes people capable of reaching our to others and basing their mutual relations on this sense of brotherhood that overcomes differences and limits, and inspires us to seek the common good together.\n“Human beings, as they become aware of being partly responsible for the plan of creation, become capable of mutual respect, instead of fighting between themselves, damaging and impoverishing the planet. States, too, understood as a community of persons and peoples, are required to act concertedly, to be willing to help each other through the principles and norms offered by international law. A source of inspiration is natural law, inscribed in the human heart, that speaks a language that everyone can understand: love, justice, peace, elements that are inseparable from each other. Like people, States and international institutions are called to welcome and nurture these values – love, justice, peace – and this must be done with a spirit of dialogue and mutual listening. In this way, the aim of feeding the human family becomes feasible.\n“Every woman, man, child and elderly person everywhere should be able to count on these guarantees. It is the duty of every State that cares for the wellbeing of its citizens to subscribe to them unreservedly, and to take the necessary steps to ensure their implementation. This requires perseverance and support. The Catholic Church also offers her contribution in this field through constant attention to the life of the poor in all parts of the world; along the same lines, the Holy See is actively involved in international organisations and through numerous documents and statements. In this way, it contributes to identifying and assuming the criteria to be met in order to develop an equitable international system. These are criteria that, on the ethical plane, are based on the pillars of truth, freedom, justice and solidarity; at the same time, in the legal field, these same criteria include the relationship between rights and food, and the right to life and a dignified existence, the right to be protected by law, not always close to the reality of those who suffer from hunger, and the moral obligation to share the economic wealth of the world.\n“If we believe in the principle of the unity of the human family, based on the common paternity of God the Creator, and in the fraternity of human beings, no form of political or economic pressure that exploits the availability of foodstuffs can be considered acceptable. Political and economic pressure: here I think of our sister and mother, Earth, our planet, and of whether we are free of political and economic pressure and able to care for her, to avoid her destruction. We have two conferences ahead of us, in Perù and France, which pose the challenge to us of caring for our planet. I remember a phrase that I heard from an elderly man many years ago: God always forgives … our misdemeanours, our abuse, God always forgives; men forgive at times; but the Earth never forgives. We must care for our sister the Earth, our Mother Earth, so that she does not respond with destruction. But, above all, no system of discrimination, de facto or de jure, linked to the capacity of access to the market of foodstuffs, must be taken as a model for international efforts that aim to eliminate hunger.\n“By sharing these reflections with you, I ask that the Almighty, God rich in mercy, bless all those who, with different responsibilities, place themselves at the service of those who experience hunger and who assist them with concrete gestures of closeness. I also pray that the international community might hear the call of this Conference and consider it an expression of the common conscience of humanity: feed the hungry, save life on the planet. Thank you”.\n|Intense work by the Ordinary Council of the Synod of Bishops|\nVatican City, 20 November 2014 (VIS) – The Ordinary Council of the Synod of Bishops will meet on 18 and 19 November to reflect on the results of the Third Extraordinary General Assembly of the Synod of Bishops, held during October, and to prepare for the 14 th General Ordinary Assembly on the theme “The vocation and the mission of the family in the Church and in the contemporary world”, to be held from .\nThe Holy Father will chair the Council 18 and his presence will underline the importance he accords to the Synod as an expression of episcopal collegiality and to the family, the theme of the two Assemblies: the extraordinary Assembly held this year and the Ordinary one, in the preparatory stages.\nAlongside the secretary general, Cardinal Lorenzo Baldisseri, and the under-secretary, Archbishop Fabio Fabene, the meeting was attended by Cardinals Christoph Schonborn, Wilfried F. Napier, Peter K.A. Turkson, George Pell, Donald W. Wuerl, and Luis A. Tagle, and by Archbishops Bruno Forte and Salvatore Fisichella. Bishop Vincenzo Paglia, president of the Pontifical Council for the Family, also participated by invitation.\nIn his introduction to the work of the Synod, the secretary general emphasised the climate of freedom and sincerity and the spirit of fraternal communion that characterised the Assembly, in which everyone was encouraged to contribute. Also, the final document, the Relatio Synodi, faithfully reflects the multi-faceted results of the Synod and offers a good summary of the process that took place during the Assembly.\nIn the meeting, it was agreed that the current period between the two Assemblies, which is unprecedented in the history of the Synod as an institution, is of great importance. It is necessary to take the path followed so far as a starting point and to make the most of this special opportunity to deepen knowledge of the themes and to promote discussion at the level of the episcopal conferences, finding the means and the tools necessary to further involve various ecclesial bodies in the synodal reflection on the family. Various ideas on communication were also considered, which may be useful in view of the preparation for the upcoming Ordinary Assembly.\nThe majority of the work was devoted to the preparation of the Lineamenta for the next Ordinary Assembly. The guidelines will be made up, as previously indicated, of the Relatio Synodi, accompanied by a series of points to help in its reception and elaboration.\nThe Lineamenta are expected to be sent to the Episcopal Conferences at the beginning of December, so that the answers can be received in good time to allow them to be developed in the Instrumentum Laboris before the summer of 2015.\n|The joy of the Gospel is a missionary joy|\nVatican City, 20 November 2014 (VIS) – The Third World Congress of Ecclesial Movements and New Communities began in Rome today. Organised by the Pontifical Council for the Laity, the meeting is a response to the appeal for missionary conversion launched by Pope Francis to all Christians in his apostolic exhortation, Evangelii Gaudium.\nThe congress – the third of this type following those held during the pontificates of St. John Paul II in 1998 and Benedict XVI in 2006 – will be attended by more than 300 members of lay associations from 40 countries, gathered to explore the theme “The joy of the Gospel: a missionary joy”.\nThe congress was inaugurated by Cardinal Stanislaw Rylko, president of the Pontifical Council for the Laity, who recalled the rich teaching of the last three pontiffs on what St. John Paul II defined as “the new season of associations of the faithful”. The cardinal emphasised that St. John Paul II closely followed and guided the rapid development of ecclesial movements and new communities, accompanying them with his clear and enlightening words … and indicated a new phase in the life of new charisms, which would necessarily have to follow their initial flourish – the phase of ecclesial maturity”.\nFor Pope Benedict XVI, he continued, “the multiple forms and the unity of charisms and ministries are inseparable in the life of the Church. The Holy Spirit desires the multiplicity of movements in the service of the single Body that is the Church”.\nPope Francis well knows the reality of ecclesial movements, insists that the new charisms “are not a closed patrimony, consigned to a specific group to guard it; they are rather gifts from the Spirit integrated into the ecclesial body, attracted towards the centre that is Christ, from where they are channeled into an evangelical impulse”.\n|Other Pontifical Acts|\nVatican City, 20 November 2014 (VIS) – The Holy Father has appointed Bishop Peter Andrew Comensoli as bishop of Broken Bay (area 2,763, population 930,000, Catholics 395,000, priests 109, permanent deacons 6, religious 155), Australia. Bishop Comensoli is currently auxiliary of the archdiocese of Sydney, Australia.","Agriculture is one of the industries that has felt the impact of climate change in profound ways. Farmers In different parts of the world have been affected by unpredictable and extreme weather conditions such as floods, drought, global warming, and shifting climatic trends. Unexpected weather changes pose challenges to farmers as they grow crops to sustain the growing population. These days, farmers are using cutting-edge tools and sustainable farming practices to reduce the amount of greenhouse gases emitted to the atmosphere from their farms. Climate-smart solutions such as improved plant breeding technologies and digital tools are being used to mitigate the effects of climate change and to help create a carbon-zero future.\nAgriculture’s role in minimizing climate change\nAgriculture is addressing a changing climate in various ways such as:\nPrecision agriculture practices and digital tools enables farmers to monitor and familiarize on what is happening in their farms. For instance, sensors equipped with high-resolution cameras can help farmers monitor pesticide application and help them ensure that they are applied more efficiently. This will help reduce pesticide runoff into the soil and greenhouse emissions. Precipitation alerts notify farmers on when to expect rainfall, strong winds or high humidity. This can help the devise an effective irrigation and pest-control program and minimize unnecessary fossil fuel use at this time. When farmers have more control over their crops, they can grow more food on a less piece of land which can translate into more profits.\nWith numerous and better weed-control solutions, farmers can minimize tillage in their gardens. Use Less soil disruption minimizes fossil fuel use and greenhouse gas emissions. The soil is also able to store carbon, nutrients, and water when there is less tillage.\nMinimizing chemical fertilizer is a powerful step towards creating a carbon-zero future. Using microbes and regular manuring can help in reduce fertilizer use in the farm. Microbes absorb nitrogen from the air which is then use by the plants.\nDraining of wetlands and massive deforestation is the largest contributor of climate change. As people clear forests to create land for farming, the ability of the natural ecosystem to absorb and store carbon reduces. Planting profitable fruit trees can be lucrative venture that promotes biodiversity and mitigates the impact of climate change.\nManaging weather changes\nSmallholder farmers are the most affected by unexpected weather changes. Extreme weather conditions such as drought and floods can have devastating effects to the crops and can ruin the entire harvest. To manage their crops even when the unexpected occurs, farmers need access to insights, tools, and resources that can help them mitigate the impact of climate change.\nSmallholder farmers are particularly dependent on climatic conditions to grow their crops. With an increasingly unpredictable climate, extreme weather conditions could threaten their entire harvest.\nCrops need water to flourish. However, too much water can damage the crops. Flooding is a challenge to most farmers during the rainy seasons. Innovative technologies such as hybrid seeds has made it possible for crops to survive for up to two weeks of being submerged. Fruit farmers should, however, avoid setting orchards in regions prone to flooding."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:d4760bf2-3826-4d8f-b554-35523cb2dc88>","<urn:uuid:cb5b6fcb-9232-4992-a61b-e94468bcf39b>"],"error":null}
{"question":"What role does scalability play in both US visa processing systems and vertical farming implementation, and what are the key limitations in each context?","answer":"In US visa processing, the system is designed to handle thousands of applications annually through standardized procedures, with consular officers able to quickly review cases based on set criteria. However, each case must be evaluated individually, which can create processing bottlenecks. In vertical farming, scalability faces different challenges - while the systems are effective at a community level, they struggle to expand beyond this scale due to high energy requirements and extensive investment costs. The technology has yet to demonstrate the ability to provide food for larger populations beyond community-scale operations, making it difficult to implement in areas with higher food insecurity. Both systems face limitations in scaling up, though for different reasons - administrative constraints in visa processing versus technological and economic barriers in vertical farming.","context":["My US Visa is rejected! Why?\nThere could be several reasons for a visa refusal or denial or visa rejection. In case consulate refuse your US visa, you may receive form with a refusal clause/reason like 221g(administrative processing) or 214b.(Refusal)\nWhat is a Visa Refusal?\nAs per the U.S. immigration and visa law guidelines , a visa must be denied if the applicant cannot establish his or her eligibility, either because the application does not meet the requirements of an established visa category, or because there are grounds for ineligibility based on other aspects of the visa case. A visa refusal is the formal denial of a non-immigrant visa application by a U.S. consular officer acting pursuant to the Immigration and Nationality Act. (More about visa refusals may be found at http://travel.state.gov/).\nHow to Overcome the refusal ?\nSome visa refusals can be overcome by the furnishing additional information by applicant information that establishes an applicant’s eligibility for the visa. If you believe you have more information and evidence that can help visa officer to make the decision in your favor, you should reapply for the visa with all the information and supporting documents.\nOther than the submitted documents. It is up to consular officers at U.S. embassies and consulates to determine eligibility on an individual basis on the merits of each case.\nMost of the cases refusal (221g) can be just because of any documents missing or any additional information required by the consulate. See a Sample of 221g document.\nApplicants are refused under Section 214(b) INA if they are unable to demonstrate to the satisfaction of a consular officer that they have sufficiently strong and long-term family, social, and economic ties outside the United States which make them depart the United States after a temporary stay.\nSee a Sample of 214b letter of refusal document.\nConsular officers tend to focus on factors that help us determine whether the applicants possess compelling ties to applicant’s home country:\n- If the applicants have traveled to the U.S. previously, how long did they stay? If they stayed longer than 6 months, did they have INS approval to do so? (Note: Please have the applicants bring their INS extension approval notices to their interview).\n- If the applicants have traveled to the U.S. previously, how long have they been back in home country?\n- How many children and grandchildren do the applicants have back in home country?\n- Have the relatives in the U.S. ever returned to home country to visit their families as is normal for foreign students, workers, and residents in the U.S.?\n- Are the applicant active professionally in their home country; if so, what is their income and the nature of their work?\nThe answers to these questions relate to whether applicants can fulfill the statutory requirement of the Immigration and Nationality Act to show that they have a permanent residence in their home country.\nEach case is different in its own and consular officer evaluates each visa application on its own merits according to visa law and procedures.\nOften, older applicants( mostly visiting Parents) do not understand why their applications to return to the U.S. a second time are denied, even though INS approved an extension of stay during their previous visit. Usually, these applicants stayed in the U.S. for a year or more and have been back in home country only a short while. Under these circumstances, the applicants have great difficulty establishing that they have compelling social or professional obligations in their home country, thereby making them ineligible to receive another visa.\nWhat do I do if my application for a visa has been refused?\nGenerally you should get a refusal letter; this will explain the reason why we are unable to issue you with a visa and provide information on the procedures you should follow.\nCan you reapply? And when?\nYes you can apply again as many times as you want.\nLooking to buy the right Visitors Insurance?\nCompare best-selling plans and buy the plan right for you.\nWhat are strong ties?\nStrong ties differ from country to country, city to city, individual to individual. “Ties” are the various aspects of a person’s life that bind them to their country or residence: possessions, employment, social and family relationships. Some examples of ties can be a person’s job and income, a house or apartment, a car, close family relationships, bank accounts, etc.\nSuch ties may include business, employment, family, property or other connections which satisfy a consular officer that the applicant will leave the United States voluntarily after a temporary visit. For example, you may bring a letter from your current employer, on letterhead, with your position/job title, length of employment, and monthly salary and your three most recent month’s bank statements.\nIn the case of younger applicants who may not have had an opportunity to establish such ties, U.S. law considers educational status, school grades and long-range plans in home country\nAs each person’s situation is different, there is no single criteria that shows compelling ties to home country. Each case is examined individually and is accorded every consideration under the law.There are so many more FAQs regarding B2 visitor visa which are answered here. Continue reading.\nConsular officers are trained to look at each application individually and consider professional, social, cultural and other factors.\nIs a denial under Section 214(b) permanent?\nNo. If an applicant has new information which was not presented to the interviewing officer at the time of the first application, or if the applicants overall circumstances have changed significantly since the last application, a visa may be approved.\nSee a Sample of 214b letter of refusal document.\nDo refused applicants have to wait three to six months before reapplying?\nThere is no time restriction on resubmitting an application after a refusal. If additional information or supporting documentation is available which may further demonstrate applicant’s qualification for a visa, an application may be resubmitted.\nI presented all the documents I was told to bring, but my application was turned down anyway. What else should I bring?\nThe problem is not the documents. Rather, the applicants current overall situation (as supported by those documents) was not adequate to overcome the presumption that he or she is an intending immigrant. Remember, U.S. law says that all applicants for nonimmigrant visas are intending immigrant until they show that their overall circumstances would be adequate to compel their return home after visiting the U.S.\nWhy are the visa interviews so short? I was refused after only a couple of questions and the interviewer hardly looked at my documents?\nVisa officers handle thousands of applications every year. Based on this experience, they are able to quickly review the application form and supporting documents in order to narrow the range in which questions may need to be asked. Keep in mind, much of the necessary information required to make a decision is already supplied on the application form itself, so there is usually no need for the officer to ask more than a few additional questions.\nWhen I applied for a visa, I told the officer I would return to my home country after a short stay in the US. Why didn’t the officer believe me?\nVisa officers are required to evaluate the applicants overall situation in reaching a decision. Statement indicating that the applicant intends to return to home country are helpful, but under the requirements of U.S. law the statement alone is not adequate to show that they qualify for a visa.\nIf my visa application is denied, would it help to have a high ranking official like congressmen/senator contact the consulate?\nNo. United States law assigns the responsibility for issuance or refusal of visas to consular officers overseas. They have the final say on all visa cases. Additionally, United States law is designed to insulate the decisions in visa cases from outside influences. An applicant can influence a reversal of a prior denial only through presentation of new convincing evidence of strong ties.\nShould I use a travel agent or other advisor to help me apply?\nThe matter is a personal decision for each applicant. However, in most cases it is not necessary for applicants hire a travel agent to assist with a visa application. Travel agents will often charge to fill out forms which are available for free. They also charge large sums on the promise of enabling the traveler to bypass the visa interview. Our experience shows that many applicants are coached by intermediaries to provide answers which are misleading. While the truthful answer would not have harmed the application, the discovery of a misleading answer often puts the entire application in doubt.\nSome ineligible applicants seek help from a “visa consultant”. Be careful. If you do decide to hire a consultant, remember that you alone are responsible for the accuracy of the information in your application.","Agricultural systems around the world need to adapt to the rapidly changing environmental, demographic, and socioeconomic landscapes, and new alternative practices, such as vertical agriculture, may offer new opportunities to accelerate such adaptation.\nNext Gen Farming Without Soil and 90% Less Water | GRATEFUL\nWhat is vertical farming and why is it important\nModern agricultural systems encompass an estimated 1.5 billion hectares of the world’s surface area. With a growing population and resource needs, the availability of arable land is shrinking rapidly.\nSince the agricultural revolution, conventional agriculture has focused on practices requiring considerable quantities of space, water, fertilizer, and pesticides. The past 50 years have seen an accelerating rate of increase in these requirements as modern food production aims to increase productivity in the hopes of addressing growing food insecurity.\nLooking into the future, yield production is forecasted to decrease due to widespread environmental and socioeconomic changes that will generate unpredictable consequences on food systems.\nIn response, many strategies have been developed as alternatives to conventional agricultural practices. These strategies have focused on key principles and their combination to be effective: require less space, less water, and increase yield per unit of area. Moreover, due to the negative effects of agrichemicals, modern practices have also aimed to use significantly less to avoid potentially adverse effects for humans and animals.\nOne such alternative is the development of vertical agriculture, also referred to as vertical farming. As the name implies, vertical agriculture relies on expanding production vertically and not horizontally. Vertical agriculture is a multilayer indoor plant production system that allows for precise control of growth factors, such as light, temperature, humidity, carbon dioxide concentration, water, and nutrients.\nThis allows for the growing and production of crops year-round, completely independent of solar light and other external conditions. Indeed, vertical agriculture makes use of key concepts within ecology and physiology to optimize growing and fertilization within controlled conditions. For instance, elements of photobiology, thermomorphogenesis, hydroponics, and genetic breeding, are all used commonly across systems of vertical agriculture.\nBenefits, challenges, and disadvantages moving from horizontal to vertical farming\nAs a result of tight control over crop breeding, growing, and harvesting, vertical farming provides several benefits relative to conventional methods of ‘horizontal’ food production. This was the topic of a literature review by Kalantari et al. published in 2016 in the Journal of Landscape Ecology.\nFrom a systems perspective, the enclosed design prevents pests and diseases from entering by the adoption of a high level of hygiene, continuous monitoring, and non-chemical disinfection, providing security from crops. Moreover, recent technology has also allowed for automated control over environmental conditions by using sensors and imaging techniques in combination with crop simulation models and artificial intelligence, limiting the need for physical labor.\nVertical farming also allows for flexible organization, with designs ranging from large vertical walls covered with crops to large hangars or re-used shipping containers that can be transported. Consequently, vertical agricultural systems, can comprise many varying sizes and be located within many different areas from the middle of highly urbanized cities to more suburban or rural areas.\nMoreover, the verticality element of this system also provides nutrient and water flow, helping to reuse costly resources. The reduction in space also means there is a significant increase in yield per area, holding extensive potential for a future world of urbanization.\nFrom an economic perspective, vertical farming also provides for more jobs in localized areas and is community-focused by addressing the needs of immediate areas, which in turn can provide food at a lower price. Finally, the optionality of location for vertical systems also allows producers to reduce transport costs, as consumers may access them within urban areas, or transport can be minimized to nearby areas.\nHowever, despite the design, environmental, and economic advantages, vertical farming also incorporates several issues that remain a challenge to its broader implementation as a system.\nVertical farming has a high energy requirement and needs extensive investment costs to implement and develop successfully. Moreover, indoor issues relating to excessive UV, heat, and ozone-induced plant damage may have unpredictable repercussions for plant growth.\nAdditionally, vertical systems are difficult to adapt to a larger scale. They are costly to build and maintain and have yet to demonstrate the ability to provide food for larger areas than community-scale populations. This would make it difficult to implement in areas at higher risk of food insecurity, such as developing agricultural nations.\nThe lack of empirical research on a broader scale has meant that vertical farming has yet to develop past the concept stage on community levels, as persistent issues make it difficult to break through to a larger scale.\nImage Credit: YEINISM/Shutterstock.com\nGrowing skywards - the implications of vertical farming in a rapidly populating and changing world\nAmong the development of alternative agricultural practices, vertical agriculture provides a promising solution for many of the challenges facing current agricultural policies. However, for vertical systems to be integrated on a larger scale requires further technological progress and economic investment.\nNevertheless, gradually implementing more verticality, or combining it with other practices aiming for more sustainable practices may be promising. For instance, the combination of verticality with other practices such as intercropping may be particularly beneficial for developing more sustainable food systems.\nIncorporating technological progress into vertical systems also holds promise, with automated sensors and machinery able to operate near-independently. Progress in gene editing and plant genome modifications will also allow for faster, bigger, and healthier crops, allowing vertical agriculture to produce more over time.\nThroughout agricultural history, farming systems have typically spread over large spans of land, yet the reduction in arable land, as well as the increase in demand to house growing populations, means that such strategies need to be reconsidered, and vertical agriculture may play a role looking into the future.\nContinue Reading: Benefits of Vertical Agriculture and Hydroponics\n- Beacham, A. M., Vickers, L. H., & Monaghan, J. M. (2019). Vertical farming: a summary of approaches to growing skywards. The Journal of Horticultural Science and Biotechnology, 94(3), 277–283. doi: 10.1080/14620316.2019.1574214\n- Chaudhry A. R. and Mishra V. P.,(2019) A Comparative Analysis of Vertical Agriculture Systems in Residential Apartments, Advances in Science and Engineering Technology International Conferences (ASET), 2019, pp. 1-5, doi: 10.1109/ICASET.2019.8714358\n- Sarkar, A., & Majumder, M. (2015). Opportunities and Challenges in Sustainability of Vertical Eco-Farming: A Review. Journal of Advanced Agricultural Technologies, 2(2). doi: 10.12720/joaat.2.2.98-105\n- SharathKumar, M., Heuvelink, E., & Marcelis, L. F. (2020). Vertical Farming: Moving from Genetic to Environmental Modification. Trends in Plant Science, 25(8), 724–727. doi: 10.1016/j.tplants.2020.05.012"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:2e157708-e483-483f-a555-f5e8b83e85e0>","<urn:uuid:3566e03d-b8ac-4d36-b13c-9d56f4d7ba0e>"],"error":null}
{"question":"What are the key differences between industrial-scale tilapia processing facilities and small-scale fish preservation enterprises in terms of business viability?","answer":"Industrial-scale tilapia processors like Regal Springs focus on high-welfare technological solutions and international certifications (ASC and BAP) to meet consumer demand for responsibly sourced seafood, with research showing 90% of global consumers prioritizing ethical sourcing. In contrast, small-scale fish preservation businesses focus on local market demands, selling preserved products like smoked fish, daing, and sardines, requiring lower initial investment and simpler processing techniques while still providing viable business opportunities through supermarkets, groceries, and market stalls.","context":["Tilapia giant adopts humane stunning in global operations\n18 January 2023\nAce Aquatec’s humane stunning technology, pioneered in salmon farming, has transformed the processing operations of the world’s biggest tilapia producer, after the system was adapted for the warm water species.\nRegal Springs collaborated with Ace Aquatec to develop the in-water electric stunner, the Humane Stunner Universal (A-HSU), for tilapia and has now introduced the high welfare solution into its main processing facilities in Mexico and Honduras. The company is also planning to install an A-HSU system in its Indonesia processing facilities in Q1 2023.\nAnd not only have the new stunners ensured that Regal Springs tilapia is harvested humanely and effectively, they have also streamlined production and delivered better quality fish.\nIn quality tests conducted by Regal Springs, the tilapia sustained no electrical damage and the company was very happy with the overall flesh standard.\nRegal Springs sustainability manager Emily McGregor said: ‘Sustainability has been at the heart of our business for more than 30 years and, in the spirit of continuous improvement, we stand proud of pioneering new ways with fish welfare.\n‘The humane stunner not only ensures better treatment of the fish, but helps deliver a superior quality product through reduced stress levels in the catchment process.\n‘This is a huge step forward, from thermal stunning to a more humane and controlled stunning process, and, with this, towards better fish welfare. ‘\nAs a side effect, process and quality parameters have also improved, with reduced bruising, better quality of the fillets, and better working conditions for staff.\n‘This supported Regal Springs’ decision to move from pilot trials to immediate uptake of the equipment, and proliferation across the business.’\nThe premium white fish producer, which raises tilapia in large floating nets in freshwater lakes in Mexico, Honduras and Indonesia, was looking for a stunning solution to both harvest its tilapia more humanely and address growing consumer and retail demand for responsibly sourced seafood.\nResearch has shown that nine in ten global consumers prioritise buying from companies that have ethical sourcing strategies in place, with 83% willing to spend more on a product if they can guarantee it meets a certain level of criteria (OpenText, 2021).\nPetra Weigl, Regal Springs’ managing director for Europe, said: ‘Retailers can be confident in accessing the very best in tilapia fish protein, made viable through the way we raise and now harvest the fish - our ASC and BAP certifications being testament to the quality we offer.’\nAce Aquatec embarked on the tilapia project with Regal Springs more than two years ago, after a £1m award from the Humane Slaughter Association to provide pilot stunning equipment to farms that had no humane harvesting in place for finfish.\nThe company approached Regal Springs to conduct trials - in conjunction with Nautilus Collaboration, The Centre for Responsible Seafood, and Global Seafood Alliance - that would validate its technology with tilapia.\nBeginning first in tank tests in Canada and then in commercial scale trials at Regal Springs in Mexico, the pilot proved to be a ‘gamechanger’ for Regal Springs and for tilapia farming.\nDr Jenny Bouwsema, Ace Aquatec’s academic advisor, who oversaw the field work for the project, explained how the ground-breaking system evolved.\n‘In many ways, the technology is similar to that used for salmonids, fundamentally sending an electric field through water and stunning the fish,’ she said.\n‘The big difference between salmon and tilapia, though, is that tilapia are very hardy, very hypoxia tolerant, meaning they can survive for a very long time on very little oxygen.\n‘The challenge was not only finding a set of stunning parameters that would give them very quick insensibility, but working out how to get that to last until processing was complete.’\nTraditionally, tilapia are culled by being cooled on ice, but it’s not clear how much consciousness they lose or whether they’re just paralysed, said Dr Bouwsema.\n‘In the trial, the fish were coming through the stunner fully unconscious and were much easier to bleed. There was no flapping around and they were unconscious for long enough for people to be able to work with them.\n‘To measure unconsciousness, we look at a number of behavioural reflexes, such as the eye roll reflex. We’re confident we’re getting very quick unconsciousness, and we’re now working on measuring brain activity in a parallel project with Stirling University.’\nAce Aquatec CEO Nathan Pyne-Cater said: ‘Regal Springs presented us with a unique challenge to create a bespoke product for them in the rural depths of Mexico.\n‘Together, we created a stunning system that puts fish welfare at the forefront of their operations. UK consumers can have peace of mind knowing that the tilapia reared by Regal Springs has been raised to the highest standards.\n‘This represents the beginning of a general acceleration across fish farming, and the wild sector, linking welfare at harvest with the economic value.\n‘We are now working with barramundi farms in Australia, prawn farms in Europe, and the trout sector in Canada as consumers and regulators insist on more humane farming processes.\n‘We’ve been able to demonstrate that when farms take a welfare first approach, they can see real economic gains in their business. This is critical if the mission to see all fish humanely harvested worldwide is to be achieved.’","FISH PROCESSING : FISH PROCESSING FISH PROCESSING : FISH PROCESSING Whether preserved for future use or cooked for meals, they must be preserved properly to avoid undesirable taste and odor. Steps in Fish Processing : Steps in Fish Processing Scaling : Scaling Hold the fish by its tail and move the scaling tool from the tail up. Use a kitchen knife slightly curved in shape with serrated blades, or a wooden scaler to do this. A wooden scaler is an implement with a flat oval head filled with protruding uniformly spaced nails and is commonly used in markets. The scaler works very well on fish of all sizes. Cutting of tails and fins : Cutting of tails and fins Lay the fish on a cutting board and use a sharp knife to cut the tails and fins. For small fish, use a pair of scissors. Eviscerating : Eviscerating Remove the gills first then the entrails, through the flaps of the head. Slit open the stomach or press the lower portion to push the entrails upward. Cleansing : Cleansing Rinse the fish inside and out in running water to ensure that no entrails or other wastes are left inside and for better flavor. TINAPA MAKING : TINAPA MAKING Raw Materials:\nAny kind of fish (bangus, dalag, hito, tunsoy, dilis) salt\nWire screen or bamboo rack\n1. Wash the fish well in clean water.\n2. Remove the internal organs through a cut made across the belly.\n3. Soak the fish for 30 minutes in a solution of 1 part salt to 9 parts water to remove the blood.\n4. Place the fish in a solution of 2 tablespoon salt to 1 cup water for 12-24 hours.\n5. Place the salted fish in a single layer on wire screens, rattan or bamboo racks to dry. Slide 9: Raw Materials:\nTamban, salt, sugar, salitre, pepper, bay leaves\nKitchen knife, smoking trays, tin cans\n1. Cut the fish along the back just above the backbone so that it will open, leaving the belly solid.\n2. Remove all the internal organs and wash off the blood.\n3. Make another cut under the backbone.\n4. Wash well and soak for 30 minutes in salt solution of ½ cup salt and 4 cups of water.\n5. Cook the fish in a boiling solution of ½ cup water, 2 tablespoons salt, 1 tablespoon sugar, ¼ teaspoon salitre, crushed black pepper and crushed bay leaves.\n6. Arrange the fish in smoking trays and drain for 10 minutes.\n7. Dry the fish partially in a cool, shady place for about 3 hours before smoking.\n8. Smoke the fish in tin cans, using sawdust for 1 to 2 hours until golden brown. FERMENTED MUDFISH (Buro) : FERMENTED MUDFISH (Buro) Wash and clean fish, remove the head and the body, slice. Salt all slices and let stand overnight. Cook 1 cup of rice in 2 cups of water. Pound 1 tbsp. of angkak (red food color from the bark) and mix with lugaw (rice gruel). Mix with the fish slices all the rice and place in a covered jar. Let stand for 3 to 4 days. This is cooked with plenty of garlic, onions and tomatoes, and sautéed in a little amount of fat. Add 1 tbsp. of vinegar before serving. FISH PASTE (Bagoong) : FISH PASTE (Bagoong) Raw Materials:\nDilis, sapsap, and ayungin can be made into bagoong.\nWooden, steel barrels or vats instead of earthenware pots.\n1. Wash the fish with clean fresh water.\n2. To every 3 cups of fish, add 1 cup of salt and mix well.\n3. Place the fish and salt mixture in earthenware pots.\n4. Cover the containers tightly to keep flies and other insects away.\n5. Let it stand for 2 weeks to 1 year to develop its characteristic aroma and flavor. SARDINES : SARDINES Ingredients:\n1 kilo tunsoy or tawiles\n6 pieces green olives\n2 tbsp. whole peppercorn\n½ c. corn oil\n6 pcs. Mixed pickles, cut around\n2 pcs. Bay leaves\n½ c. soy sauce\n1/3 c. cheap brandy\n2 pieces sili or 1 pc. Sili labuyo\n1 tbsp. MSG\n½ can tomato paste SARDINES : SARDINES Combine all ingredients on top of the cleaned fish.\nCook for five minutes in high heat, and 25 minutes in low heat.\nLet it cool.\nPlace in sterilized, airtight containers up to ¾ full only. Ways of Storing Preserved Fish : Ways of Storing Preserved Fish Dried fish is stored at room temperature for several months with cover to prevent it from insects, dust, dirty particles and flies.\nTinapa and other smoked fish keeps without refrigeration for about 3 days to one week.\nCanned fish is kept at room temperature. These canned products have shelf life of years. It is important to know the expiry date of canned fish before keeping them. Food Preservation as a Potential Business for Small Scale Entrepreneur : Food Preservation as a Potential Business for Small Scale Entrepreneur ` Selling of preserved meat, poultry and fish can be a profitable and interesting business. It can be a means of livelihood or an additional source of income for a family. Preserved meats, poultry, and fish are sold in the market, groceries, stores, stalls, and in supermarkets. Filipinos are fond of buying pork ham specially on Christmas season, beef tapa, tocino, and longaniza are non popular in the market and groceries. Preserved fish in various forms such as smoked fish, daing, sardines, fish sausage and other preserved fish are well-liked by Filipino people.\nA person planning to engage in fish or meat preserved business should study all the aspects of the business. It includes financing, analyzing the market, buying and selling, pricing, storing of preserved food, recording, accounting and merchandising control. Nevertheless many big businesses started small but expanded as the growing market demanded. FIN? : FIN?"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:0cd5db98-40c7-4a56-8d93-5aa1ed7e376f>","<urn:uuid:c6c6d737-8271-43a4-be9f-8f17d6067e3a>"],"error":null}
{"question":"As someone interested in 19th century American history - were there any similarities between the timing of Leaf Valley Township's establishment and Campbell County's courthouse in Alexandria?","answer":"While both events occurred in the 19th century, they happened at different times. Leaf Valley Township was established on November 23, 1867, with its first meeting held in December 1867. In contrast, Alexandria's courthouse construction began in 1840, after it was designated as the county seat of Campbell County, with the building being made of red brick from the Spilman family's kiln.","context":["Leaf Valley Township\nCompiled and written by Ginny Swartz\nLeaf Valley Township was established by the board of county commissioners 23 November 1867 and is comprised of congressional Township 130, Range 38. The first meeting was to be held at the house of Willard B. Ellis on 14 December 1867. The name Leaf Valley refers to its location just south of the Leaf Hills, also called \"Leaf Mountains\", area just to the north of the township in Otter Tail County. The population of the township was German Lutheran along the north and east, Irish and German Catholic along the west and south.\nThe only town located in the township is Leaf Valley which formed at a cross road. The village boasted a town hall, post office, general store, feed mill, and a large co-op creamery along with a number of homes. No railroad came through the area in the vicinity of the town.\nSchool District #23 was located in Section 34; District #59 in Section 14; District #43 in Section 7; District #28 in Section 29; and District #53 in Section 4.\nChurches serving the township were an Evangelical Lutheran Church in Section 33 and St. James Lutheran, located on the county line above Section 4 in Otter Tail County. Cemeteries include Ebenezer German Lutheran in Section 34 and the Ellis Family Plot located in Section 28 in the Village of Leaf Valley.\nThe Catholic residents went to Millerville or Urbank for church.\nAccording to records located in the Recorderís Office at the Douglas County courthouse, the following individuals were the first owners who received a patent from the U.S. Goverment on land in Leaf Valley Township. The year noted is the year the patent was recorded; often the individuals had been on the land one or two years prior to recording the patent.Enoch H. Alden - Section 1, 1873\nEnoch H. Alden - Section 2, 1873\nWilliam Marquardt - Section 3, 1869\nHenrick Thies - Section 4, 1869\nWilhelm Fentzke - Section 5, 1873\nJohn Johnson - Section 6, 1873\nMartin Faust - Section 7, 1874\nEmil Nuscke - Section 8, 1872\nJohn S. Evans - Section 9, 1868\nHenry Thies - Section 10, 1876\nWillard A. Alden - Section 11, 1871\nWilliam Johnston, Section 12 1878\nWallace Kibbe - Section 13, 1875\nSamuel Pollard - Section 14, 1871\nJohn S. Evans - Section 15, 1873\nPeter Smith - Section 17, 1876\nAndreas Reger - Section 18, 1874\nPeter Ley - Section 19, 1873\nWilson Davidson - Section 20, 1870\nLorenzo D. Peck - Section, 21, 1868\nLorenzo D. Peck - Section 22, 1868\nIsaac Johnson - Section 23, 1871\nJohn H. Hartew (Hartwig) - Section 24, 1873\nSimon L. West - Section 26, 1873\nStockly Robertson - Section 27, 1876\nW. B. Ellis - Section 28\nJohn Comoford - Section 29, 1872\nPeter Ley - Section 30, 1873\nPatrick Kelly - Section 31, 1873\nWilliam B. West - Section 32, 1881\nJohan F.N. Groseneck - Section 33, 1876\nAndrew Anderson - Section 34, 1876\nAndrew Anderson - Section 35, 1876","Alexandria and Newport Courthouses\nThis article is by Jim Reis and is reprinted here with his permission.\nCampbell County was carved out of Mason, Scott and Harrison counties in 1794. The earliest county government meetings were held in the home of John Grant at Wilmington, a pioneer settlement established on December 7, 1793. Wilmington was laid out on a 50 acre site along the Licking River. about 22 miles south of Newport. Back then, Kenton County was part of Campbell County and Wilmington was close to the county's geographic center.\nBut traveling to Wilmington was inconvenient and county officials quickly decided to move further court sessions to Newport. Court sessions were held in the home of Jacob Fowler, a woodsman and surveyor who owned the first tavern in Newport. In 1789 he built what was probably the first cabin in Newport near the confluence of the Licking and Ohio rivers.\nThe county seat was officially moved to Newport in 1797. The site of the courthouse location of the current courthouse, was donated to the county by James Taylor, the founder of Newport. Around 1800, a public whipping post, stocks and several log buildings used primarily as jails, were built on the site. The first courthouse was built there in 1815 and was a two-story brick building with a cupola and bell.\nThe county seat was moved out of Newport in 1823 by a group that wanted the county courthouse located closer to the center of the county. This time, officials selected Visalia, a small rural community on the west side of the Licking River in what is Kenton County. But Visalia, like Wilmington, was just far from everything. Within a year, a 10 man committee was selected to settle the issue. After some study, four members of the committee supported Wilmington for the county seat and one wanted to start all over with a new site. But Newport got five votes and the courthouse.\nThe county government returned to Newport and remained there until 1840. That was the year the General Assembly carved Kenton County out of Campbell County. Legislators designated Alexandria as the official county seat of Campbell County. The original courthouse at Alexandria was started in 1840 and was built of red brick fired at the kiln owned by the Spilman family. The kiln was on the site of what is now St. Mary's Church on Jefferson Street. Reverend James Jolly, a trained mason and bricklayer and at one time minister of Alexandria Baptist Church, is said to have done most of the building. The courthouse holds many valuable records which date back to 1794. Papers bearing the signatures of Daniel Boone and Henry Clay are housed there.\nThe transition from Newport to Alexandria\nwasn't smooth. It took a court order and a visit from the sheriff to get\nthe county clerk out to Alexandria. And Newport backers continued to lobby\nfor their own courthouse. That finally happened in 1883, when construction\nbegan on a Newport Courthouse. It was completed the next year. That\nVictorian building, with its four sided clock tower, marble floors and stained\nglass window, still serves as a courthouse. The building was sandblasted\nand restored in 1972.\nThese court order documents were copied by Margaret Hartman\nCourt Order Book 4, page 292, 27 April 1840\nThe report of the Commissioners appointed by an act of the last session of the Legislature of Kentucky to locate the county seat in Campbell County was this day returned to the Court which is in the words & figures following to wit:\n\"The undersigned, Samuel F Swope, David Brooks and Charles Ruddell, three of the commissioners appointed by An Act of the General Assembly of the Commonwealth of Kentucky, approved, January the 29th 1840, to locate the County Seats of Campbell and Kenton counties, would respectfully submit the following report to the honorable County Court of Campbell. to wit; that on Monday the 30th day of March 1840, they met at the Town of Alexandria, in said County of Campbell and after having been first duly sworn by H E Spilman, Esqr. a justice of the peace in and for said county, well and truly without partiality or favor to any one, to discharge the duties imposed upon them by said act and to locate the County Seats of Said Counties of Campbell and Kenton, as near the center of Said Counties, as the fact of the country would admit.\nThey proceeded to ascertain the center of the said County of Campbell, from various Maps of the County, from an examination of the fact of the Country and from information derived from aged and respectable Citizens of the County. And although they were unable to find the exact center, yet they were well satisfied and so report that the center of the said County of Campbell is a little North of East and about a half or three quarters from the Said Town of Alexandria.\nAnd after having so ascertained the center of said County, and finding from the face of the boundary at and immediately around the center, that there was no site suitable for the location of said Seat of Justice, owing to the unevenness of the Country at or immediately around the center. they proceeded to examine the various sites proposed as the most eligible and nearest to the center of said Count of Justice, believing it to be the only suitable place for the Seat of Justice in the vicinity of the center.\nThey therefore, in pursuance of said act of Assembly locate the Seat of Justice for Campbell County at the Site aforesaid in the town of Alexandria on the land of Henry E Spilman and within the following Boundary (to wit) Beginning on Fayette Street in said Town 20 feet from the North corner of Lot No 44, thence with said Street North 51 1/2 E 144 feet, Thence South 76 1/2 E 132 feet, to Benjamin D Bealls line, Thence South 45 W to the beginning, including Lots, Numbers 45 and 46 and fractional Lots No 40 and 60 as designated on the proposes and agrees to convey to the County Court of Campbell public buildings in the manner prescribed by said Act of Assembly, or in any other way so as to secure to said County Court, a good and sufficient title to said lots for the purposes aforesaid. All of which is respectfully submitted to the County Court of Campbell County.\nIn Testimony whereof said Commissioners have hereunto set their hands this 31st day of March 1840.\"\nSamuel F Swope, David Brooks, Charles Ruddell\nThe County Court of Campbell Dr. to Samuel F Swope, March 1840 to 3 1/2 days attendance as commissioner to locate the County Seat of Campbell @ $5.00 per day; $17.50\nThe County Court of Campbell Dr. to David Brooks, March 1840 to 3 1/2 days attendance as commissioner to locate the County Seat of Campbell @ $5.00 per day; $17.50\nThe County Court of Campbell Dr. to Charles Huddell, March 1840 to 3 1/2 days attendance as commissioner to locate the County Seat of Campbell @ $5.00 per day; $17.50\nIt is ordered that the County & Circuit Courts\nof Campbell County be hereafter held in the Baptist Church in the Town of\nAlexandria, and that the paper record &c of said courts be removed to the new\nhouse of Ben D Beall in the upper room in the Town of Alexandria, the county\nseat, and the Clerk is authorized to employ a suitable number of Waggons &c for\nthe transportation of said paper record, presses and office furniture to\nAlexandria at the expense of the County Court and the Jailor of Campbell County\nis, hereby directed to take possession of & safely keep and take care of all the\npublic buildings & other public property in the Town of Newport, subject to the\nfurther order of this court.\nCourt Order Book 4, page 396, 25 May 1840\nClerk did not appear for County Court at Brick\nMeeting house, in or near Alexandria on Monday 25 May 1840. The Sheriff\nopened court. When Clerk did not answer roll call, it was ordered that the\nSheriff go to Newport and notify the Clerk or Deputy for Clerk to appear at 11\no'clock AM Tuesday the 27th.\nCourt Order Book 4, page 397, Tuesday May 26, 1840\nCourt Held. H T Harris, Esqr. being of opinion\nthat this court is illegal, absents himself from the bench.\nCourt Order Book 4, page 407, 8 June 1840\nIt is ordered that the Clerk of this and the Circuit Court be permitted to occupy the lower room in addition to the upper room Ben D Beall's new building in Alexandria as a clerks office till further ordered, he the said Beall assenting thereto in open court.\nIt is ordered that James McCron, Wm Riley &\nJohn Stroube be appointed commissioners to draft a plan to be presented to the\nCounty Court at their next August Term by said Commissioners for the building of\na Courthouse, Jail & Clerk's Office, with the probably amount of costs for said\nbuildings and to advertise the letting out and contracts for the building of the\nsame on the following day to the lowest bidder.\nCourt Order Book 4, page 410, 10 August 1840\nIt is ordered that John J Thomas, Ben D Beall &\nBenjamin Smith be appointed Commissioners to examine the Clerks office of this\ncourt & report according to law.\nCourt Order Book 4, page 415, 10 August 1840\nIt is ordered that the plan proposed by Wm Riley for the Courthouse Jail & Clerks office be recorded & adopted with the exception of one of the Clerks office, the one to be built to be 20 by 30 feet in the clear with a partion through the center and it is further ordered that the Commissioners heretofore appointed to contract for the same, are hereby directed & instructed to contract & agree to pay for the same in three equal annual payments, the first payment to be made in November 1841.\nCOURT HOUSE-40 feet square; foundation stone sunk at least 2 feet below the surface of the earth and to be raised 18 inches above; lower story 13 feet upper 10 feet; the stairs to occupy the right hand corner as you go into the building; the upper story to be divided into three apartments; the front door to be in the center; door into the Clerks office.\nCLERKS OFFICE (a change in the court order book) 18 X 34; 34 in front and adjoining the Court House; the story to be 9 feet in the clear; the office to be divided by a partition of brick as as to make the room adjoining the Court house 20 X 16 to contain 1 door and 2 windows in front the door in the center; above walls of buildings to be of brick 13 inches thick.\nJames M Jolly, with securities Henry E Spilman, David Shaw, James White and Jacob White junior; found for $11,770 for Court house, Clerks office and Jail; plan received by County Court August term 1840. 3 equal installments to be paid to Jolly of $5885, first payment to be made 1 November 1841 (sealed 12 August 1840)\nSigned William Riley, James McCron, John Stroube, Commissioners\nCOURT HOUSE-the bench bar and jury seats & floor to be finished in the same manner as the Court House at New Port. Joists for second story 12 inches wide when dressed by 3 inches thick to be framed into a beam and below & above, the beam to be through the center of building & to be supported by two columns of the Dorick order.\nThe roof to be hipped with a square at top of ten ft. for a belfry to be 15 ft. to its eave of an octagon form, with plane pilasters at each angle with a neat cornice and a circular roof. The roof to be framed and finished in a strong and substantial manner, the shingles to be of good quality & of pine, to be nailed on inch sheeting and not to show more than 4 inches to the weather. The building to be finished with a neat brick cornice. The front door to be in the center 4 1/2 ft wide by 9 ft. high, to be made in two parts with 5 panels in each, the panels raised and molded on both sides, the door frames to be paneled to correspond with the door with a neat transom with a clip stick sash and a double clip stick arch over the door; the stuff for the door to be made of clear pine 2 inches thick, the door to be finished with a plain pilaster in front, one window on each side of the door dividing the front of the building into equal spaces, the windows to contain 24 lights of 12 X 14 glass, three windows in the building on the right hand side of the same side with equal spaces. The left hand side to have two windows and a door into the Clerks office and to form equal spaces. The upper story to have 12 windows to contain 15 lights of 10 by 12 glass each and to be placed directly over the windows and doors of the lower story.\nCLERKS OFFICE-2 windows in the rear of the large room and a door in the rear of the small one, the size of the windows to be the same dimensions of those in the upper story in Court house, the doors to have three lights over the, the door in the partition to be in the center; the four doors of office to have five panels raised and molded on both sides and 2 inches think; the floor to be of good hard brick; the shingles and sheeting to be the same as Courthouse; a flue for stove pipe to be run up with the partition a sufficient height above the building.\nAll the stone work above ground for Court house and Office, to be range work, the sills of Courthouse and Office to be limestone and the window sills of the above buildings to be of brick 13 inches thick, the window frames to be of yellow pine or locust 3 inches thick and 7 inches wide, the sash and shutter stops a 3/4 bead grooved into the frame, a 3/4 parting bead Do inside stops 1/2 inch to come flush with the edge of frame; the jamb casings to be of inch stuff grooved into the frame and flared. All the windows in the above named buildings finished in this way except the upper windows in Courthouse; the jamb casings of upper windows to be recessed 1 1/2 inches, the architraves for doors and windows to be 6 inches wide with a plane 2 or 2 1/2 inches Grecian ovolo; the lower windows to hve venetian shutters both of Office and Courthouse to be 1 1/2 inch stuff with a middle rail with slats mortised in the same to have suitable hinges and fastenings.\nThe sash for Court house & Office to be of 1 & 3/8 inch stuff and franked the doors to have 3 hinges each to be 3 by 5 inches, with Cincinnati locks; all the wood work to have three coats of white lead, the window shutters to be painted green. it is understood that there is to be two chimneys in the Courthouse with suitable fireplaces below and above situated as the chimneys in the Courthouse in New Port with suitable chimney pieces for each. Also a chimney piece for the jailors room.\nSpecs for jail; Jail to be completed 1 October\nClerks office 1 November 1841\nCourt house 1 April 1842\nThe above buildings, jail, clerks office and\nCourt house were bid off by James Jolly on the 11th day of August 1840 at five\nthousand eight hundred and eighty five dollars.\nReport May Term 1845\nOf importance, difference in brick cornice and\npresent finish in favor of undertaker. $30.00"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:2a441dae-245e-4aef-9591-ae322441ac1a>","<urn:uuid:4fb3770c-e2a5-4cd5-a724-2b2612f7d74d>"],"error":null}
{"question":"How did cool jazz differ from bebop in terms of tempo and style, and what role did string arrangements play in light music compositions from the 1950s?","answer":"Cool jazz contrasted with bebop by featuring slower, more relaxed tempos and lighter tones, eschewing the fast tempos and jagged phrasing characteristic of bebop. Regarding string arrangements in light music, pieces like George French's 'Highly Strung' demonstrated wild scherzo-like compositions with swirling string movements supported by brass and winds, while others like 'Little Miss Molly' featured strings with a Ravelian fairytale quality and prominent flute parts.","context":["The Golden Age of Light Music: Highly Strung\nJack MASON (1906 - 1965) Pops Polka [2:47]\nSteve RACE (1921 - 2009) Ring Ding [2:33]\nGeorge FRENCH Highly Strung (1959) [2:17]\nCarlos ROCHA Song Of Lisbon - Sempre Que Lisboa Canta; [2:34]\nRoger ROGER (1911 - 1995) Paris Pullman [2:35]\nPhilip GREEN (1911 - 1992) Sapphire (theme from the film) [2:51]\nLouis Felix Marie GASTÉ Le Soir (I’d Love To Fall Asleep) [3:06]\nMack GORDON (1904 - 1959) and Harry REVEL (1905 - 1958) Afraid To Dream (arranged by Ronald BINGE (1910 - 1979)) [2:59]\nFred HARTLEY (1905 - 1980) Jack In The Box [2:17]\nDavid ROSE (1910 - 1990) Gay Spirits [2:37]\nKurt SCHICK Sheerline [2:38]\nRobert FARNON (1917 - 2005) Little Miss Molly [3:01]\nZez CONFREY (1895 - 1971) Stumbling [2:12]\nTerry GILKYSON (1916 - 1999) Cry Of The Wild Goose (1950) (arranged by Philip GREEN) [2:30]\nOtto CESANA Whirlwind [3:14]\nBernie WAYNE (pseudonym for Bernard WEITZNER) (1919 - 1993): Life In New York [2:49]\nFrank CHACKSFIELD (1914 - 1995) Sunshine Beguine [2:42]\nGérard CALVI (pseudonym for Grégoire Elie KRETTKY) (b.1922) Gigue Ecossaise (Scottish Jig) [2:45]\nPaul DUBOIS (pseudonym for Clive RICHARDSON) (1909 - 1998) Sentimental Magic [3:12]\nRon GOODWIN (1925 - 2003) All Strung Up [2:22]\nMikis Michel THEODORAKIS (b.1925) The Honeymoon Song (from the film Honeymoon (1959)) [2:21]\nAlbert MARLAND ((1904 - 1976) Limelight Waltz [2:38]\nRudolf FRIML (1879 - 1972) Ma Belle (from The Three Musketeers (1928)) [2:03]\nAlex NORTH (1910 - 1991) The Wonderful Country (theme from the film) [2:13]\nCharles WILLIAMS (predunym for Isaac COZERBREIT) (1893 - 1978) Toy Violin [1:26]\nMitchell PARISH (1900 - 1993) and Frank SIGNORELLI (1901 - 1975) A Blues Serenade [2:43]\nPercy FAITH (1908 - 1976) Perpetual Notion [3:30]\nIrving BERLIN (1888 - 1989) A Pretty Girl Is Like A Melody (1919) (arranged by Peter YORKE (1902 - 1966) [3:28]\nAdolph DEUTSCH (1987 - 1980) Park Avenue Fantasy (underscore from film soundtrack Some Like It Hot (1959)) [4:03]\nRonald Binge (GORDON/REVEL), Gérard Calvi (CALVI), Otto Cesana (CESANA), Percy Faith (FAITH), Ron Goodwin (GOODWIN), Morton Gould (CONFREY), Philip Green (GILKYSON), Eric Jupp (ROCHA), Monty Kelly (WAYNE), Groff Love (Friml), David Rose (ROSE), Boris Sarbek (GASTÉ), Axel Stordahl (PARISH/SIGNORELLI) all conducting “their own”orchestras; Peter Yorke and his Concert Orchestra (BERLIN); Fred Hartley and his Music (HARTLEY); Manuel (pseudonym for Geoff Love) and the Music of the Mountains (Theodorakis); Boston Pops Orchestra/Arthur Fiedler (MASON); Group-Forty Orchestra/Eric Cook (FRENCH and MARLAND); Hollywood Studio Symphony Orchestra/Mitchell Powell (NORTH); The Knightsbridge Strings (RACE); Pinewood Studio Orchestra/Philip Green featuring Johnny Dankworth (saxophone) (GREEN); The Paris Studio Orchestra/Philippe Pares (ROGER); Queen’s Hall Light Orchestra/Charles Williams (WILLIAMS); Studio Orchestra/Adolph Deutsch (DEUTSCH); The Symphonica Orchestra/Curt Andersen (SCHICK and Chacksfield); Telecast Orchestra/ Charles Williams (DUBOIS and FARNON)\nrec. re-issues from 78 rpm discs and 33 rpm LP records, recorded between 1946 and 1959. ADD\nGUILD GLCD 5166 [77:38]\nAnother great selection from Guild, full of the most delicious things. George French’s title piece, Highly Strung, is a wild scherzo in the manner of David Rose’s Holiday for Strings, with lots of swirling string movement and great support from the brass and winds. Jack Mason’s Pops Polka is a typical Boston rush and Steve Race’s Ring Ding has a touch of Latin about it. Very nice.\nI am a big fan of Roger Roger, and it’s good to have his racy Paris Pullman here, perhaps not exactly highly strung but it does have a great string tune. David Rose’s compositions really do grow on you, and Gay Spirits is a delightful concoction which has some splendid pizzicato writing, not to mention a lovely violin solo. Bob Farnon’s Little Miss Molly has a Ravelian fairytale quality about it. It’s a delightful miniature with a prominent part for flute. Lovely. Zez Confrey, sans both kitten and keys, but armed with a xylophone delivers a good tune, with great orchestration - especially in the middle section for piano with a guitar or banjo in the background! Alex North is a much underrated composer and I welcome this excerpt from his music for The Wonderful Country - Americana at its very best. Charles Williams’s Toy Violin is a perfect pizzicato study. Fred Hartley’s Jack In The Box is a lovely piece of chamber music swing - of the kind sometimes offered by Alec Wilder.\nSong of Lisbon is the kind of music you’d hear in a Mexican-set western of yesteryear, “we go to de cantina and drink wiz dee greengos”, and the cool sax of the late Johnny Dankworth graces Philip Green’s theme from Sapphire - a fine composition. Gaste’s Le Soir is a sleepy cor anglais and strings duet which is followed by a sterling Ronald Binge arrangement of Harry Warren’s (known, quite rightly, as ‘Mr Hollywood Musical’) Afraid To Dream, a beautiful song very well served by its arranger. The illustrious Clive Richardson, under a pseudonym, gives us a lovely string melody with the additional of a trumpet with felt mute. This is a lovely relaxed desert island thing.\nOK, so I’ve gone to my favourites first, but can you blame me? If I didn’t it would be impossible to know where to start. For the rest there are pleasures aplenty. Schick’s Sheerline is made of the finest denier. Cry Of The Wild Goose is a bongo-driven flight, a fabulous Philip Green arrangement here. Cesana’s Whirlwind is a depiction of the wind, with romantic music in the middle, how strange this is; perhaps he had a film scene in mind. It was Cole Porter who introduced the world to the beguine and here Frank Chacksfield offers a rather lovely one, with a haunting theme, not to be forgotten in a hurry. Debussy wrote a Marche écossaise and to match it, another Frenchman crosses Hadrian’s Wall and gives us a Gigue Ecossaise, which is great fun. Ron Goodwin’s All Strung Up has the feel of the coffee bar to it, but no Teds are in evidence. Perpetual Notion, a nice title, is reminiscent of Bernstein’s Three Dance Episodes from On The Town.\nFor the rest, the most important is probably Adolph Deutsch’s underscore from Some Like It Hot, a real slice of Hollywood, but with a most unsatisfactory, inconclusive ending. But that’s the trouble with underscore. It comes and suddenly it’s gone!\nGuild has done it again, compiling a fascinating collection of pieces in excellent sound, and with helpful, but not exhaustive, notes. I have a list of pieces I’d love them to do and my mouth waters at what delights they will come up with next. As ever, I am all anticipation. This is an invaluable series.","The antithesis of bebop, cool jazz eschewed the fast tempos and jagged phrasing in favour of a lighter tone and tempos that were slower and more relaxed. In this article we highlight some of the most famous cool jazz albums and musicians…\nThe term ‘cool jazz’ came into popular use around 1953 but had previously been used to describe Miles Davis’s short lived nonet that recorded between 1948 and 1950.\nPrior to that, the term could equally be applied to the music created by Bix Beiderbecke and Frankie Trumbauer in the 1920s. Trumbauer played his C-melody saxophone with a gentle, light toned and lyrical approach that greatly influenced the cool sound of Lester Young.\nThe sound of cool jazz seemingly gravitated to the West Coast of America as opposed to the bebop and later hard bop sounds that were evolving on the East Coast. Cool jazz would therefore become synonymous with California and dubbed as West Coast Jazz.\nCool Jazz music was also often more formally arranged and would not be averse to introducing other musical genres into the arrangements. Western classical music was perceived as a major source of inspiration with the use of orchestral textures and use of dynamics.\nHere’s our round up of the most famous cool jazz musicians of all time…\nWith his light tone on the alto saxophone, Desmond was one of the early cool school musicians. His career would inextricably linked with that of pianist Dave Brubeck, and as member of Brubeck’s quartet the altoist would establish his own style and a blue print for other generations to follow and learn from.\nSuch was the relationship between the two, and Brubeck knowing what an asset he had in his saxophonist that he insisted that Desmond sign a contract stating that he would not record with any other pianist. As such recordings under the saxophonist’s leadership would feature the guitar as the chordal instrument, and he would also record without a harmony instrument as in his albums with baritone saxophonist, Gerry Mulligan.\nIt was with Brubeck he would record his greatest work and in 1959 Desmond contributed the tune ‘Take Five’ to the pianist’s repertoire which would go on to become a big hit, and feature on the classic Time Out album.\nRecommended Listening: Dave brubeck Quartet – Time Out (Columbia – 1959)\nAs a young man trumpeter Chet Baker appeared to have it all. The good looks, relaxed and easy singing voice and a trumpet sound that was light and lyrical. Unfortunately, he also had a lifelong drug habit that would plague his career and resulting in several spells of imprisonment.\nAs a musician Baker’s playing almost seems effortless. He has been criticised for his limited technique and fondness for playing in the instruments middle register, but his fluid improvisations, impeccable time and beautiful tone have ensured his playing was always worth hearing. As a singer, Baker had a very quiet voice and used a limited range to maximum expression in much the same way as he played the trumpet.\nApart from his own records, Baker was a regular feature on the West Coast scene, and was a member of baritone saxophonist Gerry Mulligan’s pianoless quartet. With Mulligan he recorded ‘My Funny Valentine’ which became a hit and Baker’s signature tune.\nRecommended Listening: Let’s Get Lost: The Best of Chet Baker Sings (Pacific Jazz – 1956)\nA highly accomplished arranged as well as saxophonist, Mulligan played the big baritone saxophone with a light and airy sound that was perfectly suited to the emerging cool jazz in the latter part of the 1940s. It was while he was working for the band leader Claude Thornhill that he met fellow arranger Gil Evans. The two men had much in common, and wrote and arranged for a rehearsal band that would gather at Evans’s apartment.\nWith trumpeter Miles Davis who would take charge in calling rehearsals and booking the band for a fortnight at the Royal Roost, so was born the Nonet that would record a series of sides for Capital that would become known as The Birth of the Cool.\nA few years later Mulligan would form his famous pianoless quartet with trumpeter Chet Baker where the two horns would jettison the idea of playing in unison, but instead play contrapuntal lines that gave the music a freshness and spontaneity that became very popular and resulting in hugely successful recordings.\nAfter the quartet broke up, Mulligan would continue to lead a small band and alternate this with his love of big bands, forming his Concert Jazz Band in 1960. He would continue touring with both small and large ensembles until his death in 1996.\nRecommended Listening: The Original Quartet (Blue Note – 1953)\nRenowned for being an educator and one of the first musicians to teach improvisation in a structured manner, Tristano was also a uniquely gifted and original piano stylist. His mature work found his discarding much of the bebop language and basing of music on harmonic freedom and flexibility and a use of rhythms that would become increasingly complex.\nHe was not a fan of drummers and when recording some of the first contrapuntal free improvisations in 1949, ‘Intuition’ and ‘Digression’ he did so sans drums. The key players on these improvisations were guitarist Billy Bauer and the saxophonists Lee Konitz and Warne Marsh.\nOften criticised for being too cold and intellectual, Tristano continued upon his chosen path. He was not one to record prolifically but has left behind and invaluable body of work that stuck to his premise that music should not be about over sentimentality or expression, buut what mattered was the purity of the line and improvisation. As such Tristano had his own disciples who continued to pursue this line of thought, the most well known being Lee Konitz and Warne Marsh.\nRecommended Listening: Lennie Tristano / The New Tristano (Rhino/Atlantic – 1955-61)\nOne of Tristano’s most well known followers, unlike fellow saxophonist Warne Marsh Konitz did deviate from the path laid out by the pianist but retained his connection to the cool jazz style of playing.\nAt just twenty years old, Konitz found himself playing on all the sessions for the historic Birth of the Coolrecordings, one of only four musicians to do so. The recordings, and Lee’s solos marked him out as an original that was not beholden the all-pervading influence of Charlie Parker.\nStudying with Lennie Tristano in the 1950s, Konitz purged his alto style yet further taking onboard the less is more philosophy and creating beautifully flowing lines.\nKonitz went onto develop his style by focussing on standards. Armed with a fairly small repertoire, Konitz would ensure that he knew the tunes intimately. By doing so he was able to play the same tunes night after night and they would always sound different. Each time he performed he was intent on not repeating himself.\nRecommended Listening: Motion (Verve – 1961)\nAs a pianist and arranger, John Lewis’s lasting contribution to the music was with the Modern Jazz Quartet. After the exuberance of the big band of Dizzy Gillespie with who he had been composer, arranger and pianist he needed a change and with vibraphone player Milt Jackson he formed the Modern Jazz Quartet.\nThe classically trained Lewis was looking to form a band that played as a cohesive ensemble, and where the emphasis was not on the soloist. As a result, much of the music composed by the pianist was scored with passages for improvisation. Influences from classical music also seeped into Lewis’s writing for the MJQ moving the music away from the cool school with the emphasis on a new kind of chamber jazz. From Bach to blues, the MJQ were a popular attraction, and Lewis’s reputation was established with his contribution to The Birth of the Cool, and his forays into Third Stream Jazz that sought to bring the influence of classical music to the fore.\nRecommended Listening: Modern Jazz Quartet – Dedicated to Connie (Atlantic Records – 1960)\nSaxophonist Art Pepper was a successful ambassador for West Coast Jazz throughout his career. Falling under the spell of Charlie Parker, he also retained traces of the giants of the swing era Benny Carter and Willie Smith, he quickly developed his own sound on the alto that owed little to anyone else, his tone alternating between acerbic and a lyricism that held a tinge of sadness.\nHindered by spells in prison for drug offences, his career was a stop start affair but when he played he always seemed to be able to deliver the goods, and he recorded prolifically from 1951 until his death in 1982. He would often record with a quartet, but there are fine examples of Pepper with a large West Coast style ensemble in which his alto sound would cut through, and we occasionally get to him on his first instrument, clarinet and tenor saxophone.\nRecommended Listening: Meets The Rhythm Section (Original Jazz Classics – 1957)\nTrumpeter and flugelhorn player Shorty Rogers was one of the leading lights of the West Coast school throughout the 1950’s. A gifted arranger he would work for both the big bands of Stan Kenton and Woody Herman, and as the vogue for West Coast cool gained in popularity, Rogers never seemed to be out of the studio.\nRecording a substantial body of work for RCA throughout the decade, frequently with the luxury of a top flight big band assembled for the occasion the music is of a consistantly high standard.\nPerhaps in danger of being neglected in recent years it is well worth the time to check out Rogers’s work.\nRecommended Listening: The Sweetheart of Sigmund Freud (Giant Steps – 1946-1953)"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:7de46fb2-c0e0-4db4-9b1b-c00f5da027b6>","<urn:uuid:086e07a6-0bcf-49f9-9174-1b7f991c423b>"],"error":null}
{"question":"What are the contrasts between Roman Torres' personal triumph in soccer and the strategic challenges faced by vertical farming companies in terms of location selection?","answer":"Roman Torres achieved personal triumph by scoring a crucial goal that sent Panama to their first World Cup, transforming him from team captain to national hero. His success was tied to specific locations - the Estadio Rommel Fernandez where he scored the historic goal, and Seattle where he won the MLS Cup. In contrast, vertical farming companies face complex location-related challenges. While they can technically operate anywhere, choosing optimal locations involves careful consideration of factors like energy costs, proximity to distribution centers, and regional market conditions. Urban centers, despite seeming ideal, may be counterproductive due to high operating costs and distribution challenges. Success in vertical farming depends heavily on selecting locations in regions with water scarcity (like Sub-Saharan Africa), extreme climates (like Scandinavian countries), or limited agricultural land (like Singapore), where their benefits can outweigh their higher operational costs.","context":["Roman Torres' life changed with 1 shot and 1 memorable goal\nSOCHI, Russia (AP) — In the euphoria of the moment and the kind of exhilaration he had never experienced before, Roman Torres completely lost sense of time.\nHe ran, and screamed, and ripped off his shirt amid the noise echoing through Estadio Rommel Fernandez creating a haze of joy and excitement. When the celebration finally dispersed and reality hit there was still work to do, Torres placed his hands over his mouth and made a request of the referee issuing him a yellow card for being too exuberant.\n\"I asked him how much time was left and that he end the match quickly,\" Torres recalled.\nIt's been eight months since that night in Panama City when Torres became a national hero. Tied 1-1 in the 88th minute against Costa Rica and in need of a goal to keep its World Cup hopes alive with the United States flopping at Trinidad and Tobago, Torres unleashed a right-foot bolt from 11 yards in front of goal, beating goalkeeper Patrick Pemberton. In an instant, Torres sent Panama to the World Cup for the first time with his winning goal — knocking out the U.S. — and cast himself as an unforgettable figure in his country's history.\nOne moment. One shot. A long-awaited World Cup appearance that begins Monday night on the edge of the Black Sea with Panama facing Belgium.\n\"I really enjoy it. I enjoy it because it's a moment that God has gifted me and I am going to enjoy it to the fullest,\" Torres said through an interpreter. \"It's something that I always dreamed about, going to a World Cup with the First Team. I had been to World Cups with the youth teams, and the truth is that my dream is achieved. I think that now instead of just enjoying it, it is time to work hard and have a good World Cup.\"\nIt's one thing to be a star in a soccer-crazed country. It's another to be responsible for a moment of unbridled joy and euphoria.\nHere's the thing about Torres: he was already widely recognizable. Whether it's his stature at 6-foot-2, his wide grin or his big hair, it was easy to pick out Torres in a crowd.\nAnd then it became amplified in a way even Torres could not have expected. He went from being the captain of the Los Canaleros, to national hero. On the cusp of another devastating shortcoming on the soccer field, Torres and his right boot became etched in Panamanian history.\nNow something mundane like going to the store can turn into a crush of fans wanting their moment with Torres. Trips to his old neighborhood are mob scenes.\nHe didn't ask for this type of attention and notoriety. He accepts it as part of who he has become.\n\"For the most part I enjoy it, but when I'm with my family I'd prefer to have some privacy,\" Torres said. \"It's something that fills me with pride to know that all of Panama loves me not just for that goal but also before, when the people have believed in the national team, they have always supported and respected the players and that's something that makes all the players proud.\"\nJust a few years ago, Torres being in that position was in question. Shortly after his arrival in the United States to join the Seattle Sounders in MLS, Torres sustained a torn ACL in his left knee and was sidelined for nearly a year.\n\"When I got injured I had times when I thought that I wasn't going to be able to return to soccer,\" Torres said. \"It was a moment of anger when I was told that I would be out for almost a year. It felt like the world was collapsing around me. After some time, I simply asked God to give me strength and the will to sacrifice myself every single day to get up early for my therapy, to give me mental fortitude. I think that was the case.\"\nWhen Torres returned, he played with the same aggressive, attacking style of defense that first attracted the attention of MLS and made him a stalwart for Panama. Yet he'll be forever remembered in Seattle for his right foot, just like he is in Panama. Torres scored the deciding penalty to win the 2017 MLS Cup for Seattle, giving the club its first league championship.\nThat goal was a precursor for what he did for Panama. And Torres understands the task beginning Monday night — while a moment of immense pride and emotion for himself and his teammates — will be tougher than anything they've faced.\n\"Getting to the World Cup wasn't easy,\" Torres said. \"Now we are there and the truth is that to win a game or to advance to the next round, we'll need to work twice or three times as hard as what we have been doing so far to achieve that objective. That's the mentality that we have.\"\nMore AP World Cup coverage: www.apnews.com/tag/WorldCup","Vertical Farming: Location a Key Factor to Success, Says IDTechEx\nVertical farming, the practice of growing crops indoors on vertically stacked layers, has received no small amount of interest over the last few years. Vertical farms commonly tout impressive numbers, such as using 95% less water and providing crop yields 20-30 times that of conventional agriculture. These claims, among many others, have seen many vertical farming start-ups being founded alongside large amounts of industry funding; funding for the industry reached a record high in 2021, with over US$1 billion being raised across the entire industry. The recent IDTechEx report, \"Vertical Farming 2022-2032\", details the economic and technological factors shaping this rapidly growing industry.\nWith crops being grown indoors under controlled environments, a selling point used by multiple vertical farms is that they can grow crops anywhere – even in the heart of a city. This has led to proponents of the industry envisioning \"smart cities\", where vertical farms in city skyscrapers help feed the urban population. While this is achievable in principle, the truth is that the choice of location for vertical farming is much more involved and intricate than it may appear from these claims alone. Choosing an ideal location can be one of the most important factors in determining the success of a vertical farm.\nSome vertical farms may choose to set up their facilities in pre-existing facilities, such as abandoned warehouses. In these cases, identifying the suitability of the venue is the first point of consideration: vertical farms are very energy intensive, and it is important to ensure the facilities chosen can support these energy loads. In addition, the ergonomics of the facility is also important; should the layout not be given proper consideration, this can impede workers and decrease worker efficiency. As labor costs are typically among the largest sources of expenditure for a vertical farm, improving labor efficiency to reduce these costs is of paramount importance.\nWhile growing crops in the center of a city may seem ideal, the reality is that this may be counterproductive. Obtaining and maintaining such a location is expensive and can contribute significantly to the operating expenditure of a vertical farm while presenting logistical challenges in distributing produce; the \"last mile\" of food distribution is often the hardest. Having a farm right next to the consumers themselves may also be less ideal than instead choosing a location near food distribution centers, as this allows for more efficient delivery of produce. As distribution centers are typically located on the outskirts of cities, the cost of land is also much cheaper. This is the approach chosen by UK-based Jones Food Company, which chose Scunthorpe as a location for its vertical farm – this is a relatively low-cost location located near food distribution centers and a network of motorways that could still reach many consumers in a day, even if it isn't right in the middle of the capital city. Vertical farms should carefully consider their place in the supply chain before establishing a base.\nOn a larger scale, vertical farms may prove more profitable in different geographical regions. Vertical farms can reduce water usage significantly over conventional agriculture, and the high degree of control over the growing environment allows them to grow crops in extreme climates – where such crops may not otherwise be able to grow. In return, vertical farms demand more energy to carry out growing operations. To maximize their potential, vertical farms would ideally be located in regions of water scarcity, such as Sub-Saharan Africa and the Middle East, or in areas with extreme climates, such as in Scandinavian countries, where the low amounts of sunlight and high costs of regulating greenhouse environments single out vertical farms as an optimal solution. The amount of agricultural land available is also an important factor – regions looking to increase food security and reduce reliance on imports while facing challenges in acquiring sufficient agricultural land would find vertical farms to be ideal. A particularly prominent example of such a country is Singapore, which has demonstrated much interest in vertical farming over the last few years.\nBeyond the considerations of water scarcity and temperature, the general availability of fresh produce and the distribution networks of given countries should also be considered. Vertical farms use the added freshness and higher quality of their crops as a primary selling point, but these are typically offset by higher prices. Should there already be a large supply of high-quality produce made available at lower costs, vertical farms will find it hard to distinguish their own produce and may struggle to establish a significant market share. The converse would also be true; should a country lack easy access to fresh produce, vertical farms are expected to see much demand for their produce. An example of such a region would be the Middle East: leafy greens typically travel several thousand miles to reach stores, resulting in consumers facing high prices and low-quality products. The high price of conventionally farmed leafy greens, alongside government subsidies, makes it easier for vertically farmed produce to approach price parity while providing much fresher, higher-quality products.\nWhile the choice of location is an important consideration, it is only one of many others that must be given proper thought. Only through proper optimization of growing operations to improve efficiency and reduce costs can vertical farms reach their true potential. In the IDTechEx report, \"Vertical Farming 2022-2032\", many further important factors for consideration are discussed in detail, and the future of vertical farming is evaluated through 10-year market forecasts.\nIDTechEx guides your strategic business decisions through its Research, Subscription and Consultancy products, helping you profit from emerging technologies. For more information, contact research@IDTechEx.com or visit www.IDTechEx.com.\nThis post does not have any comments. Be the first to leave a comment below.\nPost A Comment\nYou must be logged in before you can post a comment. Login now."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:ad9b2540-0173-489b-9a7a-5f61a500280e>","<urn:uuid:98c0eed7-8d91-42cd-b0d1-cc7c105f9a4d>"],"error":null}
{"question":"Ciao! I'm researching throat anatomy and pronunciation across languages. What's la différence between how the uvula contributes to swallowing versus its role in producing uvular sounds in languages?","answer":"During swallowing, the uvula bends backwards to block the entrance to the nasal passage, ensuring food goes down the correct path and preventing it from going up the nose. It also produces thin saliva to coat the throat lining. In contrast, for speech production, particularly in the context of uvular sounds in languages, the uvula's position and movement contribute to making specific speech sounds, as evidenced by its role in producing the characteristic r sound in French dialects where it vibrates to create the sound.","context":["The uvula is that dangly thing that sits at the back of your throat.\nTechnically its full name is the palatine uvula but the full term isn’t normally necessary to use.\nA swollen, enlarged uvula can be extremely uncomfortable but is, fortunately, not as common as other forms of inflammation.\nAn inflamed uvula has a small number of potential causes so investigating why your uvula is swollen is not as difficult as other ailments.\nStill, taking some time to familiarize yourself with its normal functions can help you understand how uvula problems develop in the first place.\nWhat Is the Uvula?\nThe uvula is an organ that descends from the soft palate (the roof of your mouth)\nThe uvula is an organ that descends from the soft palate (the roof of your mouth), and has four primary functions:\nThe entrance to the nasal passage lies behind the uvula, and when you swallow it bends backwards slightly and blocks the opening. This keeps anything you swallow going in the right direction and prevents food from going up your nose.\nThe uvula produces a thin form of saliva whenever you speak or swallow, which coats the lining of the throat. If you have ever tried to speak with a dry mouth, you will understand how useful this can be. The uvula also aids in the production of certain sounds.\nAlong with the tonsils, the uvula helps trap microorganisms and prevents them from getting further into the body. The uvula also helps govern the gag reflex and the reflex’s strength partially depends on how sensitive a person’s uvula happens to be.\nThe uvula is thought to have some involvement with snoring or sleep apnea since it’s been observed to be enlarged in individuals experiencing these conditions. However, it’s unclear if the uvula’s size causes these issues or if the enlargement is the result of stresses caused by snoring or sleep apnea.\nSymptoms of a Swollen Uvula\nIn addition to a sore throat, a swollen uvula (called “uvulitis”) has several distinctive symptoms that can be easily recognized and reported to your doctor.\nThe most obvious symptom (besides pain) is that visual inspection will reveal an inflamed, enlarged uvula. The swelling can cause certain specific problems over its duration, including:\n- Trouble swallowing, as the enlarged uvula gets in the way of food.\n- Swollen tonsils. It’s rare for the uvula to be the only part of the mouth that swells, so seeing enlarged tonsils or other areas is not uncommon.\n- Trouble breathing, especially if the tonsils are also affected.\n- Difficulty talking. Due to the role the uvula plays in sound production and how swelling can affect other parts of the throat, hoarseness can develop.\n- Gagging, as the uvula potentially brushes against the back of the tongue and triggers the gag reflex.\n- A persistent feeling of something being lodged in your throat.\n- Possibly obstructive sleep apnea if the uvula is able to block the airway when lying down.\n- Nasal regurgitation (where food/drink comes out of your nose).\n- Fever (if caused by infection).\nWhat Causes a Swollen Uvula?\nThere are only a few potential causes of a swollen uvula and fortunately, most are easy to identify or rule out.\nMuch like the tonsils, a uvula infection can develop if the immune system is unable to dispatch a trapped pathogen. As the uvula becomes infected, it will inflame and swell. Both bacterial and viral infections are capable of causing uvulitis, including strep throat, mononucleosis, or respiratory tract infections.\nIt’s worth noting that anything capable of infecting the uvula is also able to infect the tonsils and epiglottis, a muscle at the back of the tongue, causing them to swell as well. A swollen epiglottis is especially dangerous in children since it can block the airway. A child with a swollen uvula should be evaluated by a doctor in order to rule out this risk.\nAllergic reactions can trigger a rapid fluid buildup in parts of the throat and mouth, leading to swelling. If the reaction is severe enough, the fluid (edema) can spread into the uvula and make it swell.\nThis is usually a sign that an anaphylactic reaction is occurring and requires immediate treatment. Administer an epinephrine shot (EpiPen) or seek emergency medical attention at once.\nA cleft lip or cleft palate is a type of congenital trait which affects the roof of the mouth. This can result in changes to the uvula such as it being enlarged, off-place, shrunken, or missing altogether.\nAn elongated uvula is also hereditary and although this is not swelling per se, it can cause many of the same symptoms due to its size. There is also a rare genetic condition called hereditary angioedema that causes swelling in various parts of the body and can sometimes affect the uvula.\nA dry mouth is actually the most common cause of uvulitis and results from persistent irritation. Anything capable of causing a persistent dry mouth, such as dehydration, is also capable of causing uvulitis by extension.\nAs with most parts of the body, injuring the uvula can cause it to swell, though fortunately uvular trauma is not very common. Trauma can occur as a result of injury to the throat or if the uvula is accidentally struck during the placement of a breathing tube (intubation). It’s also possible to get a swollen uvula after drinking or eating something especially hot through an inadvertent burn.\nTreatment for a Swollen Uvula\nA mixture of medical and home remedies can be employed to deal with a swollen uvula. Some solutions are more suited for swelling from certain causes more than others.\nThe main medications that are used in cases of a swollen uvula are antibiotics and steroids. Antibiotics should be used only if a bacterial cause has been identified and should be taken for the full course in order to ensure full eradication.\nSteroids help reduce swelling and may be employed in treating an allergic reaction. If the pain is difficult to manage, an analgesic may be used as well.\nChewing on ice will chill and numb the throat, both reducing swelling (especially if caused by irritation) and ideally easing pain.\nIn event of dry mouth, drinking water is the most obvious way to help keep everything properly lubricated. If the issue is not being caused by dryness, gargling salt water can help soothe inflammation in certain cases.\nHoney has antibacterial properties. Although it’s difficult to rub honey directly onto the uvula (though kudos if you pull it off), licking two teaspoons of honey a day can be a way to try and get some antiseptic action in case of an infection.\nWhen to See a Doctor\nA swollen uvula is not normally something that requires a doctor’s attention except to rule out bacterial causes. There are certain circumstances, however, where scheduling an appointment is strongly advised, such as:\n- The swollen uvula is in a child who is also showing signs of an infection (fever, coughing, etc.).\n- The swelling is creating significant breathing difficulties or interfering with sleep.\n- You have difficulty swallowing and are worried about choking.\n- The pain is not manageable on your own.\n- Pus or blood begins to come from the uvula. This is a sign that the swollen uvula has ruptured and requires immediate medical attention.","Anatomy of the vocal tract\nIn addition to their normal names, many of the parts of the vocal\ntract have fancy names derived from Latin and Greek. The adjectives\nwe use to describe sounds made with each part are usually based on\nthe Latin/Greek name.\n|lips || labia|| labial |\n|teeth || ||dental |\n|alveolar ridge || ||alveolar|\n|(hard) palate|| ||palatal|\n|soft palate ||velum ||velar |\n|uvula || ||uvular|\n|upper throat ||pharynx ||pharyngeal|\n| voicebox||larynx ||laryngeal|\n|tongue tip || apex || apical|\n|tongue blade || lamina || laminal|\n|tongue body||dorsum (back) ||dorsal|\n|tongue root || ||radical|\nIn phonetics, the terms velum, pharynx, larynx, and dorsum are used as often or more often than the simpler names.\n- alveolar ridge\n- A short distance behind the upper teeth is a change in\nthe angle of the roof of the mouth. (In some people it's quite abrupt, in others\nvery slight.) This is the alveolar ridge. Sounds which involve the area between\nthe upper teeth and this ridge are called alveolars.\n- (hard) palate\n- the hard portion of the roof of the mouth. The term \"palate\" by\nitself usually refers to the hard palate.\n- soft palate/velum\n- the soft portion of the roof of the mouth, lying behind the hard\npalate. The tongue hits the velum in the sounds [k], [g], and\n. The velum can\nalso move: if it lowers, it creates an opening that allows air to flow\nout through the nose; if it stays raised, the opening is blocked,\nand no air can flow through the nose.\n- the small, dangly thing at the back of the soft palate.\nThe uvula vibrates during the r sound in many French dialects.\n- the cavity between the root of the tongue and the walls of the upper throat.\n- tongue blade\n- the flat surface of the tongue just behind the tip.\n- tongue body/dorsum\n- the main part of the tongue, lying below the hard and soft\npalate. The body, specifically the back part of the body (hence \"dorsum\",\nLatin for \"back\"), moves to make vowels and many consonants.\n- tongue root\n- the lowest part of the tongue in the throat\n- the fold of tissue below the root of the tongue. The\nepiglottis helps cover the larynx during swallowing, making sure\n(usually!) that food goes into the stomach and not the lungs. A few\nlanguages use the epiglottis in making sounds. English is fortunately\nnot one of them.\n- vocal folds/vocal cords\n- folds of tissue stretched across the airway to the lungs.\nThey can vibrate against each other, providing much of the sound\n- the opening between the vocal cords. During a glottal\nstop, the vocal cords are held together and there is no opening between them.\n- the structure that holds and manipulates the vocal cords.\nThe \"Adam's apple\" in males is the bump formed by the front part of the larynx.\nNote: the textbook tries to distinguish between sounds made with\nthe backest part of the tongue body and sounds made with a fronter part\nof the tongue body. You may want to learn this distinction if you have\nnothing better to do with your time. I will consistently refer to all\nsounds made with the tongue body as \"dorsal\".\nTo look at pictures of slices of people till your heart's content, check\nVisible Human Project.\nNext: (Section 3) The idea of segments\nPrevious: (Section 1) Unstressed vowels\nUp: Table of contents"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:cd3d839c-f408-474e-9c08-1386ec7c539c>","<urn:uuid:2420d7f0-0ea8-4364-9b11-2189fcd6d4ce>"],"error":null}
{"question":"How do FPGAs handle latency challenges in signal processing, and what are the safety considerations for power dissipation in electronic components?","answer":"FPGAs address latency challenges through pipelining methods and partial parallelization of operations. While there are issues with internal elements like multipliers and adders not completing operations in one clock cycle, this can be resolved through pipeline delay balancing and architectural optimization. For fully pipelined systems, latency doesn't affect the resulting number of channels, though additional variables and signals are required. Regarding power dissipation safety, components must operate within their power rating to prevent damage. Exceeding power ratings can cause permanent resistance value shifts, reduced lifetime, or complete component failure. In extreme cases, excessive power can cause fires, though special flameproof resistors are available that create a circuit break before reaching dangerous temperatures. The safe dissipation of energy depends heavily on operating conditions and proper derating considerations.","context":["|Advanced Audio Recording|\nAdvantages of FPGAs in the field of Audio Processing\nAt first sight, audio processing appears to be an easy task in modern signal processing since the sample rate is mostly low. A more closer look discovers that because of the desired accuracy (16 Bits and more) quite a significant demand of calculation power is required to fulfill peoples needs such as with physical modeling. To understand the principles a deeper look at the architecture of FPGAs is required:\nAdvantages of FPGAs in Signal Processing\nFPGAs can perform basic calculations such as MUL / SUM and decision much quicker than Microcontrollers and also FPGAs can process many \"tasks\" parallely in real time. For example, a current DSP operating at 60MHz performs a 2nd order differential equation describing a sine oscillation in about 1us using sequential processing, variable treatment and RAM access, while an FPGA each single step of an equation or what else can be processed parallely leading to a so called pipeline where all resources are free again to be used in the next clock cycle. So, many channels / voices / cases can be processed. There will be only a latency of dedicated number of clock cycles. As long as the result of the calculation is not required to continue with the processing directly, tasks can thus be processed much more effectively in total. Although the basic system frequency might be higher with DSPs or CPUs, FPGAs can easily become much quicker than e.g. DSP solution. FPGAs are appropriate mostly for applications which require parallel processing. The more channels required - the better is the utilization on an FPGA.\nThe subsequent example shows a timing comparison for both FPGA and DSP for a 128 TAP sequential filter (equalizer):\nHere the DSP (left) needs 13 clock cycles to process one sample and it's corresponding coefficient. All TAPs of the filter are processed at 80 MHz leading to \"exactly\" the required speed to be ready within the period given by the 48kHz sampling frequency. More TAPs required more operation frequency of the DSPs. Unlike that the FPGA consists of combinatorial logic forming deciders and calculation modules which all could do operate simultaneously. This only leads to a latency of 7 clock cycles including RAM wait states. The final result of 23000 time steps appears worse at first sight and seem to tell us, that 2 of these instances were required to complete a full operation during the given sample rate of 48kHz and possibly process the upper and lower region of the samples. But since all actions are done in parallel, only 128 clock cycles + latency are required.\nThe common issue with FPGAs is the latency problem with internal elements like multipliers and adders, which might be not quick enough to complete their operation during one clock cycle. This can be solved by partial parallelization like show here for a multiplier structure:\nPipelining method to increase throughput at a DSP system in FPGAs.\nFPGAs typically run at lower speeds than DSPs when synthesis constraints are set that way that a balanced tradeoff between speed and area is focused where not too many additional FFs will have to be added in order to achieve the desired system frequency. Usually, this is about 3 times lower. On the other hand, FPGAs do process many operations within one single step where DSPs need 2 or more and thus come closer again to the DSPs in final data operation speed. However a ratio of 1:2 might persist at this point of view. But there is room for improvement: Because of full pipelined operation any residing clock cycle which is not required to complete the total number of operations of the channel which have to be done during one sample period can be used to generate more channels in simple pipelined systems. For fully pipelined systems, the latency has no effect anymore on the resulting number of channels. Only a further set of variables / signals is required for this, so balancing the pipeline delay with the architecture width is required. Tweaking the internal architecture that way, that complex operations like filtering are done the parallel way, saves pipeline delay and latency and increases the used area only moderately, where doubling the number of voices in a DSP system requires up to the doubled operation frequency.\nRead more about DSP-Systems for Audio Processing\n|© 2005 - Jürgen Schuhmacher|","What is the power rating of a resistor?\nThe power rating of a resistor defines the maximum energy a resistor can (safely) dissipate. As is stated by Joule’s first law, the generated electrical power is related to the voltage and current:\nWhen the electrical power equals the dissipated heat (by radiation, convection and conduction), the temperature of the resistor will stabilize. The temperature is not equal across the resistor. The resistor body is slightly hotter than the terminals, with the highest temperature at the center of the body. The higher the rate of heat dissipation to the environment, the lower the temperature rise will be. Larger resistors with a bigger surface area can generally dissipate heat at a higher rate. If the (average) power dissipation is larger than the power rating, the resistor may be damaged. This can have several consequences. The resistance value can shift permanently, the lifetime can significantly be reduced or the component is completely damaged resulting in an open circuit. In extreme cases the excessive power can even cause a fire. Special flameproof resistors are available, that cause a circuit brake before the temperature reaches a dangerous state.\nPower rating definition\nThe power rating of a resistor defines the maximum energy a resistor can (safely) dissipate.\nThe nominal power rating is defined for a certain ambient temperature in free air. Note that the amount of energy that a resistor in practise can dissipate without causing damage, is strongly dependent on the operating conditions and therefore not equal to the nominal power rating. For example, a higher ambient temperature can significantly reduce the power rating. This effect is referred to as derating. It should be taking into account by the designer. Often the power rating is chosen largely above the electric power. Typically resistors are rated for a temperature of 70°C, above this resistor starts to derate. This means that above this temperature the resistor can only utilize a reduced power level. This is illustrated by a derating curve.\nNext to the influence of the ambient temperature, there are several other factors impacting the derating. The most important factors are detailed below.\nThe rate of heat loss is limited by installing the resistor in an enclosure. The enclosure limits air flow and therefore the removal of heat by convection. Radiated heat will removed at a lower rate, because the walls of the enclosure act as a thermal barrier. The effect of the enclosure on the heat loss rate is strongly dependent on the size, shape, orientation, material and wall thickness. It is difficult to indicate how these parameters affect the temperature rise.\n- Forced cooling\nIncreasing the heat transfer by forced convection allows for a higher watt dissipation than for normal natural convection. This can be achieved by creating an air flow, or even liquid cooling. Some resistors are designed with conducting air fins, to create a bigger surface for heat dissipation.\n- Component grouping\nOn a circuit board resistors are often positioned close to each other. The heat radiation of one resistor will be received by the next resistor and therefore have an extra increase in temperature for a given power consumption.\nResistors loose heat by convection and radiation. When the air density decreases, the convection will also decrease. Above 30 km convection has dropped so low that only heat dissipation by radiation exists.\nFor most electronic circuits the power rating is not a key parameter, since those resistors dissipate low amounts of energy of one watt or less. In power electronics however, the power rating is an important characteristic. Generally speaking hereto is referred when power ratings are one watt or higher. Typical applications include power supplies, dynamic brakes, power conversion circuits, power amplifiers and heaters."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:fcf6192f-b328-4958-aef1-115e12e7c727>","<urn:uuid:6ea5ae99-d439-44fa-8fc2-fc282c5e0351>"],"error":null}
{"question":"Can you compare the key functions of a radome in protecting satellite antennas versus radar equipment? What are their main protective purposes?","answer":"Both radar and satellite antenna radomes serve critical protective functions but with some distinct focuses. For radar equipment, radomes primarily protect against environmental threats including rain, wind, hail, snow, sand, insects, bird strikes, UV damage and temperature fluctuations. They also prevent debris, ice and freezing rain from accumulating on metal surfaces. For satellite antennas, radomes specifically protect against extreme conditions at varying altitudes, functioning from ground level up to 40,000 feet and in temperature ranges from -60 to +50 degrees Celsius. They protect the delicate satellite antenna and its moving parts from heat, pressure and humidity that could otherwise reduce their lifespan. In both cases, the radomes must be essentially transparent to radio frequency signals while providing physical protection.","context":["Protecting Signal Strength – General Plastics’ Foam for Radomes\nFrom defense and solar system research to boats and aircraft, radome structures perform the function of protecting radar equipment. These weatherproof shells transparent to radio frequency systems, notably radar, microwave, and other antennae, are used for signal transmission and capture that do not affect the signal passing through them. Although “radome” is a blend of “radar” and “dome,” these protective structures are not always dome-shaped but come in many different types, which include flat panels covering sensitive components of antennas on large dishes and small radar systems used in naval applications.\nGeneral Plastics’ polyurethane foams are commonly used as composite materials and offer dielectric properties for constructing radomes and related housings. They provide an optimal, insulating barrier between sensitive electronics used in communication, telemetry and radar systems and environmental threats posed by rain, wind, hail, snow, sand, insects, bird strikes, UV damage and rapid fluctuations in temperature.\nWide-ranging radome applications\n- Security/Military/defense – Radomes protect and conceal electronic surveillance equipment, such as that used to intercept satellite communications and other radar air defense applications. They support military aircraft platforms for reconnaissance, electronic warfare, defense and preemptive strikes, data links and electronic countermeasures.\n- Stationary antennae – Radomes prevent debris, ice and freezing rain from accumulating directly onto the metal surface.\n- Commercial aircraft – Needed for navigation or communications, commercial flights rely on signals. Radomes used in protective structures on the noses of aircraft ensure optimal antenna functionality for weather detection.\n- Maritime satellite communications – Ships employ radomes to protect dish antennae used to continually track fixed satellite and for navigation.\n- Broadband communications – On oil tankers and large cruise ships, radomes extending more than three meters in diameter may cover antennae connecting them to voice, data television and Internet transmissions.\n- Private yachts – Small private yachts may use radomes as small as 26 cm in diameter for voice and low-speed data.\n- Solar system research – NASA uses large radar dishes in far-flung, uninhabited areas that offer minimal pollution of signal.\nWhy polyurethane foams are optimal for constructing effective barriers\nRadomes built using suitable materials and configured properly for the application and radio frequency range are essentially invisible electronically, preventing negative impact on the performance of the signals produced or captured. Versatile, robust and cost-effective, our polyurethane foams offer high performance and low dielectric interference, with superb dimensional stability. Two reasons they don’t change over time is that these foam materials are closed-cell and hydrophobic: They do not absorb water. Water is highly polar and can cause them to lose their properties or change over time.\nWhat’s more, in extremely cold and windy environments, foam structures surrounding radar dishes prevent snow and wind from moving them around. And, as a natural insulator, our foam material prevents cold and heat from transferring, slowing down potentially undesirable changes in temperature. For example, in the transition from night to day, an unprotected antenna in direct sunlight can heat up quickly, jeopardizing performance and longevity.\nGenerally, radomes are fabricated using layup or prepreg methods in which resin-reinforced laminate materials are readily bonded to low- or medium-density rigid polyurethane foams. Our polyurethane foams are already renowned for supporting composite structures, which capitalize on their high strength-to-weight ratio.\nAll of General Plastics’ foam material holds distinct characteristics and advantages that help determine their applications. Specific General Plastics foam feature low dielectric constant and low loss tangent, making it ideal for radome applications. Material selection may also depend on the shape or contours of the sensitive electronics being covered and how imperative it is to protect them. The polyurethane foams best suited for these applications are our LAST-A-FOAM® FR-3700 Performance Core series and FR-7100 Multi-Use Core series.\nLAST-A-FOAM® FR-3700 has specifically engineered properties that make it tougher and more durable than the FR-7100. The FR-3700 is able to handle rugged environments for a given density, such as those needed for military and defense applications that dictate the highest levels of protection. This performance core series is flame-retardant, is an excellent alternative to wood, resistant to most chemicals and solvents, and has a high-strength to weight ratio.\nAlthough not as tough as the FR-3700, our LAST-A-FOAM® FR-7100 is sufficient and more affordable for applications involving less risk. Other benefits of this multi-use core series include its fine cell structure that supports smooth finishes, dimensional stability, and its closed-cell characteristic that does not absorb water or moisture. We recommend using FR-7100 for applications that allow for more variation or have less performance requirements.\nLarger radomes typically have simpler exposure requirements. For example, a very large radome in Alaska only has to handle some wind and potentially hail, whereas a naval ship or a weaponized system will call for a tougher, more significant composite to protect that radar system from loss. This is also a function of foam formulation and density driving material properties.\nTesting conducted on General Plastics’ signature LAST-A-FOAM® materials (see our dielectric materials white paper for dielectric constant and loss tangent data), demonstrates how the foams performed well under a range of applied microwave frequencies without significant heat loss. Our products are proven impervious to moisture and virtually transparent to radio signals, they are the leading choice for protecting aerospace, marine and land-based microwave antennae.\nOur polyurethane foams can be provided in three ways: 1) as sheet stock, which can be further modified to meet customer needs, 2) machined to shape based on a supplied drawing with dimensions noted and 3) as a molded part. In addition, for some applications, we can provide material cast to a specified shape.\nRegardless of whether you are selecting foam material in boards or blocks, or you rely on General Plastics for machining or finished product, we advise contacting our Customer Solutions team early in the design process. Each query may be very specific, so tap our expertise to identify in advance the design’s impact on cost. Our technical data sheets for each product also provide valuable guidance.\nComposite Core: Factors to Consider When Choosing Core Material for Your ApplicationRead More\nGeneral Plastics’ Aerospace-Grade Core Materials and Built-to-Print Polyurethane Parts For the Business Aviation IndustryRead More\nGeneral Plastics to Feature High Temp, Low CTE Tooling Board, Dielectric Foam and Other High Performance Polyurethane Foam at CAMX 2019.Read More\nGeneral Plastics to Spotlight Lightweight Composite Core and Dielectric Materials at SAMPE, May 22-23Read More","Spare a thought for the little white bump sitting on top of an aircraft. What you are looking at is probably a radome – a cover for the sophisticated satellite connectivity system sitting underneath it.\nBut what exactly is a radome and why are they so special?\nThe radome has two basic functions. The first is to protect the delicate satellite antenna and its moving parts from the extremes of heat, pressure and humidity that would otherwise shorten their life.\nGiven that it must work from zero to around 40,000 feet, and in temperature extremes that range from perhaps -60 degrees to +50 degrees Celsius, you start to see some of the technical challenges associated with manufacturing radomes.\nA radome’s other function is to be as transparent as possible to the incoming and outgoing microwave signals to and from a satellite.\nThis latter function is more difficult that it sounds. Materials used in radome construction must be free of carbon fibre conductive particles. These would attenuate the signals to such an extent that your connectivity system wouldn’t work.\nMost radomes are glass, quartz, polyethylene or aramid-based and are designed for transmission efficiency. The materials used have to possess low dielectric constants and low moisture absorption qualities. This allows increased efficiency from the antenna and very low resistance to electromagnetic waves.\nThe exact material will depend upon the frequency being used. L-band systems (such as Inmarsat SwiftBroadband) use frequencies around 1.6MHz, but Ku-band (as used by Panasonic) is about 12-18GHz (12-18,000MHz) and Ka-band (Viasat Exede and Inmarsat GX) is up around 26.5-40GHz (26,500 – 40,000MHz).\nEvery material will respond differently to these different frequencies, so a radome is generally designed for one particular band, although some can cope with all frequencies.\nLet’s look at a quick case study.\nWhen LiveTV was looking for a new radome for its new Ka-band system that uses ViaSat’s satellites, contractor General Dynamics Armament and Technical Products (GDATP) selected a quartz fibre/epoxy material from TenCate Advanced Composite in California.\nQuartz would have given the best transmit performance, but the TenCate epoxy resin brought cost savings to the project.\nThe triband radome had to maintain the lowest possible profile to preserve aircraft aerodynamics and meet a strict weight requirement, yet provide ample clearance for the antenna hardware underneath it.\nGDATP used computer modelling to determine what the RF characteristics of the radome might be before committing to a design.\nThe company analysed several radome profiles that LiveTV and ViaSat had identified as possible solutions, along with options developed in-house.\nThe programme concluded with testing to validate its performance and FAA certification. This includes bird impact and lightning strike tests.\nThe FAA mandates that bird strike tests are required to demonstrate that a flight can be successfully completed with any structural damage sustained if a radome is struck by a four-pound bird at speeds of more than 400 miles per hour.\nAnd according to statistics published by the Royal Canadian Air Force, a plane can be struck by lightning on average every 1,000 to 3,000 flight hours. For commercial aircraft, that’s equivalent to one strike per aircraft per year.\nRadomes are tested with multi-megavolt generators and real-life lightning can produce up to 200,000 amp currents.\nThe tests were fine and the rest is now history with LiveTV, now part of Thales, launching its Ka-band service on JetBlue and United Airlines.\nSo next time take a closer look at the little white blob on the top of your aircraft’s fuselage. There’s more to it than meets the eye."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:76f67e3e-32fc-4375-80cb-bba94bd34a49>","<urn:uuid:d19bc8eb-6c28-4a82-b8b5-61bb22cea249>"],"error":null}
{"question":"How does Axon's integration of drone technology affect police surveillance capabilities, and what are the racial bias implications of this surveillance system?","answer":"Axon's partnership with DJI allows for integration of drone footage into Evidence.com, a cloud-based database used by over 200,000 public safety professionals that combines drone, body-camera, police-car-camera, and CCTV footage. This creates a comprehensive surveillance system where all digital data can be associated with a single case file. However, this system raises significant concerns about racial bias, particularly given the documented issues with facial recognition technology. Studies have shown that facial recognition systems have dramatically higher error rates for Black individuals, especially Black women (up to 36% error rate) compared to light-skinned males (0.8% error rate). This disparity could perpetuate racial profiling, as police surveillance technologies have historically been used with bias against people of color.","context":["A company that makes stun guns and body cameras is teaming up with a company that makes drones to sell drones to police departments, and that might not even be the most worrisome part. The line of drones from Axon and DJI is called the Axon Air, and the devices will be linked to Axon’s cloud-based database for law enforcement, Evidence.com, which is used to process body-camera data too. And it could open a vast new frontier for police surveillance.\nBy working with a company that is already familiar with contracting with police departments, the Chinese-owned DJI—the world’s biggest consumer drone manufacturer—could widen up a new, growing customer base: cops. Axon Air, which was announced Tuesday by Axon, is marketed as a way to help law enforcement with search-and-rescue operations, crowd monitoring, traffic-accident reconstruction, and evidence collection. It will make drone data the latest addition to Axon’s suite of tools for police, which include tasers, body cameras (of which Axon is the country’s biggest seller), and car cameras. Axon CEO Rick Smith recently said that his company is actively considering using facial recognition with its camera technology.\nThe company seems to be aware of the troubling societal implications—or at least the ugly optics—of such a move, announcing in April that it was setting up an artificial intelligence–ethics board to inform its use of A.I. in police surveillance tech. Nevertheless, that announcement sparked serious concerns, among civil rights and technology-privacy advocates including the NAACP and the American Civil Liberties Union, that pairing Axon’s products with A.I. could further perpetuate racial profiling by police. For example, a mug-shot database that may be scanned to match footage from a police body camera is likely to have more photos of black faces than white ones. So if police pull over a black driver, the officer could be more likely to match his or her image with a mug shot and engage in further questioning, while a white person pulled over might be less likely to generate a match.\nDespite Smith’s statement, Axon told me it isn’t currently working to deploy facial recognition in its cameras. “While we do see the value in this future capability, we also appreciate the concerns around privacy rights and the risks associated with mis-identification of individuals,” spokesman Steve Tuttle wrote in an email. But it’s not just surveillance that some advocates are wary of when it comes to the police-tech company getting into the drone game. “Axon also makes tasers, so you could imagine drones being equipped with tasers or with tear gas, rubber bullets, and other weaponry,” said Harlan Yu, the executive director of Upturn, a policy nonprofit that works on social justice and technology issues. This isn’t necessarily hypothetical. In 2015, the North Dakota legislature passed a law that legalized the use of armed drones by law enforcement, Yu pointed out. Axon has already demonstrated how a stun gun can be added to a drone.\nEvidence.com, according to Axon’s press release, is currently used by more than 200,000 public-safety professionals. According to Axon’s Tuttle, “all digital data including PDFs, crime scene photos, CCTV footage, in-car cameras, and now DJI drone video can be associated to a single case file”—meaning it’s possible to look up a case involving a camera mounted in a police car and see if the same case also has drone footage associated with it. Tuttle said that law enforcement agencies own what they upload to Evidence.com, even though the repository itself is owned and maintained by the company. But that doesn’t mean police departments can’t share that data with other law enforcement agencies—many already share their surveillance data, through various databases—nor does it mean Axon can’t request to access to the data to, say, train artificial intelligence systems. Vigilant Solutions, a police-surveillance-technology company that specializes in storing license-plate-reader data used by law enforcement, allows police departments and federal agencies across the country to share their data with each other, including at times between police departments in sanctuary cities and agencies within Immigration and Customs Enforcement.\nBy combining drone, body-camera, police-car-camera, and closed-circuit-TV footage, Axon is clearly hoping to create a central hub for police to cross-reference and access surveillance data—a treasure chest of information that, according to Elizabeth Joh, a law professor at the University of California–Davis who studies civil liberties and police surveillance technology, police departments could find difficult to stop using once they start. “Not only is there no real competition from other vendors,” said Joh, “but once a police department has bought into a certain contract with a company, it’s very hard to drop it and move on. There’s a lot of investment in training the agency and the officers how to use it.” Which could raise a competition issue, with Axon positioning itself as a panoptical must-subscribe for law enforcement agencies. “The question here is whether we want this kind of tech monopoly at a time when it’s clear that tech monopolies like Facebook haven’t really served the public interest that well,” said Joh.\nThe monopoly question with Axon isn’t just about departments being locked into the company’s service because of a lack of competition or switching costs. It’s also about how the company could monetize its access to police data in the future. Axon’s dominance in the police-camera surveillance-data market could give the company an unbeatable leg up. That’s because the more data A.I. has to train itself on, the better it is, and so whatever company has the most data will likely have the best product. Axon did, after all, acquire two different artificial intelligence companies for analyzing video footage last year, which the company said in a press release will be combined to form a new division, Axon AI.\nA DJI spokesperson said that its “partnership with Axon does not include any attachments with offensive capability, or any facial recognition technology”—but once a drone is purchased and in the hands of law enforcement, it’s theirs to do what they want within the bounds of the law. That could mean surveilling a protest with a drone, which is something police have certainly explored doing in the past. In May, Chicago Mayor Rahm Emanuel threw his support behind a bill that would permit police to fly drones over large events for surveillance. And Amazon has been marketing its facial recognition software, Rekognition, which can identify up to 100 people in a single photo, to law enforcement agencies for the past two years. There’s no reason to think that software couldn’t be applied to drone footage, whether the capability is contained within the drone itself or is applied to footage sent to a computer on the ground in real time.\n“There are good uses of drones that we don’t object to in limited situations where it makes sense to have a camera in the sky, whether it’s for construction or for finding a lost child in the woods,” said Jay Stanley, senior policy analyst at the ACLU. He said he becomes concerned with the technology when it ends up being used to monitor a wide area, like by flying over a city broadly collecting data from the air. “It could give police the ability to hit rewind on people’s lives and see anywhere they’ve been,” he said.\nIt’s not unusual for police departments to procure surveillance technologies without public discussion. But communities concerned about police use of surveillance drones aren’t without recourse. Oakland, California, passed a strong new ordinance regulating police use of surveillance technologies in May, requiring any surveillance technology that the city wants to be subject to review and approval by a local board of volunteer commissioners. In doing so, police must disclose and engage in conversation around new surveillance technologies they wish to deploy, meaning they couldn’t buy surveillance drones without disclosing that information to the public. The California legislature is currently considering a statewide model for this kind of police surveillance privacy check.\n“When municipalities are considering the adoption of drones, they need to be extremely careful,” said Yu. “They need to consult with communities before adopting these technologies to get their approval, and whether its drones and other police technologies, it should be a democratic decision.”","Implications of Facial Recognition Technology\nNot too long ago, my twin sister and I did an experiment to see which of our devices were able to tell the difference between us. Being identical, we often are not able to be told apart from one another by those who do not know us very well. While we feel that we do not look exactly alike, we agree that we do look very similar to each other. We tried both my Windows laptop and her iPhone 12 to see if we could crack into each other’s devices, and we quickly found out that we could easily use our faces to unlock both. It was relatively easy to trick the facial recognition software on the phone and computer, which got me curious about how accurate facial recognition is. This got me thinking about the potential danger that any inaccuracy in facial recognition technology could have if it identified the wrong person in a picture or video.\nTo start off, facial recognition technology, as defined by the Electronic Frontier Foundation, “is a method of identifying or verifying the identity of an individual using their face. Face recognition systems can be used to identify people in photos, video, or in real-time”. It is essentially any device or software that can be used to identify people based on their facial structure. Many believe that facial recognition is a highly accurate medium, however, that seems to be far from the truth. In a study done by Joy Buolamwini and Timnit Gebru, it was found that in the three different facial recognition technologies they used, there was a huge disparity between the rates of misidentification between Black and White people. The study found that while there was only a .8% error rate for light-skinned males, that rate of error sharply increased when looking at both Black men and women. The error rate for Black women was consistently the highest across all three programs used in the study, with an error rate as high as 36%. Many police precincts use this technology to identify potential criminal offenders and place people at certain crime scenes. In a 2003 article that discussed the idea of implementing facial recognition technology into the police force stated that one positive was indeed surveillance to look for crime suspects or suspected terrorists. This is especially harrowing as there has been a deep rooted history of government agencies using surveillance against people of color based on racist ideologies. The idea of facial recognition and both the positive and negative consequences it holds leaves many people having a stake in the issue of whether it should be used as a trusted technology.\nIn this case of facial recognition, there are many stakeholders at play. Citizens, both in support and opposition, have a say in what value it actually holds. For some, it may make them feel safer as there are criminals who may be getting caught with this technology; for others it may act as a reminder of institutionalized racism and bias that is so perverse in other parts of life. For those in support of facial recognition technology, they may advocate for its increased use to monitor public spaces. Those in opposition may advocate for a complete stop of its use or a redoing of the systems behind the technology in order to make it more accurate for all people, not just for white people. The technology companies that create the software hold a huge financial stake in this topic, as they profit from any sales of their technology, as well as from any partnering with business and government agencies. Any information that they put out to the public may be done so in a way that highlights all the positive aspects of facial recognition, while glossing over any negatives or inconsistencies with their technology. Lastly, government agencies, such as Immigration and Customs Enforcement (ICE) and Police forces, hold a deep stake in this issue. These agencies may see them as holding value for their investigations and prevention of crime, as they will be able to identify who was in a photo or video taken during the crime. There have already been cases of ICE gaining access to driver license photos in order to find any undocumented citizens they are searching for. Each of these stakeholder’s views and opinions can be looked at through 5 different lenses that help to explain and define them.\nThe first lens that can be used to look at each stakeholder’s belief is the Rights Perspective. This can help explain how citizens, companies, and government agencies approach this topic by examining how it impacts individual rights and the role that it generally places on the people who use it. For citizens who are in support of facial recognition, they may feel that they are creating a safer environment for every citizen in the country, as they may be better protected against crime. However, the dignity of others may be lost through this belief, as it means various agencies and businesses can monitor those without their knowledge. The citizens who are against the use of facial recognition, or feel that its use should be limited, are basing this off the idea that this can be used as a way to invade people’s protected privacy and may even make them feel unsafe as this could negatively affect one group of people over another with misidentification. For businesses that create the software, they are seeing those that are buying the facial recognition technology as consumers. There is a very transactional balance for this viewpoint, as they are more of a focus on selling a product, rather than thinking about the negative implications that it may hold. For government agencies, their view may be a way to protect more citizens and increase their overall well-being and safety. However, there is a side of this that is favoring one group’s well-being over another, as it can be negative for those who are often misidentified with the technology.\nWhen looking through each view through the Justice/Fairness perspective, we are evaluating how an increase or decrease in the use of facial technology may be treating individuals differently or may be treating one group better than another. With any citizen, business or government agency that advocates for its continued or increased use, there is a large issue on how this technology treats everyone that is being evaluated with it. There is an unbalance in the system, and until that unbalance is solved, it will only act to reinforce and worsen any bias that is held in surveillance of citizens. For those who support it decreased use, it may help contribute to a drop in misidentification of those suspected to be in a crime scene, as a different technology would have to be relied on in order to identify suspects,\nThe Utilitarian perspective has us looking at each viewpoint by examining how facial recognition works, what outcomes are supposed to be positive or negative, and whether any harm caused by the technology may be outweighed by its positives. For those who are in support of facial recognition, they do feel that any increase of public security may outweigh the percentage of people that are misidentified with the technology. Also, the outcome of facial recognition is inherently to implicate someone in a crime, as it is used to place a person at a crime scene. For those that are opposed to facial recognition, there is the belief that the percentage of people that are misidentified is too high and negates the positives that it may hold in identification. The decreased use of facial recognition technology may be justified as it means that other forms of identification, such as fingerprints or DNA, will need to be relied on.\nWith the Common-Good perspective, the beliefs and viewpoints are evaluated on whether it benefits all groups of people or just some and if it’s creating a positive outcome for anyone that uses it. The advocates of increased use of facial recognition may find that there is a benefit for all people. For government agencies, they may feel that they are helping to keep dangerous people off the street and are preventing undocumented citizens from living in the United States. For those in opposition of facial recognition, there is the perspective that facial recognition is inherently biased and uneven in terms of those who actually can benefit from the technology.\nLastly, the Virtue perspective evaluates whether something is leading us to a better society, what character traits inherently come from choosing this position on facial recognition. For those with the belief that facial recognition is an overall positive technology, they may feel that the technology is creating a deterrent of crime that will lead to an overall safer community. For those in opposition, they may view the technology as something that does not create a better society, but instead reinforces already seen institutionalized racial disparities.\nWhen looking at either argument of supporting or advocating against the use of facial recognition, the two perspectives that I feel best suit this are the Rights perspective and the Utilitarian perspective. Much of this debate involves the idea of surveying people without their knowledge or expressed consent. Many of the pictures used to identify those with facial recognition are driver’s license photos. This means that those who have a license will be more likely to be placed into the facial recognition system than those who do not have their license. This puts certain groups of people more at risk to be misidentified than others. This is not protecting rights as citizens, as there is a large emphasis on creating a role for citizens that revolve around always being a suspect for crime. Also, with the Utilitarian perspective in mind, we are seeing that the goal of facial recognition technology is that someone is identified correctly. However, when there is a high percentage of misidentification with Black people compared to the much lower rate among White people, there is something inherently wrong with the technology being used. With all this information in mind, I feel that it is best to decrease the use of facial recognition technology, and it cannot be used until the percentage of misidentification is virtually zero.\nThere are many reasons that people choose to support or oppose facial recognition technology. For some, it can feel like a safety cushion that can be used to deter crime and create a safer community. For others, it showcases that there is an increasing presence of police and government agencies within our communities that lead to a worsening of institutionalized racial bias. Whether you support facial recognition technology or not, you must be aware of the alarming rate of misidentification of Black people that occur from these machines. The consequences held for individuals that are misidentified for a crime they did not commit hold much larger consequences than the ones found by two twins being able to unlock each other’s phones and computers.\nBedoya, A. (2016, January 18). What the Fbi’s surveillance of Martin Luther King tells us about the Modern Spy Era. Retrieved March 03, 2021, from https://slate.com/technology/2016/01/what-the-fbis-surveillance-of-martin-luther-king-says-about-modern-spying.html\nBuolamwini, J & Gebru, T. (2018). Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification. Retrieved March 03, 2021, from http://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf\nChappell, B. (2019, July 08). Ice uses facial recognition to sift state driver’s license records, researchers say. Retrieved March 03, 2021, from https://www.npr.org/2019/07/08/739491857/ice-uses-facial-recognition-to-sift-state-drivers-license-records-researchers-sa\nFace recognition. (2021, February 15). Retrieved March 03, 2021, from https://www.eff.org/pages/face-recognition\nWoodward, J. D., Virginia, & Rand Corporation. (2003). Biometrics : A Look at Facial Recognition. RAND Corporation. Retrieved March 03, 2021, from http://web.b.ebscohost.com.ezp1.lib.umn.edu/ehost/detail/detail?vid=0&sid=a558cda8-6ac1-49e8-b12b-7b130163e3b5%40sessionmgr102&bdata=JkF1dGhUeXBlPWlwLHVpZCZzaXRlPWVob3N0LWxpdmU%3d#AN=81628&db=nlebk"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:5c6f3941-64b0-4bb7-abe9-a507085dc9fa>","<urn:uuid:549fad59-45f0-4469-8a8f-d0e3a57aed13>"],"error":null}
{"question":"What are the key factors that determine whether a species can be successfully domesticated, and what aspects of herd health management are critical for their ongoing care?","answer":"Successful domestication depends on several key factors: the species must have a flexible diet, reasonably fast growth rate, ability to breed in captivity, pleasant disposition, calm temperament that doesn't panic easily, and a modifiable social hierarchy that accepts human leadership. Animals that lack these traits, like zebras or African buffalos, have proven difficult or impossible to domesticate. For ongoing care, critical aspects of herd health management include maintaining proper nutrition, providing clean water, controlling environmental stressors, quarantining new animals, practicing proper workflow from healthy to sick animals, using appropriate pain control for procedures, keeping detailed health records, and developing a relationship with a veterinarian to create tailored health programs. These practices help maintain immunity and minimize pathogen exposure.","context":["Individual differences |\nMethods | Statistics | Clinical | Educational | Industrial | Professional items | World psychology |\nDomestication refers to a population of animals or even a species as a whole. Humans have brought these populations under their care for a wide range of reasons: to produce food or valuable commodities (such as wool, cotton, or silk), for help with various types of work, transportation and to enjoy as pets . Animals domesticated for home companionship are usually called pets while those domesticated for food or work are called livestock or farm animals.\nDomestication requires that the animals instinctive behavior patterns are modified through time so that traits for aggression and territorality etc are reduced and temperamental qualities for obedience, submissiveness etc are increased in order to enable them to live and to be managed by humans. These results can sometimes be achieved in individual cases by animal training but domestication is a deeper species wide process\nProcess of domestication Edit\nThere is debate within the scientific community over how the process of domestication works. Some researchers give credit to natural selection, where mutations outside of human control make some members of a species more compatible to human cultivation or companionship. Others have shown that carefully controlled selective breeding is responsible for many of the collective changes associated with domestication. These categories are not mutually exclusive and it is likely that natural selection and selective breeding have both played some role in the processes of domestication throughout history.\nThe domestication of wheat provides an example of how natural selection and mutation can play a key role in the process. Wild wheat falls to the ground to reseed itself when it is ripe, but domesticated wheat stays on the stem when it is ripe. There is evidence that this critical change came about as a result of a random mutation near the beginning of wheat's cultivation. Wheat with this mutation was the only wheat harvested and became the seed for the next crop. This wheat was much more useful to farmers and became the basis for the various strains of domesticated wheat that have since been developed.\nThe example of wheat has led some to speculate that mutations may have been the basis for other early instances of domestication. It is speculated that a mutation made some wolves less wary of humans. This allowed these wolves to start following humans to scavenge for food in their garbage dumps. Presumably something like a symbiotic relationship developed between humans and this population of wolves. The wolves benefited from human food scraps, and humans may have found that the wolves could warn them of approaching enemies, help with hunting, carry loads, provide warmth, or supplement their food supply. As this relationship evolved, humans eventually began to raise the wolves and breed the types of dogs that we have today.\nNonetheless, some researchers maintain that selective breeding rather than mutation or natural selection best explains how the process of domestication typically worked. Some of the most well-known evidence in support of selective breeding comes from an experiment by Russian scientist, Dmitri Belyaev, in the 1950s. His team spent many years breeding the Silver Fox (Vulpes vulpes) and selecting only those individuals that showed the least fear of humans. Eventually, Belyaev's team selected only those that showed the most positive response to humans. He ended up with a population of grey-coloured foxes whose behavior and appearance was significantly changed. They no longer showed any fear of humans and often wagged their tails and licked their human caretakers to show affection. More importantly, these foxes had floppy ears, smaller skulls, rolled tails and other traits commonly found in dogs.\nDespite the success of this experiment, some scientists believe that selective breeding cannot always achieve domestication. They point out that known attempts to domesticate several kinds of wild animals in this way have failed repeatedly. The zebra is one example. It is possible that the historical process of domestication cannot be fully explained by any one principle acting alone. Some combination of natural selection and selective breeding may have played a role in the domestication of the various species that humans have come into close contact with throughout history.\nWhatever the mechanisms domestication is not easily achieved. Of the largest 150 animals less than 20 have been reliably domesticated \nDomestication of animalsEdit\n- Flexible diet — Creatures that are willing to consume a wide variety of food sources and can live off less cumulative food from the food pyramid (such as corn or wheat) are less expensive to keep in captivity. Most carnivores can only be fed meat, which requires the expenditure of many herbivores.\n- Reasonably fast growth rate — Fast maturity rate compared to the human life span allows breeding intervention and makes the animal useful within an acceptable duration of caretaking. Large animals such as elephants require many years before they reach a useful size.\n- Ability to be bred in captivity — Creatures that are reluctant to breed when kept in captivity do not produce useful offspring, and instead are limited to capture in their wild state. Creatures such as the panda and cheetah are difficult to breed in captivity.\n- Pleasant disposition — Large creatures that are aggressive toward humans are dangerous to keep in captivity. The African buffalo has an unpredictable nature and is highly dangerous to humans. Although similar to domesticated pigs in many ways, American peccaries and Africa's warthogs and bushpigs are also dangerous in captivity.\n- Temperament which makes it unlikely to panic — A creature with a nervous disposition is difficult to keep in captivity as they will attempt to flee whenever they are startled. The gazelle is very flighty and it has a powerful leap that allows it to escape an enclosed pen.\n- Modifiable social hierarchy — Social creatures that recognize a hierarchy of dominance can be raised to recognize a human as its pack leader. Bighorn sheep cannot be herded because they lack a dominance hierarchy, whilst antelopes and giant forest hogs are territorial when breeding and cannot be maintained in crowded enclosures in captivity.\nA herding instinct arguably aids in domesticating animals: tame one and others will follow, regardless of chiefdom.\nDegrees of domestication Edit\nThe boundaries between surviving wild populations and domestic clades of elephants, for example, can become vague. This is due to their slow growth. Similar problems of definition arise when, for example, domesticated cats go feral. A classification system that can help solve this confusion might be set up on a spectrum of increasing domestication:\n- Wild: These species experience their full life cycles without deliberate human intervention.\n- Raised at zoos or botanical gardens (captive): These species are nurtured and sometimes bred under human control, but remain as a group essentially indistinguishable in appearance or behaviour from their wild counterparts. (It should be noted that zoos sometimes exhibit domesticated or feral animals such as camels, mustangs, )\n- Raised commercially (captive or semidomesticated): These species are ranched or farmed in large numbers for food, commodities, or the pet trade, but as a group they are not substantially altered in appearance or behavior. Examples include the elephant, ostrich, deer, alligator, cricket, pearl oyster, and ball python. (These species are sometimes referred to as partially domesticated.)\n- Domesticated: These species or varieties are bred and raised under human control for many generations and are substantially altered as a group in appearance or behaviour. Examples include the Canary, Pigeons, the Budgerigar, the peach-faced Lovebird, dogs, cats, sheep, cattle, chickens, llamas, guinea pigs and laboratory mice.\nThis classification system does not account for several complicating factors: genetically modified organisms, feral populations, and hybridization. Many species that are farmed or ranched are now being genetically modified. This creates a unique category because it alters the organisms as a group but in ways unlike traditional domestication. Feral organisms are members of a population that was once raised under human control, but is now living and multiplying outside of human control. Examples include mustangs. Hybrids can be wild, domesticated, or both: a liger is a hybrid of two wild animals, a mule is a hybrid of two domesticated animals, and a beefalo is a cross between a wild and a domestic animal.\nA great difference exists between a tame animal and a domesticated animal. The term \"domesticated\" refers to an entire species or variety while the term \"tame\" can refer to just one individual within a species or variety. Humans have tamed many thousands of animals that have never been truly domesticated. These include the elephant, giraffes, and bears. There is debate over whether some species have been domesticated or just tamed. Some state that the elephant has been domesticated, while others argue the cat has never been. One dividing line is whether a specimen born to wild parents would differ in behavior from one born to domesticated parents. For instance a dog is certainly domesticated because even a wolf (genetically the origin of all dogs) raised from a pup would be very different from a dog.\nLimits of domestication Edit\nDespite long enthusiasm about revolutionary progress in farming, few crops and probably even fewer animals ever became domesticated.\nDomesticated species, when bred for tractability, companionship or ornamentation rather than for survival, can often fall prey to disease: several sub-species of apples or cattle, for example, face extinction; and many dogs with very respectable pedigrees appear prone to genetic problems.\nOne side effect of domestication has been disease. For example, cattle have given humanity various viral poxes, measles, and tuberculosis; pigs gave influenza; and horses the rhinoviruses. Humans share over sixty diseases with dogs. Many parasites also have their origins in domestic animals.\nDates and places of domesticationEdit\nSee the table by species below\nSince the process of domestication inherently takes many generations over a long period of time, and the spread of breed and husbandry techniques is also slow, it is not meaningful to give a single \"date of domestication\". The methods available to estimate domestication dates introduce further uncertainty, especially when domestication has occurred in the distant past. So the dates given here should be treated with caution; in some cases evidence is scanty and future discoveries may alter the dating significantly.\nDates and places of domestication are mainly estimated by archaeological methods, more precisely archaeozoology. These methods consist of excavating or studying the results of excavation in human prehistorical occupation sites. Animal remains are dated with archaeological methods, the species they belong to is determined, the age at death is also estimated, and if possible the form they had, that is to say a possible domestic form. Various other clues are taken advantage of, such as slaughter or cutting marks. The aim is to determine if they are game or raised animal, and more globally the nature of their relationship with humans. For example the skeleton of a cat found buried close to humans is a clue that it may have been a pet cat. The age structure of animal remains can also be a clue of husbandry, in which animals were killed at the optimal age.\nNew technologies and especially mitochondrial DNA provide an alternative angle of investigation, and make it possible to reestimate the dates of domestication based on research into the genealogical tree of modern domestic animals.\nIt is admitted for several species that domestication occurred in several places distinctly. However, this does not rule out later crossing inside a species; therefore it appears useless to look for a separate wild ancestor for each domestic breed.\nThe first animal to be domesticated appears to have been the dog, in the Upper Paleolithic era; this preceded the domestication of other species by several millennia. In the Neolithic a number of important species (such as the goat, sheep, pig and cow) were domesticated, as part of the spread of farming which characterises this period. The goat, sheep and pig in particular were domesticated independently in the Levant and Asia.\nRecent archaeological evidence from Cyprus indicates domestication of a type of cat by perhaps 7500 BC.\nThe earliest secure evidence of horse domestication, bit wear on horse molars at Dereivka in Ukraine, dates to around 4000BC. The unequivocal date of domestication and use as a means of transport is at the Sintashta chariot burials in the southern Urals, ca 2000 BC. Local equivalents and smaller species were domesticated from the 2500s BC.\nThe availability of both domesticated vegetable and animal species increased suddenly following the voyages of Christopher Columbus and the contact between the Eastern and Western Hemispheres. This is part of what is referred to as the Columbian Exchange.\nApproximate dates and locations of first domesticationEdit\n|the risk of extinction|\n|Honey bee||4000 BC||Multiple places|\n|Asian Elephant||2000 BC||Indus Valley civilization|\n|Fallow Deer||1000 BC||Mediterranean Basin|\n|Indian Peafowl||500 BC||India|\n|Barbary Dove||500 BC||North Africa|\n|Japanese Quail (see Quail)||1100–1900||Japan|\n|Canary||1600||Canary Islands, Europe|\n- REDIRECT Template:Original research\nA project is underway to that is attempting to find the genetic basis for taming. Researchers at the Max Planck institute have reared two sets of rats. One set has been selected for aggressive traits and another for more tame traits. The researcher hope to mimic the process by which neolithic farmers first domesticated animals.\nOld (Ancient) domesticationEdit\nSome species are said to have been domesticated, but are not any more, either because they have totally disappeared, or since only their domestic form no longer exists. An example would be the African and Asian elephants (See War elephant) and Bos aegyptiacus.\nGenetic pollution in naturally evolved purebred wild speciesEdit\n- Main article: Genetic pollution\nAnimals of domestic origin and feral ones sometimes can produce fertile hybrids with native, wild animals which leads to genetic pollution in the naturally evolved wild gene pools, many a times threatening rare species with extinction. Cases include the mallard duck, wild boar, the rock dove or pigeon, the Red Junglefowl (Gallus gallus) (ancestor of all chickens), carp, and more recently salmon [How to reference and link to summary or text]. Another example is the dingo, itself an early feral dog, which hybridizes with dogs of European origin. On the other hand, genetic pollution seems not to be noticed for rabbit. There is much debate over the degree to which feral hybridization compromises the purity of a wild species. In the case of the mallard, for example, some claim there are no populations which are completely free of any domestic ancestor. [How to reference and link to summary or text]\nSee also Edit\n- Lists and timelines\n- Animal captivity\n- Animal breeding\n- Animal training\n- Assistance animals\n- Companion animals\n- Domestication of the dog\n- Domestication of the horse\n- Gene pool\n- Genetic erosion\n- Genetic pollution\n- Genetic engineering\n- Genomics of domestication\n- Lion taming\n- Military animals\n- Selective breeding\n- Service animals\n- Turkey (domesticated)\n- Working animals\n- ↑ See Origin of the domestic dog\n- ↑ Melinda A. Zeder, Goat busters track domestication (Physiologic changes and evolution of goats into a domesticated animal), April 2000, (English) .\n- ↑ Michaël Lallemand, Courte synthèse sur l'histoire du mouton, de la domestication à nos jours, 2002, (French) . See also Pre-Historic Zawi Chemi Shanidar, (English) .\n- ↑ Giuffra E, Kijas JM, Amarger V, Carlborg O, Jeon JT, Andersson L. The origin of the domestic pig: independent domestication and subsequent introgression., April 2000, (English) .\n- ↑ Late Neolithic megalithic structures at Nabta Playa (Sahara), southwestern Egypt.\n- ↑ Source : Laboratoire de Préhistoire et Protohistoire de l'Ouest de la France , (French) .\n- ↑ .Un chat apprivoisé à Chypre, plus de 7000 ans avant J.C., Press release from the CNRS, April 2004, (French) . Original article: J.-D. Vigne, J. Guilaine, K. Debue, L. Haye & P. Gérard (2004) Early taming of the cat in Cyprus, Science, 9 April 2004.\n- ↑ West B. and Zhou, B-X., Did chickens go north? New evidence for domestication, World’s Poultry Science Journal, 45, 205-218, 1989, PDF (26.3 KiB), 8 p. (English) .\n- ↑ History of the Guinea Pig (Cavia porcellus) in South America, a summary of the current state of knowledge\n- ↑ Beja-Pereira, Albano et al., African Origins of the Domestic Donkey, Science 304:1781, 18 June 2004, cited in New Scientist, (English) .\n- ↑ Roger Blench, PDF (235 KiB) (English) .\n- ↑ The Domestication of the Horse; see also Domestication of the horse\n- ↑ Nice Rats, Nasty Rats: Maybe It’s All in the Genes\n- Discussion of animal domestication\n- Guns, Germs and Steel by Jared Diamond (ISBN 0-393-03891-2)\n- News story about an early domesticated cat find\n- Belyaev experiment with the domestic fox\n- Use of Domestic Animals in Zoo Education\n- The Initial Domestication of Cucurbita pepo in the Americas 10,000 Years Ago\n- Phytolith evidence for early Holocene Cucurbita domestication in southwest Ecuador\n- An Asian origin for a 10,000-year-old domesticated plant in the Americas\n|This page uses Creative Commons Licensed content from Wikipedia (view authors).|","Herd health is top priority when raising livestock, but its impact could go unnoticed to the untrained eye. Herd health displays not only in the number of sick or injured animals, but also in your animals’ welfare and productivity on the whole. Many producers don’t realize that their animals are fighting off an underlying disease that is costing them money. Ailments can be hard to spot without monitoring feed intake and production numbers. In short, some might assume that if they don’t see any visible signs of sickness, their animals are healthy.\nWhen your farm has a disease outbreak, there are two groups affected: a small number of the sick ones, and the rest that are fighting off the disease but may not be showing any signs. Those seemingly healthy animals are paying a price just like those more obviously afflicted. It’s like an iceberg, and the majority of your production losses are invisible under the water, because it is a decrease in milk, eggs, fiber growth, or weight gain.\nDairy producers who monitor milk production on a daily basis are well aware of the impact of subclinical diseases. They can tune into a disease outbreak before any visible signs of sickness appear because they’re aware of any drop in milk production. This production loss is due to the fact that the immune system requires large amounts of energy to fight off illness, and animals tend to eat less when they don’t feel well. Boosting your herd’s immunity is the most important part of maximizing your herd’s production and welfare.\nComponents of health\nYour animal’s health is a result of the interplay of three things: its immunity, the pathogen, and the environment. These are interacting daily, even when disease isn’t visible on your farm. The environment is constantly impacting an animal’s immunity and the number of pathogens an animal is exposed to. How you manage your animals impacts all three of these factors by determining how many stresses your animals have in their environment, indirectly affecting their immunity, directly boosting their immunity with vaccinations, and determining which pathogens are present and how numerous and widespread. Whether you see disease in a herd is determined by two things: the ability of the low-immunity animals to fight off disease and the number of pathogens those animals are exposed to.\nIt is important to note that the environment only decreases an animal’s immunity; it cannot increase it regardless of any marketing claims of nutritional supplements. A clean, comfortable environment along with proper nutrition allows the immune system to perform at its best, but does not better prepare the immune system to fight off particular diseases. The best we can do is help keep an animal’s immunity functioning to its fullest and minimize their exposure to pathogens through proper herd management.\nThink of the immune system as an army; improving the environment can be equated with keeping the army well-fed, well-rested, clean, and in good fighting condition, which while important for winning a battle, does little to turn the outcome if they have to manufacture their weapons after the enemy arrives. The only way to truly increase your animal’s immunity is through vaccinations or natural disease exposure. However, vaccines require proper herd health management to work to their fullest. The goal of herd management is to minimize the number of pathogens and improve the environment. Then, depending on the farmer’s preference, vaccinating can maximize your animal’s immunity (knowing that the environment is constantly trying to lower it).\nNot all stressors are painful or would seem that detrimental, but they can add on to each other, with each stress successively reducing an animal’s immunity. Eventually, the animal’s immunity can decrease to a level that can be overwhelmed by the particular number of pathogens it is exposed to, and result in subclinical production losses and eventually illness.\nAnother thing to consider is that there are no truly closed herds, where there are no new pathogens being brought onto your farm — only varying levels of disease risk. Any new animals, including sires, semen, and embryos, can bring disease onto your farm. Often you hear of “closed herd” farmers or ranchers purchasing a new breeding sire or taking on an orphan from the auction barn. Even animals getting out and mixing, fence-line contact, or you visiting a neighbor’s farm or auction can be a potential source of infection. Wildlife and the usual roaming farm dog are common sources of disease transfer. It is important for producers to consider any possible ways that disease could enter their herd or flock, and have a management plan that can help prevent the introduction of any preventable diseases.\nMany people confuse vaccines and antibiotics, thinking they are the same thing. In reality they are completely different, and vaccines actually help reduce the number of antibiotics producers might need to use. Proper use of vaccines helps minimize the amount of antibiotic and parasitic treatments.\nA vaccine mimics a natural infection without actually causing infection. This boosts an animal’s immunity to that bacteria or virus, protecting them from future disease. A suitable analogy is that we’re showing the immune system the uniform of an enemy so it can be recognized when the real enemy comes. Though the immune system will generally respond to infection, the response is delayed, often by several days, while the immune system prepares itself. Conversely, an animal with an immune system that has been “primed” by past exposure — such as a vaccine — is ready to fight off the pathogen as soon as it arrives, as opposed to several days later after production loss or disease has set in.\nBy boosting your animal’s immunity, you may reduce the number of times they have to fight off an infection and require antibiotics, which also helps reduce antibiotic resistance. In fact, proper management to reduce stressors, along with vaccinations, play a major role in reducing antibiotic use in livestock. While vaccines help, they are not a crutch for poor management. The benefit of vaccination is its ability to boost the animal’s immunity, which provides a buffer against stressors.\nHerd immunity is another important part of preventing the spread of disease within a group of animals by reducing the amount of pathogens shed by the whole herd. Animals that have been vaccinated to have a strong immunity fight off infections faster and therefore are a source of exposure to the rest of the herd for a shorter amount of time. This protects the animals that didn’t respond to the vaccine, or have a weakened immune system, by keeping the pathogen load to manageable numbers.\nOn the flip side, some livestock producers avoid immunization because they feel they are unnecessary and might even inhibit the natural ability of the herd to adapt to their environment and develop immunity to specific common pathogens.\nMaintain a relationship with your veterinarian, too, so you and your vet can develop a herd health plan that is best tailored to your farm, as diseases can be specific to your area and farm. Veterinarians know best what diseases and nutritional deficiencies are common in your area and can help you develop a herd management plan to combat them. It’s important to remember that your livestock are pretty good at taking care of themselves, but there may be a few additional measures you can take to provide them with the best possible environment and ensure they’re living the good life.\nCommon stressors for livestock\n• Temperature extremes\n• Poor nutrition or a change in feed\n• Handling and sorting — even for non-painful procedures such as shearing\n• Castration and other painful procedures such as branding, dehorning, teeth cutting\n• Breeding — of particular concern for breeding males in a herd, who generally fail to eat and rest as much as they should during breeding season\n• Introducing new livestock\n• Remember that disease can also be caused by vitamin and mineral imbalances, toxicities, and parasites, and that vaccination cannot protect against any of these problems\nWhat’s the difference between bacteria & viruses?\nBacteria are single-celled microorganisms that can reproduce on their own. Bacteria can be killed by antibiotics, which are medications that directly affect bacterial cells but do not affect animal cells. Many common bacterial diseases can be prevented with vaccines; vaccines that protect against bacterial infections are called bacterins.\nUnlike bacteria, viruses cannot reproduce on their own. Viruses consist of genetic material (DNA) in a protective capsule, and reproduce by finding a host cell in another organism, such as an animal, and tricking that cell into making copies of them. Viruses cannot be killed by antibiotics. While there are some antiviral medications, they are very non-specific, quite expensive, and not available for use in animal production. The most effective means of preventing viral infection is through vaccination.\nMany viral infections lead to secondary bacterial infections. For example, a viral pneumonia infection damages the cells in the airways, which breaks down the animal’s natural defenses and allows secondary bacterial invaders to set up their own infection.\nTips to maintain your herd’s health\n• Avoid auction marts and stockyards for purchasing animals when possible — purchase directly from producers that don’t buy a lot of animals from off farm, but keep a healthy herd of their own. Enquire about their health management program prior to purchasing animals.\n• Ensure your animals have proper nutrition and consistent access to clean water.\n• Avoid temperature stressors by providing shade and cool areas in the summer, and windbreaks and bedding in the winter.\n• Quarantine new animals for two to three weeks before introducing them to the herd — this means not just a separate pen, but no fence-line contact or shared water source.\n• Always practice proper workflow — youngest to oldest, healthy to sick, and always disinfect equipment and footwear after being used on or around sick animals.\n• Watch your run-off. Many diseases occur because of manure run-off that accumulates.\n• Use pain control and anti-inflammatory medication to minimize the impact of disease and painful procedures.\n• Avoid stacking stressors. For example, don’t work animals on extremely hot or cold days, if it can be helped. Spread out painful procedures such as castration and ear tagging. Hold off on non-essential procedures on new animals until they settle into their new environment. This includes not vaccinating new animals the day they arrive. Stressed animals will not respond as well to vaccination as happy, healthy animals.\n• Develop a relationship with your veterinarian. Create a herd management program to minimize the effect of disease in your herd and perform herd health audits.\n• Keep records of your animals’ performance. The bare minimum would be feed intake and their output (eggs, milk,weight gain, fleece growth). If you notice a drop, you need to talk to your veterinarian, as this is an indicator that something might be wrong in the herd.\n• Remember that most of your profit losses will not be the visibly sick animals.\nRyan Ridgway owns a rural veterinary practice. He enjoys blacksmithing in his spare time, and is the author of the book Home Blacksmith."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:b2cf775a-c765-4e62-b411-87f400144cd7>","<urn:uuid:f1e2693b-2a72-41e5-84f0-720427a89b88>"],"error":null}
{"question":"How does dendritic cell dysfunction lead to autoimmunity, and what strategies exist to prevent antibiotic-induced gut inflammation?","answer":"Dendritic cell dysfunction, specifically the loss of Lyn kinase in these cells, can trigger severe autoimmune/inflammatory disease through MyD88-dependent signaling, leading to breakdown of immune tolerance. To prevent antibiotic-induced gut inflammation, several strategies can be employed: using strain-specific probiotics during and after antibiotic therapy, implementing prebiotics derived from sources like apple soluble fiber to enhance beneficial microbe growth, and utilizing Saccharomyces Boulardii which has been shown to reduce inflammatory markers and increase protective antibodies. These approaches can help maintain gut barrier integrity and prevent both local and systemic inflammatory responses.","context":["Autoimmune diseases such as human lupus erythematous (and related disorders) are generally considered to arise from defects in lymphocytes leading to production of antibodies that recognize self- proteins. We have found that genetic defects in innate immune cells, which are involved in protection from bacterial, fungal and other infections, can also cause autoimmune disease. The goal of this project is to determine the mechanisms by which defects in innate immune cells cause autoimmune and inflammatory disease.\nThere is a growing recognition that innate immune cells play a critical role in initiating and sustaining autoimmune and inflammatory disorders. The Lyn tyrosine kinase is one of the primary inhibitory enzymes that regulate innate immune cell signaling. Lyn functions by phosphorylating inhibitory receptors that recruit tyrosine phosphatases to down modulate cellular activation. In the absence of Lyn kinase, mice develop spontaneous autoimmunity resembling human systemic lupus erythematous (SLE). In preliminary studies, we have found that loss of Lyn kinase in dendritic cells (DCs) alone is sufficient to cause a severe autoimmune/inflammatory disease, with strong tissue inflammation and reduced survival, compared to the global lyn-/- mice. This disease is completely dependent on MyD88-signaling, since generation of mice lacking MyD88 and Lyn in DCs alone lack the inflammation and autoimmunity. These observations provide a clear example that mutations resulting in loss of inhibitory signaling in DCs can result in breakdown of immune tolerance in lymphocytes, leading to autoimmunity. This proposal consists of 4 specific aims.\nOur first aim is to define the molecular mechanisms by which inhibition of tyrosine kinase pathways impacts MyD88 signaling in DCs. We hypothesize that the cross talk between these pathways occurs via the CARD9/Malt1/Bcl10 complex, which we will investigate biochemically and genetically. We will use a chemical genetic approach to define the molecular substrates of Lyn in DCs.\nAim #2 will expand on our preliminary observations, done with Dr. Lynch (UCSF) that loss of Lyn in DCs results in dysbiosis of gut microbiota, allowing for outgrowth of species that may drive systemic inflammation by altering the intestinal barrier function. We will expand on these observations in a series of microbiota profiling experiments, by use of bacterial supplementation methods, and by directly examining intestinal barrier function in the various Lyn-deficient strains.\nAim #3 will expand on preliminary data suggesting that an undefined Lyn-mediated signaling pathway in non- hematopoietic cells may have an immunomodulatory effect on the disease process in lyn-/- mice. Lyn related inhibitory signaling in non-hematopoietic cells is very poorly studied. We will focus on follicular retricular cells using biochemical and genetic means (including generating mutant mice lacking Lyn in these cells specifically).\nAim #4 will expand on preliminary studies done with Dr. Locksley (UCSF) showing that group 2 innate lymphocytes (ILC2s) are expanded and activated in lyn-/- mice. This aim will address whether altered signaling in ILC2 cells alone can lead to spontaneous disease phenotypes (by generating novel ILC2-specific lyn mutants) and whether these cells may contribute to autoimmune disease.\nSince changes in Lyn kinase related signaling pathways have been observed in human SLE patients and Lyn is now a therapeutic target in diabetes treatments (therapeutic trials) understanding the inhibitory signaling pathways regulated by this kinase in innate cells will have direct impact on human autoimmune and inflammatory conditions.","Michael Ash BSc (Hons), DO, ND FDipION reviews the current understanding of the role of antibiotics in the initiation of gut associated inflammation and local and systemic health problems, and briefly explores some strategies to prevent and manage this.\nWhat is perhaps the greatest medicinal discovery in the last 100 years has a sting in its tail, the tremendous success in managing bacterial infection has encouraged over and inappropriate use of antibiotics, the problems of which have been well documented. This review explores the developing comprehension that even a single day of antibiotic use has consequences that may produce transient and long term effects that compromise the health and well being of the patient and their bacterial co-habitants.\nSir Alexander Fleming discovered the antibiotic substance penicillin in 1928 and was awarded a co share in the Nobel Prize in Medicine in 1945.\nIt was a discovery that would change the course of history. The active ingredient in that mould, which Fleming named penicillin, turned out to be an infection-fighting agent of enormous potency. When it was finally recognised for what it was—the most efficacious life-saving drug in the world—penicillin would alter forever the treatment of bacterial infections. By the middle of the century, Fleming’s discovery had spawned a huge pharmaceutical industry, churning out synthetic penicillin’s that would conquer some of mankind’s most ancient scourges, including syphilis, gangrene and tuberculosis. (Time Magazine April 1999)\nHowever, as the combined benefits of decent engineering for sanitation, prevention via vaccination and bacterial infection control through antibiotics have contributed to life extension, they have also produced microbe and human disturbances. The incidence of immune mediated disorders is continuing to increase and the gastrointestinal tract is continuing to gain traction as a site of significant origination.,\nMost healthcare professionals are now aware of the complication of prolonged antibiotic therapy and the risk of developing antibiotic resistance or trans/bacterial development. Patients are often less comfortable with this notion and will still seek antibacterial treatments for primary viral illness, follow the treatment protocol badly and continue to apply dubious standards of self care.\nThe Journal of Mucosal Immunology in March 2010, ran an editorial and paper on the adverse effects of antibiotics beyond those previously understood. Most Nutritional Therapists and clinicians will agree that there may be some level of bacterial disruption after a course of treatment. Most conservative researchers had suggested that the ‘fingerprint’ of species in the gut, maintained through bacterial communication techniques would ensure the bacterial architecture resolves a short time after cessation. Bonnie Basler PhD describes this quorum communication in an informative film from one the famous TED presentations.\nSome intestinal bacteria are mutualists that promote normal human physiology including proper digestion, metabolism, epithelial cell function, angiogenesis, enteric nerve function, and immune system development. Although bacterial communities in the intestine promote normal immune homeostasis, patients with inflammatory bowel disease or allergies have altered intestinal bacteria, indicating that microbial populations might influence disease pathogenesis and in particular those linked with adverse immune driven inflammation.\nIt is now understood that the composition of the microbiota is significantly altered by the use of antibiotics including the increase in urinary tract infections, diminished carbohydrate fermentation, loss of bile acid metabolism, pathogenic bacterial colonisation, immune disturbances, barrier defects and mucin degradation.\nMicrobe Associated Molecular Patterns (MAMP’S) are the molecular signatures used by bacteria to impart friendly messages to the mucosal immune receptors. They are also used to promote defence when a pathogen’s sticky patterns are identified. It is proposed that a change in the concentrations of these messengers by antibiotic therapy could disrupt the homeostatic health of the gut contributing to various significant changes in the competence of the gut related immune responses. It is becoming clear that a large part of our bacterial bedfellows have similar MAMP’S allowing them to operate in a symbiotic manner for immune tolerance and gastrointestinal health. It is this strategy used by probiotics to impart different messages to maintain a healthy digestive tract, and may also be used in the resolution or management of more complex immune mediated diseases.\nOur mucins are a vital part of the overall management, composed of an inner layer, a dense composition and free of bacteria, and the outer layer, made up of a looser matrix and offering a home to bacteria. The inner layer acts like a muffler, diminishing contact with the intraepithelial lining and yet still able to allow MAMP’s via dendritic cells to communicate with the immune system. The use of probiotics; L.plantarum and L.Rhamnosus (LGG) have shown a beneficial increase in this mucin layer, adding volume to the material and improving resistance to pathogen adhesion.\nA loss of this layer as shown in the diagram above may increase the total information load on the lining cells by loss of the muffling mucins in effect increasing the frequency and noise of the bacterial chatter, and may also facilitate translocation of bacteria across the lining, inducing an inflammatory response and additional loss of barrier quality. This increase in inflammation may induce local damage such as IBD but may also induce collateral damage to tissues far distant from the gut, such as the brain, joints and skin as described in a previous post.\nBacteriotherapy (the treatment of disease by the use of bacteria or their products)\nThe use of certain strains of probiotics have demonstrated barrier protection and cell survival. The opposite effect of loss of barrier integrity has many potential health complications related to inflammation as explained in a previous article. Antibiotic therapy offers the reverse scenario and contributes to pro-inflammatory cytokine production and loss of antimicrobial proteins, used by the gut tissues to maintain microbiota colonies and prevent pathogens binding. The use of selected probiotics (MAMP’s) during and post antibiotic therapy to selectively agitate the mucosal immune system represents a safe strategy.\nOur bacterial bedfellows and the single cell lining of the gut communicate through a variety of mechanisms, a loss of the bacterial composition can alter, tight junction expression, mucins, antimicrobial peptides and cytokine ratio’s. The resulting disturbance may then as a result affect the TH17/Treg ratio in the gut leading to increased production of the cytokine (IL-17), associated with inflammatory and autoimmune disease. Interestingly we as humans use our food source to provide control over the adverse production of this protein, Vitamin A derived from our foods, helps to programme the naive T cells in the gut to develop Treg or peacekeeping cells, rather than the inappropriate conversion into TH17 cells. The role of Vitamin A in mucosal health is well understood but it’s unique role in mucosal tolerance is only just being fully elucidated.\nAntibiotics used in clinic might be used to remove or suppress undesirable components of the human microbiome. Antibiotic treatment causes significant temporal and spatial alterations in various colonies of bacteria that have been proposed to have causative or therapeutic roles in human diseases. Antibiotic treatment also has significant negative effects on the output of pro-inflammatory cytokines in gut associated lymphoid tissues.\nFindings from this paper indicated that even short antibiotic courses can result in dramatic alterations to intestinal bacterial communities. In particular, significant reductions in the frequency of mucosal-associated Lactobacillus species were observed in antibiotic-treated as compared with control-treated animals.\nProbiotics can introduce missing microbial components with known beneficial functions for human health. Prebiotics such as those derived from apple soluble fibre can enhance the proliferation of beneficial microbes or probiotics as well as diminishing total inflammation, to maximise sustainable changes in the human microbiome.\nCombinations of these approaches might provide synergistic and effective therapies for specific disorders. The human microbiome could be manipulated by such “smart” strategies to prevent and treat acute gastroenteritis, antibiotic-associated diarrhoea and colitis, inflammatory bowel disease, irritable bowel syndrome, necrotising enterocolitis, and a variety of other disorders in which altered inflammation is a key driver.\nNutritional Therapists and other healthcare practitioners are going to have to consider the interactions of the medicines, foods, Saccharomyces Boulardii, and strain specific probiotics to optimise rather than compromise the restoration of gastrointestinal function – this is an exciting area of opportunity for specialism and research.\nThe incidence of lactic acid bacterial depletion and its potential role in the health of humans may make the use of a special strain such as LGG or combinations of strains a practical approach to post antibiotic minimisation of adverse immune disruption in the mucosal tissues. The role of SIgA in mucins and bacterial balance is also an area of significant opportunity for treatment, and Saccharomyces Boulardii has been shown to reduce IL-8 and increase SIgA as well as limit adverse effects associated with antibiotic therapy. In the gastrointestinal tract, SIgA exhibits properties of a neutralising agent (immune exclusion) and of an immunopotentiator inducing effector immune responses in a ‘non-inflammatory context’ favourable to preserve local homeostasis and control disease risk.\nS. boulardii effectively reduces the risk of antibiotic-associated diarrhoea in children. \nAntibiotics, and most likely other agents of bacterial disruption, can alter the composition of the human gastrointestinal bacteria. In some people this may be enough to cause a loss of barrier quality and other adverse changes. The increase in immunological chatter can then cause damage locally and systemically via numerous routes.\nNo longer can antibiotics be viewed as a benign self recovering challenge to commensal bacteria. Nutritional Therapists can lead the way in the judicious use of strain specific bacteria and yeast to prevent and restore these damaged tissues.\n Johansson ME, Phillipson M, Petersson J, Velcich A, Holm L, & Hansson GC (2008). The inner of the two Muc2 mucin-dependent mucus layers in colon is devoid of bacteria. Proceedings of the National Academy of Sciences of the United States of America, 105 (39), 15064-9 PMID: 18806221\n Mack DR, Michail S, Wei S, McDougall L, & Hollingsworth MA (1999). Probiotics inhibit enteropathogenic E. coli adherence in vitro by inducing intestinal mucin gene expression. The American journal of physiology, 276 (4 Pt 1) PMID: 10198338\n Brandl K, Plitas G, Mihu CN, Ubeda C, Jia T, Fleisher M, Schnabl B, DeMatteo RP, & Pamer EG (2008). Vancomycin-resistant enterococci exploit antibiotic-induced innate immune deficits. Nature, 455 (7214), 804-7 PMID: 18724361\n Hill DA, Hoffmann C, Abt MC, Du Y, Kobuley D, Kirn TJ, Bushman FD, & Artis D (2010). Metagenomic analyses reveal antibiotic-induced temporal and spatial changes in intestinal microbiota with associated alterations in immune cell homeostasis. Mucosal immunology, 3 (2), 148-58 PMID: 19940845\n Kotowska M, Albrecht P, & Szajewska H (2005). Saccharomyces boulardii in the prevention of antibiotic-associated diarrhoea in children: a randomized double-blind placebo-controlled trial. Alimentary pharmacology & therapeutics, 21 (5), 583-90 PMID: 15740542\n- All Immunity is Mucosal – The GUT is No 1\n- A Novel Approach to Treating Depression – How Probiotics Can Shift Mood by Modulating Cytokines\n- Coeliac Disease – Local & Systemic Consequences\n- Lactobacillus GG: A Potent Immune Regulator Effective in Many Disorders\n- Whats New in The Understanding Of The Immunology Of Ulcerative Colitis?\nKeywords:antibiotics, autoimmune, bacteria, cytokines, diet, dysbiosis, evidence, gut, gut health, immunity, inflammation, microbiome, mucosal, nutrition, probiotics, regulatory T cells, Saccharomyces Boulardii\n3 Responses to “Antibiotics Can Cause Gut Related Diseases”\nSee what others are saying about this post...\nYou can ask technical questions, be as supportive, critical or controversial as you like, but please don't get personal or offensive, and do keep it brief. Your comments will be published only after verification."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:7eef83e2-ea3c-4cde-aa63-4847319e3460>","<urn:uuid:c93be313-9e75-42db-9fe1-db72fc438485>"],"error":null}
{"question":"How do fish-free aquaculture feeds contribute to production efficiency, and what technical considerations must be addressed for sustainable Mediterranean aquaculture development?","answer":"Fish-free feeds have demonstrated comparable performance to standard diets, with Empagran achieving yields up to 4 MT per hectare using vegetarian diets that replace fishmeal with soybean meal and fish oil with algal oil. However, challenges include addressing bioavailability of plant protein sources and managing anti-nutritional factors that can affect digestibility due to short shrimp gut passage time. For Mediterranean aquaculture development, technical considerations include improving productivity without compromising environmental performance, considering the carrying capacity of surrounding environments (particularly for sea cages), and implementing proper environmental monitoring procedures. Key factors include site selection, environmental impact assessments, and developing tools for spatial planning to ensure sustainable development.","context":["The F3 — Future of Fish Feed announced today the three winners of the F3 Challenge - Carnivore Edition. The Ecuadorian company Empagran won for its vegetarian recipe that replaces fishmeal with soybean meal and fish oil with Veramaris’ algal oil rich in both EPA and DHA omega-3 fatty acids for Pacific white shrimp.\nWe spoke with Pablo Intriago, technical advisor at Empagran, and Jorge Torres from Veramaris, about the feed performance and its future prospects.\nAQ: Tell us about your company and its sustainability focus.\nPI: Empagran is a 100% Ecuadorian group dedicated to aquaculture and operating since 1975. Its sustainability focus is based on a fully integrated operation with more than 3,300 hectares in Ecuador and Colombia, hatcheries, packing plants and a feed plant (ABA) with a production capacity of 140,000 TM of feed per year. Empagran is in constant pursuit of improving its CO2 footprint, improving the efficiency of its pumping stations, reducing water intake, developing recirculation systems to reduce water discharge or owing more than 3,000 automatic feeders with solar panels.\nJT: Headquartered in Delft, the Netherlands, Veramaris is a joint venture between DSM and Evonik. Veramaris natural marine algal oil contains the highest levels of EPA & DHA Omega-3 on the global market today and is the first microalgae oil producer for feed to achieve joint ASC-MSC certification.\nThis year we also committed to reducing our Greenhouse Gas (GHG) emissions by setting a science-based target which has been approved by the Science Based Target initiative (SBTi) aimed at urgently limiting global warming to below 1.5°C. Veramaris will achieve a 38% reduction in absolute Scope 1 and Scope 2 emissions by 2030 from a 2021 base year. We recognize that through our own commitment to decarbonize, it helps customers address their Scope 3 emissions while also creating additional transparency in their supply chains.\nAQ: What ingredients did your company use to replace fishmeal and fish oil? Was the extrusion process affected by these new formulas?\nPI: ABA the feed plant/division of Empagran has been using alternative ingredients and byproducts for the past 15 years. Besides soybean meal (SBM), the main protein source, we have used different plant proteins, such as sunflower meal, camelina meal, guar korma, guar meal, DDGS and corn gluten meal. We have also used single-cell protein derived from Corynebacterium glutamicum. Free amino acids are also a good alternative to compensate for amino acid deficiency. When feeding marine species, fishmeal can be replaced with SBM, however, the oil fraction which is rich in highly unsaturated fatty acids, such as 20:5w3 and 22:6w3 and in some species 20:4w6, is a challenge. After studying the market, our choice was Veramaris oil. We have not found any change in the concentration nor the bioavailability of these ingredients during pelleting or extrusion.\nAQ: Where were the ingredients sourced from? What are the main constraints in terms of ingredient supply?\nPI: Most of the SBM and starch sources (wheat) are imported and that is a challenge in Ecuador. To improve the sustainability of the aquaculture industry, we need to start reducing the dependence to import these ingredients.\nJT: Veramaris can provide our customers a fully traceable and consistent quality omega-3 oil, free from contaminants and of the same high quality 365 days a year, 24/7.\nAQ: What has been the shrimp performance achieved so far? Do you plan to test or commercialize fish-free feeds for other aquaculture species?\nPI: We have tested our vegetarian diet (zero marine or animal ingredients) with no major differences in yields up to 4 MT per hectare compared to standard diets. However, our feeling is that it could be better to sacrifice a bit the production yields and harvest a better-quality product. Now the real challenge as an industry is to achieve a better price.\nEmpagran has already manufactured more than 2,000 MT of animal-free feed. It was used on our own farms and in selected customers. We also manufacture tilapia feed that has been free of fishmeal in the past 12 years.\nAQ: Did you find any palatability issues? Have your formulas had an impact on the final fillet quality? From your point of view, what is the main nutritional issue to solve to increase shrimp performance utilizing your formula?\nPI: One advantage of feeding shrimp is that the composition of its tail is mostly protein and water, and proteins are all the same regardless of the source. On the other hand, the fat concentration of shrimp tail is so low that its source does not affect palatability. However, we must work on the bioavailability of plant protein sources. Shrimp gut passage is so short that any anti-nutritional factors can affect the digestibility and hence growth rate. The use of fermented proteins, probiotics and phytobiotics can reduce this problem.\nJT: Farmed shrimp have nutritional requirements which impact health, resilience and profitability. Not meeting these requirements comes at a cost for the farmer. The success of the F3 Challenge shows that we are able to provide a nutritionally complete diet while decoupling from earlier reliance on marine ingredients. Veramaris recently published Optimum Omega Nutrition™ (OON) white paper for shrimp which shows new results under controlled conditions leading to excellent performance and sensory characteristics for ‘fish free shrimp’. That being said, there are ample opportunities in the market for shrimp with the product specifications that retailers and shoppers are looking for.\nAQ: Are these formulas cost-effective and competitive with standard feeds?\nPI: The price of replacing traditional ingredients such as fishmeal and fish oil with biotechnological products, such as Veramaris oil, is much higher. Convincing farmers and wholesalers that this product is worth a better price is a real challenge.\nJT: When optimum levels of EPA and DHA nutrients are specified in the feed formulation, algal oil containing both EPA & DHA can be the most cost-effective way to meet these constraints. Much depends on the variable quality, availability and price of conventional omega-3 sources compared to the consistent and reliable performance of algal oil as a feed ingredient.\nThat being said, in today’s environment it’s about de-risking the supply chain and that should be top of mind for the shrimp sector. Feed price inflation has been severe in part due to a reduced availability of feed materials. As a result, feed formulators and farmers are exposed to supply shocks. When it comes to the consistent availability of EPA & DHA omega-3, farmers risk sub-optimal nutrition.\nInnovative feed alternatives are already being used to do just that with the added benefit of improving health, productivity as well as sustainability. The salmon sector has already started taking action and we’re seeing large feed millers and farmers including innovations like ours while, at the same time, we are seeing retailers starting to deepen their sustainability efforts by looking back up the supply chain all the way to feed.\nAQ: Who are your current farm partners?\nPI: ABA main partner is Empagran with 2,300 hectares in Ecuador and more than 1,000 hectares in Colombia.\nJT: We have a global market in aquaculture, from the salmon farms of Norway and Scotland in the North to those in Chile in the South. Today, our algal oil is used to grow shrimp, salmon, trout, steelhead trout, yellowtail, largemouth bass, seabream, and seabass. We now have customers around the globe.\nAQ: What are the future expectations in terms of supply and markets for your fish-free feed?\nPI: The free-fish feed market is still to be developed. Empagran through ABA made a huge step in pioneering its production but the wholesalers and the final consumers must prioritize their needs. Some wholesalers interested in this product have requested that the product also needs to be GMO free. If the price is a constraint, developing a product free of fishmeal and fish oil and non-GMO at the same price is impossible. The public should also be educated that more than 90% of soybean meal in the market is GMO, the non-GMO product almost doubles the price and is difficult to find. Most importantly, there is not enough product available for everybody.\nJT: The aquaculture sector will continue to grow but so will the pressure for it to do transparently and sustainably. We expect a stronger focus on improving animal health and welfare across the aquaculture sector for both shrimp and fish to improve survival rates. The science has shown us that a diet rich in both EPA & DHA omega-3 plays a significant role in the health and therefore productivity outcomes for farmed seafood.","The MedAID project (Mediterranean Aquaculture Integrated Development) aims to increase the competitiveness and sustainability of the Mediterranean marine fish aquaculture sector throughout its value chain, by improving its technical productivity and economic performance with a market- and consumer-oriented approach, as well as achieving higher social and environmental acceptability and better governance (Aguilera et al., 2019). The development of aquaculture will necessarily involve an increase in the spaces devoted to this activity, due to the expansion of existing businesses and/or the creation of new ones. Conflicts pertaining to the use of marine space and the implementation of existing policies and legislation are two of the main factors hindering aquaculture growth (Galparsoro et al., 2020). Marine spatial management must be improved to facilitate site selection processes, alongside the establishment of transparent procedures and licencing processes, thus reducing the length of time and investment needed to develop new aquaculture activities. In addition, the increase in production will generate a proportional increase in the amounts of feed, which are often produced outside the countries concerned. If aquaculture is to double its production by 2030, the sector must improve its productivity, without compromising environmental performance (Lotze et al., 2019). Aquaculture can affect ecosystems (socially, economically and environmentally) positively or negatively, and aquaculture can be impacted by other human activities. Environmental impacts vary greatly depending on the type of farming in question (inland open flow, RAS, cages in protected areas or offshore) and husbandry practices (species, stocking density, feed composition, etc …). As for marine fish, whereas fry production takes place in inland hatcheries, as well as many pre-ongrowing farms, most ongrowing production takes place in sea cages, where the carrying capacity of the surrounding environment (hydrodynamic circulation, sediment characteristics etc…) is a critical constraint. To ensure sustainable development, ecological carrying capacity should be considered and environmental impacts of aquaculture should be minimized by either improving farm management or production systems, site selection, etc… Furthermore, all other uses of water and natural resources must also contribute to ensuring a sustainable ecosystem. The objective of this report (D8.5) is to review inputs and recommendations from international organizations and recent EU projects on environmental impact assessments, environmental monitoring procedures, as well as to discuss technical solutions to reduce the environmental impacts of Mediterranean fish farming and promote environmentally sustainable development.\nAfter a brief introduction on Mediterranean fish farm production based on MedAID results, the “Ecosystem Approach to Aquaculture” (EAA) framework and general aquaculture constraints at different spatial scales (farm, waterbody and regional scales) are described. We then focus on the key steps of the EAA: Marine Spatial Planning (MSP), Site Selection, Environmental Impact Assessment (EIA) and the Environmental Monitoring Procedure (EMP) before explaining how recent EU projects have developed tools and methods to facilitate these different steps. We reviewed decision support tools and methods tested and developed to facilitate spatial planning ( AQUASPACE), site selection and licencing procedures (TAPAS). We have then listed key indicators selected by stakeholders for Environmental Impact Assessments (EIA) and Environmental Monitoring Procedures (EMP) during different projects (including Indam and PerformFISH).\nFinally, the local (eutrophication) and global (use of fishery resources, carbon footprint) environmental impacts related to feed and fish faeces are discussed. The main strategies and recommendations for minimizing the impact of feed are: improving feed use through improvement of FCR, feed composition or best management practices, implementing innovative farming systems such as recirculating aquaculture systems (RAS) and Integrated Multi-trophic Aquaculture (IMTA) to improve the treatment and recovery of waste. Finally, prevention of fish escapees is reviewed (Prevent-Escape project).\nAccess to the full deliverable"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:f05bfdff-0e8f-4fdb-a4dd-7dd8ea635403>","<urn:uuid:205686ff-ae0e-4b7c-ab7a-853ec0a4487d>"],"error":null}
{"question":"As someone working in healthcare technology, I'm curious how AI's application in medical diagnosis compares between general clinical practice and edge computing devices - what are the key differences in their implementation and challenges?","answer":"In general clinical practice, AI primarily focuses on diagnostics and radiology, using machine learning algorithms to improve diagnostic accuracy and analyze patient data from electronic medical records. However, it faces challenges like the 'black box' problem where decision-making processes are poorly understood, and issues with healthcare data noise and lack of external validation. In contrast, edge computing devices for medical AI applications, like skin cancer detection apps, offer advantages of lowered latency for local decision-making and reduced reliance on internet connectivity. These edge applications are particularly valuable in remote locations with limited connectivity, though they typically focus on specific tasks rather than broad clinical implementation. Both approaches face validation challenges - clinical AI needs diverse patient datasets to avoid bias, while edge applications like the skin cancer detection app require careful preprocessing and model training to achieve accurate results.","context":["Artificial intelligence (AI) will bring in a new wave of changes in the medical field, likely altering how we practice medicine. In a timely contribution, Chen et al.  outline the current landscape of AI and provide us with a glimpse of the future, in which sophisticated computers and algorithms play a front-and-centre role in the daily hospital routine.\nWidespread adoption of electronic medical records (EMRs), an ever-increasing amount of radiographic imaging, and the ubiquity of genome sequencing, among other factors, have created an impossibly large body of medical data. This poses obvious challenges for clinicians to remain abreast of new discoveries, but also presents new opportunities for scientific discovery. AI is the inevitable and much-needed tool with which to harness the ‘big data’ of medicine.\nCurrently, the most immediate and important application of AI appears to be in the field of diagnostics and radiology. In prostate cancer, for example, machine learning algorithms (MLAs) are not only able to automate radiographic detection of prostate cancer but have also been shown to improve diagnostic accuracy compared to standard clinical scoring schemes. MLAs can use clinicopathological data to predict clinically significant prostate cancer and disease recurrence\nwith a high degree of accuracy. The same has been shown for other urological malignancies, including urothelial cancer and RCC. Implementation of MLAs will lead to improved accuracy and reproducibility, reducing human bias and variability. We also predict that as natural language processing becomes more sophisticated, the troves of nonstructured data that exist in EMRs will be harnessed to deliver improved and more personalized patient care. Patient data and clinical outcomes can be analysed in short time, drawing from a deep body of knowledge, and leading to rapid insights that can guide medical decision-making.\nCurrent AI technology, however, remains experimental and we are still far from the widespread implementation of AI within clinical medicine. A valid criticism of today’s AI is that it functions in the setting of a ‘black box’; the rules that govern the clinical decision-making of an algorithm are often poorly understood or unknowable. We cannot become operators of machines for which we know not how they work, to do so would be to practice medicine blindly.\nAnother barrier to incorporating AI into common practice is the level of noise in healthcare data. MLAs will use whatever data that are fed to the algorithm, thus running the risk of producing predicative models that include nonsensical variables gleaned from the noise. This concept is similar to multiple hypothesis-testing, where if you feed enough random information into a model, a pattern might emerge. Furthermore, none of the studies described by Chen et al. have been externally validated on large, representative datasets of diverse patients. MLAs trained on a narrow patient population run the risk of creating predictions that\nare not generalizable. This problem has already been popularized within genome analysis, where one study found that 81% of all genome-wide studies were taken from individuals of European ancestry . It is easy to imagine situations where risk score calculators or biomarkers are validated using non-representative datasets, leading to less accurate and even inappropriate treatment decisions for underrepresented patient populations. At best, MLAs that are not validated using stringent principles can lead to erroneous disease models. At worst, they can bias the delivery of healthcare to patients, leading to worse patient outcomes and exacerbation of healthcare disparities.\nChen et al. write of the possibility of AI in urology today. What about the future? Imagine a world in which computers with a robotic interface see patients in clinics, design and carry out complex medical treatment plans, and perform surgery without the aid of a human hand. This future may not be far off . Or, even stranger, consider a world in which generalizable AI exists. Estimates of the dawn of this technology range, however the most optimistic projections put the timeline on the order of 20–30 years. Not far behind could be the ‘singularity’, a moment when technological advancement occurs at such an exponential rate that improbable scientific discoveries happen almost instantaneously, setting off a feed-forward cycle leading to an inconceivable superintelligence.\nThe future is, of course, hard to predict. Nevertheless, AI and the ensuing technology will certainly transform the practice of urology, albeit not without significant challenges and growing pains along the way. The urologist of the future may look very different indeed.\nby Stephen W. Reese, Emily Ji, Aliya Sahraoui and Quoc-Dien Trinh\n- Chen J, Remulla D, Nguyen JH et al. Current status of artificial intelligence applications in Urology and its potential to influence clinical practice. BJU Int 2019; 124: 567–77\n- Popejoy AB, Fullerton SM. Genomics is failing on diversity. Nature 2016; 538: 161–4\n- Grace K, Salvatier J, Dafoe A, Zhang B, Evans O. When Will AI Exceed Human Performance? Evidence from AI Experts, 2017","Intelligent Edge: Building a Skin Cancer Prediction App with Azure Machine Learning, CoreML & Xamarin\nThis post is authored by Anusua Trivedi, Carlos Pessoa, Vivek Gupta & Wee Hyong Tok from the Cloud AI Platform team at Microsoft.\nAI has emerged as one of the most disruptive forces behind digital transformation and it is revolutionizing the way we live and work. AI-powered experiences are augmenting human capabilities and transforming how we live, work, and play – and they have enormous potential in allowing us to lead healthier lives as well.\nAI is empowering clinicians with deep insights that are helping them make better decisions, and the potential to save lives and money is tremendous. At Microsoft, the Health NExT project is looking at innovative approaches to fuse research, AI and industry expertise to enable a new wave of healthcare innovations. The Microsoft AI platform empowers every developer to innovate and accelerate the development of real-time intelligent apps on edge devices. There are a couple of advantages of running intelligent real-time apps on edge devices – you get:\n- Lowered latency, for local decision making.\n- Reduced reliance on internet connectivity.\nImagine environments where there’s limited or no connectivity, whether it’s because of lack of communications infrastructure or because of the sensitivity of the operations and information involved. There the only alternative to cloud servers are proprietary data centers that cost a lot to set up and maintain. Remote locations that can benefit immensely from artificial intelligence may end up having limited access to AI applications because of their poor connectivity. As IoT moves into more unpredictable environments including disconnected ones, it becomes increasingly more important to support such hybrid environments of cloud and edge computing.\nTake our skin cancer detection app as an example. Skin cancer is the most common type of cancer, globally accounting for at least 40% of all cases, and it is much better controlled when detected at an early stage. What if we create a real-time AI app which can quickly suggest whether or not a given individual needs to seek medical help? Such an app would flag a set of images which, in turn, could help doctors become more efficient by focusing most of their energies on their most critical patients.\nThe model/application being proposed here is intended for research and development use only. The model/application is not intended for use in clinical diagnosis or decision-making or any other clinical use. The performance characteristics of the application for clinical use has not been established.\nDataset and Preprocessing\nFor this work, we us the ISIC Skin Cancer Research dataset. We have split up the ISIC Dataset for training and testing – 80% of the images for training and 20% of the images for scoring. ISIC dataset contains 2000 images as training data, including 374 “melanoma” images and 254 “seborrheic keratosis” images, with the remaining 1372 being benign images. The training data is provided as a ZIP file containing dermoscopic lesion images in JPEG format and a CSV file with some clinical metadata for each image. Here we use only JPEG images for training our AI model. The ISIC dataset has far fewer melanoma examples than seborrheic keratosis and nevus. Only about 20% of the default ISIC dataset is malignant, a total of 374 images. The skewed distribution has a big impact on how we judge our classifier and how we train it. We apply different augmentation techniques such as rotation, cropping etc. to balance the dataset.\nBuilding an Intelligent Skin Cancer Prediction App\nTraining the AI model for the app:\nWe build the AI Model using the Microsoft Azure Machine Learning Workbench. Azure ML is a cross-platform application, which makes the modelling and model deployment process much faster versus what was possible before. We create a deep learning model using open-source packages supported in Azure ML. We use Keras with a Tensorflow backend to build the model.\nWe first tried the transfer learning approach for training the AI models. Applying transfer learning on a standard ImageNet pretrained ResNet-50 model was not giving good results on smaller domain-specific datasets such as ISIC. As seen in Figure 1, we used a smaller 2 convolution layer network with a sigmoid classifier. We did some hyperparameter tuning and Relu activation with Adam optimizer worked best for this model. This model, when trained on ISIC dataset, gives ~97% training accuracy on our training set and ~89% test accuracy on our test set.\nDeploy trained AI model as an intelligent app:\nWe want to run this trained model on our iPhone. We use CoreML to convert the trained Keras model to an iPhone compatible format (CoreML brings machine learning to iOS). Apps can take advantage of trained machine learning models to perform all sorts of tasks, from problem solving to image recognition. We pip installed the CoreML package in our Azure ML environment. We can run the CoreML converter on the Azure ML Workbench and create an mlmodel (see Figure 2 below).\nUsing Xamarin to develop an intelligent application:\nA key benefit of Xamarin is that the UI uses native controls on each platform – this helps us create apps that are indistinguishable from other iOS or Android apps. We start with the sample Xamarin app at this GitHub link. Next, we change the name of the model in the view controller file and load the compiled CoreML model. In the view controller file, we change the result extraction function to output the messages we want the app to spit out (see Figure 3). By changing only the highlighted lines of code in our sample Xamarin app, we can run any AI model on the phone.\nAt the end of these steps, we have our intelligent skin cancer prediction app for iOS (see Figure 4).\nFigure 1. Training DNN in AML\nFigure 2. Convert Keras model to CoreML in AML\nFigure 3. Intelligent Xamarin app\nFigure 4. Skin Cancer Prediction App Architecture\nIn this blog post, we showed how to use Azure Machine Learning to train and test an AI model and create an intelligent iOS app. Such apps can help with time-critical decisions at the edge, referring to the cloud only if more intensive computation or historical analysis is needed.\nWe hope you are inspired to use the combination of intelligent cloud and intelligent edge in your own scenarios and build a bunch of cool AI-powered apps for your business.\nAnusua, Carlos, Vivek & Wee Hyong\n(You can email Anusua at firstname.lastname@example.org with any questions pertaining to this post.)"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:33935736-a14e-425c-8e55-155730c48eee>","<urn:uuid:5b04595d-2dc7-45e7-8987-597b5b0b192a>"],"error":null}
{"question":"What are the main challenges in nutrient recovery from organic wastes, and what is the current state of circular economy policies addressing these materials in Europe?","answer":"The main challenges in nutrient recovery from organic wastes include the presence of heavy metals, organic pollutants, pharmaceuticals, and pathogens in the materials. There are also technical challenges related to the chemical and physical composition, such as dustiness of raw material and reactivity problems in wet chemical processes. Regarding circular economy policies in Europe, the EEA assessment reveals that most countries focus primarily on waste management and recycling, with very few having specific policies on circular economy. Most initiatives target waste and secondary raw materials, with only two countries acknowledging that circular economy requires going beyond increasing recycling rates. The EEA also noted that key concepts like resource efficiency are not clearly defined at either national or EU level.","context":["The European Environment Agency has released findings of an assessment of national progress on the efficient use of resources and has highlighted a lack of progress in adopting circular economy policies.\nThe assessment covered 32 countries and focused on material resources such as biomass, minerals, metal ores and fossil energy materials. According to the EEA, most countries reported a focus on closing material loops, especially waste management, recycling and prevention. ‘Fewer countries looked at the circular economy as a broader concept, and very few reported already having a policy document specifically on the circular economy and closing material loops,’ the EEA found.\nCircular economy policies are important as these are likely to form the overall framework for actions that will affect water, in terms of its use as a resource in circular economy activities such as reuse and in terms of actions that will protect the aquatic environment such as efficient use and recycling of nutrients.\nAccording to the EEA’s report on the assessment, ‘More from less – material resource efficiency in Europe’, most circular economy initiatives are targeted at waste and secondary raw materials and at the abiotic part of the economy. ‘Only two countries explicitly commented that the circular economy requires going beyond increasing recycling rates and a higher use of secondary raw materials,’ the report states. It recommends looking at how policies on the transition to a circular economy should encourage initiatives beyond waste and recycling.\nThe assessment focused on material resources entering or leaving the economy and covering biomass, non-metallic minerals, metal ores and fossil energy materials, and secondary raw or waste-derived materials. Broader resource efficiency was only covered by an optional question in the assessment, encompassing aspects such as water, land, soil, marine resources and biodiversity. This focus reflects the European Commission’s circular economy package launched in December, which focused on action on chemicals, plastics, food waste, construction, critical raw materials, industrial and mining waste, consumption and public procurement, with fertilisers and water reuse to be dealt with later.\nConcerns raised by the EEA include the fact that key concepts such as resource efficiency and the scope of material resources are not clearly defined in either national policies or at the EU level. ‘There is no uniform definition or even implicit understanding of key terms such as materials, raw materials or resources in EU policy documents that deal with resource efficiency and raw materials,’ it also notes.\nThe EU’s critical list of raw materials includes phosphates, which from a water perspective represent an environmental concern and one of the main areas in which water and wastewater utilities can contribute to a circular economy approach. ‘No countries reported having targets for reducing the use of primary materials (metals, minerals or biomass), or for specific materials, including those on the EU list of critical raw materials,’ the EEA found.\nThe EEA also raised concerns around how to go about measuring progress towards a circular economy. ‘Indicators on material use and/or resource efficiency that are currently available or in use do not seem well suited to measuring the environmental effects of material use or the decoupling of resource use from economic growth and its impacts,’ it found.\n‘More from less – material resource efficiency in Europe. 2015 overview of policies, instruments and targets in 32 countries’, EEA Report No 10/2016\n- Europe, resource recovery","How to retrieve nutrients from organic wastes Judith Schick, Silvia Haneklaus, Ewald Schnug A Greener Agriculture for a Bluer Baltic Sea ‐ Visions for nutrient management Scandic Marina Congress Center, Helsinki, Finland 27‐28 August 2013 www.jki.bund.de Outline • Nutrient recovery potential from organic wastes Nutrient recovery potential from organic wastes • Challenges • Nutrient recovery from – Waste water treatment (process water, sewage (p , g sludge, sewage sludge ash) – Urine – Manure – Meat and bone meal • Summary and recommendations Summary and recommendations Recovery potential Estimation of the potential amounts of p nutrients in selected organic g waste materials in the EU (1000t/year) (Werner, 2008) N P K Manure 6700 1583 6534 Sewage sludge 0330 0250 A i l Animal meals l 0120 0155 Bio‐/green waste 0216 0047 Residues from gelatine production from gelatine production 0001 4 0001.4 0000 7 0000.7 Residues from potato starch production 0018.8 0002.9 Fermentation filter cakes Fermentation filter cakes 0003.6 0001.6 Molasses production (vinasse) 0037.4 0000.9 Defecation lime sugar industry 0018.7 0027.4 0149 0037.5 0058.0 Challenges • Organic waste materials may contain: – – – – Heavy metals H t l Organic pollutants Pharmaceuticals Pathogens • Chemical and physical composition – Dustiness of raw material – Reactivity problems in the wet chemical processes • Important: stability of chemical quality I t t t bilit f h i l lit • Possible solution: designing new process to produce NPK – or PK ‐ fertilisers from recycled materials fertilisers from recycled materials • Finding a suitable market to distribute the product – Agronomic efficiency – Financial viable and environmentally safe Technologies for nutrient recycling Nutrient-recovery from waste water, sewage sludge and sewage sludge ashes http://assets.inhabitat.com/wp‐content/blogs.dir/1/files/2010/07/sewage‐sludge.jpg Possible locations for P‐recovery at a waste water treatment plant waste water treatment plant (Adam, 2009) Technologies for P Recycling Watery phase: waste water (treated) or process water (e.g. sludge liquor) • Process Berliner Wasserbetriebe/Air Prex (Heinzmann, 2008) Process Berliner Wasserbetriebe/Air Prex (Heinzmann, 2008) Precipitation • Prisa process (Pinnekamp and Montag, 2007) • DHV‐Crystalactor® (Giesen and De Boer, 2003) Crystallization • The OSTARA PEARLTM (Esemag, 2006) Dewatered or dried sludge Wet chemical b / fh ( ll ) • Seaborne /Gifhorn process (Versterager, 2003; Müller, 2005) Crystallization • CSH‐process Darmstadt (Petzet, 2009) Thermal • Mephrec process (Scheidig et al., 2009) Sewage sludge ash • Sephos process (Cornel and Schaum, 2005) Sephos process (Cornel and Schaum 2005) Wet chemical • PASH process (Montag et al., 2005; Pinnekamp et al., 2007) • BAM/AshDec process (Adam, 2009; Herrmann, 2009) BAM/AshDec process (Adam 2009; Herrmann 2009) Thermal • Electro thermal P (Cornel, 2002; Korving and Schipper (2009) (Adam, 2009) Watery phase ‐ crystallization OSTARA PEARL OSTARA PEARLTM Process Recovering struvite (NH4)Mg(PO4)*6H2O) Crystal Green® already sold as “slow release fertiliser” http://www.scientificamerican.com/media/inl ine/sewages‐cash‐crop_1.jpg • 5% N + 28% P + 15% MgO • Inorganic • Free from pathogens >> 85% of P and 40% of N 85% of P and 40% of N can be recovered www.ostara.com/technology Sewage sludge ‐ crystallization • P P‐recovery from Bio‐P sludges using calcium‐silicate‐ recovery from Bio P sludges using calcium silicate hydrate (CSH) pellets (Petzet & Cornel 2009) • Pellets are directly fed into the anaerobic reactor for sludge stabilisation • P is directly (“in‐situ”) taken up by the CSH pellets • Crystallisation of Ca‐P is triggered Crystallisation of Ca P is triggered • P‐loaded pellets are removed from the sludge and reused in the fertiliser industry Sewage sludge ‐ crystallization (P t t & C (Petzet Cornell 2009) • P‐recovery approx. 30% of P contained in wastewater • Costs: approx. 5€/kg P Costs: approx 5€/kg P Sewage sludge ash – thermo‐chemical • Raw sewage sludge ash – P‐forms: AlPO4 and Ca3(PO2)2 [whitlockite] – Free from organic pollutants – High heavy metal concentrations • Thermo‐chemically treated sewage sludge ash y g g – Significant reduction (< 90%) of Cd, Cu, Pb, and Zn off gas treatment system gas rotary kiln sewage sludge ash Cl‐donator P rich secondary raw P‐ rich secondary raw material (Adam, 2008) Sewage sludge ash – thermal – Reformation of P Reformation of P‐forms: forms: • Ca5(PO4)3Cl [Chlorapatite] • Ca4Mg5(PO4)6 MgCl2 [Stanfieldite] • Ca5(PO4)3Cl Cl [Chlorapatite] C Cl2 CaCl • MgCl2 Cl‐donor: fertilisation performance of ashes close to SSP Cl‐donor: fertilisation performance of ashes close to SSP • CaCl2 Cl‐donor: lower yield and P‐uptake post processing – Addition of a fully digested P fertiliser (i.e TSP) – Partial digestion e.g. with H3PO4 or H2SO4 • Costs: approx 2.3€/kg P Nutrient‐recovery from urine y http://media.treehugger.com/assets/images/2011/10/nomix‐toilet‐photo‐001.jpg Fertiliser products from human urine • Problem: risk of contamination with pharmaceuticals/synthetic estrogens • Solution: • Struvite precipitation by adding MgO or MgCl2 at pH ≤ 9 • P recovery rates: 90‐98% • Final product: • Low in heavy metals and micro‐pollutants Low in heavy metals and micro pollutants • Represents a valuable market fertiliser • Fertilising effect comparable to commercial fertilisers (Ganrot, 2009) Distribution of N and P in human excretions (Vinneras, 2004; quoted after Kroiss et al., 2011) Urine g/(PE*a) Faeces g/ (PE*a) Urine (%) Faeces (%) N 4000 550 88 12 P 0365 183 67 33 Nutrient‐recovery from manure http://www.tierschutzbund.de/information/hintergrund/landwirtschaft/schweine/sc hweinemast-anlage-allstedt.html Slurry separation • Slurry: improper N/P‐balance which does not match plant need • Solution: Separation of slurry Solution: Separation of slurry – – – – Sedimentation Centrifugation Drainage Pressurised filtration • Liquid fraction: high N:P ratio on farm use as N‐source • Solid fraction: narrow N:P ratio transport to farms with low livestock density – Substitution for mineral fertiliser P • Problems: bl – Change of plant nutrient/heavy metal ratio in the biomass (depending on the separation process) p p ) – Fate of pathogens? Nutrient recovery from meat and bone meal Nutrient‐recovery from meat and bone meal http://www.ave.at/ave_at/images/315200390213632229_4999946469489 09218_0p6MtR0E.jpg Thermal digestion of meat and bone meal • Average nutrient concentration MBM: 8% N, 5% P, 1% K and 10% Ca (Chen et al., 2011) ( h l 20 ) • Bone fraction: apatite; meat fraction: organic P • Slow release fertiliser on acid soils (< pH 5.5) • Comparable to rock phosphate • MBM‐ash: also poor agricultural performance • Digestion of MBM MBM‐ash ash in liquid converter slag (1600 (1600°C) C) increases : – P solubility (e.g. Citric acid from 53% up 87%) – DMY and P‐uptake DMY and P uptake comparable to fully digested P fertiliser • Technique also applicable to SSA Technique also applicable to SSA (Rex, 2009) Summary/conclusion • Nutrient‐recycling with focus on P is essential • Different secondary raw materials can be used for recovery – Process water – Sewage sludge and sewage sludge ash S l d d l d h – Manure – Urine – Meat and bone meal • Different techniques can be used to recover nutrients – Precipitation – Crystallisation – Separation S ti – Thermal treatment – Wet chemical process Wet chemical process Recommendations Political: – Formulation of threshold values for relevant heavy metals in the European fertiliser ordinance – Mandatory mixing of recycling P with rock Mandatory mixing of recycling P with rock phosphate P – Imposing charges/taxes on Cd and U in mineral P‐ Imposing charges/taxes on Cd and U in mineral P‐ fertilisers – Supporting the development and improvement of Supporting the development and improvement of technologies for P‐recovery Thank you for your attention!\n© Copyright 2019"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:6caa100d-f15c-4fed-88ce-e89170a5a368>","<urn:uuid:9895a8e0-8736-470c-a9f5-d8a51fc9cc8f>"],"error":null}
{"question":"As a basketball enthusiast visiting Istanbul, I'm curious - how does the city's school system contribute to basketball's popularity?","answer":"Basketball is very popular in Istanbul's schools because every school has a basketball hoop, while they typically don't have soccer fields due to limited green space. Every student has the opportunity to play basketball during breaks, and it's a favorite pastime since it's easy to play - just throwing a ball without requiring exceptional speed or fitness. This accessibility is reflected in the statistics: out of Istanbul's 140,000 licensed athletes, 35,000 are basketball players, nearly matching soccer's 40,000 players.","context":["- Basketball Capitals\nCities in Focus - Istanbul\nWITH one foot in Europe, and another in Asia, Istanbul is a unique capital city, bridging two great continents.\nIt is also a city divided by sporting allegiances, as surely as it is split in two by the mighty Bosphorus river. Growing up in Istanbul means pledging allegiance to a sporting powerhouse like Galatasary or Efes; Fenerbahce or Besiktas.\nBut there is one thing that unites every Istanbul native, every son or daughter of Turkey come to that - the sport of basketball.\nCurrent Toronto Raptors assistant coach Scott Roth played for Anadolu Efes Istanbul, one of three clubs from the city that made up the 24-team Euroleague field this season and went on to become an assistant coach with the Turkish national team. His experience is typical of so many outsiders who experience their own taste of Turkish delight.\n\"My first two years there were some of my best basketball and life experiences ever,\" says Roth. \"My mother cried when I decided to go so far away to play in 1985 after (being released from the San Antonio Spurs), but it was an awesome experience and a very exciting city to live in and play in. Great club with super fans … and some of my closest friends to this day are my teammates from Efes.\n\"I was also lucky enough to return to Istanbul more than 20 years later as a coach with the national team when Turkey was the host country for the 2010 World Championships. I look back on those two weeks of the tournament as the two greatest weeks of my basketball life. You could feel the entire country rallying around the team when we beat Serbia to go the finals. And I'll never forget going to the championship game with a police escort and streets full of people for miles and miles cheering as the bus passed by on our way to the arena. People who went to that tournament still talk about that team and those two weeks in Istanbul.\"\nThose 2010 World Championships, in which a Turkey team inspired by NBA superstar Hedo Turkoglu made it all the way to the final in Istanbul before succumbing to Kevin Durant and the USA 81-64, signaled that the hosts had become a definite power on the world stage.\nBut surprising as that performance may have been to some outsiders, Turkey's success was inevitable in the eyes of those, like Roth, who had experienced first-hand the growing passion for the sport in the country, and in Istanbul especially.\n\"Istanbul does not have a lot of green fields,\" explains Naci Cansun, Senior Director of NBA Turkey. \"So basketball is very popular because it is easy to play, especially in schools. I don't know of any school - whether primary, secondary of high school - that has a football (soccer) field, but every school has a hoop. Every school kid in Istanbul has the chance to play basketball and it's the favourite pastime during breaks. You don't have to be super-fast or fit to try basketball in a school yard. It's just about throwing a ball.\n\"If you look at the numbers, Istanbul has about 140,000 licensed athletes, 40,000 of those are for soccer and 35,000 for basketball so the difference is not that huge.\"\nAt the heart of Istanbul basketball lies the mighty professional clubs - Anadolu Efes Istanbul, Besiktas JK Istanbul and Fenerbahce Ulker Istanbul, the three teams in this year's Euroleague, plus current league leaders Galatasary Medical Park Istanbul (note how European teams incorporate the names of sponsors into their official titles).\nAs with teams in Spain, many Turkish basketball clubs are part of bigger \"sporting clubs,\" who field teams in football, handball and volleyball, among other sports. \"What that means,\" explains Cansun, \"Is that people who are fans of a club, but not necessarily a sport, diversify their interest. That happens in terms of participation as well. If someone is a Fenerbahce supporter, they may get their sons and daughters involved in basketball education.\"\nIn turn, the clubs have responded and reached out to the hundreds of thousands of potential new players around the vast city. \"There are so many basketball schools,\" explains Engin Ozerhun, general manager of Efes. \"We are teaching basketball to children without any charge, a social responsibility project called 'First Step with Anadolu Efes,' which we started in 2004 and which reaches over 20,000 children in 40 centres. We also have centres in Northern Cyprus and Sarajevo and organise education programmes, not only for children but for technical staff and coaches.\"\nWhen a story hit the Turkish media recently about a high school game in a far-flung, impoverished corner of south-east Turkey, near the border with Iran and Iraq, in which a team beat a rival from a remote village 299-0, Efes quickly sent out a shipment of basketballs and equipment to the losing school.\nMeanwhile, at the top level of the sport, modest ticket prices - Efes, for example, charge an average 7.70 Turkish lira, or $4.30 for a ticket to a top Euroleague game - mean that most games are played to sell-out, fanatical crowds.\nAnd that fanaticism makes Turkish basketball among the most exciting and passionate in the entire basketball world. The rivalry between clubs like Fenerbahce and Besiktas has lasted a century or more and covers not only basketball but other team sports, most notably football. And, while that passion sometimes looks close to exploding and becoming something more sinister, those close to it claims this is not the case.\n\"Turkish people are affected by the Mediterranean Culture,\" explains Ozerhun. \"And this effect is reflected on the court. But this passion is always gentle!\"\nAlthough the city's most famous basketball export, Orlando Magic forward Turkoglu, has not played club basketball in his homeland since leaving Efes for the Sacramento Kings in 2000, he has noted the growth of the sport with the pride of an Istanbul native.\n\"Istanbul is a spirited basketball city,\" he says. \"There is a lot of passion for the game. The game continues to grow as they continue to build new facilities. You can see kids bouncing basketballs everywhere.\"\nOf course, living in a city of 13.9 million people - by some estimates, second only to Shanghai on the list of the world's most populous cities - is not without its challenges. \"I lived in Moscow and I know LA and people say they have the worst traffic in the world,\" says NBA journeyman Pops Mensah-Bonsu who played for Besiktas last season. \"Wrong! You haven't seen real traffic until you have been to Istanbul. There are 20 million people there and they seem to all drive at once, completely insane.\n\"Istanbul was great though - the people nice, the coast is nice, the architecture, scenery, it was a really nice place to be after I took time to get to know it.\"\nBasketball Capitals is a new ESPN documentary series profiling the passion for basketball within the world's most iconic cities. The four-part series will premiere in May across ESPN in Europe, Middle East, and Africa."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:f7ca76cf-046b-45dc-a914-ef0610270ae9>"],"error":null}
{"question":"What are the age requirements for bone marrow donation compared to kidney donation?","answer":"For bone marrow donation, donors must be between 18 and 60 years old, with a preference for donors aged 18-44 since bone marrow transplant is most successful with younger donors. For kidney donation, the only specified age criterion is that donors must be at least 18 years old. Being under 18 is listed as an absolute exclusion criterion for kidney donation, while being between 18-21 years old or older age (unspecified) are considered relative exclusion criteria that require further evaluation.","context":["Now…About Your Health\nOnce you’ve agreed to be considered a donor, you’ll go through an in-depth assessment of your health. What the transplant team wants to evaluate is whether:\n- Your blood type and tissues are compatible with the recipient,\n- You are healthy enough to withstand major surgery and recover completely,\n- You have a healthy kidney—preferably the left one—to donate, and you have a healthy kidney to keep—one that can compensate for the loss of a kidney, and\n- Your are psychologically ready to donate and are donating for the right reasons.\nWith these three primary goals in mind, here is how donor candidates are medically evaluated.\n1. Blood and Tissue Compatibility\nBlood Type. The first step is to determine your blood type. There are four blood types, designated by the presence or absence of two antigens—the A antigen and the B antigen. Blood type A means you have the A antigen. Type B means you have the B antigen. Type AB means you have both antigens. Type O means you don’t have either antigen.\nAs a general rule, you must have a blood type compatible with the recipient or you will not be able to donate. Note that the Rh factor (positive or negative) does not matter for matching purposes. Here is who can donate to whom:\n- Type A can donate to types A and AB.\n- Type B can donate to types B and AB.\n- Type AB can donate to type AB.\n- Type O can donate to types A, B, AB, and O.\nThe blood type is determined by drawing your blood and testing it.\nIf you and your potential recipient have blood types that are not compatible, there are four things you can consider:\n- Paired exchange or chain donation. As explained on a prior LDO web page, paired exchange involves finding another donor-recipient pair who have incompatible blood types but where your blood type is compatible with the other recipient, and the other donor’s blood type is compatible with your intended recipient’s blood type. In that situation, you donate to the other recipient, and the other donor donates to your recipient. In a growing number of situations, more than two donor/recipient pairs are linked in an extended “chain” of donation.\n- Plasmapheresis. Plasmapheresis has the transplant recipient undergo a special medical process that removes the blood’s incompatible antigens. With removal of the recipient’s antigens, the donor is now able to donate. Note that plasmapheresis may be considered an experimental procedure and medical insurance may not cover the expense. Be sure to check the insurance plan before proceeding.\n- A different living donor. If you don’t match your intended recipient, maybe there is another friend, relative, or non-directed living donor who can be considered.\n- Deceased donation. Finally, the recipient could wait for a compatible deceased donor.\nTissue Type. A second test looks at the compatibility of your tissues by comparing your human leukocyte antigens (HLA) with the intended recipient. There are many different kinds of HLAs, but usually there are three categories evaluated for kidney donation. You inherit one set of these three antigens from each parent giving each person a total of six of these donation-related HLAs.\nYour antigens are determined by drawing blood and testing it. A similar test is run for the recipient, and the antigens are compared. You might hear of a “six-out-of-six” or “full” match (all donor and recipient antigens match) or a “half match” (three of the six antigens are the same) or a “zero match” (none of the antigens matches). The closer the match the better because the recipient is less likely to reject the donated organ over the long run.\nThere was a time when this type of tissue compatibility was very important. However, the development of more effective anti-rejection drugs has reduced the importance of the HLA match. In fact, some transplant teams ignore tissue typing. Therefore, even if your degree of matching with the donor is relatively low, you may still be considered for donation. However, given a choice among potential donors, the one with the highest level of tissue compatibility typically is preferred.\nCrossmatching. The third blood test, called crossmatching, is a further test of antigen compatibility. In this test, white blood cells from you are mixed with blood from the intended recipient. If the white blood cells are attacked, then the crossmatch is “positive,” which is a negative as far as your ability to donate to that person. It means the intended recipient is “sensitized” to you—he or she has antibodies to some of your antigens—so the intended recipient’s immune system would turn on the donated organ and destroy it. If the crossmatch is “negative,” you are compatible with the intended recipient.\nFor a “positive” crossmatch, plasmapheresis can be tried as a technique to allow the donation to proceed.\nAt this point, if there is more than one potential donor, the group is winnowed down to one or two. The reason for reducing the number of potential donors is because the remaining tests are more involved, time consuming, and expensive.\n2. Your General Health\nLiving donation may be the only medical procedure allowed where the patient (the donor) purposely leaves the hospital in worse physical health than when he or she walked in. Consequently, the transplant team needs to make sure you are in excellent health — better than the average person — so you can continue to enjoy good health after the donation.\nYou will go through an extensive physical examination, one that has more tests and evaluations than you have probably ever experienced before. Standard procedures for a medical evaluation do not exist but guidelines have been provided by several medical professional organizations. The transplant center will provide you with a schedule for the exams and testing, which often stretches over multiple days.\n- Physical exam including blood testing (cholesterol, blood count, creatinine, urea, etc.), blood pressure, height, weight, BMI calculation, personal medical history, family medical history, prescription drug use, substance abuse, smoking history, alcohol intake, history of mental illness and treatment, kidney history (stones, injury, etc.), gout history, chest x-ray, electrocardiogram, and testing for viral and bacterial infection (HIV, hepatitis, syphilis, herpes, tuberculosis, etc.).\n- Fasting blood glucose test and, depending on diabetes risk factors, a glucose tolerance test.\n- Echocardiogram and stress test if over age 50 or presence of other risk factors.\n- Pulmonary function test and a chest CT scan for smokers.\n- Female donor candidates undergo a gynecological exam, mammography (if over age 40), PAP, and pregnancy test.\n- Male donor candidates may undergo a PSA test if over age 50.\n- Potential donors over age 50 may undergo a colonoscopy.\nCertain medical conditions will exclude you from being a donor. These conditions, called “contraindications,” vary from one transplant center to another because of the lack of common medical guidelines for evaluating living donors. However, to get an idea of the kinds of conditions that would typically exclude a donor, here is a list that was proposed by the UNOS Living Donor Committee:\nAbsolute Exclusion Criteria. The following conditions would exclude a living donor candidate without any further evaluation:\n- Under age 18.\n- Hypertension blood pressure greater than 130/90 plus one of the following conditions: in someone younger than 50 years old, with evidence of end organ damage, non-Caucasian, or on three or more anti-hypertensive medications\n- Abnormal glucose tolerance test\n- History of thrombosis or embolism\n- Psychiatric contraindications [UNOS did not specify which conditions]\n- Obesity: Body Mass Index (BMI) greater than 35\n- Coronary artery disease\n- Symptomatic valvular disease [damage of heart valves]\n- Chronic lung disease with impairment of oxygenation or ventilation\n- Recent malignancy or cancers with long times to recurrence (e.g., breast cancer)\n- Urologic abnormalities of donor kidney\n- Creatinine clearance under 80 ml/min/1.73m2, or projected glomerular filtration rate (GFR) with removal of one kidney at 80 years old of under 40 ml/min/1.73m2\n- Peripheral vascular disease [diseases of blood vessels outside the heart and brain, usually a narrowing of vessels that carry blood to the legs, arms, stomach or kidneys.]\n- Proteinuria [blood in urine] greater than 300 mg in 24 hours\n- HIV, hepatitis C, or hepatitis B virus infection\nRelative Exclusion Criteria. The following conditions may exclude a potential donor, subject to further evaluation:\n- Age between 18 and 21, and older age [UNOS did not specify] relative to the medical condition\n- Obesity (BMI between 30 and 35)\n- Kidney stones\n- Distant history of cancer\n- Past history of psychiatric disorder\n- Renovascular disease [blood flow in and out of the kidneys]\n- Thin basement membrane disease [an inherited disease that affects the glomeruli – the small blood vessels in the kidneys that filter wastes from the blood]\n- Prior valve surgery\n- Moderate cardiac valvular disease with otherwise normal echocardiographic findings [heart issues]\n- Mild sleep apnea without pulmonary hypertension\nKeep in mind that policies and procedures vary from transplant team to transplant team. You should confirm the actual contraindications with your transplant team.\nIf you are overweight but otherwise a good potential donor, you may be given time to lose weight. Several donors who have visited LDO said they were able to lose weight and donate successfully. If you are a smoker, it is suggested you stop smoking at least four weeks prior to donation to reduce the risk of complications when recovering in the hospital (a smoke-free environment) from the surgery. Permanently quitting is recommended because of the negative impact smoking and its associated diseases can have on the health of your remaining kidney.\n3. Health of Your Kidneys\nIn addition to a general assessment of your health, the donor evaluation focuses on the health and structure of your kidneys with these tests:\n- Urine tests. Your urine will be examined for the presence of blood and protein, and to ensure your urinary tract is not infected. You will be asked to undergo 24-hour urine tests, called creatinine clearance tests. Creatinine is a protein excreted in the urine and is a measure of kidney function. These tests are run to make sure your kidneys are working properly and to measure your glomerular filtration rate (GFR). (Your GFR will also be estimated using the level of creatinine in your blood from the blood drawn during your physical exam.) Your GFR is the most important measure of your kidney function, and having a high level is important because you will be giving up half your kidney capacity when you donate. Transplant specialists say having a GFR of 90 or more is an acceptable level for kidney donation, while having a GFR less than 60 means you should not donate. For a GFR between 60 and 89, the transplant experts suggest looking at demographic and health considerations to determine whether you should donate.\n- Screening for polycystic kidney disease (PKD). If indicated by your family history, you will have an ultrasound of your kidneys if over 30 years old, and genetic testing if under 30 years old.\n- Anatomical evaluation. You’ll undergo a procedure to identify the structure of the kidney, veins, arteries, the ureter, and other anatomy. A common approach is a Computed Tomography (CT) Angiogram test, commonly called a CT scan, which is a sophisticated form of X-ray. For this procedure, a dye is injected into a vein, you lay flat on a table, and the table moves through a special machine shaped like a giant doughnut. The machine projects a thin x-ray beam through your body and measures the output. The dye gives more contrast to the blood vessels making them easier to identify. A computer takes the information from the x-ray scan and generates a three-dimensional image of your kidneys and surrounding anatomy.\nThe information from the anatomical evaluation is critical to the surgeon for determining which, if any, of your kidneys is best for donation. Generally, the left is preferred because of its longer renal vein. But there may be structural complications in the left kidney such as multiple arteries that result in consideration of the right kidney.\nFor tests that use x-rays, female donor candidates should inform the medical technician if you are pregnant or might be pregnant. Also, the tests use a dye that some people may have an allergic reaction to. Let the technician know if you have had allergic reactions in the past, especially to iodine.\nNote: You will want to keep copies of all your pre-donation test results. This information will form a useful basis of comparison for test results after donation.\n4. Psychosocial Assessment\nDuring the medical evaluation you will meet with a social worker, psychologist, or psychiatrist for a psychosocial assessment, the goal of which is to evaluate your state of mind. This evaluation looks at the mental, emotional, social, and spiritual aspects of being healthy.\nUsually this assessment is done in a meeting during which the assessor asks you several questions about your level of understanding of the living donation process and risks, whether are you freely choosing to be a donor, and whether you are emotionally and psychologically ready for donation and recovery. There are no standard procedures for this kind of assessment. However, the UNOS Living Donor Committee put together recommendations. The recommendations were not approved, but they indicate the subjects that might be covered in your psychosocial evaluation:\n- History and current state. Obtain standard background information such as the prospective donor’s education level, living situation, cultural background, religious beliefs and practices, significant relationships, family psychosocial history, employment, lifestyle, community activities, legal offense history, and citizenship.\n- Capacity. Ensure that the prospective donor’s cognitive status and capacity to comprehend information are not compromised and do not interfere with judgment; determine risk for exploitation.\n- Psychological status. Establish the presence or absence of current and prior psychiatric disorders, including but not limited to mood, anxiety, substance abuse, and personality disorders. Review current or prior therapeutic interventions (counseling, medications); physical, psychological or sexual abuse; current stressors (e.g., relationships, home, work); recent losses; and chronic pain management. Assess repertoire of coping skills to manage previous life or health-related stressors.\n- Relationship with the transplant candidate. Review the nature and degree of closeness (if any) to the recipient (i.e., how the relationship developed), and whether the transplant would impose expectations or perceived obligations on the part of either the donor or the recipient.\n- Motivation. Explore the rationale and reasoning for volunteering to donate, i.e., the “voluntariness”, including whether donation would be consistent with past behaviors, apparent values, beliefs, moral obligations or lifestyle. Determine whether the donation would be free of coercion, inducements, ambivalence, impulsivity, or ulterior motives (e.g., to atone or gain approval, to stabilize self-image, or to remedy a psychological malady).\n- Donor knowledge, understanding, and preparation. Explore the prospective donor’s awareness of the following:\n> Any potential short- and long-term risks for surgical complications and health outcomes, both for the donor and the transplant candidate;\n> Recovery and recuperation time;\n> Availability of alternative treatments for the transplant candidate; and\n> Financial ramifications (including possible insurance risk).\nMake sure that the donor understands the data on long-term donor health and psychosocial outcomes continue to be sparse. Assess the prospective donor’s understanding, acceptance, and respect for the specific donor protocol, e.g., willingness to accept potential lack of communication from the recipient and the donor’s willingness to undergo future donor follow up.\n- Social support. Evalute support networks available to the prospective donor on an ongoing basis as well as during the donor’s recovery from surgery. Consider significant others, family members, social contacts, and employers.\n- Financial suitability. Determine whether the prospective donor is financially stable and free of financial hardship; has resources available to cover financial obligations for expected and unexpected donation-related expenses; is able to take time away from work or established role, including unplanned extended recovery time; and has disability and health insurance.\nKeep in mind that policies and procedures vary from transplant team to transplant team. You should confirm the actual psychosocial evaluation process with your transplant team.\nA Review and Decision\nOnce your physical and psychosocial evaluations are complete, the results are reviewed by the transplant team and a transplant review committee at the transplant center. The purpose of the review is to decide whether it is safe for you to donate and whether your being a living donor is the best course of treatment for the recipient. The committee will also determine if you are donating for the right reasons and are able to consent to the donation.\nIf you are not approved, you will be told why and then you can work with the transplant coordinator on how to communicate the news to the recipient. More importantly, if you are not approved for a health reason, you should be referred to a health professional to address the issue. There have been situations where the health evaluation revealed the potential donor had a serious health issue he or she was previously unaware of. While the potential donor wasn’t able to save the life of their intended recipient, their interest in living donation did save another life — their own.\nIf you are approved, you will move to the next phase of the living donation process — the actual donation itself. Remember that even if you are approved for donation, you can change your mind at any time.","Most healthy individuals age 18 to 44 could be potential blood and marrow stem cell donors. For some people, finding the right donor for a bone marrow transplant may be their only hope for a cure. UCLA Health helps bone marrow transplant recipients, their families and donors understand the process and the risks – and find the right match.\nThe National Marrow Donor Program runs a bone marrow registry. Potential donors can join, be tested and add their names to list of people willing to donate bone marrow to anyone in need. Whether you want to become part of the bone marrow registry or donate to a relative, the donation process is the same.\nHow to donate bone marrow\nFor a bone marrow transplant to be successful, the donor and the recipient have to be well matched. Unlike matching blood types, matching bone marrow stem cells is a bit more complicated.\nTo see if you are a potential bone marrow match, you will be tested to find out what type of human leukocyte antigen (HLA) you have. HLA is a protein found on most cells in your body — including those in your immune system. The closer the HLA match, the better chance that a bone marrow transplant will succeed. Bone marrow produces the infection-fighting white blood cells that are key to a functioning immune system.\nThe good news is that you don’t have to actually donate bone marrow to find out if you’re a match. The process starts with a simple cheek swab to provide a sample of your DNA. If you are a basic match for a recipient based on that test, you’ll have additional blood tests or cheek swabs. Those results will give doctors more details about your HLA type.\nIf you would like to be tested as a match for a relative who is being treated at UCLA Health’s Blood and Bone Marrow Transplant & Cellular Therapies Program, contact us. The patient’s doctor will arrange all of your testing and answer any questions you have about becoming a donor. Find out more about how a recipient prepares for bone marrow transplant.\nBone marrow donation procedure\nIf you are a match for someone needing a transplant, you will start the process of donating bone marrow stem cells. This process is the same whether you are donating for a relative or for someone using the National Marrow Donor Program registry.\nBefore your donation, you will spend a couple of days undergoing a consultation that includes:\n- Thorough health evaluation\n- Medical history\n- Blood tests\n- Filling out consent forms\n- Meeting with doctors about the donation procedure\nHow stem cells are extracted\nThere are two ways to obtain the stem cells used in a bone marrow transplant. The transplant recipient’s doctor will determine which method is best for his or her condition. The two procedures are:\n- Bone marrow harvesting: Doctors use needles to withdraw liquid bone marrow from both sides of the back of your pelvic bones. This is a surgical procedure that usually takes one hour. You will receive anesthesia so that you feel no pain during the extraction. Most people go home from the hospital that same day, but some donors stay overnight for observation.\n- Apheresis: Apheresis is a nonsurgical, outpatient procedure. Instead of collecting bone marrow, it allows for collection of peripheral blood stem cells.\n- Preparation: For five days before apheresis, you will get injections of filgrastim. This drug stimulates your bone marrow to make more stem cells and release them into your bloodstream.\n- Procedure: On the day of the donation, expect to spend up to eight hours at the collection facility. A catheter (thin, flexible tube) is placed in a large vein in your arm. The blood will flow into a machine that separates the stem cells from the blood. A catheter in your other arm transfers the remaining blood back to your body.\nBone marrow donation recovery\nAs you prepare to donate, you may be worried about possible bone marrow donation risks. The vast majority of donors experience few side effects — most of which are mild. Most donors report feeling completely recovered within a few weeks of their donation.\nThe side effects will vary depending on the type of donation procedure you had:\nSide effects of bone marrow harvesting\nThe most common side effects of bone marrow harvesting are related to anesthesia. If you have general anesthesia, you may experience nausea or vomiting. If you have regional anesthesia (such as an epidural), you may have headaches or a decrease in blood pressure. There is a very small risk of having damage to bone, nerves or muscles in the pelvis during the extraction procedure.\nSide effects of apheresis\nCommon side effects from the filgrastim injections include headache, bone or muscle aches, nausea, fatigue and insomnia. These typically diminish quickly after you finish taking the medication. During the donation procedure, you may have chills, tingling around the mouth, fingers and toes and muscle cramps. Your care team can slow down the procedure to help reduce these symptoms.\nJoining the national bone marrow registry\nThe registry needs donors of all races and ethnicities to provide the best matches for the most patients. They accept donors between the ages of 18 and 60. But because bone marrow transplant is most successful with younger donors, people ages 18 to 44 are preferred.\nDonors must be in excellent health. Certain diseases, medications, treatments and weight limits can exclude you from becoming a donor.\nFor more details about medical qualifications and how to donate bone marrow, go to Be The Match.\nIf you are interested in donating bone marrow to a relative in our care, please contact our Adult Blood and Bone Marrow Transplant & Cellular Therapies Program at 310-206-6909."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:d7888172-dd10-4b19-bc9c-dfd652b78224>","<urn:uuid:1df8b4df-ab4d-4651-8eaa-2198393bc4b0>"],"error":null}
{"question":"I'm researching Indian textile history. Could you compare the silk production heritage of Varanasi with India's overall historical significance in global silk manufacturing?","answer":"Varanasi has been a center of fine textile weaving for at least two millennia, with Buddhist texts from the first millennium mentioning Benaras fabrics. The city reached its pinnacle during the Mughal era, with Muslim weavers of the Julaha community (some tracing lineage to 990 AD) developing unique combinations of Indian and Persian patterns. Looking at India's broader silk heritage, the country has been historically significant as one of the oldest silk-producing regions, with some believing the Indian Himalayas to be the homeland of silk, situated on the 6,000-mile silk route from China to the Mediterranean. India's silk production was further developed under rulers like Tipu Sultan of Mysore and saw increased production in Bengal during the British era due to World War II parachute demand. Today, India stands as the second-largest silk producer globally and is the only country producing all four commercial varieties of silk: Mulberry, Eri, Tasar, and Muga.","context":["Benaras or Varanasi has the pride of being the one of the most famous Handloom centers in the entire world. In fact it is among the few centers in the world that has painstakingly preserved the ancient tradition of hand weaving. In fact, in spite of persistent assault by technology, globalization and market forces Benaras stuck to handloom and didn’t switch to Power loom as some other famous centers such as Malegaon, Bhiwandi and Murshidabad did. The main products in Varanasi are Zari and brocades.\nBrocades are actually textiles woven with warp & weft threads of different colors and often of different materials. The brocades are woven in silk with profuse use of metal threads in ‘Pallars’ (end pieces) and the field of the Sarees. These Sarees have been named Banarasi Sarees and are the most popular and beautiful Saree in India.\nBanarasi Saree holds a unique status in the world of fashion. It is an Indian woman’s coveted possession. An Indian woman, clad in a Banarasi silk saree, complete with her solah sringar (16 makeup items), is the dream girl of every Indian man. There is hardly any woman in India whose wardrobe does not include Banarsi sarees. Benarasi Sari offers such grace to a woman that can hardly be matched by any other dress.\nHISTORY OF BANARASI SAREE\nThe tradition of making Varanasi or Banarasi sarees in Varanasi or Banaras is very ancient. But it has continued to be passed down from one generation to another and continues to flourish. One will find thousands of weavers making the Varanasi silk saree in this scared city even today.\nSeveral first-millennium Buddhist texts mention Benaras fabrics, giving the indication that Benaras has been the center of fine textile weaving for at least two millennia. During the past few centuries, the weavers of Benaras have been overwhelmingly Muslims belonging to the Julaha community. Some of the weavers have been able to trace their lineage back to 990 AD. The Mughal era was the time when the fame and recognition of Banarsi silk sarees of India reached its pinnacle. Even the motifs underwent a change and the saree saw new designs, resulting from the combination of Indian and Persian patterns. Today, Indian craftsman are exporting Banarsi sarees, the specialty of Benaras/Varanasi, to the remotest corners of the world. Numerous weavers, in and around the city of Benaras, are engaged in this ever-expanding industry. The silk used in the making of Indian Benarasi silk sarees is being sourced from the southern parts of the country, mainly Bangalore.\nTYPES OF BANARASI SAREE\nZari and barcode are main products\nThere are following four basic varieties of Banarasi silk saree:\n- Pure Silk Saree (Katan)\n- Organza Saree (Kora), with Zari And Silk\n- Georgette Saree\n- Shattir Saree\nBrocade refer to those textiles where in patterns are created in weaving by transfixing or thrusting the pattern-thread between the warp. In regular weaving the weft thread passes over and under the warp thread regularly. But when brocade designs in gold, silver silk or cotton threads are to be woven, special threads are transfixed in between by skipping the passage of the regular weft over a certain number of warp threads (depending upon the pattern) and by regularising the skipping by means of pre-arranged heddles for each type of patterning. There may be several sets of heddles so arranged that on different occasions, they raise and depress irregular number of threads in turn, as required by the exigencies of the pattern.\nThe Banarasi Brocade based on the design and patterning and the type of material used can be divided into following:\n- Opaque zari brocade\n- Amni brocades\n- Tanchoi brocades\n- Banaras brocades\n- Zari brocades\n- Kincab brocades\nKincab Banarasi saris can be recognized as heavy gilt brocades. They make use of at most 50% or less zari in fabric surface. As a result more zari is visible than the silk these type of saris were quite famous in the 18tgh and 19th centuries especially amongst the royal members of the societies. The designs were also called as bafta or bafthana at that time. Kincab Banarasi saris have evolved over the years with changing fashion trends 1950s- Light weight opaque silks with heavy zari borders Early 1990s- More dense, heavy silks with thin bordersOpaque Banarasi saris come with different variations which is easily identifiable through the difference in supplementary weft zari used.\nTanchoi Brocade saris found their basis in China. They border on the lines of ‘figured silk’. This type of sari features a complex weave just like the lampas. You will find heavier, dense patterns in Tanchoi saris with absence of floats or reverse.\nAmni Brocade Banarasi saris are counted amongst one of the most traditional Indian saris. These saris make use of silk and not zari in their supplementary weft patterns. Normally, one can revel in the beauty of theses saris available in both thick designs (untwisted thread) and more fine, dense pattern (twisted yarns).\nZari Brocade Banarasi saris are also known as amru. The sari is made up of transparent silk muslin or organza with fine colored silk and zari. Perhaps the light prints of this sari can be owed to the use of contrasting color supplementary weft patterning. These weft designs are done up in silk, zari, synthetic fibers and sometimes even wool.\nOTHER STYLES OF BANARASI SILK SAREE\nBANARAS SILK JAMDANI\n- The silk Jamdani, a technical variety of brocade or the ‘figured muslin’ ,traditionally woven in Banaras may be considered to be one of the finest products to come out of the Banarasi loom. Here silk fabric is brocaded with cotton and rarely with zari threads. jamdani is woven by transfixing the pattern thread between a varying number of warp threads in proportion to the size of the designed then throwing the shuttle to pass the regular weft. By repeating this process, where in the size and placing of the cut-thread is in accordance with the character of the pattern, the Jamdani weaver produces arrange of intricate designs.\n- Some of the traditional motifs of Jamdani included Chameli (Jas mine), panna hazar (Thousand emeralds) genda buti (marigold flower)pan buti (leaf form) tircha (diagonally striped) etc. The most attractive design feature of the Jamdani sari was konia or a corner-motif having a floral mango buta.\n- It has own special character of (URTU) Binding in the figured disignes on ground fabrics using extra weft designs thread dampatch technique for the or namentation of the sharee. It is silk x silk base fabrics or-namented with extra looking and technique of weaving in karhuwan.\n- Brocade weavers of Banares have often endeavoured to add a sense of gaiety and festivity by brocading patterns in colourful silk threads amidst the usual gold and silver motifs ;of the brocade convention. The present sari is an example in which muga silk motifs have been in laid. Jangala wildly scrolling and spreading vegetation motif is among the eldest in Banares brocades. This old rose sari is embellished with beautifully contrasted gold-creepers and silver flowers of the Jangala motif.The borders have brocaded running creepers in muga silk and gold and silver-Zari threds.The end panel is a combination of motifs of the borders and condensed Jangala of the field. Muga silk brocading in-hances the beauty of the sari while reducing the cost. All over Jal Jangla design to get the stylish work of the sarees and also used mena work for the decoration of the fabrics. The exclusive design saree has time taking skilled work, costly fabrics are widely accepted during the wedding occassion.\nJAM WAR TANCHOI SARI\n- Using a technique similar to that of brocade, weavers of Banaras weave saris using colorful extraweft silk yarn for patterning . This varietyis known as tanchoi. This maroon-coloured sari in satin weave is brocaded with elaborate motifs from the Jamawar shawl tradition from Kashmir, the characteristic feature of which was paisley motif, often elaborated into a maze which would look kateidos-copic in character. The field has a densely spread minute diaper of Jamawar style paisley. The end panel has large motifs of multiple paisley forms-one growing out of the other. The border, as well as the cross-borders of the end panel, have miniature paisley creepers. Tanchoi fabric has remarkable fame in the India as well as all over in the world widely acceptable to all kind of the people.\n- The renowned Zari brocade weavers of Banaras has evolved a technique of weaving tissue material which looked like golden cloth. By running Zari in weft a combination of Zari and silk in extra-weft (pattern thread) and silk in warp, the weave of this sari has densely patterned with golden lotuses floating in a glimmering pond.The ‘drops of water’ are created by cut work technique. The borders and the end panel have a diaper of diamond patterns enclosed by a border of running paisley motifs. Tissue saris are most popular as wedding saris among the affluent. Tissue sari has glazed, shining character due to the use of real gold Zari/Silver Zari in weft on silk worp ground are ornamented with the particulars traditional design such as Jangla Butidar, Shikargah menadar etc.\n- This type of saree prepared by cut work technique on plain ground texture after removing of the floated thread which are not design (Woven) during the weaving process which provide good transparent look.\n- Cut work is the cheaper version of the Jamdani variety. In cut work the ;pattern is made to run from selvage to selvage letting it hang loosely between two motifs and the extra-thread is then cut manually, giving the effect of Jamdani.\n- The most striking feature of this dark blue silken saree is that it is brocaded with pattern threads of gold, silver and silk. Due to darkar shade of gold and lighter of silver this variety of patterning in brocade is conventionally known as Ganga-Jamuna, indicating the confluence of these two river whose waters are believed to be dark and light receptively. The end panel has a row of arches, in each of which a bouquet of flowers is placed. A slightly smaller and variegated bouquet is diapered all over the field.\n- The butidar saree is a rich kind of the Banaras Saree in high traditional pattern and motiff of the design locally popularised such as Angoor Bail, Gojar Bail, Luttar Bail, Khulta bail, Baluchar bail, Mehrab bail, Doller butti,Ashraffi Butti, Latiffa Butti, Reshem Butti Jhummar Butti,Jhari Butta, Kalma Butti,Patti Butti, Lichhi Butti, Latiffa Butta, Kairy Kalanga Thakka Anchal, Mehrab Anchal, Baluchar Butta with the use of real gold and silver Jari and Katan silk in the weft.\nMAKING OF BANARASI SAREE\nSari weaving is kind of a cottage industry for millions of people around Varanasi. Most of the silk for the Banarasi saris comes from south India, mainly Bangalore. . An ideal Banarasi Sari comprises of somewhere around 5600 thread wires, all of them 45-inch wide. The Sari weavers weave the basic texture of the sari on the power loom.In case of weaving the warp, the craftsmen make the base, which is around 24 to 26 m long. The weaving of Banarasi sari involves teamwork. Ideally three people are engaged in making the Sari. One weaves, the other works at the revolving ring to create bundles.\nAt the time of bundling a new process of designing the motifs begins. For creating design boards, the first thing that is done by an artist comprises of sketching the design on a graph paper, along with color concepts. Before selecting the final design, punch cards are created. A single design of an Indian Benarasi saree requires hundreds of perforated cards for the implementation of the idea. Different threads and colors are used on the loom to knit the prepared perforated cards. The knit perforated cards are then paddled in a systematic manner. This is done to ensure that the main weaving picks up the right colors and pattern.\nAt this point, another important process begins. This is related to designing the motifs. For one design of Banarasi sari, one requires hundreds of perforated cards to execute the idea. The prepared perforated cards are knitted with different threads and colors on the loom and then they are paddled in a systematic manner so that the main weaving picks up the right colors and pattern. The normal Banarasi Sari takes around 15 days to one month and sometimes more time to finish. However, this is not a hard and fast rule as all depends on the complexity of designs and patterns to be produced on the sari.\nBanarasi sarees are no doubt expensive due to its material, thread, design and meticulous labor involved but even then it is a must have possession for every Indian woman.","The Amazing World of Indian Silk\nThe Wondrous Fibre of India\nSilk is the most revered and valued fibre of all the textile fibres in India. In India, silk is considered to be pure and holy, and no religious function is complete without the use of silk. All religious scriptures of Hinduism, Islam, Christianity or Buddhism do find a mention about silk, connecting this holy fibre to their eschatology.\nIndia has been the land of ancient civilizations and has contributed many things to the world, silk being one of them. Silk is a glorious gift of nature. With its rich heritage, assorted influences and a dynamic legacy of art, culture and traditions, Indian Silk has inherited some of the most finely crafted marvels of the world. Indian Silk has a global appeal because the soul and warmth of the culture is wrapped within the Indian designs. Indian Silk, with the perception of ‘looking good & feeling great’, undoubtedly is the nature’s performance fibre.\nSome believe that Indian Himalayas is the homeland of silk, which was on the fabled silk route which stretched 6000 miles across the heartland of Asia from China to the Mediterranean. In the later days, princely rulers like the Tipu Sultan of Mysore encouraged silk cultivation in India. Bengal region of India saw a boost in silk production during the British era due to the increased demand from parachute industry during World War II. India’s rich and versatile silk culture is deep rooted, closely blended to the ethos and heritage of each silk producing cluster. The marvel of Indian Silk handcrafted by the traditional artisans of the respective clusters is unique and simply unmatched.\nIndia, the Biggest Consumer of Silk\nIndia, besides being a silk producer, is also an importer, exporter and consumer of silk. India is the second largest silk producer and is also the largest consumer in the world. The demand and supply position is tilted to such an extent that India needs to import sizable quantity of raw silk to meet the domestic requirement. The saree industry consumes the lion’s share of the country’s domestic production of silk that is almost to the tune of 75%. While the traditional sarees are woven in handlooms, there are a few light weight varieties, plain and printed, being woven in power-looms. Other items in production are dress materials, made-ups, ready-made garments, scarves and stoles, carpets and home furnishings.\nIndian Silk – Embraced across the World\nIndian Silk has aroused global interest since decades. This has swayed the design and fashion industries where elements of stylized motifs, colours and intricate designs have been an inspiration. Over the years, Indian Silk has carved out a niche market, the principal buyers being US and Europe. Although the traditional designs and value-added embroidered items form the thrust area, the export basket includes, dress materials, sarees, scarves, made-ups, ready-made garments and carpets. Dupions of Bangalore, Matka silks of Malda, Tasar silks of Bhagalpur are the sought after silk materials for the European market. With global fashion influencing India and India influencing the global trends, one can see a reciprocal movement of fashion trends that is only going to become stronger in the current globalised environment.\nIndian Silk with a Humane Face\nSilk cultivation called sericulture is practiced as a cottage industry in India, spread over to 59,000 villages covering over 25 states. As the developed countries have almost withdrawn from the active silk production due to industrialization and urbanization, India continues to encourage sericulture as a tool for rural employment and poverty alleviation. This labour intensive industry provides gainful employment to more than seven million people, women constituting over 60%. Sericulture is finely blended with the country’s heritage and plays an important role in the socio-economic growth by providing millions of jobs to the weaker sections of the society.\nIndian Silk – Unique in it’s Diversity\nIndia is the only country that produces all the four commercially known varieties of silks viz: Mulberry, Eri, Tasar and Muga, each one distinctly different from one another in terms of texture, feel and colour. India is home to some of the most exotic and wide ranging silks in the world, thanks to the endless varieties of handspun yarns available in each of the above four varieties of silks.\nOf all the silk varieties available in India, mulberry is the most popular and most commonly known form of natural silk. Mulberry silk is light with a natural sheen and a smooth feel constituting about 85% of the total silk production in the country. Silk is light but strong, smooth and soft, and superbly adaptable. When worn or draped, its fluidity is spellbound. It can be dyed subtle or bold as it is rich in affinity to dyes and hence is a dyer’s delight. The special magic of silk comes from its interaction with light, which it refracts in a way similar to objects found in nature like pearls and sea-shells.\nIndia’s Wild silks, Tasar, Eri and Muga, now being branded as Vanya silk, reflect the exotic and untamed spirit of wild silk worm in texture, feel, sheen and colour. The silk that is closest to the nature has inspired designers to create distinct fashion statements in clothing and home décor.\nVanya silks portray the rich crafts, culture and folklore of the North-Eastern and tribal zones of Central and Eastern India. Collecting wild cocoons from the forest, reeling silk threads from cocoons and hand weaving of silk clothes have given the source of livelihood to the tribal and other weaker sections of the society.\nThe Tropical or Indian Tasar silks are highly textured and has a dull, uneven sheen and can be dyed in a number of colours and easily blended with other fibres. An array of handspun yarns like Gicha, Katia, Jhuri besides the reeled silk goes in the making of a spectrum of fashion fabrics and finds its way to the export market. Among the Vanya silks, Tasar silk tops in the export basket.\nEri silk rearing is purely a traditional and a leisure time avocation of the tribal population of Assam numbering around 1.30 lakhs. Eri having very high thermal properties, the culture is practiced to meet the partial need of warm clothing. Moreover, eri pupae are a popular delicacy among the tribal population of Assam.\nMuga, the shimmering golden silk of India is used in its natural colour. This magnificent, exclusive silk of India which no other country possesses is cultivated mostly in the high humidity regions of Assam and Cooch Behar areas of West Bengal. With its limited production, Muga is hot with the home décor and fashion designers across the globe and commands highest premium amongst all silks.\nSilk Weaving Clusters\nIndian Textiles have a range of techniques and design variations distinct to each of the weaving clusters determined by geographical factors, cultural influences, climate, etc.\nSilk Weaving Clusters at a Glance\n|Indian state||Silk Weaving Cluster||Popular Silk Products|\n|Karnataka||Bangalore||Plain silk, dupion, crepe, organza, hand woven zari sarees, printed sarees|\n|Mysore||Crepe and printed sarees|\n|Kollegal||Plain fabrics and handloom sarees|\n|Ilekal||Hand woven zari sarees|\n|Moolakalmooru||Hand woven zari sarees|\n|Andhra Pradesh||Dharmavaram||Hand woven zari sarees of wedding and festive class|\n|Pochampalli||Typical style of pochampally sarees of wedding and festive class|\n|Venkatagiri||Venkatagiri handloom sarees|\n|Tamil Nadu||Kanchipuram||World famous zari woven sarees, dhotis and angavastras, wedding and festive styles|\n|Arni||Zari woven sarees|\n|Thirubuvanam||Zari woven sarees|\n|Uttar Pradesh||Varanasi||Renowned banarasi zari woven sarees of intricate designs, wedding and festive class|\n|Mubarakpur||Hand woven zari sarees similar to banaras sarees|\n|West Bengal||Murshidabad||Plain silk fabrics and sarees of lighter weight|\n|Baluchari||Mulberry silk sarees|\n|Bihar||Bhagalpur||Wide range of tasar and mixed silk varieties|\n|Maharashtra||Paithan||Renowned paithani sarees of golden zari with floral and animal motifs|\n|Bhandara||Tasar and mix-silk fabrics of all range|\n|Yeola||Plain silk fabrics and sarees|\n|J & K||Srinagar||Tabby silk fabrics and printed sarees|\n|Gujarat||Patola||Handloom mulberry silk sarees|\n|Madhya Pradesh||Maheshwari||Classic maheswari handloom sarees|\n|Chanderi||Tasar silk varieties|\n|Orissa||Naupatna||Export varieties of tasar and matka silks|\n|Chattisgarh||Champa||Tasar silk varieties|\n|Assam||Sualkuchi||Traditional handloom silk sarees and chaddars with typical colour scheme of eri and muga varieties|\nBanarasi Sarees – Epics Interwoven\nBanarasi saree, acclaimed the world over, is famous for its royal look and rich feel. Woven with intricate designs using jacquard looms with pleasing colours and contrast borders, Banarasi brocades become the natural choice for wedding and festive occasions.\nKancheepuram – Alluring & Exotic\nA typical Kancheepuram silk saree is known for its distinguishable characteristics of heavy silk with classic colours and rich zari woven pallu and border using koruvai technique. Woven on heavy lustrous filature silk in warp and charka silk in weft, usually with contrasting borders and fabulous pallus of intricate designs, the Kancheepuram sarees with its rich golden ornamentation is made to last a life time or more.\nPaithanis – A Poetic Marvel\nThe very name conjures up reminiscence of Mugal art. For centuries, the paithani saree with its golden zari formed part of the bridal trousseau. Beautifully crafted, this nine yard wonder with an exquisite pure gold zari border and pallu boasts of ‘Karigars’ specializing in weaving the lotus and other motifs inspired by murals from nearby Ajanta.\nBaluchari – The Bengal’s Pride\nThe origin of Baluchari saree is stated to be in a small village called Baluchar situated in the bank of river Bhagirathi in Murshidabad district of West Bengal. Baluchari sarees are known for its fabulous pallu with large flowing Kalka motifs in the centre surrounded by narrow ornamental borders depicting ancient stories using silver zari.\nNakshi Kanta – Amazing Handcraft of Bengal\nNakshi Kanta is a part of the cultural heritage of rural Bengal and is a centuries old tradition of folklore embroidery art. These sarees are embroidered with Kanthas along with motifs taken from folklore and mythological stories using elaborate running stitches producing enchanting designs.\nChampa – Awesome Tassar\nChampa is one the biggest centre for weaving of tasar silk fabrics in the country. Dress materials, fashion accessories, home furnishing made-ups, sarees, scarves and stoles in tasar silk from here are very popular.\nPochampally Sarees – Delight of Fine Craftsmanship\nPochampally sarees are handcrafted to perfection by skilled artisans who are endowed with critical skills in intricate designs based on Ikats. These sarees are perfectly reversible with the same appearance of the design in the same intensity. Weaving of intricately designed sarees can take up to three to four months.\nChanderi and Maheswari – Ethnic wonder\nChanderi Sarees are known for transparency, translucency because of kora silk in warp and weft, usually Ashraffy buti. Famous traditional designs are: Hazaar buti, Ashraffy saree, Jangla design saree, Addedar saree, Ugata Suraj saree and Mehandi Rachi Hath saree.\nBhagalapur – DazzlingTassar\nThe major product mix being produced in Bhagalpur include silk dress material, sarees, salwar suits, dupatta, bed sheets, scarves, runners, etc. The tasar silk sarees and furnishing materials produced in Bhagalpur are popular both in the domestic as well as in international markets.\nSualkuchi – Jewel in the Crown\nThis cluster specializes in the weaving of the golden muga silk and eri fabrics. Mekhla Chadar sarees and dress materials are the most sought after silk products of Sualkuchi.\nDharmavaram – Spectacular Weaves\nDharmavaram silk sarees are famous for its broad solid colored borders with contrast pallu woven with brocaded gold patterns. Simpler patterns for everyday use have the specialty of being woven in two colours which give an effect of muted double shades accentuated by the solid color border and pallu. The muted colours, the double shades create a total different effect that adds a striking appeal to the saree.\nCentral Silk Board – The Apex body for silk in India\nThe Central Silk Board is the apex body for the development of sericulture and silk industry in the country and is in the forefront of development of these sectors for over 65 years. The role of Central Silk Board encompasses Planning & Monitoring the developmental schemes in the country, Research and Development, encouraging scientific, technological and economic research for improving the production and productivity, creating greater opportunities for gainful employment and improving the levels of income of sericulturists and silk manufacturers.\nIndia Takes the Lead with Silk Mark\nThe high demand of silk has led to serious distortions and malpractices in the silk value chain. Adulteration with lookalike fibres like Nylon, Rayon, Viscose, Polyester, etc., which may be hardly 10% of the cost of pure silk, is rampant. It is very difficult for the consumers to detect the same and therefore these products are passed on as pure silk, thus depriving the consumers the real value and the livelihood of the stakeholders. This menace continues unabated in all silk consuming countries. The absence of a quality mark for silk either from the international organisations or by the silk producing countries was felt for a long time. India took the lead by launching Silk Mark Organisation of India (SMOI) in 2004 with the twin objectives of Consumer Protection and Generic Promotion of silk.\nSilk Mark Organisation of India (SMOI) is a registered Society under Karnataka Society Act 1960 is an initiative by Central Silk Board, Ministry of Textiles, Government of India. SMOI has competent Textile Technologists, who are well experienced in Silk Industry and Trade. SMOI is headquartered in Bangalore and has thirteen Silk Mark Chapters located strategically in and around the silk clusters of the country.\nOver the years the institution has evolved and spearheaded awareness among consumers. There are more than 2800 Authorised Users of Silk Mark and more than 22 million Silk Mark labelled products are already in use.\nThe Silk Mark operation is monitored by a two-tier surveillance system – one by the in-house surveillance team of Silk Mark and another by an independent third-party surveillance team. The Silk Mark team takes up series of surveillance measures by visiting the Authorised Users and conducting on the spot purity tests on the Silk Mark labeled products. The team conducts tests on silk mark labeled products through their testing laboratories in major cities and silk manufacturing and marketing clusters throughout India. On the other hand, an Independent third-party team makes surprise checks and conduct surveillance audit on the Silk Mark operation. Consumers are thus assured of the credibility in Silk Mark products.\nSilk Mark – The Label of Purity\nThe Silk Mark label is provided only to Authorised Users, who are manufacturers and Retailers of pure silk and are authenticated to use the tag only on genuine silk products. The Authorised Users are given extensive training in identification of pure silk, use of Silk Mark and in accountability to the label usage.\nSilk Mark Expos – Epicenter Unleashing the Silk Mark Potential\nIn order to enable consumers to source pure silk products from different silk clusters of the country and also to provide a platform to Authorised Users to promote their pure silk products, the SMOI conducts series of Silk Mark Expos in various cities across the country. These expos provide an opportunity for the silk lovers to get a range of silk products of different weaving clusters under one roof. Thus, Silk Mark Expo has come to establish as an excellent platform for the manufacturers and weavers to showcase and sell their products directly to the consumers besides being a powerful tool for the promotion of Silk Mark."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:9eb47994-9158-432e-a43e-94df21274bfe>","<urn:uuid:9c6fbacc-76d7-4a16-84c6-2ce75c443041>"],"error":null}
{"question":"Is the new wing of Centre Guillaume II visible from the outside, and what makes its appearance unique?","answer":"Yes, the new wing is visible from the outside and has several unique features. It is characterized by a continuous silk-screened glass skin that wraps around the steel structure. The wing's appearance changes based on light conditions - it can adopt the color of the sky or surroundings and can appear either transparent or more opaque, reflecting the historical buildings around it. The exterior features a white vertical pattern of silk-screen printing in various widths, which provides sunshade and gives the building an original materiality. The pattern has a four-density alternation that modifies the level of protection and intimacy depending on orientations and desired views.","context":["\"Centre Guillaume II manifests itself both as a regeneration and extension project in the heart of the historical center of the capital. Thus, located in a Unesco world heritage context, the project required delicate and strategic architectural interventions in the existing historical environment and buildings.\nThe city of Luxembourg has decided to reorganize the citizen’s services in the historical center of the capital. The project required the rehabilitation of a set of historical buildings from 1691 and the addition of a wing including a new ceremony hall as well as assuring a connection between the City Hall and this new complex. This rehabilitation of the existing buildings offers a thorough redesign of the interior spaces to provide them with clarity and fluidity - essential qualities for a busy public building. The street block center, that was just a dark and cluttered area, has become a glass-covered courtyard that deploys the light over four stories and enhances the former interior façade. New access balconies distribute each story and enable the routing of all technical flows required for the new functions without interfering with the restored heritage.\nEvery historic building element has been closely examined along with archeologists, heritage specialists and the national administration of ‘Sites & Monuments’ to set up the implementation of the new programs while respecting the existing structures. The analysis of the historical phases was crucial to both the design of contemporary interventions and the civil engineering issues specific to such interventions. A complete inventory of all parts of the heritage to be preserved was drawn up detailing their mode of conservation and the specific restoration techniques. Pastiche was banned, authentic decors were restored and contemporary elements were integrated through careful choices of materials, colors and moldings. The elements of styles from five centuries of history are blending in with new harmony.\nThe new construction, which combines the two ancient buildings, incorporates a clear confrontation of ages for reciprocal enrichment. Surrounded by historical buildings with orderly moldings made of sandy stones, sealers, slates and zinc, the contemporary wing offers a clear contrast of a geometrical but irregularly shaped pavilion made of glass and steel.\nThe first part of the wing, housing the new ceremony hall, rests on the ground to reinforce the urban features of the pavilion next to the public square. The second part, a metallic structure exposed inside the gallery, looks flexible and evolutionary until it becomes a cable-staged footbridge protruding from the square to the city hall. The wing is abstractly materialized by a continuous silk-screened glass skin wrapping the steel structure. Depending on the light conditions, it will adopt the color of the sky or that of the surroundings and will either be transparent or more opaque reflecting the historical buildings around. The white vertical pattern of the silk-screen printing is applied in various widths on the exterior side of the glass. Hence, it provides a sunshade to the building and gives it an original materiality. A four-density alternation allows modifying the level of protection and intimacy depending on orientations and views desired. Inside, the vertical wood-slat acoustic partitions repeat the pattern of the windows and provide the touch of warmth for the reception and authority functions of this public service facility.\""],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:c54edf18-241b-47d9-8262-efcda2afca69>"],"error":null}
{"question":"I'm planning to buy a diamond ring with small stones around the center - do all these small diamonds need certification?","answer":"No, small melee diamonds used in halo or pave settings typically don't need certification. For diamonds smaller than 0.05 carats, the certification cost would exceed the diamond's value. These small stones are instead sorted into parcels and assigned range values for clarity and color, like G-H color or VS-SI clarity.","context":["If you had done a little reading up about buying diamonds, one of the first things you are probably told is to make sure that it is certified. Therefore, the answer to the question raised in the title is rather obvious. No. Buying a loose diamond without certification is never a good idea.\nA reliable grading report is the ultimate blueprint of your diamond. Not only would it accurately depict the 4Cs, it offers additional details like physical measurements, florescence rating and inclusion plots.\nAt times when you have to leave your jewelry with someone else, the certificate offers details that can help you identify your diamond. Besides, a proper lab report from either AGS or GIA will give you assurance that you are getting exactly what is stated in the report.\nConsumers who intend to buy jewelry insurance can use the grading report as an objective assessment of its quality. In the unfortunate event that you need to make a claim or need to get your diamond replaced, you can make use of the grading report as a basis for the replacement value.\nEven though most people romantically believe that a diamond is going to have an eternal position among the family jewels, situations might arise where you have to sell off your jewelry. Naturally, you would expect a fair amount of money for your diamond.\nWithout a grading report to back up your jewelry and authenticate its value, I can tell you upfront that it would almost be an impossible task to find a buyer.\nFull length GIA report with sealed loose diamond for authenticity\nSadly, there do exist jewelers in the industry who are out to rip uneducated consumers off. Many times, I had heard jewelers telling me that a GIA certificate is just a marketing gimmick and I could save costs by buying “ungraded” diamonds instead.\nWell, the truth is far from that. This is a shady tactic often used to make a false argument based on face value. You see, any jeweler worth his salt knows exactly what he is selling to you. The problem with buying uncertified diamonds is; do you know what you are buying?\nMost consumers don’t. And this is how unethical jewelers take advantage of their naivety by overcharging prices of inferior diamonds. So, I have to say this again. Never settle for anything less than a GIA or AGS report. It’s for your own good. Also, you should avoid labs like EGL and IGI too.\nI know a lot of consumers try to game the system by trying to be “too smart” for their own good. It might be tempting to pay seemingly lower prices for an uncertified diamond and have it sent to a 3rd party grading lab at a later time. This entire process is not only lengthy but also costly when you have to factor in shipping and lab fees.\nOn top of that, not all labs will accept stones from non-trade members. For example, AGS does not deal directly with the public. If you want a stone to be graded by AGS, it’s tough luck for you. You will need to source for an AGS approved jeweler who is authorized to submit the stone on your behalf. Again, this results in an increased cost and places unnecessary stress on you.\nDid you know that some stores actually provide an “Authenticity” or “Guarantee” card when you make jewelry purchases? Do not confuse this for the equivalent of a grading report even though they may appear to state similar specifications.\nFor branding purposes, these cards could contain data regarding the origins of the uncertified stone. Some even go so far as to mention milestones about the diamond’s history, who the diamond cutter was, how the diamond was designed, awards won and etc… Don’t be swayed, this is just pure marketing bullshit. Nothing else matters as much as the grading report.\nYep. You heard that right. There are scenarios whereby it is OK to buy diamonds without grading certificates. For example, if you are buying a halo or pave set ring, there could be numerous small (melee) diamonds that make up the entire design. It isn’t economically feasible for every single stone to be submitted for a vigorous lab grading processes.\nWhy? Cost is the number one reason behind this. For melees smaller than 0.05 carats, the cost of the lab report fee can be more than the cost of the diamond. Imagine having a halo ring design consisting of 50 melees, how much do you think it would cost if every single one of them came with a certificate?\nThe Dossier report doesn’t include a clarity plot diagram and is cheaper.\nInstead of sending them to the labs for grading, melee stones are simply sorted into parcels based on their quality. They are usually assigned a range of values for the clarity and color they possess. For example, you might sometimes see terms like G-H or F-G color and VS or SI clarity in ring setting descriptions that utilizes sidestones.\nAs a rule of the thumb, every diamond larger than 0.3 carats must always be accompanied with a grading report. If you are buying diamonds that are smaller than 0.3 carats, grading reports could be optional and be subjected to the purpose of purchase."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:5cb12770-b0a1-4cbf-b898-ea1a5482f65c>"],"error":null}
{"question":"I am renovating my house - how to prevent electrical fires from bad wiring? Como puedo prevenir los incendios eléctricos?","answer":"To prevent electrical fires, follow these key steps: Don't plug multiple power cords into one outlet, replace broken three-prong plugs, never use extension cords as permanent wiring, keep power cords away from heat/water/oil, inspect tools and cords for damage, use correct size fuses, and have a qualified electrical contractor routinely inspect your system. Watch for unusually warm outlets and exposed wiring. Additionally, ensure circuit breakers and fuses match wire size to restrict amperage, as too much amperage can cause high temperatures that break down insulations and start fires.","context":["Contrary to popular belief, electrical fires are fairly common. They account for one fifth of all fires in Canada, significant property damage and serious injuries. They’re mainly caused by faulty electrical maintenance, however, poorly installed electrical components are fire hazards as well.\nElectrical systems which have built in safety margins are designed for the building occupant’s various needs. As these needs change, electrical equipment and motors change with them. As their electrical components age and deteriorate, the possibility for failure increases, making their inspection and maintenance increasingly important over time.\nCheck these items regularly to lower the risk of electrical fires:\n- Components that are subject to damage, heat or moisture\n- Circuit load\n- Temporary wiring that’s used instead of permanent wiring\n- Components that deteriorated due to age or conditions\n- Components that are poorly installed and maintained\nCircuit breakers and fuses are designed to restrict the amperage to electrical wiring. Too much amperage can cause high temperatures which break down insulations and start fires, so make sure overcurrent protection matches the wire size.\n|Wire size (A.W.G.)||Maximum Current (AMPS)|\nMotors, lights and switches with special safety features are required in areas where flammable gas, vapours, dust or fibrous material is present. Qualified electrical contractors should be consulted to determine whether explosion proof, dust ignition proof or fibre ignition proof components are necessary for the application.\nElectrical systems deteriorate over time and require preventive maintenance. Wire insulation dries out, receptacles and switches loosen, and equipment accumulates dirt and oil. All this can lead to overheating, which is why a qualified electrical contractor should routinely inspect your system.\nThermal infrared imaging can identify hot spots which can result in an electrical fire. That’s why any abnormal condition the camera picks up in the electrical system should be investigated immediately.\nGeneral fire prevention and safety tips\n- Don’t plug several power cords into one outlet.\n- Replace broken three-prong plugs and make sure the third prong is properly grounded.\n- Never use extension cords as permanent wiring – they should only be used to temporarily supply power to areas without outlets.\n- Keep power cords away from heat, water and oil. They damage the insulation and cause shocks.\n- Don’t allow vehicles to pass over unprotected power cords. Instead, put them in conduits or place them between planks.\n- Inspect tools, power cords, and electrical fittings for damage or wear before using them. Repair or replace damaged equipment immediately.\n- Always tape cords to walls or floors when necessary so nails and staples don’t damage them and cause fires or shock hazards.\n- Use cords or equipment with appropriate levels of amperage or wattage.\n- Always use the correct size fuse. Excessive currents and fires can by caused by larger fuses.\n- Unsafe wiring may cause outlets to be unusually warm. Unplug any cords to these outlets and don’t use them until a qualified electrician has checked the wiring.\n- Always use ladders made of wood or other non-conductive materials when working near electricity or power lines.\n- Place halogen lights away from combustible materials such as cloths or curtains as halogen lamps can overheat and cause fires.\n- There’s a greater risk of electric shock in wet or damp areas. Install Ground Fault Circuit Interrupters (GFCIs) to interrupt electrical circuits before their currents are strong enough to cause death or injury.\n- Make sure exposed receptacle boxes are made of non-conductive materials.\n- Know where the breakers and boxes are located in case of an emergency.\n- Label all circuit breakers and fuse boxes clearly. Each switch should identify its corresponding outlet or appliance.\n- Don’t use outlets or cords with exposed wiring.\n- Don’t use power tools without guards.\n- Don’t block access to circuit breakers or fuse boxes.\n- Disconnect the current before touching a person or electrical apparatus if an electrical accident occurs."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:e6dc8b16-f7df-4f40-813b-ad4d050ac474>"],"error":null}
{"question":"How do both modern international anglers and Alaska fishing guides approach the challenge of accessing remote fishing spots?","answer":"Both groups face different access challenges. In Alaska, anglers must adapt to limited road access and rely on small planes, boats, or 4-wheelers to reach fishing spots. For international fishing, as demonstrated by extensive travel experiences across 40 countries, anglers often need to venture into exotic and sometimes challenging locations, such as navigating Angola for giant tarpon or dealing with security situations in Panama.","context":["1) You guide both experienced and novice fly anglers regularly. What are the common casting mistakes you see, regardless of experience?\nPudge: Lots of fly fishers simply don’t stop the rod in the correct places. That causes the fly line to hit the water on either/both the front stop and the back stop. They just can’t get the distance they want, and they have trouble with spooking fish because of the disturbance when the fly hits the water.\nOther fly fishers get a lot of wind knots in their leaders and don’t know how to avoid them. Wind knots form when the caster loses the rhythm need to make a good cast. (Remember when the dad in The River Runs Through It gets the metronome off the piano and sets it down on the grass so the boys can learn the timing for the rod tip to go back and forth?) Maintaining that rhythm will help avoid wind knots as you cast.\n2) Alaska presents very different fly-fishing terrain than visitors from the Lower 48 might be used to. What would you say stands out as the most difficult thing for anglers new to Alaska to conquer when on the water?\nPudge: I think that access to the fishing is probably the most difficult thing that new fly anglers experience when coming to Alaska. They are used to driving where they’re going to fish (except for saltwater fly fishing, of course). New Alaskan fly anglers must adjust to the fact that there are few roads in Alaska, and that they may need to travel by small plane, boat, or perhaps even 4-wheelers to get to the fishing and their chosen water.\n3) If you wanted to catch as many species as possible but could use only six different flies, what patterns would you choose?\nPudge: If I wanted to catch as many species of fish in Alaska as possible, I would choose the following flies (in different colors and sizes, of course): egg-sucking leech, the woolly bugger, the bunny fly, the elk-hair-caddis, the egg imitation bead, and the parachute Adams.\n4) What’s your favorite time of the season to fish in Alaska? Why?\nPudge: My favorite time to fish in Alaska is late July through September. All five species of Pacific salmon are in the rivers then, and the eggs and rotting flesh that they produce definitely make all the other species get more active.\n5) As an angler who’s experienced a wide range of Alaska destinations, and chased all of the state’s gamefish with a fly, what would you recommend to a traveler who could make only one trip north and wanted to experience the “quintessential Alaska fly-fishing experience”?\nPudge: I would say that the “quintessential Alaska fly-fishing experience” is one where the angler has defined for him/her self:\n1. The definition of quintessential in terms of the fish they want to catch,\n2. Whether they wish a trip into parts of Alaska that are rustic or off the beaten path, or perhaps one that could be experienced with or without fly-outs,\n3. How much they are willing to spend. The lodges in Bristol Bay are exceptional for the range of species they can provide on one trip, but they are expensive. From rainbows to salmon, to grayling, to char, to pike, and lake trout, they usually offer the most options. Many visiting anglers, however, prefer rafting and fishing where they can really experience a particular part of Alaska, and many who can’t afford an expensive trip might choose to fish along the road system in a rented motorhome.\nI love all of these types of trips and suggest that it is their consideration of these factors that will help them decide for themselves what they want their trip to Alaska to be.\nCecilia “Pudge” Kleinkauf has owned and operated Women’s Flyfishing, a Trout Unlimited-endorsed business, for 28 of the 44 years she has lived and fished in Alaska. She teaches women how to fish with a fly rod and guides women and couples to various locations in Alaska throughout the summer. Besides being a contributing editor for Fish Alaska magazine, Pudge is the author of four books, the most recent of which is Pacific Salmon Flies: New Ties & Old Standbys. She can be reached at www.womensflyfishing.net.","Basic shipping only. What's this?\nFISHING PASSION: A LIFELONG AFFAIR WITH ANGLING\nAuthor: Jim C. Chapralis\nPublisher: INDEPENDANT PUBLISHERS GROUP, Sep 2002\nNot about how to catch fish, or where to fish; there are countless books that cover these subjects nicely. It's a 60-year odyssey of pursuing angling from various perspectives including guiding, writing, tackle manufacturing & finally pioneering the international fishing travel field - over 40 countries. You'll meet many one-of-a-kind characters from the \"Pimp\" (his boyhood fishing chum) to Charles Ritz. 130 skteches, 384 pgs.\nFishing Passion: a lifelong love affair with angling is not about how to catch fish, or where to fish; there are countless books that cover these subjects nicely. It's Jim Chapralis' 60-year odyssey of pursuing angling from various perspectives including guiding, writing, tackle manufacturing and finally pioneering the international fishing travel field. He started fishing at age eight, just as WW II was escalating, when he trolled across the Atlantic Ocean (interrupted by a Nazi submarine!). For the next six decades, Jim found a way to fish in 40 countries, some for as many as a dozen times, and earned a living by doing so. In Fishing Passion, you'll meet many one-of-a-kind characters from the \"Pimp\" (his boyhood fishing chum) to Charles Ritz, the world famous French hotelier and superb angler to Don Dobbins-Jim's mentor-who must decide whether to fish for salmon and die because of a heart ailment, or give up serious fishing and perhaps live for another ten years (he chose to fish for the salmon). Jim takes you to Angola in search of giant tarpon (and to the most unusual \"outdoor beer garden\" found anywhere); to Panama where he and friends are held at bay by a dozen guns; to Colombia where witch doctors practice their medicine on two of his clients; and, to many other fascinating exotic fishing destinations. Fishing Passion includes a number of weird or paranormal experiences, including the disappearance of two men and their big boat. What's it like to fish with four of the best anglers ever? In the \"Fishing with the Greats\" section, Chapralis devotes four chapters as he takes you on fishing trips with Stu Apte, A. J. McClane, Winston Moore, and Lee Wulff.\nABOUT THE AUTHOR\nJim C. Chapralis was a pioneer in international fishing. In 1961/62 he set up the Fishing Division for Safari Outfitters, Inc. In 1975, he and his partners founded PanAngling Travel Service. Jim edited The PanAngler, (the first monthly newsletter devoted to international fishing) for 25 years. In 1998 he sold PanAngling. Since the early 1960s, Jim and his staff booked more than 40,000 fishing trips for clients and have assisted in the exploration, development and marketing of numerous fishing areas around the globe. He has fished in more than 40 countries. Although he has fished most of the great places in the world, ironically, Jim is addicted to Wisconsin trout fishing. Jim has written dozens of articles for major fishing and outdoor magazines and wrote World Guide to Fly Fishing (a 450-page, hardcover book) in 1987, and co-authored, Fishing Escapes in 1998. Jim was elected to the original Fishing Hall of Fame and was the recipient of the prestigious Dolphin Award for his contributions to international fishing. He won the International Distance Fly Casting Championship (Paris, France,1955) and the All-Round Casting Championship (Stuttgart, Germany, 1956). In 2001, Jim won the Senior Distance Single-Hand Fly Casting Championship with a cast of 163 feet. His varied background includes guiding in Ontario for a year, manufacturing and importing fishing tackle (Sportackle International), editing a regional outdoor publication and serving as a fishing consultant. Jim is also a Representative of the International Game Fish Association."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:1f23b63e-2441-42da-bded-4e6bf70e895c>","<urn:uuid:5a2f70cd-619a-45aa-9006-33442071c6da>"],"error":null}
{"question":"What similarities exist between the gender-related struggles portrayed in 'Shakespeare in Love' and the professional challenges faced by women in 1950s fashion houses?","answer":"Both settings show significant gender-based restrictions in professional environments. In Shakespeare in Love, women were completely banned from the English stage until 1662, forcing Viola to disguise herself as a man to pursue acting. Similarly, in 1950s fashion houses, there was a rigid hierarchical structure where women worked under strict rules and etiquette, with workers being required to follow specific protocols like wearing white gloves during fittings and adhering to formal ways of address (using Mr. or Mrs. with first names). In both cases, women had to navigate male-dominated professions while dealing with social conventions and strict professional hierarchies.","context":["Theatre in Film: Shakespeare in Love (1998)\nWritten by Ashleigh Gardner\nNovember 8, 2016\nWe return to Part V in our Theatre in Film series, a weekly segment of Performer Stuff’s blog where we discuss a film that features a life in theatre. Part V of Theatre in Film celebrates movies from 1995 to 1999 that feature social, moral, and ethical issues within the theatre. This week, we feature the 1998, seven-time Academy Award winning film (co-written by Tom Stoppard and Marc Norman) Shakespeare in Love.\nShakespeare in Love (1998)\nDirector: John Madden\nStarring: Joseph Fiennes, Gwyneth Paltrow, Geoffrey Rush, Colin Firth, Ben Affleck, and Judi Dench\n1593, London. Philip Henslowe (Geoffrey Rush) owns the Rose Theatre and is in tremendous debt. To escape the wrath of those he owes, he commissions William Shakespeare (Joseph Fiennes) to write him a comedy that will bring The Rose Theatre money. Unlucky for Henslowe, Shakespeare is suffering from writer’s block and must find a muse to inspire him again. He finds his inspiration in Viola de Lesseps (Gwyneth Paltrow), a woman betrothed to the Lord Wessex (Colin Firth). She escapes her high-born family’s castle to audition for his new play and appears as Thomas Kent, and is cast as Romeo. When Shakespeare finds out that she is Viola de Lesseps, they begin an affair that endangers Shakespeare’s career, Viola’s reputation, and the life of Christopher Marlowe (Rupert Everett).\nOn the eve of Romeo and Juliet’s debut performance, it’s revealed that Viola is not a man, but a woman. The theatre is shut down, and the play is cancelled. Richard Burbage (Martin Clunes) takes pity on the cast, as they are his fellow theatre folk, and invites them to perform the play at his rival theatre. Hearing of the performance, Viola escapes her wedding, and rushes to the theatre, arriving in time to play Juliet in front of a crowd of hundreds — including her new husband Wessex.\nWhy it matters:\nShakespeare in Love, written by Tom Stoppard (yes, the Tom Stoppard) and Marc Norman, is usually celebrated for its sweeping love story that parallels Shakespeare’s Romeo and Juliet script: two people in love who are divided by social conventions. However, Shakespeare in Love warrants more credit in regards to its social commentary about gender equality.\nDuring the years of Elizabethan theatre, women had been banned from the English stage since Medieval times. The Dark Ages were a time of vast illiteracy, and the Church needed something besides the written word to inform the populace about religion. They resorted to the “Miracle Plays”, stories of the Bible that taught audiences about Christianity. These touring shows were run solely by men, and women were not allowed to participate in productions — a woman’s place was in the home, and if any woman were seen doing any activity deemed un-domestic, they were considered immoral and sinful. Women and girls were played by young men and boys. It was not until 1662, when King Charles II signed a decree that all female parts were required to be played by women, that women were legally allowed to perform onstage.\nViola is a girl who dreams of becoming something greater than her life of domesticity allows, but she is denied that dream on the basis of her gender. In addition to being restricted from becoming an actor, she is forced into an unwanted marriage with a hostile husband. These social conventions, however, place no damper on her refreshingly stubborn and driven personality. Her nurse (Imelda Staunton) also provides a trustworthy confidant despite having an obligation to Viola’s conservative parents. She encourages Viola to pursue her acting dream and her relationship with Shakespeare, risking her job and reputation to do so. After Viola is outed as a woman after she’d been playing a man for so long, the company of entirely men is sad to see her go. Even the Prologue player, Wabash (Mark Williams), regrets her departure, telling her through a strong stutter, “You…were wonderful.”\nShakespeare in Love uses Shakespeare’s plots (Two Gentlemen of Verona, Romeo and Juliet, and Twelfth Night) to address gender inequality, plays in which women must dress as men in order to be taken seriously, trusted with important tasks, or protected from assault. As Rosalind says in As You Like It, “Alas, what danger will it be to us, / Maids as we are, to travel forth so far! / Beauty provoketh thieves sooner than gold.” Women must disguise themselves as men in order to reap the basic rights that are denied them. Additionally, even when they are skilled in their profession, especially when it is a male dominated one, they are still rebuked by those who uphold the belief that women should remain at home.\nAs Queen Elizabeth stands onstage after the performance and addresses the players, she summons Viola forward and calls her “Master Kent”, the name that gave Viola agency and power in the theatre. She sums up her admiration and understanding of Viola’s hardwon performance with a statement of solidarity, implying that her struggle is Viola’s struggle, too: “I do know something of a woman in a man’s profession. Yes, by God, I do know about that.”\nThis film is the third featured in Part V of “Theatre in Film”. See below for the others in Part V.\n- An Awfully Big Adventure (1995)\n- Theatre in Film Halloween Special – Stage Fright (2014)\n- Waiting for Guffman (1996)\n- Cradle Will Rock (1999) (Coming soon.)\n- Topsy Turvy (1999) (Coming soon.)\nWant to start with Part I? Begin with 42nd Street (1933).\nMiss Part II? Check out The Band Wagon (1953).\nNeed a refresh for Part III? Start with our feature on All That Jazz (1979).\nHow about a recap from Part IV? Jump into A Chorus of Disapproval (1989).","Phantom Thread wins an Academy Award for Best Costume Design!\nLearn the secrets behind the gorgeous costumes of new film Phantom Thread\nWe are thrilled that this fabulous film has been awarded an Academy Award – an oscar for Best Costume Design! Read all about the costumes in this fascinating behind the scenes look at the designs and costumes from the film.\nThe film is set in the glamour of 1950s post-war London and tells the story of fictional renowned dressmaker Reynolds Woodcock (Daniel Day-Lewis) and his sister Cyril (Lesley Manville) who are at the centre of British fashion, dressing royalty, movie stars, heiresses, socialites, debutants and dames with the distinct style of the House of Woodcock.\nThrough his creations, Reynolds can make the timid feel courageous and the unattractive feel beautiful. He’s immensely talented and at the very top of his game, but he’s also fussy, self-consumed and difficult. He meets a young, strong-willed woman, who soon becomes his muse and lover. Once controlled and planned, he finds his carefully tailored life disrupted by love.\nAcademy Award-nominated writer-director Paul Thomas Anderson had little interest in dressmaking or fashion history until he discovered couturier Cristóbal Balenciaga (1895-1972), whose collections were internationally renowned for their iconic lacework, innovative cutting and shapely elegance.\nImmersing himself in Mary Blume’s biography, The Master of Us All: Balenciaga, His Workrooms, His World, the writer-director became fascinated with the designer’s monastic life and all-consuming approach to dressmaking, which dovetailed with the New Look in Paris and Christian Dior’s reinvention of the female silhouette.\nWith his handsome, angular features, Balenciaga reminded Anderson of his There Will Be Blood lead actor Daniel Day-Lewis. A major Hollywood star, who also happens to be trained shoemaker, Day-Lewis has an appreciation for making things by hand. Anderson and his star became devoted students of haute couture, learning everything they could about Balenciaga and his contemporaries, including Dior and British-born designer Charles James. They studied classic English tailoring from the period, in particular John Cavanagh and Hardy Amies, and the artistic temperament of contemporary figures like Alexander McQueen.\nDay-Lewis relished the chance to focus on the British specialists;\n“It felt right somehow that our work should reflect the history of England and the fabric that came from the British Isles, which is extraordinary. The tailors and dressmakers are still making these garments, and they are beautiful. Every season when the fabric arrives, they look at the fabric, feel it, smell it and make designs from it. There was something fascinating to us about the idea of England emerging from the war years, amid austerity.”\nPrincess Mona’s wedding dress, from Phantom Thread, by costume designer Mark Bridges\nThe title Phantom Thread came from the predicament common among East London seamstresses in the Victorian era who were accustomed to working long hours in miserable conditions. After marathon periods of sewing magnificent dresses for royals and aristocrats, the exhausted workers found themselves, like automatons, sewing invisible thread outside the workroom — aka, a phantom thread. Daniel Day-Lewis learnt to drape, cut and sew for the role\nDay-Lewis mastered the finer points of dressmaking during this period, studying dozens of volumes on the subject, examining archived dresses by world-class couturiers and learning how to cut, drape and sew under the instruction of Marc Happel, Director of Costumes of the New York City Ballet. “Marc taught him everything from basic sewing and cutting to the more elaborate process of draping and measuring,” says Anderson. “At the end of his training period he proved himself by making a fantastic copy of a Balenciaga suit.”\nFor costume designer Mark Bridges (of 2012’s The Artist), creating costumes from scratch was the only solution for a story in which dressmaking is central. Authenticity and sophistication were of the highest importance and true couture vintage was in short supply. The result was 50 unique garments for the movie, including nine original pieces showcased in a spring fashion show sequence.\n“We discovered early on that we would be making a lot more garments than we initially thought,” Bridges says. “Silk only lasts for so long even if the garments have been well preserved. Time marches on, and moths are busy. Most of the clothes we sourced we wound up using for inspiration or understanding construction techniques. If we were duplicating a garment, we tried whenever possible to reproduce the fabric as closely as possible to the original garment.”\nThe veteran costume designer resisted focusing on a single couturier as inspiration for his creations. Instead, he researched designs from the era, combed through vintage editions of Vogue and watched segments from the British Pathé archive on YouTube. “Having the [Victoria and Albert Museum] archive at our disposal was very helpful because we could see how lines were cut and patterns constructed,” says Bridges. “It’s amazing how simply conceived a lot of the garments are, including Balenciaga’s embroidery, with its meticulous details.”\nJoan Emily Brown and Sue Clarke were working as volunteers at the V&A when Anderson discovered that the women had extensive backgrounds in fashion. He hired both as creative consultants, based on their ability to verify in an instant whether a bobbin or pin was appropriate to the era. But he also gave them roles as actors, playing the crucial backroom roles of head seamstresses Nana and Biddy.\nClarke had taught fashion for most of her adult life before retiring and Brown spent decades in couture ateliers across London sewing, cutting and beading. They helped cast and crew understand workroom hierarchy, including the intricate power structure between cutters and fitters and assistants and hands. They shared minute workroom details like the mandatory white gloves worn by handlers during House fittings, and recounted stories of rigidly enforced etiquette that was the hallmark of the top Houses. “It’s a very organised world to work in with an emphasis on following the rules,” says Brown. “If you were the head of a workroom, you were addressed as Mr. or Mrs. along with your first name. It was all part of the etiquette of the time and you learned things quickly as you worked. There was a very disciplined way of doing things.”\nIn her essay The New Bloom of Couture, Cassie Davies-Strodder explains London couturiers produced two collections per year, for autumn/winter and spring/ summer. The garments were made with the finest fabric and trimmings, the majority made by hand by highly skilled seamstresses before the garments were fitted bespoke to each customer. Up to three fittings were required, and it took up to four weeks to produce the finished piece.\nCurator of 20th and 21st century fashion collections at the Victoria and Albert Museum, Davies-Strodder reports how clients would enter the tall, terraced Mayfair couture houses on the ground floor where the grand rooms were used as a reception space. A twisting staircase, often at the center of the house, led the way to the first-floor showrooms and fitting rooms.\nMark Tildesley, production designer sought to achieve this in the film: “The House of Woodcock is a place of work but it’s also a theatrical space, where clients are beguiled and made to feel glorious and wonderful as if they were on stage.” Balenciaga was a great inspiration for the protagonist and his signature style © Victoria and Albert Museum © Images Courtesy of Focus Features and UPI Media."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:024a511a-f2ac-4a1d-8022-8afcc9f5f53f>","<urn:uuid:72fcd1e9-9bad-424d-be21-71aa682b60f5>"],"error":null}
{"question":"What activities are available at Nuuksio National Park during winter?","answer":"During winter, visitors can enjoy cross-country skiing at Solvalla, which has excellent skiing trails from January until March. Downhill skiing is also possible at Solvalla-Swinghill, which has three small slopes with one lift and a 70-meter elevation difference, typically with snow from January to early March.","context":["Nuuksio National Park\nCovering an area of 45 square kilometers, Nuuksio is one of the smaller national parks in Finland, but also one of the best accessible to visitors as a day-trip from Helsinki. The main attraction of Nuuksio is a broad selection of different types of forest, lakes, ponds, and some swamps. The pine forests near Solvalla and the different forest types near Haukkalampi and Mustalampi are particularly attractive.\nEstablished only in 1994, Nuuksio is one of Finland's newest national parks, set up to ensure that a piece of pristine wilderness is kept within striking distance of the capital. Its location so close to a major city is unusual, and due mostly to the fact that the rocky and wet terrain was unsuitable for farming or other development.\nNuuksio's landscape is archetypically Finnish: conifer and birch forests, forty-three lakes, small swamps between them and gentle rolling hills, sometimes covered in moss, sometimes with the granite bedrock exposed where the vast ice sheets of the last ice age scraped them clean. There are plenty of quiet spots of beauty, but don't expect jaw-dropping gorges or soaring mountains (good advice for traveling anywhere in Finland, that).\nFlora and fauna\nThe Siberian Flying Squirrel (Liito-orava) is official park emblem, but being nocturnal and living high up in the treetops, it's very difficult to spot. The Haukkalampi info center has an exhibit about the critter and even gives handy tips on how to spot its poo.\nLarger mammals are rarely seen. Lynx, fox, hare and deer are present in the southern end of the park.\nThe adder (viper) is not uncommon in the rocky areas near Solvalla and Mustalampi. These small snakes are venomous, so don't try to catch. Not that you are likely to see them: they tend to escape and hide when approached.\nNuuksio's climate is the same as Helsinki's: cool but relatively sunny and dry springs, lovely yet possibly rainy summers, rainy autumn, cold winters with snow or slush. The high season is obviously summer, although mushroom pickers continue to tramp the trails well into the autumn, and hardcore cross-country skiers venture within in the winter. Late April, May, and early June are excellent times to visit Nuuksio, as it is less likely to rain and there are no or only few mosquitos.\nFor those coming by car, there are major parking lots at Solvalla, Haukkalampi and Kattila, and lots of other parking possibilities elsewhere. It is a 35 minute drive from the center of Helsinki. Besides car, the other options are bicycle and bus.\nThe bus services to Nuuksio require a transfer if coming from Helsinki. Check schedules from the route planner  before setting off, as services are quite limited on some routes. The main bus route through Nuuksio goes along the eastern shore of the Nuuksion Pitkäjärvi lake, denoted eastern side of the park below. The most popular parts of the park are accessible from along that bus route.\nTo get to the eastern side of the park, take the commuter train S, U, E or L from the Central Railway Station to Espoo station, then transfer to bus 245. The Haltia nature centre in Solvalla is the first good point for accessing the area. Get off at Nuuksionpää 2 kilometers after Solvalla/Halti if going to the Haukkalampi area. It's a two-kilometer stroll on the unpaved road to Haukkalampi. If going to the northern parts of Nuuksio, get off the bus at the last stop at Kattila (May-October only).\nTo get to the southern side of the park at Siikajärvi, take the trains A, E, U, S, L or Y to Leppävaara and transfer to bus 238, 238K or 242. You need good maps and prior planning to enter Nuuksio from here, as the entrance to Nuuksio is poorly marked and there are no park facilities here.\nTo get the southwestern side of the park, take a bus 280 or 290  from Helsinki City Bus Terminal (Kamppi Center) to Veikkola koulu and take a taxi to last few kilometers north to the park. You can also walk or cycle those quiet village roads. You need good maps and prior planning to enter Nuuksio from here, as the entrance to Nuuksio is poorly marked and there are no park facilities here.\nTo get to the rarely visited western side of the park, take a bus 280 or 290  from Helsinki City Bus Terminal (Kamppi Center) to Tervalammen kartano and walk several km. You need good maps and prior planning to enter Nuuksio from here, as the entrance to Nuuksio is poorly marked.\nTo get to the quiet northeastern side of the park, take a bus 346  from Helsinki City Bus Terminal (Kamppi Center) to Pyyslampi. The nature park with its lakes begins right from the southern side of the road.\nMost nature excursions by Feel The Nature (see Do) include return transportation from Helsinki City Centre and Espoo.\nEntry to the park is free and no special permits are necessary.\nMotorized vehicles are prohibited in the park, so most visitors get around is by hiking. The Haukkalampi information cabin (Haukkalammen luontotupa) near the main entrance has simple free maps, or invest €10 in a detailed topographic map of the area. You can also pick up the map at Helsinki tourist info offices.\nBicycling is allowed on 30 km of designated routes, including National Cycle Route 2, 14 km of which passes through the park. Nuuksion Ratsastuskeskus  can arrange horse rides on 22 km of routes as well.\nA number of well-signposted trails are available, while hardcore hikers can head out into the bush and stay at one of the many campsites. For the first time visitor, doing the Haukankierros loop and half of Korpinkierros will provide a good representative look (see the Trails section below). Other shorter, less formal walks are easy to do.\nThe area with the best facilities is Solvalla with its Haltia nature centre, including a cafe and lunch restaurant. The Solvalla area has the most easily accessible paths for walking and biking, and the maps are good. There is a good choice of short and longer walks. This area right east of Haltia/Solvalla is mostly dry pine forest with rocky areas, not much lakes or ponds. This is some of the prettiest pine forest you will see in Nuuksio. The Haltia center is at a scenic location next to the Nuuksion Pitkäjärvi lake. To reach the forest paths from Haltia, walk the steep asphalt road or wooden stairs up to the sports field, a couple of hundred meters from Haltia. Walking paths both north-east and south-east start from behind the field.\nThe second area for walks and with some facilities is the Haukkalampi lake, with a small hut (Haukanpesä) with coffee and small snacks (open Tuesday to Sunday from 10am until 4:30pm in the summer season June, July, August). From Haukkalampi it is a short 500 meter walk west and and south to the scenic Mustalampi lake. There are campfire facilities, including firewood here. From Mustalampi you can walk about 1.5 kilometers south to the Siikajärvi lake, and catch a different bus toward Espoo centre. Alternatively, you can walk west to Holma-Saarijärvi, and come back the same way.\nA third starting point for walks is the end of the Nuuksio main road at Kattila. From Kattila you can walk south 3 kilometers to Haukkalampi. The path starts towards south-west from the parking lot, heading across the pasture with sheep. Walks north from Kattila are first less attractive: the more attractive forest and lake area starts 3 kilometers north at the Iso-Parikas lake. Then you either have to walk further 5 kilometer north to the main road there (large part of which is not in the forest), or walk back the same way.\nHaltia nature center\nThe Haltia complex in Solvalla includes a cafeteria (with a basic lunch & dinner buffet, not a particularly good deal at 18 euros), and a multi-media exhibition (admission 13 euros adults, 8 euros for children from 7 to 17, and free for children under 7). The not-that-extensive exhibition mostly consists of nature photography, and a couple of small non-photo exhibits, including a sound & video depiction of birds' nests in trees. Most adults will spend about 10 minutes in the exhibitions, while small children may find some opportunities to play there a bit longer, including an interactive \"game\" in the middle of the main exhibition hall.\nHaltia is open from 10am to 5pm every day except Mondays in winter, and every day from 10am to 6pm in the summer season from May to September. Closed on Christmas Eve and Christmas day, and possibly on the adjoining holidays (Confirm opening hours from the web site [].)\nPicking berries in late summer and mushrooms in the fall are popular activities. Fishing is allowed, although there isn't all that much to catch.\nRock climbing is allowed only at Pitkäjärvi and the eastern Kolmoislammet. Ice climbing is permitted throughout the park.\nCross-country skiing Solvalla has excellent skiing trails much of the winter from January until March.\nDownhill skiing is possible at Solvalla-Swinghill on its three small downhill slopes with one lift and a very modest elevation difference of 70 meters. There is snow generally from January to early March. This is some of the best downhill skiing near Helsinki (but unimpressive in comparison to skiing in real mountains like the Alps, or even compared to Lapland.)\nSeveral tour operators specializes in Nuuksio:\nEat, Drink or Buy\nThere are two cafes in Nuuksio.\nWater is available at the Haukkalampi information center. Making an open fire is allowed at the designated fireplaces near the campgrounds, so bring some sausages and marshmallows and have a picnic. Some of the fireplaces are covered and thus usable even when it rains.\nHotel Siikaranta (see below) restaurant offers Finnish-style buffets for hungry hikers, but opening hours are limited.\nOvernight stays in the Nuuksio area are possible, although most visitors stay somewhere else in Espoo or in Helsinki.\nSeveral wilderness lodges can be rented cheaply, but they're popular so advance bookings are essential. You will also need to bring your own sleeping bags.\nFor groups, Green Window (see Do) can also arrange private lodgings elsewhere in the park.\nCamping is permitted only in four designated campgrounds in the park. None have any facilities, but open fires are allowed.\nApart from vipers (consult a doctor if bitten!) and the very remote chance of meeting a bear, there is little dangerous fauna in the park. Thanks to the swampy terrain, mosquitoes can be a (minor) nuisance (June until August). Remember to check yourself after hike for possible ticks (risk of disease). Stay on the main trails if you don't have a compass, map and orienteering experience. If you get lost, remember that Nuuksio is surrounded by major road on all sides, and by walking straight in any chosen direction will take you out of the park in at most 3 hours, and probably much sooner."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:985db01b-bf8d-4e4c-83ee-44c766f4c2ed>"],"error":null}
{"question":"What are the spiritual significance of Laylat al-Qadr during Ramadan, and what specific duas should be recited when starting Umrah?","answer":"Laylat al-Qadr (Night of Predestination) is a highly significant night during Ramadan when the Holy Quran was first revealed to Prophet Muhammad. It is considered better than a thousand months, and angels descend on this night. While its exact date is unknown, it's often sought on odd nights (21st, 23rd, 25th, 27th, or 29th) of Ramadan. For Umrah, specific duas must be recited, including 'Bismillahi, Tawakkaltu, 'a-lallahi' when leaving home, 'Labbaik Allaahumma 'Umrah' when entering the state of Ihram, and 'Labbayk Allahumma labbayk' until reaching Makkah.","context":["The month of Ramadan is considered the most important time of the year for Muslims. If we see this holy month historically, the Holy Quran was revealed to Prophet Muhammed in the month of Ramadan. The Holy Quran is a holy book for Muslims as a source of guidance for all of humanity. Ramadan is the month of fasting, reflection, offerings, devotion and sacrifice.\nNight of Predestination (Laylat al-Qadr)\nThe word “al-Qadr” is often translated as “power.” Although the “greatness” option can be considered more successful, since Allah says in the Quran that this night, which He called “the night of al-Qadr,” is more majestic than a thousand nights. Just think about it! Thousand nights – more than eighty three years! It’s a lifetime! On this night, the Holy Quran was first sent down to the Prophet Muhammad, (SAW). Lord says:\n“Verily, We sent down (the Quran) on the night of predestination (greatness). How could you know what a night of predestination (greatness) is? The night of predestination (greatness) is better than a thousand months. On this night, the angels and the Spirit (Jibril) descend with the permission of their Lord according to all His commands. Peace until the rising of the dawn. “(Quran 97: 1-5)\nThe Night of Predestination is the great gift of the Lord to mankind. However, Muslims do not know the exact date of this night. Someone from the Companions of the Prophet (SAW), conveyed that this is the twenty-seventh night of Ramadan, but the rest of the Companions (which are more) call completely different dates during the last third of the Holy Month. In his Hadith, the Messenger of Allah advises to point to any of the odd date the 21st, 23rd, 25th, 27th and 29th nights of Ramadan in eager worship, hoping that this is the Night of Predestination. Some Muslims devote whole night to worship. However, it is better not to neglect to sleep, and to rest at least a third of the night, because the prophet (SAW), and his Companions did so.\nIn some Islamic countries, the 27th of Ramadan is a day off when people can rest after a night of worship. Schools are closed from the 27th of Ramadan to the 2nd Sha’wal (5-6 days) to unite Laylat al-Qadr and ʻEd al-Fitr (Holiday of breaking the fast in honor of the end of the fast).\nItekaf or Solitude\nThe Prophet Muhammad (SAW) spent the last ten days and nights in a mosque. Following the example of the Messenger of Allah — solitude in the nearest mosque — is considered worship. While remaining in the mosque, Muslims dedicate themselves to the remembrance of the Allah: performing additional prayers, reading the Holy Quran, studying the Hadiths (sayings of the Prophet Muhammad, peace and blessings of Allah be upon him) and calling each other to be pious through the worship of the Allah and His Messenger. Muslims who intend to retire are not allowed to leave the mosque, unless necessary. They sleep and enjoy the amenities available in the mosque.\nREAD MORE: Story Of Abraham: Resettlement To Canaan\nFood for the retreated prepare either relatives or someone from the Muslims. The term of solitude ends with the end of the month of Ramadan. Busy people may spend a shorter time in solitude – a day or a few days.\nAny material assistance rendered to the poor, the needy and those who ask for it is called a Sadaqat. Sadaqat al-Fitr, which is also known as Zakat al-Fitr, is a compulsory alms given to the poor before the beginning of the celebration of the end of Ramadan, so that they can prepare for the feast. The head of the family is obliged to pay zakat al-fitr for each member of his family. The size of zakat is 2-2.5 kg of common food (for example, rice).\nThe end of Ramadan is celebrated on the first day of the tenth lunar month of Shawal. On the 29th night, people take to the streets to make sure at the beginning of the tenth month, looking at the new moon on the western horizon. If the moon sickle does not appear, Ramadan is extended for another day.\nOn the morning of the holiday, Muslims take a full bath, have breakfast, put on the best clothes, use incense (men only) and go to where they gather for a holiday prayer. On the way, a Muslim repeats takbir: “Allah is great, there is no deity worthy of worship except Allah, and all praise is to Him.” Muslims say takbir at home, on the street and in the place of the collective prayer in anticipation of the leader of the prayer – the imam. According to the tradition of the Prophet Muhammad, peace and blessings of Allah be upon him, the festive prayer was performed under the open sky. And today, Muslims are trying to maintain this custom: in Islamic countries with a warm climate, special areas for festive prayers are organized.\nAt the appointed time, the imam performs a prayer, followed by a festive sermon. After that, people greet, embrace each other and congratulate on the successful completion of Ramadan, and also ask the Almighty to accept their fast and efforts to obey Him.\nOn a holiday, Muslims visit each other, give gifts; in some countries, on this day, it is customary to go outdoors. In essence, ʻEid is the day of thanksgiving to Allah, gathering family and loved ones.\nUmrah or small hajj in the month of Ramadan\nIn the message from the Prophet Muhammad, peace and blessings of Allah be upon him, comes that, Umrah performing in the month of Ramadan, is equated with the basic or complete Hajj. Hajj is a pilgrimage to Mecca, a reminder of the trials and tribulations of the Prophet Ibrahim (Abraham) (peace and blessings be upon him), his wife Hajjar (Hagar) and elder son Ishmael. Unlike Hajj, which lasts five days, Umrah takes only a few hours. This is only a small part of the hajj. At the end of the umrah you can stab the sacrificial animal. A small pilgrimage is made at any time of the year, however, according to the prophet Muhammad, peace and blessings be upon him, the best time for this is the holy month of Ramadan.","Everything to know about Umrah\nPosted In : umrah guide\n3 : comments\nIt’s an earnest desire of every Muslim to visit the Bait Allah, the exhalted Haram Shareef in Makkah and Madina. There are two main ways to visit Khana Ka’bah for the Muslims living outside Saudi Arabia, Hajj and Umrah. In this article we would give you a quick over view of Umrah only.\nEverything to know about Umrah\nDocumentary Requirements for Umrah\nYou need to have a valid passport and visa for Saudi Arabia to proceed for Umrah. Every country has its own Visa and passport regulations. You need to consult us or relevant government office for that.\nIt is mandatory for all Muslims proceeding for Umrah to have compulsory vaccination and necessary medical certificates to enter Saudia Arabia. Government of your country arrange for provision of such medical facilities before you board for Umrah (If required).\nSome of the Muslims have little or no understanding of the process which needs to be completed before performing Manasiq of Umrah (Rituals of the holy pilgrimage) for this purpose, professional Umrah services make all the arrangements for a specified sum of money they charge for their service.\nThese services are offered against certain type of Umrah Packages. Generally Umrah packages are less expensive than Hajj packages.\nEvery company has its own way of offering Umrah packages. Umrah agencies provide packages that include better living arrangements, shorter duration (like 07 days or less), and moreover Umrah packages can be customized as per your requirements.\nIn a customized Umrah package you can opt for a package that suit your budget and time available with you.\nMany people prefer longer duration packages which allow them to spend more number of days in the holy places but at the same time there are many people who want to visit Mecca and Madina on Umrah but have less time.\nThere are many brother & sisters who want to visit Mecca and Madina on Umrah but have less time.\nUmrah travel or Umrah tours agencies:\nMost Umrah travel or Umrah tours agency offers private and government packages simultaneously. These companies offer packages basing the calculations on the number of nights that you get to spend in Makkah and Madina, the quality of living, food and other facilities like travelling arrangements etc.\nIf, you do not want to search food and restaurants by yourself then you can opt for a package that offers to arrange your breakfast, lunch and dinner. In such an arrangement, you will have to pay more than the normal package.\nMost of the people who belong to Pakistan, Bangladesh, India and rest of the South East Asia prefer packages without food arrangements.\nThey find it inexpensive and prefer to have their own private arrangement for food from local Pakistani and Indian restaurants. All food served in Kingdom of Saudi Arabia is Halal.\nIf you are performing Umrah for the first time, it would be advisable to take such packages that include complete facilities from hotels, to breakfast, lunch, dinner and transportation.\nIf you have performed Umrah several times and know the circumstances, markets and hotels of Makkah and Madina then you can opt for any package.\nMost of the Umrah travel companies provide transportation facilities as well. You can opt for such packages to save your time for Ibadah. Most people take these packages, especially those who perform Umrah for the first time as they have little or no knowledge about procedural and other matters like hotel bookings etc.\nPreparations before leaving for Umrah:\nThe most important step is to know which duas and necessary preparations you need to do before leaving your house for Umrah.\nNow that you have some amount of understanding about Umrah packages, Umrah travel and Umrah tour companies, the next important step is to know which duas and necessary preparations you need to do before leaving your house for Umrah.\nIt is important to note that Umrah is less physically demanding than Hajj, but still it is a difficult Ibadah considering 45-50-degree centigrade and above temperature of Makkah.\nYou need to be healthy to make sure that you can perform all ibadah at ease.\nWhen you are selected and awarded with Umrah Visa, your Umrah travel company would arranges for your Umrah arrangements.\nYour Umrah tours agency will also provide you some guidance literature and dua books that are compulsory to be recited before and during Umrah.\nRules of Ihram:\nAl-Bukhari states that Prophet Mohammed (PBUH) said: \"one shouldn't pass the Miqat unless he/she is in the state of Ihram.\" (Al-Bukhari)\nIhram is the special dress that you wear for Umrah. It has some compulsions that you have to follow.\nIhram consists of two white pieces of unstitched cloth for men. One piece is wrapped around lower half of the body to cover it completely and the other piece is used to wrap one shoulder and leave the other shoulder uncovered.\nWomen have to wear abaya and scarf that cover their entire body from head to toe. Women can use any neutral or light color of their choice (except for bright colors, which are too conspicuous).\nThe following dua is preferred to be recited when leaving home:\n“Bismillahi, Tawakkaltu, ‘a-lallahi, wa laa hawla wa laa quwatta illah billah”\n(In the name of Allaah, I place my trust in Allaah, and there is neither might nor power except with Allaah)\nFollowing dua is again important to recite before setting off in your car or travel arrangement.\n“Allahu Akbar, Allahu Akbar, Allahu Akbar. Subhaa-nalathee, Sakha-ra-la-naa ha-thaa wa maa kunaa, lahu muq-ri-nee-na wa innaa ilaa rabbinaa la-mun-qa-le-boon”\n(Allaah is the greatest x3, How perfect He is, The One Who has place this (transport) at our service, and we ourselves would not have been capable of that, and to our Lord if our final destiny.)\nMen are required to recite this dua at the time of changing their clothes for Umrah (changing over to Irham)\n“Labbaik Allaahumma ‘Umrah”\n(Here I am O Allah making ‘Umraah)\n“Allaahumma mahillee haithu habastanee”\n(I come out of the state of Ihraam from the place You prevent me from continuing)\nNow you have to continue to recite following dua till you reach to Makkah and start performing Tawaf\n“Labbayk Allahumma labbayk, labbayka laa shareeka laka labbayk, innal-hamda wan-ni’mata laka wal-mulk, laa shareeka lak”\n(Here I am, O Allah, here I am. Here I am. You have no partner. Here I am. Surely all praise, grace and dominion is yours, and you have no partner.)\nAt the time of entering into Makkah with your right foot recite following dua\n“Bismillahi, Allallhumma salli ‘alaa muhammadin wa sallim – allaahumma aftah lee abwaaba rahmatika”\n(In the name of Allaah! O Allaah! Exalt the mention of your Messenger. O Allaah! Forgive my sins, and open the gates of Your mercy for me).\nDuring your 7 Tawaf around the Ka’bah be sure you are in wudu and recite following Dua’s:\n\"Rabbanaa aatinaa fid-dunyaa hasanatan wa feel aakhirati hasanatan wa qinaa ‘adhaaban naar\"\n(Our Lord, grant us good in this life and good in the hereafter and save us from the punishment of the Hellfire. [Quran; 2:201])\nAfter completing Tawaf recite these verses\n“Wattakhidhoo min-maqaami ibraaheema musalla”\n(And take you (people) the Maqaam (place) of Ibraheem as a place of Prayer. [Quran; 2:125])\nThen visit Zam Zam dispensing point and pour water over your head. Start with Sai and recite these duas\n“Bismillahi was-salaatu was-salaamu ‘alaa rasoolillahi, Allahum-ma inee a’-aluka min fadhlika, Allahum-ma a’simnee minash-shaitaanie-rajeem”\n(In the name of Allah, and prayers and peace be upon the Messenger of Allaah. O Allaah, I ask You from Your favour. O Allaah, guard from the accursed devil.)\nUpon reaching the Mount Safa, recite these aayaah\n“Innas-safaa wal marwata min sha’aa’irillaahi faman hajjal baita ‘awi’tamara falaa janaaha ‘alaihi an yattawwafa bihimaa wa man tatawwa’a khiran fa’innallaaha shaakirun ‘aleemun”\n(Verily, As-Safaa and Al-Marwah are from the symbols of Allaah. So it is not a sin on him who performs Hajj or ‘Umrah of the house (ka ‘bah) to perform the going (tawaaf) between them. And whoever does good voluntarily, then verily, Allaah is the All-Recognizer, All-Knower. [Quran; 2:158])\nAfter completing all steps of Sai, men have to shave their head or trim the hair to the minimum.\nThis would complete your umrah inshallah"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:301228f9-4dec-4668-9158-1d80a455dd6e>","<urn:uuid:8f3cebcb-5362-4436-8ada-b8a6e5ae4f1f>"],"error":null}
{"question":"For my research paper on economic systems, could you compare how wealth distribution works under capitalism versus socialism?","answer":"Under capitalism, wealth remains concentrated in the hands of private capitalists who own the means of production, with workers receiving a smaller share of earnings. This leads to class divisions with rich becoming richer and poor becoming poorer. In contrast, socialism aims for equal wealth distribution since the state owns the means of production - everyone receives equal earnings regardless of their level of productivity. This stems from the socialist vision of creating a classless society, following Marx's principle of 'from each according to his abilities, to each according to his needs.'","context":["The Economy & Society\nIn this lesson, you’re expected to learn:\n– the difference between capitalism and socialism\n– the required conditions for economic growth to occur\n– how economic policy affects growth\nWhat is Capitalism?\nCapitalism is an economic system in which investment in and ownership of the means of production, distribution, and exchange of wealth is made and maintained chiefly by private individuals or corporations.\nIt is a social system based on the principle of individual rights. Politically, it is the system of laissez-faire (freedom). Legally it is a system of objective laws (rule of law as opposed to rule of man). Economically, when such freedom is applied to the sphere of production, its result is the free-market.\nIt is centered on the belief that human beings are naturally motivated by self-interest and, when they are not interfered-with in their economic activities, a balanced system of production and exchange based on mutual benefit emerges (Adam Smith’s invisible hand).\nCompetitive markets often deliver improvements in allocative, productive and dynamic efficiency. But there are occasions when they fail – providing a case for intervention.\nThey believed in a bountiful nature and innate goodness of humankind, and asserted that governments should leave the individual alone except when social liberties are infringed.\nFor example, in France, it is not uncommon for the government to take a major stake in French companies, if not outright own them. The French labor market is also quite heavily regulated.\nMore often than not, socialist countries manage the prices of many goods and services. The European Union (EU) manages prices on things like pharmaceuticals and cellphone service. Also, socialist countries are more active in taxing in order to redistribute income from workers to non-workers.\nKarl Marx said, “From each according to his abilities, to each according to his needs.”\nMarx envisioned an economy where the problem of scarcity was addressed through the complete redistribution of wealth and income, from the owners of land and capital to the workers.\nIn his utopian vision, social justice, economic equality, and relief from scarcity would be achieved when society was organized in such a way that all were equal regardless of their level of productivity.\nCountries that are capitalist rely on market prices for efficient product allocation, promote the private ownership of economic resources, and leave most economic decisions to individuals.\nThey do, however, permit the government to:\n– regulate markets\n– preserve competition\n– subsidize and tax firms\n– enforce private contracts\n– redistribute income from workers to non-workers\nEconomic growth occurs when there is a sustained increase in a nation’s real GDP per person over time.\nWhat is GDP?\nGross domestic product is the best way to measure a country’s economy. It includes everything produced by all the people and companies that are in a country (i.e. final goods and services).\nIt creates benefits for society and leads to increases in living standards, nutrition, healthcare, longevity, and material abundance.\nOn the other hand, this growth can also result in environmental destruction and increased income inequality.\nBut others are less apparent. Let’s take a look at some of these conditions.\nThe most important element in economic growth is human capital. Human capital consists of the education, skills, and abilities possessed by an individual.\nCountries that invest heavily in human capital tend to have more economic growth than similarly endowed countries that do not.\nIndividual freedom and the ability to acquire private property are also essential elements in developing human capital. When individuals are free to choose their vocation and enjoy the benefits of private property, their productivity is higher.\nFor economies to develop and grow, it is important that the population grows as well. Population growth must also occur alongside productivity growth.\nLarger populations are capable of producing more output as well as more innovation because the greater the population, the greater the number of productive resources.\nDeveloping human capital alone is not enough to create economic growth. Economies must also invest in developing physical capital.\nPhysical capital refers to the tools, factories, and equipment that are used in the production process. As the stock of physical capital increases, the nation experiences capital deepening. Capital deepening refers to the amount of capital available to each worker – which provides for a more productive labor force.\nRoads, waterways, rail systems, and reliable utility systems make capital easier to access and greatly improve the chances that it will be used effectively.\nResearch and development requires sacrificing current profits in order to gain even greater profits in the future. For firms to take this risk, incentives must exist and be protected. Patents, which provide legal protection for inventors, provide the protection firms need to realize the profits of their research and development.\nWestern and Japanese firms spend far more on research and development than do firms in the developing world. Thus, if developing countries want to continue growing, they must find ways to encourage innovation.\nCorruption and cronyism discourage domestic and foreign investment by effectively raising the cost of capital. Firms, individuals, and foreign investors must know that their property is protected by law.\nOne reason that capital investment is lacking in the developing world stems from the fact that corrupt governments are far more likely to seize private property in the name of national interests.\nGovernment policies:stabilization policies by the central bank affect interest rates and thus capital investment.\nFiscal policy impacts capital investment indirectly through the effect of government debt on interest rates.\nTax policies that affect consumption and saving decisions influence economic growth by way of their impact on interest rates and work incentives.\nAlthough monetary policy primarily affects short-term interest rates, it is the central bank’s effect on long-term interest rates that influences growth. Firms are unlikely to make long-term investments in capital if they are uncertain about future interest rates and inflation.\nThis expected inflation and increased long-term interest rates will discourage capital investment, and ultimately, long-run economic growth.\nEffect on Businesses\nIncreasing the tax burden on firms reduces their ability and incentive to invest in capital. Increasing the capital gains tax on financial investors reduces the flow of savings firms use to make real investments in physical capital. Businesses faced with too high a tax burden may choose to produce elsewhere.\nThus, placing taxes on business, although politically popular, is a recipe for reduced growth.\nTaxes on personal income affect work incentives and can thus also influence the rate of growth.\nGenerally, the more productive you are, the more income you earn. The more income you earn, the higher your marginal tax rate. This is what economists call a progressive tax system. If tax rates are increased on upper incomes, they increase the tax burden of the most productive members of society.\nIf tax rates are too high, the productive worker will either reduce productivity or move to where productivity is not taxed as highly. This results in a situation know as brain drain (the emigration of educated or talented individuals).\nEurope has suffered a brain drain as its best and brightest (most highly taxed) move to countries with lower tax rates.","Capitalism vs Socialism\nBefore we try to find out the differences between capitalism and socialism, it is prudent to have a look at the turn of events that led the development of socialism and finally communism from capitalism that had played a vital role during the industrial revolution in England and later in France, Germany, Japan, and many other European countries. The invention of the steam engine, mass production, and the industrial revolution in Britain meant a large-scale displacement of people from rural settings to cities where industries were established, making them work as wage earners. Capitalists that owned industries and mines attracted men and women from villages to cities where they were asked to work for long hours at low wages.\nThese events had a drastic effect on growing inequalities with rich becoming richer and poor becoming poorer. The Great Depression in the thirties prompted many countries to look for alternatives to capitalism. Thinkers like Karl Marx proposed state ownership of means of production (resources) and equal share of all. This appealed to many countries, especially the Eastern Bloc countries that adopted socialism, which appeared to them as being superior to capitalism.\nWhat is Socialism?\nSocialism is a political and economic system that exists with a controlled market and public ownership of the means of production. The proponents of socialism suggested that the problems of unemployment and financial crises would not arise as economy would be planned with means of production, and distribution remaining concentrated in the hands of the state. This would safeguard the interests of the individual, as he would be shielded from the unpredictable forces of the market-dominated economy.\nSocialists dreamt of a classless society as against the extremely rich and poor divide in capitalism, which was inevitable with individual property and ownership of means of production remaining in the hands of private people. Socialists argued that with wealth being equally distributed, there would be no poor, and all will be equal.\nIt was in 1917 that Soviet Union adopted socialism as state instrument of controlling the economy under the leadership of Vladimir Lenin. The initial success of the policies of the communist government attracted many other countries with China, Cuba, and many others following suit.\nWhat is Capitalism?\nCapitalism is a political and economic system that exists with a free market and private ownership of the means of production. Capitalism that is based upon the belief that competition brings out the best in people evolved in 15th century, and ruled supreme in the world till the 20th century, with the industrial revolution taking place in countries with capitalism in place. Capitalism encourages individual enterprise with the incentive of earning more and rising up the social ladder working to motivate people. Private ownership of property means, wealth remains concentrated in the hands of capitalists, and they gobble up most of the margins with a very small share going to those who work in factories and mines, to produce goods and services.\nWhat is the difference between Capitalism and Socialism?\nThe world has seen the rise and fall of socialism and the loopholes in capitalism. No one system is perfect and can be installed discarding the other. While there is no doubt that capitalism has survived the onslaught of all other ideologies like communism, socialism, etc., it is a fact that the great bubble of communism has burst with the breakup of Soviet Union and failing of other communist economies. The time has come to evolve and put into practice a system that takes up salient points of both ideologies, not only to encourage private enterprise but also to implement government control in resources to work for the good of the poor and the oppressed in the society.\n• Definitions of Capitalism and Socialism:\n• Capitalism is a political and economic system that exists with a free market and private ownership of the means of production.\n• Socialism is a political and economic system that exists with a controlled market and public ownership of the means of production.\n• Ownership of Means of Production:\n• In capitalism, means of production were owned by individuals.\n• In socialism, means of production were owned by the state.\n• Social Classes:\n• A society that followed capitalism had classes in it.\n• A society that followed socialism dreamt of a classless society.\n• In capitalism, those who owned the means of production had more of a share of the earnings while the workers got only a little share.\n• In socialism, everyone was given equal earnings as the state owned the means of productions.\n• Capitalism had a free market system.\n• Socialism had a government controlled market system.\n• Government Interference:\n• In capitalism, government interference is minimal.\n• In socialism, government decides everything."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:97a01dec-925c-43f1-af6e-53f761c97c0d>","<urn:uuid:cf87bb54-c20b-4138-ab90-c3c336d5e64a>"],"error":null}
{"question":"As an environmental science student: What were the economic benefits of Aboriginal-European marriages during fur trade, and what economic costs does tar sands mining create through environmental damage?","answer":"Aboriginal-European marriages created significant economic benefits by securing trade relationships between tribes and European traders. Aboriginal women gained access to valuable European goods like kettles, cloth, knives, and axes, while European traders gained knowledge of Aboriginal hunting techniques and better trading opportunities with tribes. These marriages were seen in an integrated social and economic context, providing Aboriginal people free access to trading posts and provisions. Regarding tar sands' economic costs through environmental damage, they're substantial. The operations require massive water usage (one million cubic meters daily from the Athabasca River), with 92% ending up in toxic tailings ponds. The mining destroys thousands of square kilometers of boreal forest habitat, which cannot be effectively reclaimed as the complex soil relationships take thousands of years to develop. The operations are also Canada's fastest-growing source of greenhouse gases, producing three times the emissions of conventional oil production, leading to broader environmental impacts that affect wildlife and local communities.","context":["The University College of the North is an institution devoted to community & northern development & reflects the Aboriginal reality & cultural diversity of northern Manitoba.\nThe fur trade was one of the biggest economic trends in Canadian history. Even though much of the trading happened between European & Aboriginal men, women played a very interesting & an important part in the fur trade. From creating & strengthening relationships between the European & Aboriginal men, to helping navigate, dressing furs, even cooking & setting up camps, women had a big part in the fur trade. When it came to the actual act of trading & being on trade routes, many people believe that it was just between native men & European men, but in actuality women sometimes also travelled on trade routes trapping, preparing, & traded their own furs. While men dominated the fur trade, women played a very important role in the fur trade, often being the suppliers for their trader husbands, & some even going as far to participate in the trading as well.\nWhen the European traders first came to North America “colonization was not envisaged” by them, so the traders brought no white women from Europe over to North America. This made it much harder for the European traders to practice their own culture & start families in North America so “instead, the traders were forced to come to terms with an alien, nomadic culture,” a culture that the Europeans traders’ own livelihoods depended on. The Aboriginals culture & way of life had given them “distinct advantages with coping with the wilderness environment,” & the fur traders knew that having the knowledge of the land would be crucial to their survival in the harsh conditions of North America. The traders also knew that the Aboriginals had distinct & valuable techniques in hunting, trapping, tracking, & navigating. So, European men started turning to Aboriginal women for companions on their long journeys. The Aboriginal Women educated the European men with their ways of living on the land & practicing their own culture while, helping traverse & navigate the harsh wilderness of North America.\nWhen it came to Aboriginal women & European men, their encounters together were not usually “casual promiscuous encounters, but the development of marital unions which gave rise to distinct family units.” Even though “there were differences in attitudes & practices between the Europeans & the Aboriginals; the fur trade society developed its own marriage rite, marriage a la facon du pays, which combined both Aboriginal & European marriage customs.” When a European man married an Aboriginal woman in fur trade society, the European men would gain & strengthen trade relationships with Aboriginal men, & would “secure the trade of the tribe or band” that the Aboriginal woman belonged too. This tradition soon caught & became accustomed to European traders, with many marrying Aboriginal women to create the social ties to improve their access trade opportunities & gain better knowledge of the aboriginal culture & way of life. Many intermarriages between Aboriginal women & European traders became more & more popular, with both sides of the marriages having a lot to gain from the courtship. With the increased intermarriages the fur trade society began to grow, creating new & strengthening the existing relationships among traders & Aboriginals almost everyday.\nThe European traders had gained a lot by marrying into an Aboriginal family as the Aboriginal women were “trained in the skills necessary for survival” in the harsh wilderness of North America. The Aboriginal women helped the European traders navigate & traverse the wilderness & taught them many survival skills, crafted snow shoes to make it easier to travel through the deep snow, & provided traditional Aboriginal clothing for the traders to keep from freezing in the sub-zero temperatures. Aboriginal women would also cook, preserve food, & prepare camp while their trader husbands were off either trading or trapping furs. One major food contribution that Aboriginal women made was “preservation & manufacturing of pemmican,” which was a very important & nutritious staple food in a fur trader’s diet. European traders also enjoyed the presence of Aboriginal women in their everyday lives as they kept the company on the long journeys between trading posts; for the traders the aboriginal women also filled “the role of a wife & mother left void by the absence of white women.” The men of the North West Company, a Montreal-based company at time of the fur trade in particular, “had always appreciated the economic advantages to be gained by forming alliances with Aboriginal women.” European traders’ marrying into an Aboriginal family helped them “secure the trade of the Aboriginal women’s tribe or band.” Besides helping the European traders strengthen & secure trade relationships, the Aboriginal women “did much to familiarize the European men with the Aboriginal way of life.” The Aboriginal women also taught the European traders trapping techniques, fur preparation, & even going as far to teach the traders a bit of their language. By teaching the traders their language Aboriginal women “greatly contributed to the men’s effectiveness as a trader,” & helped further close the cultural gap between Aboriginals & Europeans. Intermarriages in the fur trade were very beneficial for European traders as they learned many valuable skills & techniques used by Aboriginals for hundreds of years. At the same time those parties filled the void that the lack of white women left in their lives, & greatly increased the success of their livelihoods by creating & strengthening trade relationships between them & Aboriginals.\nAboriginal women were also benefiting from the intermarriage during the fur trade, with the influx of European technology that they were enjoying the luxuries of goods from Europe & the courtships by the European men. Many Aboriginal women were anxious to keep trade flowing, so they could have more access & the ability to use more “European goods such as kettles, cloth, knives, needles, & axes to help alleviate their sometimes-onerous work roles.” Their working roles often included cooking, preparing & dressing furs, & crafting clothing & snowshoes, & making other tools. During the early years of the fur trade “many Aboriginal tribes & bands actively encouraged the formation of marriage alliances their women & traders.” In Aboriginal society “marriage was seen in an integrated social & economic context.” So, the European traders & Aboriginals made an agreement that if the Aboriginals allowed European traders marry & begin families with their women the Aboriginals would have “free access to the trading posts & provisions.” This would give the Aboriginals full trading capabilities at trading posts across British North America, & it would also give the Aboriginals more access to European technology. The European traders, in turn, would strengthen & gain better access to trade relationships with the Aboriginals, while simultaneously gaining knowledge of Aboriginal techniques & culture to further increases their profits. Even though Aboriginal men & European traders were more dominate when it came to being hunters & trappers, some Aboriginal women were trapping, preparing, & trading their own furs. Kees-Jan Waterman & Jan Noel outline that “fur transactions were the norm for people of both sexes” rather than just being confined to men. When it came to the act of trapping itself “men were the hunters of beavers & larger game animals, & the women were responsible for trapping smaller fur-bearing animals, especially the martin whose pelts were highly prized.” Aboriginal women & the Aboriginal population in general benefited greatly due to intermarriages in the fur trade, with gaining more access to trading posts & European technology, which greatly impacted their lives & made their traditional ways of hunting & fur preparing easier.\nEven though white women did not come to the predominantly fur trading areas of British North America until later when the fur trade society was already greatly established, & when they did arrive, they also had great contributions to the fur trade as well. The white women played a largely subsidiary role in fur trade society often being compared to a modern-day house wife. The majority roles of white women who were married to traders were “as suppliers of food & other supplies,” which means they often cooked & set up camp for the traders if they travelled with them, so that their trader husbands could focus on the trapping & hunting rather than setting up his camp & cooking meals. If a white woman did not travel with her trader husband, she often stayed at home to take care of the children, whilst the trader was out making money to support the family. Even though white women did not serve the major role & exert the same impact as Aboriginal women did in fur trade society, they still made contributions by helping the traders on their long journeys for the business.\nIn conclusion, women were very impactful & important in fur trade society & were one of the reasons that the fur trade was as successful of & economic trend as it was. If women had not been as involved so much, many European traders would not have had such strengthened social relationships with Aboriginals tribes & bands at that time. The traders also wouldn’t have had the knowledge of the land & Aboriginal culture if it wasn’t for the intermarriages with the Aboriginal women. This also proves that major companies in the fur trade such as The Hudson’s Bay Company & The North West Company may not have been as successful as they were, with The North West Company outlining the many “economic advantages to be gained by forming alliances with Aboriginal women.” Even if women didn’t travel on trade routes with their trader husbands, they were able to stay home & care for their families & raise the next generation of traders. In the end women really were one of the major reasons that the fur trade was as profitable & successful as it was, & greatly benefited both Europeans & Aboriginals alike.\nVan Kirk, Sylvia. Many Tender Ties: Women in Fur-trade Society, 1670-1870. Norman, Oklahoma: University of Oklahoma Press, 1980.\nVan Kirk, Sylvia. “The Impact of White Women on Fur Trade Society.” Visions Pre-Confederation (2015): 338-351.\nVan Kirk, Sylvia. “The Role of Native Women in the Fur Trade Society of Western Canada, 1670-1830.\" Woman of the Western Front (1984): 9-13.\nWaterman, Kees-Jan. Noel, Jan. “Not Confined to the Village Clearings: Indian Women in the Fur Trade in Colonial New York, 1695–1732.” New York History Vol 94 (2013): 40-58.\nWhite, Bruce M. \"The Woman Who Married a Beaver: Trade Patterns & Gender Roles in the Ojibwa Fur Trade.\" Ethnohistory Vol 46. (1999): 109-47.","Last week, the Boreal Songbird Initiative, Pembina Institute and the Natural Resources Defence Council released a report describing the predicted impact of the tar sands on bird populations. The report, Danger in the Nursery, used modelling based on best current knowledge of bird populations in northeastern Alberta, combined with documented and estimated impacts of different elements of tar sands development and expansion on bird populations.\nThe picture is grim for many reasons. Impacts include:\n- direct lost of habitat to strip mining\n- settling ponds threat to migrants\n- fragmentation and destruction of habitat from deep drilling installations with their road and pipeline networks\n- air pollution from the operations and the production and refining processes\n- water withdrawal, diversions and contamination\nHow do the tar sands impact habitat?\nOne of the most common ways to extract the bitumen, the oil saturated sand and soil particles, is by stripping the vegetation, top soil and sub soils, draining the watercourses, and then scooping it out with giant machinery. 3,000 square kilometres of boreal forest will be strip mined in the next 30 to 50 years, based on current predictions. Strip mining destroys everything in its path. All the life-giving processes are removed. Soils are “stock-piled” as they are in more familiar residential housing developments. However, once stripped and piled, the vitality of the soil is destroyed.\nEfforts to reclaim mined lands and restore boreal forest fail miserably. The complex relationships between soil organisms such as bacteria, fungus, plants, invertebrates and larger fauna (including birds that are the hallmark of the boreal forest) are thousands of years in the making, but take only a few moments for the giant machines to destroy. This is the fate of habitat for up to 3.6 million birds!\nThe tailings ponds are created to store and ‘cap’ the residual waste product, after most of the oil has been removed from the bitumen. The residual is a toxic sludge that is pumped into artificial lakes, some several kilometres across, and ‘capped’ with clean water. These lakes will eventually cover about 100 square kilometres of area. They are death traps to birds landing in them, as was documented when 500 ducks died after landing in a Syncrude tailings pond in the spring of 2008. Annual mortality from tar sands to bird populations could be as high as 100,000 individuals!\nDeep drilling used to extract deeper bitumen deposits, requires a huge infrastructure of road networks, rigs, and pipelines and a reactor to produce steam. These typically burn natural gas, but there is much talk about using nuclear energy to produce steam, as is done for electrical generation. These operations and its infrastructure will destroy 5,000 square kilometres of boreal forest and result in significant fragmentation of a much larger area. These remaining fragments imbedded in the network of roads, pipelines and drilling rigs will be subject to excessive noise, dust, and pollution. Up to 14.5 million birds could be lost due to these activities!\nThe tar sands are by far the fastest growing source of greenhouse gases in Canada, producing as much as three times the amount of greenhouse gases as conventional oil production. In addition, production and refining operations produce huge emissions of toxins, from nitrogen oxides that acidify hundreds of square kilometres, to cadmium and arsenic that cause cancer. Many of these chemicals bioaccumulate in the food web, concentrating in predators such as birds, and ultimately impacting their reproductive success. Climate change is happening at a rate faster than wildlife can adapt, particularly in the north. For example, insect hatches on which so many species of migrating songbirds depend can be out of synch with migration timing.\nWater diversion and contamination\nApproximately one million cubic metres of water is diverted from the Athabasca River to tar sands operations each day. This water is used both in the tailings ponds and in the process to remove the oil from the soil particles. This is done by using steam, requiring vast amounts of water. The process uses approximately three times the water for every unit of oil produced. For the deep in situ extraction process, steam is injected into the ground to heat up the bitumen so that it can be pumped out. Tailings ponds are constructed in close proximity to the river, raising the potential for contamination of one of the Canada’s largest watersheds. Cancer rates in First Nations communities downstream from the tar sands operations have sky rocketed. Only 8 percent of the water removed from the river is returned. Ninety two percent ends up in the tailings ponds. The Athabasca watershed downstream is threatened, as the River is already under increasing stress from dropping water levels as the glaciers that feed into the Rocky mountains gradually retreat and sources diminish.\nBirds most at risk\nOf the 22 to 170 million birds that breed in the area that is and could be impacted by the tar sands, a large number of species are in trouble. Here are two very different examples, one big and one small.\nThe only natural population of Whooping Crane, a critically endangered species currently numbering around 400, is in Wood Buffalo National Park, directly northwest of the tar sands. The strip mines, forest fragments, and most ominously the 50 to 100 square kilometres of toxic tailing lakes which appear particularly inviting from the air, lie directly on their migration route. What are the chances over the next fifty years that a group of migrating Whooping Cranes drops out of the sky to take refuge from a storm in the toxic death traps below?\nOlive-sided Flycatcher was added to the official list of Canadian Species at Risk in 2007. The population of this exclusively insect eating bird has declined almost 80 percent in the last 40 years in North America. Most of its world population occurs in the Canadian boreal forest. Like many other boreal dependent species, it is being assaulted on many fronts, both on its breeding grounds, non-breeding grounds in the Amazon basin and Andean slopes of South America and during its extremely long migration in between.\nThe Olive-sided Flycatcher lives exclusively off flying insects, catching them in flight. The boreal forest in north eastern Alberta is an important area for this species. Loss of thousands of square kilometres of habitat will remove a chunk of its population. Climate change adds an additional stress. Climate change, particularly global warming, alters hatching dates for the insects, putting this important food source out of synch with the timing of bird migration. Climate change also leads to desiccating droughts and contributes to subtle changes in habitat that have not-so-subtle impacts. The tar sands are the biggest single contributor by far to greenhouse gases in Canada.\nIt is time to put a moratorium on the tar sands. It is also time to ask the Federal Government of Canada why it is not using the Migratory Bird Convention Act as an instrument to better protect boreal birds. This will be discussed in my next blog.\n(Photos: Evening Grosbeak, Jeff Nadler; Whooping Cranes, USFWS; Olive-sided Flycatcher, Mark Peck)"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:1b530c54-aafe-4d42-b180-2b2a1002e366>","<urn:uuid:bbc769df-d50a-410f-b7cf-d91527ce4cab>"],"error":null}
{"question":"As a fire safety inspector, I'm curious how the price range of home safety devices compares between radon test kits and smoke alarms - which is more expensive for basic testing?","answer":"Short-term radon test kits are less expensive than basic smoke alarms. Radon test kits cost between $15-$30 for short-term kits (3-4 days). In comparison, even the most basic ionization smoke alarms cost around $150 when including professional installation costs, as required by law. While you can purchase a basic ionization smoke alarm unit for as little as $10 or a photoelectric unit for $20, the total cost increases significantly due to mandatory professional installation requirements.","context":["Self-Testing for Radon in a Home Using Test-Kits\nAdd picture of a test kit…….\nHomeowners can test their home for radon in 2 ways. One is to hire professional services. Detailed information regarding this is available under the sub tab “Finding qualified professionals to fix radon in a home”.\nSecond option is to buy a test kit and perform the test on one’s own.\nRadon test kits are of two types: short-term (3-4 days) and long- term (3-12 months). The short-term kits are quite inexpensive and in the range of $15- $30. These provide quick results.The long term kits are more expensive but provide a better idea of average radon levels in a home. Short-term kits are the ones a homeowner should use when testing a home for the first time. EPA recommends “Whether you test for radon yourself or hire a state-certified tester or a privately certified tester, all radon tests should be taken for a minimum of 48 hours…”\nProper Testing Conditions (essential to getting accurate results)(EPA, 1993)\n1. Correct placement of test kit is important to get accurate results. The kit should be placed in the most often used room of a home and in the lowest occupied level of the home. This might be a bedroom, family room, living room or a play area. However, it CANNOT be a laundry room, kitchen or bathroom.\n2. The kit should be placed at least 20 inches above the ground and 4 inches away from any other object.\n3. It should be at least 3 feet away from doors, windows or any other “openings” to the outdoors.\n4. If the room has no doors or windows, the kit should be placed at least more than 1 feet away from the building’s exterior wall.\n5. If the kit is being suspended in the air, it should hang so as to be in the general breathing zone of most people i.e. 6-8 feet from the floor.\n6. The kit should not be disturbed during the entire testing period. It should also be kept away from heating and cooling vents, fan, direct sunlight, fireplace.\n3. The home must be closed 12 hrs before the test begins and for the entire duration of test. This means all windows of the home and doors should be kept closed at all times except when entering or leaving the home under normal circumstances.\n4. Minimum 48 hours testing is a must.\nShort-term or Long-term test?\nFor first time testing, short-term kits are ideal. These can provide a quick initial estimation of radon levels in a home. Long-term test provide results for average year round conditions. EPA recommends the levels to be below 4 pCi/L.\n- If the results are below 4 pCi/L no follow up action is needed.\n- If results find radon levels between 4 pCi/L to 10 pCi/L, EPA (1993) recommends a second follow-up test which could be either long-term or short-term. If the long-term test is done and its value is found at 4 pCi/L or higher, a mitigation action is recommended.\n- If results find radon to be above 10.0 pCi/l , a second short-term test is recommended by the EPA (1993). At higher levels it is desirable to take the mitigation (reduction) action quickly. Then waiting for a long term test is not seen as a good option.\nFor both steps 2 and 3 when a second short-term test is done, an average of the two short-term tests is taken and if this comes to be 4 pCi/L or higher, than mitigation actions need to be taken by the homeowner (EPA, 1993).\nProtocols for Radon and Radon Decay Product Measurements in Homes is an excellent guidance document published by EPA (1993) on how a home should be tested for radon. It can be accessed here. For quick reference, important aspects of home testing can be found here.\nWhere to get a short-term test-kit ?\n- The best option is to call one’s state radon office and find out if they provide the kits for free or at a discounted price under their radon program. January is National Radon Action Month and many state radon programs give away free test kits on first come basis to the residents.\n- If not, these can be purchased online for a discounted price under the National Radon Program Services housed in Kansas State University.\n- Lastly, the kits might be available at the local home improvement stores and purchased from there.\nNote: If a person is buying or selling a home, it is recommended that professional services be used for testing rather than the self test kits. Here is a good video by U.S EPA for home buyers and sellers providing useful information on what either party should know about radon before a home transaction","Smoke Alarm Buyers Guide\nAlthough it’s not always a pleasant consideration, thinking about the risk of fire is important. Having a functioning smoke alarm installed is one of the easiest and most effective ways of protecting your property against fire. However, you may have to look at a range of fire safety systems before you find the best one for your needs.\nStatistics on smoke alarms and house fires in Australia\nSerious house fires can result in extensive property damage and even death. According to the Australian Bureau of Statistics, more than half the number of deaths caused by accidental fires or flame injuries occurred in a home fire. While the total number of fatalities caused by fire fell by about 47 percent from 1968 to 1998, those resulting from residential fires dropped by 20 percent only.\nHouse fires are more prevalent during the colder months and account for 1.5 percent of preventable deaths in Australia. Approximately 44 percent of residential fires occurred in the kitchen, 30 percent of which resulted from cooking.\nWith an increase in the number of deliberately set fires, suspicious and incendiary fires are becoming more common. Unfortunately, these two generally cause more damage than accidentally ignited fires.\nAccording to statistics, 90 percent of separate houses have a fire safety measure while only 68 percent of units, flats, and apartments had one installed. However, fires that occur in units, flats, and apartments have a greater potential for fatality due to proximity. As such, installing a fire safety measure in higher density areas is just as important as it is in separate homes.\nCompared to privately owned properties or those rented from a public housing authority, properties rented from real estate agents or private landlords were less likely to have a type of fire safety measure installed.\nSmoke alarm laws in Australia\nIn Victoria, the law mandates that smoke alarm systems must be installed in residential properties. Although the exact requirements may vary per state, the smoke alarm installed has to meet every fire safety requirement applicable to the property’s year of construction.\nProperties constructed before February 1998 can have smoke detectors that feature a replaceable battery. On the other hand, those built after 1998 must have either a mains powered smoke alarm system or one driven by a non-removable battery. However, the battery needs to have a lifespan of ten years. Smoke alarms have to be a permanent installation.\nOnly licensed electricians may install smoke alarms, and they must have the permission of local authorities. It’s illegal for homeowners to perform any electrical installation or repair work in their homes. Non-compliance with smoke alarm laws might lead to criminal charges or civil penalties.\nHow smoke alarms work\nOptical smoke alarms: Also known as photo-electric smoke alarms, this type applies the light scatter principle. They comprise of a pulsed infra-red LED that checks for smoke particles by pulsing a ray of light into the sensor chamber after every 10 seconds. In the absence of smoke, this beam keeps passing in front of the sensor. Once a fire breaks out, smoke enters the optical chamber through vents. As the smoke crosses over the ray of light, its particles scatter some of the infra-red light onto the photodiode light receptor, which triggers the alarm by sending a signal to the integrated circuit.\nIonization smoke alarms: This type ionizes the air between two oppositely charged electrodes as the alpha particles pass through the chamber, creating a small constant electric current. When there is a fire, the smoke particles that enter the chamber absorb the alpha particles, charging the balance of current. This change in current will only occur if enough smoke enters the chamber. The uninterrupted electric current sends a signal to the integrated circuit, causing the alarm to sound.\nHigh-quality smoke alarms feature insect screens to keep bugs from entering the chamber, reducing the likelihood of false alarms.\nTypes of smoke alarms\nThere are about five different types of smoke alarm systems, these are:\n- Ionization smoke alarms\n- Photoelectric smoke alarms\n- Combination smoke alarms\n- Projected beam smoke detectors\n- Aspirating smoke detectors\nResidential homes only use the following three smoke alarms.\nIonization smoke alarms:\nIn general, this type consists of a radioactive source that emits alpha particles, and an ionization chamber. They are highly sensitive, and prone to false alarms. They are not recommended to be installed in kitchens.\nPhotoelectric smoke alarms:\nThis type is a nephelometer or scattered light sensor that consists of a light source, a lens for focusing light into a projected beam, and a sensor angled to the beam. Thanks to the optical technology, photoelectric smoke alarms are not as prone to false alarms as their counterpart.\nCombination smoke alarms:\nThis type includes the features of both the ionization and photoelectric alarm systems. While the photoelectric technology responds to smoldering, low-energy fires, the ionization technology responds to rapid, high-energy fires.\nSmoke detectors are also classified in two categories, namely:\nHard-wired smoke alarms: This type is wired to your household’s main electrical circuit.\nBattery operated smoke alarms: This type is generally powered by a 9V detachable or non-removable battery. Lithium batteries are long-lasting and can last as much as 10 years.\nWhich is best?\nIonization smoke alarm:\nThe thought of radioactive isotopes hanging in your home frightens some people. Quick death by fire might not sound as bad as a slow death by radiation. You should, however, rest easy since the alpha particles contained have very little penetrative power and cannot get through the plastic. Furthermore, if the alpha particles escaped by any chance, they cannot travel far. Because of the alarm’s design and the amount of Americium contained, your health is not at risk. This will, however, depend on whether you tinker with the chamber and inhale or ingest the particles. The disadvantage is that old ionization detectors call for proper disposal because of the radioactive isotope. Additionally, the alarm is extremely sensitive, and therefore prone to false alarms.\nPhotoelectric smoke alarms:\nThese smoke alarms are not nearly as sensitive as the ionization smoke detectors. They do not contain any radioactive isotope and therefore not a health hazard. Unlike the ionization smoke alarms, you can install a photo-electric smoke alarm in the kitchen area.\nIf you are not sure about the best smoke alarm to get, having a professional assess your building might help. Regardless of the type you select, you must have your smoke alarms professionally installed, and adhere to all testing and maintenance instructions. If you would like to ask a question contact Pro Electrician Melbourne for professional non biased advice.\nWhat to look for\nWhen it comes to choosing a smoke alarm, compliance with Australian Standard 3786 is the most important feature. Make sure the Australian Standard’s logo is clearly displayed on the package. Here are some of the other features to look for:\n- Long-life lithium batteries (10-year lifespan)\n- Low battery level warnings\n- Integrated emergency exit lights\nYou can get a basic ionization smoke alarm for as little as $10, and the photoelectric type for $20. However, more advanced photoelectric units can cost up to $100. For standalone smoke detectors:\n- A 9V battery-powered dual sensor photoelectric smoke alarm costs about $55.00\n- A 9V battery-powered ionization smoke alarm costs around $9.98.\n- A lithium battery-powered photoelectric smoke alarm that features an escape light costs $58.50.\nOn average, setting up one smoke alarm costs around $150, but the price might vary depending on factors such as access and whether you need the alarms interlinked.\nOther cost variations include:\n- Type of ceiling\n- Size of the home\n- Whether the structure is concrete or timber\n- Whether it’s single-story or multi-story\nGetting quotes from different technicians might help you get a better sense of the current market rates. Remember, every price listed above is indicative, subject to market forces, and may vary locally.\nTips from the Pro\nWhen choosing a smoke alarm system, there are other factors to consider besides the type of sensor. These variables include:\nLocation: Smoke can set off ionization alarms, so photoelectric alarms are the best choice for the kitchen. You need to place a smoke alarm near the kitchen because cooking is the leading cause of residential fires.\nThe size of your property: Most houses need to have a smoke alarm installed in every room, attics and basements included. You may need to place smoke detectors in both ends of the stairways and hallways near bedrooms.\nYou can determine the fire risks to your property and the most suitable type of smoke alarm to install by conducting a complete fire-risk assessment. As such, engaging the services of a professional might be the best option. Remember, smoke alarms are key to life safety."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:34ad3dad-39e5-43d0-8835-75c2f4cdaae0>","<urn:uuid:754eb791-ba97-4034-a971-8bd4f32330f0>"],"error":null}
{"question":"What are the similarities and differences between saving files in InDesign and Excel?","answer":"In both InDesign and Excel, the basic save command uses Ctrl+S (Windows) or Cmd+S (Mac). Both programs also offer a 'Save As' function using Ctrl+Shift+S or Cmd+Shift+S. However, InDesign has an additional feature where it allows infinite 'Undos' until you save a file, while Excel does not mention this capability. Excel provides more extensive keyboard shortcuts for file management, including Ctrl+W/Cmd+W to close windows and Ctrl+O/Cmd+O to open files.","context":["This is part of a series. Here is a complete list of current posts in my InDesign Beginner’s Cheat Sheet.\nOkay, time to enter some text into your InDesign file.\nIn this post, I’ll discuss my experience with the basics of adding text. You’ll have many decisions to make once you’ve populated your pages, but I’ll get to those later. For now, let’s just get some text in.\n***Click on the images for a larger version. Then use CTRL/COMMAND + + (plus sign) to enlarge them still further.***\nHere’s a warm blanket if you need one: Until you actually save a file, InDesign allows you infinite “Undos.” If you don’t like what you just did, hit CTRL/COMMAND + Z. You’re back where you were, ready to try again.\nOne problem you may face that I mentioned earlier: If your workspace doesn’t show the tool menu to the left, or any panel options to the right, go to Windows > Workspace > Advanced. The various components should appear.\nRemember: You’re now working with content pages rather than master pages. You can’t change master-page elements on content pages. For example, you can’t fool around with the font in your running heads, assuming you created some. You must return to your masters and make the alterations there.\nYou can override master-page elements, but you’ll only need to do so in a couple of specific places, and the process is quite simple, as I’ll explain below.\nAn important step: clean up your Word file first!\nIf you have already formatted your text for Kindle or for one of the other ebook platforms, like Smashwords, and it came out without odd line breaks and other formatting errors, you’ve probably done this work. If not, I recommend following Mark Coker’s formatting guidelines at Smashwords. At their most basic, and as Joel Friedlander of The Book Designer web site tells us, these guidelines say you should:\n- Run your text through a plain-text program like TextEdit for Mac or Notepad to strip hidden formatting behind your Word document\n- Then use Word’s “Styles” to format, rather than tabs and returns.\nAbove all, NO TABS and no stacked returns! Styles allows you to set features like first-line indents and spaces before and after paragraphs or headings.\nHere’s help with Word’s Styles process. As one of the footnotes tells us, this is the way to “clean” text for print as well as for ebooks.\nNow that you have a clean Word file, it’s time to adopt a very different basic process from the one you’re used to in Word:\nYou CAN type directly into text boxes in InDesign, and you CAN copy/paste from your Word files. But the preferred process is to use the “Place” command, under “File.”\nIn fact, Joel Friedlander considers using copy/paste instead of “Place” one of the four basic formatting mistakes beginners make. For one thing, he says, if you copy/paste, you’ll lose your italics, if you have used any. He also says that you will lose a number of important formatting options.\nSo the basic steps are these:\n- Create a clean Word file of the text you want to insert into your InDesign document.\n- In InDesign, go to File>Place\n- When offered the chance to browse, select the file you want to insert. The file will “load” onto the cursor; you’ll see it as miniature text attached to the cursor.\n- Position the loaded cursor in the upper left-hand corner of the first page of your document in your Pages Panel (not the master!).\n- When the little black cursor arrow turns white, click.\nYou still have formatting to do, but the text is now in your InDesign document.\nI recommend that you load your book a chapter at a time. It is possible to load an entire 90K manuscript at once, but in my view, doing so has disadvantages:\nHandling larger files creates more opportunities for your program to get annoyed with you and make mistakes, perhaps garbling page order or even leaving out portions. I’m not saying it will; I am saying that if it ever does, the only way you’ll know is if you read the entire ms.\nYou’ll be doing this anyway, but will have no reason to do so until your formatting is in place, since you’ll want to limit the number of times you have to read the whole book all the way through. If you find a major error midway through after formatting, correcting the error can affect all the work you’ve done all the way to the end of the book. Better to be able to do a quick inspection a chapter at a time so you can catch any misbehavior on the program’s part before you do a lot more work.\nYou will need to apply the correct style to each chapter title and subhead or subsection (I use Arabic numerals to denote subsections within larger chapters). To me, it’s a lot easier to catch all of these in a chapter than if I have to comb through a long manuscript looking for them, even using the Find and Replace option in InDesign.\nThese are just my preferences. If you want to load the whole book at once, you should be able to.\nWhat if this process loads only one page!\nIt’s possible that this can happen when you insert a multipage file. If so, you’ll see a tiny red square low on the right margin of the page into which you placed the file. This means the text is “overset”: you haven’t made provisions for such a long document.\nSo what are those provisions you should have made?\nIdeally, you should have your document set up for “Smart Text Reflow” (STR). This toggle is supposed to automatically create pages as needed when you load a multipage file. To see if STR is turned on, go to Preferences, which is located under “Edit” on a PC and under the InDesign logo in the upper left corner on a Mac. Choose Type, and in the box that appears, you’ll see the STR button about two-thirds of the way down.***\nYou’ll have a couple of options; I suggest going with the defaults unless you run into a problem, then trying other options to see if they change anything.**\nThere’s another easy solution if by some chance your full file won’t load:\n- Select the last page in your current Pages panel (probably the one with the single page of the text you’re trying to add)\n- Go to Layout>Pages>Insert Pages and just add a bunch of pages.\nYour pages should flow right into the new space.\n**UPDATE! What if neither of these strategies work? What if STR sulks and won’t flow text, and adding pages doesn’t drag it out of its cave? It happened on my next project. Go to my latest post, “InDesign Obstacle: When Smart Text Reflow Doesn’t Work” to see the thrilling solutions I found!**\nMy final Beginner’s Cheat Sheet tip for today: removing the running heads and page numbers on your opening chapter pages.\nAccording to the designers, best practices state that these pages should not carry the running heads (nor should your “front” and “back” matter, but we’ll address those in future posts).\nTo clear the heads from these pages, simply select the page in the Pages panel, go to Layout>Apply Masters to Pages, and in the dialogue box that opens, select “none.”\nNote that you can add your chosen master, or no master, to a range of pages. Just type the range into the box.\n* When I was working on my latest book interior, STR went into a snit. The first chapter loaded beautifully, but subsequently, only a single page of Chapter Two marked with the overset emblem would load.\nI jiggled around in the program for a while to see whether I had changed a setting somehow. Everything appeared normal.\nFinally, I went to my masters to see if I had inadvertently done something to them.\nPoking around, I found a small icon of a manuscript page with an arrow attached to the upper right margin of each of my master pages. Hovering the cursor, I read that “This story is your primary text flow.” Wondering whether this had anything to do with my problem, I clicked both these toggles to “off.”\nBingo! STR leapt into action on the next try.\nI’ll leave it to the experts to explain what happened. So far, the chapters seem to be loading fine.\n**UPDATE! I was too hopeful. This didn’t work the next time I opened the file. Go to “InDesign Obstacle: When Smart Text Reflow Doesn’t Work” to see what I did next.**\n**BTW, in case you’re wondering, “Story” is an alternative editing space you can choose to use. My book suggests that it can be superior for editing work, but I only used it for a single option I’ll discuss in future posts, and I can’t see that failing to use it regularly for editing caused any problems.","Excel Shortcuts PC Mac\nCheat sheet of the most important Excel keyboard shortcuts to be familiar with\nIt can initially seem hard to use shortcuts if you have been accustomed to working with the mouse, but learning these shortcuts will eventually save you a tremendous amount of time in the long run by making you more. Often in finance careers, knowing the quick keys and shortcuts in Excel can be the difference between going home at 11:00 P.M. and going home at 3:00 A.M.\nAlthough we include the shortcuts for Apple/Mac on this page, if you plan to work in investment banking or another high finance career, we strongly recommend that you purchase a PC keyboard and use parallels on your Mac to mimic a PC environment since you almost certainly will be using a PC for your work computer.\nLearning the shortcuts in Mac is like learning to play the Banjo (5 strings) when you are training to be a lead guitarist (6 strings) for a famous rock band. In other words, please don't do that for your own sanity!\nMost common Excel shortcuts\nOne of the most common and well-known shortcuts is:\n|Ctrl + C||Copy||Cmd + C|\nThis format means that you would press Ctrl (Control, or the button in the corner of your keyboard) AND C at the same time. The process for a Mac would be slightly different as you would have to press Cmd (Command, or the button next to the spacebar) AND C at the same time.\nFor some of the more complicated shortcuts, we will have them listed as:\n|Alt + H , A , C||Center Cell Contents Across Selection||Alt + H , A , C|\nThis means that you would press Alt AND H at the same time. Then pressing A followed by C. A '+' means that you would press the key before AND after it at the same time while a ',' means that you press the button after it in sequence.\nYou may also see some shortcuts or shortcut tasks with a \"/\" listed between buttons or tasks. This \"/\" functions as an \"OR\" and serves to show that either button or task will work depending on the situation.\nBenefits of Excel quick keys:\nOne of the biggest advantages of usingquick keys instead of the mouse is that they allow you to be fast, productive, and efficient. Ideally, you should try to be proficient enough to use Excel with only a keyboard, and learning these shortcuts is a big step to that end.\nIt is not uncommon for investment banks to rigorously test their incoming analysts and associates on their Excel abilities. As time is of the essence at these banks, they expect their analysts to become so proficient in Excel that they are able to build entire financial models using just the keyboard. As the list can be intimidating at first glance, we suggest starting out by only using a few of the shortcuts at first and incorporating more as you get better at these few to gain overall mastery.\nWSO's tip: Finding the shortcut you want\nTo quickly search the entire article for a shortcut, you can use the search function built into your browser. By pressing \"Ctrl + F\" (on Windows) or \"Cmd + F\" (on Mac) you can search the entire article for key search words.\nUseful Excel Quick Keys for Windows & Mac\nPlease note that not every Windows shortcut has a duplicate Mac shortcut to complement it. It is also easier to find more information about shortcuts for Windows than Mac.\nIf you have trouble remembering the shortcuts on Mac, you can open the menus at the top of the screen and see the keyboard combinations listed next to the corresponding action. The process is similar for a Windows user, except that the shortcuts are displayed when you leave your mouse cursor hovered over the desired action. This displayed tooltip does not appear for all actions, just the more frequently used ones such as \"Ctrl + S\".\nBelow is a reference image for Macs of the shortcut next to its respective action.\nBasics & General Shortcuts For Excel Modeling\nListed below is a brief list of some of the most common shortcuts that you will encounter when using Excel. Mastering these will pave the way for your future success as well as an understanding of the more complex and complicated shortcuts. If you find yourself frequenting a shortcut or action multiple times try creating a macro for this task. Creating macros is covered further down in the article.\n|Ctrl + S||Save||Cmd + S|\n|Ctrl + Shift + S||Save As||Cmd + Shift + S|\n|Ctrl + W||Close Window||Cmd + W|\n|Ctrl + O||Open||Cmd + O|\n|Ctrl + N||New||Cmd + N|\n|Alt + F4||Quit||Cmd + Q|\n|Ctrl + A||Select All||Cmd + A|\n|Ctrl + Z||Undo||Cmd + Z|\n|Ctrl + Y||Redo||Cmd + Y|\n|Ctrl + X||Cut||Cmd + X|\n|Ctrl + V||Paste||Cmd + V|\n|Ctrl + B||Bold||Cmd + B|\n|Ctrl + P||Cmd + P|\n|F2||Edit Active Cell||Control + U|\n|F3||Paste Name||Fn + F3|\nAlt + E , S\nCtrl + Alt + V\n|Paste Special *The following Paste Special shortcuts will also work with either of the listed Windows shortcuts, simply replace the first three actions with either version.*|\nCmd + Option + V\nCmd + Control + V\n|Alt + E , S , V||Paste Special Values (No Formatting)||Cmd + Option + V , V|\n|Alt + E , S , T||Paste Special Formats||Cmd + Option + V , T|\n|Alt + E , S , F||Paste Special Formulas||Cmd + Option + V , F|\n|Alt + E , S , C||Paste Special Comments||Cmd + Option + V , C|\n|F4||Toggle References||Cmd + T|\n|F9||Recalculate Workbook||Fn + F9|\n|Ctrl + Shift + :||Insert Time||Cmd + ;|\n|Ctrl + ;||Insert Date||Control + ;|\n|Alt + Enter||New Line Within Cell||Option + Enter|\n|Ctrl + F2||Print Preview||Cmd + P|\n|Alt + Tab||Next Open Program||Cmd + Tab|\n|Shift + F2||Insert or Edit Comment||Cmd + Shift + Fn + F2|\n|Shift + F10||Shortcut Menu||Shift + Fn + F10|\n|Hide / Show Ribbon||Cmd + Option + R|\nSelection & Navigation Excel Quick Keys\nHere are some shortcuts to help you select and navigate large batches of data. Not only can these shortcuts help increase the efficiency of your work, but once you gain an understanding of how to use them they can make simple Excel tasks that much easier.\n|Ctrl + Arrow||Jump to Edge||Cmd + Arrow|\n|Arrow||Move Between Cells||Arrow|\n|Alt + I , R||Insert Row||Cmd + Shift + +|\n|Alt + I , C||Insert Column||Cmd + Shift + +|\n|Alt + E , D||Delete Row / Column||Cmd + -|\nFn + F5\nControl + G\n|Ctrl + F||Find||Cmd + F|\n|Ctrl + H||Find & Replace||Control + H|\n|Shift + Tab||Switch Workbooks||Cmd + `|\n|Shift + F11||Insert Worksheet||Shift + Fn + F11|\n|Ctrl + Page Up / Page Down||Next / Previous Worksheet / Tab||Option + Left/Right Arrow|\n|Alt + E , L||Delete Worksheet|\n|Alt + O , H , R||Rename Worksheet|\n|Alt + O , H , T||Recolor Worksheet|\n|Page Up||Move Screen Up||Fn + Up|\n|Page Down||Move Screen Down||Fn + Down|\n|Alt + Page Up||Move Screen Left||Fn + Option + Up|\n|Alt + Page Down||Move Screen Right||Fn + Option + Down|\n|Ctrl + Tab||Next Workbook / Next Divider||Cmd + `|\n|Shift + Page Up||Extend Selection Up One Screen||Shift + Fn + Up|\n|Shift + Page Down||Extend Selection Down One Screen||Shift + Fn + Down|\n|Alt + Shift + Page Up||Extend Selection Left One Screen||Option + Shift + Fn + Up|\n|Alt + Shift + Page Down||Extend Selection Right One Screen||Option + Shift + Fn + Down|\n|Ctrl + Home||Go To A1||Fn + Control + Left Arrow|\n|Home||Go To Row Beginning||Fn + Left Arrow|\n|End||Go To Row End|\n|Ctrl + A||Select All Used Cells||Cmd + A|\n|Ctrl + Spacebar||Select Column||Control + Fn + Spacebar|\n|Shift + Spacebar||Select Row||Shift + Spacebar|\n|Shift + Arrow||Extend Selection||Shift + Arrow|\n|Ctrl + Shift + Home||Select To A1||Control + Shift + Fn + Left Arrow|\n|Ctrl + Shift + End||Select To End||Control + Shift + Fn + Right Arrow|\n|Ctrl + Shift + Arrow||Select To Last Value||Cmd + Shift + Arrow|\nExcel Hotkeys For Formatting\nHere are some shortcuts to help you format and edit the text of large batches of data. Formatting the text in your data often helps with the legibility and professionalism of the data. Mastering these shortcuts will increase the efficiency of your work and present a cohesive presentation.\n|Ctrl + B||Bold||Cmd + B|\n|Ctrl + I||Italic||Cmd + I|\n|Ctrl + U||Underline||Cmd + U|\n|Ctrl + D||Formula Fill Down||Cmd + D|\n|Ctrl + R||Formula Fill Right||Cmd + R|\n|Ctrl + 1||Open Formatting Dialogue||Cmd + 1|\n|Ctrl + Shift + 1||Autoformat Number Style||Control + Shift + 1|\n|Ctrl + Shift + 2||Autoformat Time Style||Control + Shift + 2|\n|Ctrl + Shift + 3||Autoformat Date Style||Control + Shift + 3|\n|Ctrl + Shift + 4||Autoformat Currency Style||Control + Shift + 4|\n|Ctrl + Shift + 5||Autoformat Percentage Style||Control + Shift + 5|\n|Alt + H , A , C||Center Cell Contents|\n|Ctrl + Shift + 7||Outline Cell||Cmd + Option + 0|\n|Ctrl + Shift + -||Remove Cell Border||Cmd + Option + -|\n|Alt + O , C , A||Autoformat Column Width|\n|Alt + O , R , A||Autoformat Row Height|\n|Alt + D , E||Text To Columns|\n|Alt + D , F , F||Filter Data||Option + Down Arrow|\n|Alt + D , S||Sort Data||Cmd + Shift + R|\n|Alt + O , D||Conditional Formatting|\n|Alt + H + F , G||Increase Font Size||Cmd + Shift + Arrow|\n|Alt + H + F , K||Decrease Font Size||Cmd + Shift + Arrow|\n|Alt + H , 0||Increase Decimal|\n|Alt + H , 9||Decrease Decimal|\n|Alt + H , B||Borders||Cmd + Option + 0|\n|Alt + H , H||Fill Colors|\n|Alt + H , 6||Increase Indent|\n|Alt + H , 5||Decrease Indent|\nBest Excel Quick Keys For Data Manipulation\nHere are some shortcuts to help you manipulate and control large batches of data. These shortcuts will allow you to complete tasks like grouping rows/columns at the press of a few buttons. Once you master these shortcuts you will increase your work output and be able to manipulate your data more efficiently.\n|Ctrl + F3||Name Cell||Cmd + Fn + F3|\n|Alt + D , G , G||Group Rows / Columns||Option + Shift + Right Arrow|\n|Alt + D , G , U||Ungroup Rows / Columns||Option + Shift + Left Arrow|\n|Alt + D , G , H||Hide Grouped Rows / Columns|\nOption + 9\nOption + 0\n|Alt + D , G , S||Show Grouped Rows / Columns|\nOption + Shift + 9\nOption + Shift + 0\n|Alt + =||Autosum Adjacent Cells||Cmd + Option + =|\n|Ctrl + `||Show Formula / Values||Control + `|\nAdvanced Quick Keys In Excel For Tables\nHere are some advanced shortcuts to help you create data tables for your large batches of data. These shortcuts allow for the creation of pivot and data tables at the press of a few buttons. These data tables allow for a better presentation of more complex data.\n|Alt + D , P||Open Pivot Table Wizard|\n|Alt + D + S||Create Data Table|\nOther Useful Excel Quick Keys\nHere are some additional shortcuts to help you complete a wide array of different tasks with your batch of data. Some of these shortcuts allow you to trace dependents, paste special, and clear cell data. Mastering these shortcuts will allow your work to be more efficient and can help you troubleshoot your formulas.\n|Alt + T , U , T||Trace Precedents|\n|Alt + T , U , D||Trace Dependents|\n|Alt + T , U , A||Remove Precedent / Dependent Arrows|\n|Ctrl + [||Highlight Precedents||Control + Shift + [|\n|Ctrl + ]||Highlight Dependents||Control + Shift + ]|\n|Alt + Shift + `||Show Formulas||Control + `|\n|Alt + W , F , F||Freeze Panes Around Cell|\n|Alt + T , M , R||Start / Stop Recording Macro|\n|Alt + T , M , M||Show Macros||Option + Fn + F8|\n|Alt||Ribbon Accelerator Buttons / Drive Menu Bar|\n|Ctrl + F1||Show / Hide Ribbon||Cmd + Option + R|\n|F5 , Alt + S , O||Show All Constants|\n|F5 , Alt + S , C||Highlight Cell Comments|\n|Ctrl + Shift + A||Change Function Name to Function||Ctrl + Shift + A|\n|Delete||Clear Cell Data||Delete|\n|Alt + H , E , F||Clear Cell Formats|\n|Alt + H , E , M||Clear Cell Comments|\n|Alt + H , E , A||Clear All|\nExcel keyboard shortcuts for financial modeling\nAs most of theacross the world are currently built on Excel, it is of utmost importance for aspiring financial professionals to learn how to maximize efficiency using these shortcuts.\nThe faster you get in Excel, the more assets you analyze, the more investment opportunities you uncover, which is what matters the most in the world of finance (along with presentation skills, of course). Models are frequently included as part of investor presentation documents such as pitch books and investment memos.\nA tried and tested method of learning is one where the learner applies the concepts learned to real-life situations. In this case, the best way to learn Excel quick keys would be by actively applying them while working on your own financial models.\nTo give you a head start on applying these shortcuts, we have provided two free videos from our Financial Statements Modeling course. Check out how many shortcuts you can use while learning how to use a model for forecasting financial statements and then keep improving your personal best score. (Two birds, one stone!)\nWSO Excel courses\nIf you are looking to build onskills in general, please check out a video from . This course is designed to bring you up to speed no matter your level of experience using Excel.\nUsing shortcuts can shave off seconds at a time, which turn to minutes and eventually over the course of a day, hours. And you may wonder, how do I get to become so quick using shortcuts? For starters, stop using the mouse and start using that keyboard! Practice, practice, and PRACTICE!\nDid you know about the WSO's Excel Challenge?\nWSO's Excel Challenge is a quick excel formatting exercise we have put together to test your Excel skills. We CHALLENGE you to complete this Excel quiz in under 2 minutes or if you are really good, you may be able to get it to under 1 minute like some of our talented forum members here. If you create a video and post it to this thread on WSO, we will send out a free WSO t-shirt with your name on it, but ONLY if you have the fastest time. Every month we'll be sending out a free WSO t-shirt to the fastest recorded time. Good luck!"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:c41d5d2e-cfd4-4439-97a2-109c04f3dc52>","<urn:uuid:f7010596-0c88-4b37-96ce-99104b326f31>"],"error":null}
{"question":"How significant is Ohio's egg production industry and what measures are in place for salmonella prevention?","answer":"Ohio is the nation's second-largest egg producing state, producing more than seven billion eggs annually. In 1996, Ohio established the Egg Quality Assurance Program in collaboration with various agricultural departments to minimize the risk of Salmonella Enteritidis (SE) in eggs. This program has been effective, as the Center for Disease Control reports that SE outbreaks have been reduced 48 percent since 1995 due to such farm-level quality assurance programs. The risk of encountering a Salmonella-contaminated egg is estimated at one in 20,000 eggs.","context":["Ohio: A Leader in Egg Production & Egg Safety\n- Egg Safety at a Glance\n- About Egg Safety & Egg Handling\n- Egg Quality Assurance Program\n- Protecting our Food Supply\nOhio is the nation's second-largest egg producing state, producing more than seven billion eggs each year. With that leadership comes a responsibility to help protect the safety of the country's food supply.\nOhio's egg farmers take that commitment seriously and have put in place strict standards and programs to ensure the eggs consumers eat are safe, nutritious and of the highest quality. In 1996, Ohio's egg farmers joined forces with the Ohio Poultry Association, the Ohio Department of Agriculture, the Ohio Department of Health and the U.S. Department of Agriculture to establish the Ohio Egg Quality Assurance Program.\nThe program was created to minimize the risk of Salmonella Enteritidis (SE) in eggs. It enhances the safety of Ohio-produced eggs, while maintaining consumer confidence in the quality of the eggs they buy.\nEgg Safety at a Glance Top of Page\nThe egg is one of nature's most nutritious, economical and versatile foods. It poses no greater food safety risk than any other perishable food.\nMost mishandling and reported foodborne illness outbreaks have occurred in restaurants and institutions. Inadequate refrigeration, improper handling and insufficient cooking are factors that have contributed to disease outbreaks.\nProper sanitation by food preparers and cross-contamination from other foods are other factors important to egg safety. Egg recipes properly prepared in individual servings and promptly eaten are not a problem.\nAccording to the Center for Disease Control, Salmonella Enteritidis (SE) outbreaks have been reduced 48 percent since 1995 because of continuing egg industry support of farm-level quality assurance programs like Ohio's and through nationwide industry food safety education programs.\nQ: How long can I keep eggs in the refrigerator?\nA: Eggs, kept in their cartons in the refrigerator, will keep at least four weeks from purchase.\nQ: How long can I keep hard-cooked eggs?\nA: Once the eggs are cooked and cooled promptly, refrigerate the hard-cooked eggs in their shell and use within one week's time.\nHint: Fresh eggs may be difficult to peel. Eggs which have been refrigerated for a week to 10 days before cooking will usually peel more easily.\nQ: How can I keep a fresh egg \"FRESH\"?\nA: Eggs lose quality very quickly at room temperature, so buy eggs only from refrigerated cases. Take the eggs home and refrigerate promptly. Look for shells that are clean and whole. Buy as many eggs as you will use within a two to three week period.\nQ: What are the chances of getting a Salmonella-infected egg?\nA: The Center for Disease Control estimates that, on average across the U.S., one in 20,000 eggs might contain bacteria. At this rate, if you consume 260 eggs per year, you might encounter a contaminated egg once every 77 years.\nQ: What is the best way to store eggs?\nA: Store eggs in their carton because eggs can absorb refrigerator odors.\nQ: Is it safe to eat raw eggs?\nA: The risk of foodborne illness from eggs may increase with raw and lightly-cooked dishes. It's best not to serve raw or lightly-cooked dishes made with eggs.\nNote: There is no health risk if eggs are handled and prepared properly.\nOhio Egg Quality Assurance Program (OEQAP) Top of Page\nThe OEQAP, a state voluntary program intended to minimize the risk of Salmonella Enteritidis (SE) in eggs, is a cooperative effort between egg farmers, the Ohio Poultry Association and the Ohio Department of Agriculture. The program provides step-by-step procedures for egg farmers to produce, pack and sell the highest quality, freshest and safest eggs possible.\nOEQAP outlines stringent guidelines for the production of eggs, including health monitoring of the chickens and environmental testing in chicken houses. The program continues those guidelines through processing, egg washing and inspection and transportation to grocery and convenience stores across the region in refrigerated trucks that are temperature-controlled to 45 degrees Fahrenheit.\nProtect Our Food Supply Top of Page\nConsumers who purchase Ohio-produced eggs can be confident the eggs they buy are safe and of the highest quality, because Ohio egg farmers make egg safety a top priority.\nAt the state level, the Ohio Department of Agriculture is working diligently to increase efforts to protect the state's farms and livestock and maximize food safety for consumers. The Department is the state's lead agency in investigating and controlling infectious livestock diseases, including those that pose a threat to human life. The Department also provides technical assistance to other state agencies and industries regarding agriculture biosecurity and has emergency-response plans to quickly control disease outbreaks through animal quarantines and other measures.\nAt the industry level, Ohio's egg farmers are doing their part by making both food safety and biosecurity top priorities. Many Ohio egg farmers have increased farm security by installing security systems and video surveillance and by alerting their employees of possible threats. In addition, egg farmers are working with local law enforcement and prosecutors in identifying and prosecuting trespassers at agriculture facilities."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:a834cb85-4b5e-4263-81be-5658a4a74112>"],"error":null}
{"question":"How does astrophotography equipment setup differ between historical 19th century attempts and today's professional-amateur practice?","answer":"19th century astrophotography was characterized by long exposures that often resulted in blurry images due to telescopes losing power, focus, or direction. In contrast, modern astrophotography employs sophisticated equipment like guide scopes/cameras (such as the Orion SSAG) and telescope mounts that compensate for Earth's rotation, allowing for precise tracking and superior images with long exposures and round stars. Computer software and digital cameras have also made professional-quality imaging accessible to hobbyists.","context":["Known to the online world as \"AstroTanja,\" 34-year-old Tanja Sund of South Africa is a magazine editor by day, and a devoted astrophotographer by night. Oh, and she's also the mother of a 2-year-old daughter.\nThough Sund admits to a \"continual state of sleep deprivation,\" her images and blog have begun to impress a worldwide audience, and she shows no signs of slowing down. Sund counts an 8\" Orion Astrograph and Autoguider among her gear, a fact that makes us immensely proud. Here is our interview of Tanja Sund, South Africa's hottest new Astrophotographer:\nOrion: As publisher and editor of Fitness Magazine, SA, how was it that you got into astrophotography, and has it really been only 20 months since you started shooting the night sky?\nAstroTanja: I've always been interested in science and astronomy, and yes, it's been 20 months since I first started imaging. I became a publisher in an industry that I'm passionate about, the fitness industry, due to my background in art, design and entrepreneurship. Starting the business just over 10 years ago now allows me a lot more freedom to chase my other passion, astrophotography.\nOrion: What was the first night sky image you shot, and were you happy with it?\nAstroTanja: First image I ever shot was the Orion Nebula, M42. At the time I was ecstatic, just to be able to capture something in the sky that's unseen to the naked eye. As first images go, it wasn't anything spectacular, but it got me absolutely hooked.\nOrion: What are your favorite objects to image these days?\nAstroTanja: Nebulae most definitely. The colors and structures fascinate me, and they all look different - each with its own challenges.\nOrion: Have you noticed that there are very few women in the astronomy and astrophotography field, or is that not the case in the southern hemisphere?\nAstroTanja: Yes, there aren't many women in the astrophotography field. I think it's mostly due to science and astronomy not being such a highlight for a lot of women, but also because it's quite technical and potentially physically strenuous (well my setup is anyway). There are imaging couples, and women mainly stick to post-processing rather than image acquisition, however I take pride in every aspect of my imaging. From packing up the scope, transporting, setting up, acquisition to post editing. I'm proud of my images because I know what went into capturing them, from start to finish. This statement is more of a generalization, but I think most ladies would rather spend an evening relaxing (or shopping) than being out in the dark all night.\nOrion: What is the greatest lesson you've learned through your work?\nAstroTanja: To put proper focus and time into setting up, prepping for an imaging session, and to be extremely precise with polar alignment. Don't overlook the small things - they make for a better end result.\nOrion: How dark are the skies over Johannesburg, and is that where you do most of your imaging?\nAstroTanja: Jozi is the most light polluted spot in Africa. That said, it's not impossible to image here. Having the right equipment and shooting shorter exposures, but many, many, more of them help increase SNR. I'm switching to narrowband imaging soon, so the light pollution won't bother me. But for the most part, I try and get away to image. My favorite spot is a 2400km round trip drive, Sutherland in the Northern Cape. It's a truly dark sky there. Sutherland is the home of SALT (South African Large Telescope)\nHelix Nebula. Credit: AstroTanja. Shot with a 10\" Orion Astrograph. Full blog post about capturing this image here.\nOrion: Any must have equipment?\nAstroTanja: A must have for superior images, is a guide scope/cam. Post editing software has come a long way to bridge the gap between average and superb optics, yet everything is irrelevant if you can't have long exposures and round stars. Even with excellent polar alignment you're not going to be able to get a 5min exposure on an entry level/average mount. I currently use the Orion's SSAG, (Star Shoot Auto Guider). It's easy to use, cost effective and works wonderfully with PHD Guiding and my Celestron mounts.\nOrion: Has observing and astrophotography changed your life or sense of self in any way? If so, how?\nAstroTanja: It's changed everything in my life. It's a challenging form of photography and I'm always striving to better myself. I'm indeed slightly obsessed with improving my images, and I'll chase dark skies all over the world to photograph the sky. It's awakened my sense of adventure and I see imaging opportunities as a way to explore the world. Whether it's driving 12 hours to get to a dark sky in South Africa, flying to the USA with my APO to image the northern sky, or getting to Iceland to capture some aurora - it's all a big adventure. Furthermore, astrophotography is the reason I found that one person I couldn't live without - this shared passion for photographing the sky brought Cory (@TheAstroShake) and I together.\nOur galactic core as it rises over the desert landscape of the Karoo, South Africa (Sutherland). Credit: AstroTanja\nOrion: Have you been to the northern hemisphere to image yet? I'm very interested on your take on how the skies differ between the northern and southern hemispheres.\nAstroTanja: Yes. In September I traveled to the USA to photograph the Andromeda galaxy and a few other northern targets. And in November I traveled to Iceland to photograph Aurora. It's slightly disorientating seeing objects rotate counter-clockwise around the celestial pole (in the south they go clockwise around the SCP), but it's great to see a few of the constellations I never see from where I live.\nOrion: For us northern hemisphere observers hoping to travel, can you recommend some top targets to look for in the southern hemisphere?\nAstroTanja: Top Southern Hemisphere targets are Omega Centauri, the largest globular cluster in the Milky Way Galaxy. Tarantula Nebula - NGC 2070, the most active starburst region known in the Local Group of galaxies, located on the rim of the large Magellanic cloud in the constellation of Dorado. The Small and Large Magellanic Clouds - as satellites of our Milky Way, these magnificent southern objects are only about 180,000 light years away, 15 times closer than the Andromeda Galaxy, M31. The Milky Way core overhead - the southern skies get a spectacular Milky Way core right overhead in our winter months. The Carina Nabula, one of the largest diffuse nebulae in our skies. Although it is some four times as large and even brighter than the famous Orion Nebula, the Carina Nebula is much less well known, due to its location far in the Southern Hemisphere. And finally, the Southern Cross and the Coalsack Dark Nebula. The Coalsack Dark Nebula is easily visible with the naked eye as a dark nebula in southern skies, in the constellation Crux.\nI'll say Carina and Tarantula are probably two of the favorites with imagers as they carry more nebulosity and structure.\nOrion: What would be your dream astrophotography trip?\nAstroTanja: Any place dark, really dark - that's about it.... In both hemispheres. Oh - and I'd like to do star trails on the equator.\nOrion: Any last words of wisdom for aspiring astrophotographers?\nAstroTanja: Attaining great images requires dedication. Acquisition and processing isn't an easy feat. Persist - and you'll get great results. Don't always blame your optics, I've seen superb images come from mediocre equipment.\nKeep up with AstroTanja on twitter (@astrotanja) and on her blog, Astrotanja.com, and on Flickr.","Author : Lowell Bradford\nAstrophotography is the process of taking photos of objects in space. Whether photographing a celestial object visible with the naked eye, such as the moon or a group of stars, or astronomers photographing space with the Hubble telescope, photographing space is astrophotography. The practice of astrophotography does not date as far back as some other sciences, simply because it depends on photography. Photography didn’t become a viable invention until the early 19th century. The first case of astrophotography took place in 1840 when the moon was photographed for the first time. Over a century later, astrophotography is the method used to capture the world’s most phenomenal images of space. Astrophotography is available to everyone. From professional astronomers to the backyard skygazer, all can enjoy the wonders of astrophotography.\nOverview of Astrophotography\nThere are several methods used in astrophotography including various techniques, camera and video equipment, and various telescopes. Understanding the type of equipment used in astrophotography will help ensure you select the best methods for taking photos. The first thing to understand is that astrophotography is different from standard photography. Those accustomed to taking standard photos may find photographing celestial objects is more difficult than anticipated. Lighting, shadows, atmospheric changes, and the distance of heavenly objects must be taken into account to ensure the best photos are captured.\nTelescopes should be adjusted to accommodate for the rotation of the earth. This is accomplished by setting equipment to rotate in an opposite manner from earth. Telescope mounts are an important device used in astrophotography that ensures photos captured are precisely timed and accurately track heavenly objects. Preventing tracking errors is vital to successful astrophotography and there are modern-day breakthroughs in computer science that helps make that happen.\nAstrophotography is one of the oldest forms of science-based photography. Beginning in the 19th century, early astrophotography consisted of photographing the moon, stars, eclipses, and nebulas. The procedure requires long exposure and early images were known for being quite blurry. It was not uncommon for telescopes to lose power, focus, or direction during a prolonged photo shoot.\nThe earliest astrophotography photos captured were of the moon, followed by the sun and stars. It wasn’t until the early 20th century that astrophotography began to become an important scientific research method. The invention of refracting telescopes enabled more powerful imaging to be captured. As the 20th century progressed, new telescopes such as the Hale, Samuel Oschin, and Hubble revolutionized the art of professional astrophotography. By the late 20th century, new telescopes and equipment allowed for some of the most awe-inspiring space photos to be captured for the first time in history.\nWhile astrophotography is an important tool used in scientific applications, it is also a popular hobby. Advances in video equipment, standard, and digital cameras have enabled the backyard enthusiast to capture amazing photos. Computer software makes it possible to take photos that appear as though a professional took them. From the novice to the advanced hobbyist, everyone can enjoy the art and science of astrophotography.\nA variety of media devices and equipment setups are used. Examples include video and webcams, CCD, over-the-counter cameras, single lens and digital single lens cameras. Computer software may be used to adjust cameras and telescopes to zoom in on certain objects then take pictures. Photos taken may be edited in image processing software, for a clearer picture. Please consult the following links for additional information on astrophotography."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:2729395d-6745-4634-8d2a-2cc99580ecbd>","<urn:uuid:98662f17-7243-44e6-8b93-f249dc488e6a>"],"error":null}
{"question":"What manufacturing quality issues affected the LeMat revolver and Whitworth rifle?","answer":"The LeMat revolver had significant quality issues, with the manufacturer constantly having problems getting the revolvers approved by Confederate Ordnance due to production quality. The guns were complex with many small parts prone to breakage - parts like the loading lever retaining catch spring and frame index pin spring frequently needed replacement. This led to production being moved to England to improve quality, though this happened too late to affect Confederate use. Regarding the Whitworth rifle, quality varied significantly - there were both 'BEST' configuration rifles and '2nd QUALITY' versions, with the Confederate purchases being mainly of the lower quality type. The Whitworth Project database tracks these quality differences, noting cases where rifles have been altered, such as B376 having its 'BEST' marking fraudulently replaced with '2nd QUALITY'.","context":["2nd Model LeMat - Lovely Untouched Example\n- Product Code: FHG-2259-SOLD\n- Availability: Out Of Stock\nThere is no revolver that is more instantly recognizable and synonymous with the Confederate military and the American Civil War than the LeMat “Grapeshot” Revolver. Even people with only a passing interest or knowledge of small arms used during the American Civil War will recognize the massive LeMat revolver that was about 14” in overall length and weighed in about 3 ½ pounds! For those who saw the movie or read the book Cold Mountain, the LeMat revolver carried by the protagonist through much of the story was practically a character in and of itself.\nThe LeMat was the invention of Louisiana Dr. Jean Alexander Francois LeMat who developed a uniquely powerful revolver that combined a 9-shot cylinder with a 6 ¾” .42 caliber octagonal barrel that revolved around a 5” long, .63 caliber (approximately 20 gauge) shotgun barrel that served as the cylinder arbor. By flipping a small lever on the end of the pivoting hammer nose, the shooter could determine whether the single action revolver was firing the standard pistol rounds from the cylinder or the shotgun barrel. While the shotgun barrel was short and held a relatively light load of shot, or a .63 caliber slug, it must have been a truly devastating weapon at close range. The total of ten shots without reloading made the LeMat an awesome amount of firepower in a period when the typical revolver held only five or six charges. With the LeMat all of this firepower, practically double a normal revolver’s round count, could be held in one hand. A Confederate cavalry trooper armed with a pair of LeMat revolvers could lay down more fire than two Yankee troopers each armed with a Colt pistol and a single shot carbine, and just one shot less than three troopers so armed! Approximately 2,900 full-sized LeMat percussion revolvers of all models, not counting the “Baby LeMat”, were produced between 1859 and 1865. Of those, at least 1,500 of them were directly contracted for by the Confederacy; 900 for the Confederate army and 600 for the Confederate the navy.\nThe LeMat revolver went through two distinct model variations, with a number of “transitional” guns produced in between. The First Model revolvers were produced in Belgium circa 1862 in the approximate serial number range of 1-450. These guns featured a loading lever on the right side of the barrel, a pronounced trigger guard spur and large rotating lanyard ring in the butt. The Second Model revolvers were produced in Paris circa 1864-65 and featured a loading lever on the left side of the barrel, a rounded trigger guard without the spur and a small, and a fixed lanyard ring in the butt of the pistol. These guns appear in approximate serial number range of 451-2500. Eventually the production of the LeMat revolver moved to England, where the balance of the pistols produced were manufactured in their own, somewhat eccentric, serial number ranges. This move was an attempt to improve the overall quality of the guns being produced, but it was done so close to the end of the war that most of the English produced guns almost certainly never got into Southern hands for use. It is not uncommon to find mixture of 1st Model and 2nd Model features on many of the earlier, Paris made, 2nd Model production range pistols, which collectors refer to as “Transitional” LeMats.\nThe pistol offered here is an about VERY GOOD, untouched condition example of a Paris manufactured 2nd Model LeMat “Grapeshot” Revolver. As is often the case on examples of the LeMat revolver found today, the coveted combat handguns saw heavy use and tend to show significant wear when encountered today. It is not uncommon to encounter LeMat revolvers with a number of the small, and even larger parts replaced, as well as some restoration; sometimes significant. The guns were complex and were manufactured with many small parts that were prone to breakage. In fact, due to issues with production quality, LeMat was constantly having problems getting the revolvers that he delivered approved by the Confederate Ordnance department. This gun is almost an exception to that rule in that it is nearly 100% complete and correct, with essentially no restoration and with only a couple of tiny replacement parts. As is often the case, even on extremely high condition examples, the loading lever retaining catch spring appears to be an old replacement. This is part that is subject to breakage from normal use and in my mind is almost irrelevant in terms of a replacement part; almost every surviving LeMat has had this part replaced. The small spring that retains the frame index pin on the lower right side of the frame may be replaced as well; again, a fragile part that is often replaced. Amazingly the larger and more important parts that are normally repaired or replaced are original to the gun and remain in nice, untouched condition. The original loading lever is in place on the revolver, a part that is regularly replaced with a modern reproduction part. The lever even retains the original shotgun loading rod in its center and both the small shotgun rod and the main loading lever are numbered to the revolver. Additionally, the pivoting hammer nose that fires the shotgun barrel is original and undamaged, again a part that is regularly repaired or replaced. The pistol remains in relatively crisp, untouched condition with clear markings throughout. The barrel is engraved in Gothic block letters:\nCol Le Mat Bte s.g.d.g. Paris\nThe marking is flanked by a pair of intertwined brackets that terminate in flourishes. As noted, the marking remains quite clear and fully legible. The left side of the barrel shows the expected * / LM proof mark as it should, which is proceeded by the serial number 1784. The matching serial number is found on the cylinder, frame, face of the take down pin, loading lever pivot, shotgun loading ramrod and trigger. The interior of the left side of the frame is assembly numbered 19, and the interior of both grips are numbered with the matching assembly number in ink in a period hand.\nWhile it is somewhat typical for later production Paris LeMat revolvers to be marked with English, usually London, commercial proof marks this revolver was produced before that process started. In fact, the serial number places the gun in a rich range of Confederate purchased and used LeMat revolvers.\nThe metal of the revolver is essentially untouched and has a deeply oxidized, rich brown patina over most of the metal surfaces. While the gun is essentially devoid of finish, there are some flecks and flashes of original blue in protected areas around the rear edge of the recoil shield and here and there on the frame. Much of the metal remains relatively smooth, although the oxidation has left some areas of surface crust and minor roughness in places, and there is some scattered light pitting that is the result of actual use. The most obvious areas of light pitting are around the face of the cylinder, the frame in this area, the loading lever pivot hinge and of course in the chambers of the cylinder and the cone recesses of the cylinder at the rear. All of this is the result of the erosive characteristics of the caustic percussion caps of the period. This wear, light pitting and caustic erosion are typical of a percussion revolver that saw any significant use. There is also a thumb sized patch of light pitting on one quadrant of the cylinder, suggesting the revolver laid on that side, on fabric for a number of years, causing the minor roughness. The revolver also shows some scattered dings and surface mars, again not uncommon for any large revolver that saw military service 150 years ago.\nThe action of the pistol functions very well, and it times, indexes and locks up exactly as it should. The loading lever functions as it should, and the often replaced, friction fit rammer that pulls out of the loading lever to load the shotgun barrel is original, in place and as previously noted, is numbered to the gun. The original cones (nipples) remain in place at the rear of the cylinder and show moderate oxidation and some wear. The original front sight is dovetailed into the top of the barrel near the muzzle, but is missing the “Barley Corn” from the top of the sight base; a part that is often broken and missing from English and Continental revolvers of the period as it was a delicate part that was easily broken and lost. The bores of the revolver remains in GOOD to NEAR VERY GOOD condition as well. The five-groove pistol bore shows some evenly distributed moderate surface oxidation with strong rifling and light to moderate pitting along its length. The shotgun bore is moderately oxidized as well with patches of surface crust and roughness here and there. The screws in the gun all show moderate use, with slot wear ranging from minimal to moderate. The grips are actually in about VERY GOOD condition as well. They have been lightly sanded, leaving the checkering somewhat light and smooth. As noted, the grips are assembly numbered 19 in period ink on their interiors, matching them to the assembly mark on the interior of the frame. The grips appear to be free of any breaks, structural cracks or repairs. There are a couple of marks on the left grip that almost look like grain or surface cracks, but appear to be scrapes and surface mars only, not actual cracks. Neither grip shows any cracks or repairs on their interiors. The grips show some scattered light to moderate dings, mars and handling marks indicative of service and use, which are somewhat less apparent due to the sanding.\nWhile this is not a pristine or “minty” example of a 2nd Model LeMat Revolver, it is an essentially all original and complete example of a scarce and desirable gun with only a couple of inconsequential small parts replaced. It is very common to find these revolvers with major replacement parts, most often the loading lever. This gun clearly saw some real world use and shows that wear but does not appear to have been abused during its service. The gun is a nice, solid example of a well-marked, functional 2nd Model LeMat with a nice Paris address. The gun has escaped cleaning and has a wonderful, untouched look and remains fairly crisp with clear markings. The revolver would be fine addition to any collection of Civil War handguns or Confederate collection and is certainly priced very fairly for the quality, condition and eye appeal of the revolver.","This information is the result of Bill Curtis and De Witt Bailey research concerning original Whitworth rifles. Research Press is now managing the Whitworth Research Project Database. If you have access to ANY original hex bore Whitworth from the period 1857-1865 please note its serial number and letter for recording. Please contact David Minshall at Research Press with details.\nWarning! - The Whitworth Research Project has identified problems with several rifles that have appeared on the open market from time to time. See notes below regarding the following original Whitworth rifles; numbers 449, B376, B678, C575.\nWhitworth Rifle Number 449\nThis is a military match Whitworth (i.e., a full stocked target rifle, not equipped for a bayonet and having delicate sights unsuitable for military use. Not, however, as complicated as those of the later Match Rifles), serial number 449. The gun has a 36\" barrel. The lock is marked Whitworth in front of the hammer with the Whitworth trademark (sheaf and crown over W) at the rear of the lock. The barrel is marked \"Whitworth Patent\". It has the original 52 bore proof marks on the left rear of the barrel. The buttplate is checkered, the trigger is checkered, the wrist and forearm are also checkered. There is a 'C.S.' stamped at the rear of the barrel and on the tang of the buttplate.\nThis rifle was sold by Christies in Australia in August 2001. Christies auction catalgue noted that the inside of the patchbox is inscribed 'Sgt. C.D.Grace 4th GA Regt. 1863'. Grace is (one of the marksmen) credited with shooting Gen. Sedgwick; who fell dead while reassuring his men that Confederate snipers \"couldn't hit an elephant at this distance.\" The 'Grace' markings are most likely spurious.\nThis is a very early model made in about 1858/59 and right outside any serial number range or type associated with Confederate imports. It is remotely possible that the rifle was bought second hand and added to Confederate stocks, although there is currently no evidence to authenticate the 'C.S.' marks. These were expensive rifles and eagerly bought by the members of the new National Rifle Association.\nThe CSA series are in the upper B and lower C series and are good plain knock about rifles with simple sights apart from that proportion equipped with telescopes. All those known to have any provenance are marked 2nd QUALITY and nearly all follow a set pattern although a very few slight variations are known.\nWhitworth Rifle Number B376\nThe Whitworth Rifle Number B376 which may appear on the market as a Telescope Sighted Whitworth, with the inference that this might have been Confederate, should be considered in the light of the following information.\nB376 was noted by the Whitworth Research Team at the Baltimore Gun Show in March 2000.\nIt was then an absolutely typical Military Match in Whitworth's 'BEST' configuration, conforming to the standard form of all the 'BEST' marked rifles. It did not have either a telescope or the mountings for one.\nAt some time in the following three months this rifle has been fitted with a side mounted brass telescope sight and the 'BEST' removed from the guard tang and replaced with the words '2nd QUALITY'.\nThe rifle bears no resemblance whatsoever to Whitworth's '2nd QUALITY' rifles and bears a serial number from well before the first appearance of this series.\nThe telescope and its mountings are not Whitworth Pattern.\nThe possible inference that may be drawn from this, is that whoever committed this atrocity has read or otherwise knew that the Confederate Whitworths were marked '2nd QUALITY' and changed the rifle to tempt collectors without specialised knowledge.\nWhitworth 'BEST' Pattern Number B678\nThis rifle was initially offered by Heritage Auctions, Dallas, and appeared in the 30 April / 1 May 2012 sale as Lot 50488. This rifle was subsequently withdrawn from the auction and returned to the vendor.\n\"Lot 50488 Rare Confederate Marked British Whitworth Military Percussion Rifle.... (Total: 1 Items) 2012 Apr 30 - May 1 Arms & Armor Signature Auction - Dallas #6076.\"\nFAKE ALERT - A fine rifle has been marred by a faker stamping \"NATCHEZ\" into the wood just in front of the trigger guard finial. It would appear the faking was applied only a few weeks before the auction date. Purchasers should be aware of this as it will probably crop up somewhere else.\nThis rifle (B 678) has been recorded by the Whitworth Research Project for over twenty years through owners in South Africa, Italy, and US Auctions and the word \"Natchez\" has never been on it before. Apart from this, the CSA purchases were not of this enhanced and more expensive version.\nWhitworth Rifle Number C575\nThe well known Confederate Whitworth rifle number C575 is an odd-ball which carries the so far unique lock mark for the series of WHITWORTH FOR COOK & BRO. NEW ORLEANS. The guard tang carries the inscription 'Co. F. 8th NC Regt.' C575 has spawned a whole mythology of its own I suspect. What speculation there must have been about Co. F of the 8th NC Regt !\nHowever, I have to tell you that this rifle was sold through the Weller & Dufty auction house in Birmingham on March 22nd 1967 when IT DID NOT HAVE ANY SUCH INSCRIPTION !\nWe are aware of the June 1970 Gun Report article which describes the tang engraving.\nI have no idea who engraved it but the time frame is clear and the 8th NC were 100 years gone by then."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:a7a6a818-a9b0-4bac-a8e7-9d8c1919cea3>","<urn:uuid:2a4df384-4f52-42c2-86af-f4606b6b4b74>"],"error":null}
{"question":"As a healthcare administrator, I'm interested in understanding what counts as medical waste and how it impacts the environment. Can you explain the classification of medical waste types and their environmental effects?","answer":"Medical waste is classified into eight types according to WHO: infectious waste (contaminated with bodily fluids), pathological waste (tissues and organs), sharps waste (needles and scalpels), chemical waste (solvents and disinfectants), pharmaceutical waste (expired drugs), cytotoxic waste (cancer treatment materials), radioactive waste (contaminated by radionuclides), and non-hazardous waste. Only about 15% of healthcare facility waste is actually hazardous. Regarding environmental impact, medical waste can create various problems including airborne pollutants, radioactive contamination, groundwater pollution, and wildlife hazards from pharmaceutical ingestion and sharps injuries. Even proper disposal methods like incineration and autoclaving produce CO2 emissions.","context":["Before a medical facility can offer care, it has to have an effective method of medical waste disposal in place. But which method is the right one? There are so many guidelines and regulations at play, and the many methods of disposal come with varying price tags, often preventing a facility from aligning with their preference. Maintaining this proper disposal of medical waste is overwhelming. Between labeling, containment, and treatment, this issue has many healthcare facilities stumped as to their next steps in ensuring they are following federal guidelines. In this article we are going to cover:\nWhat wastes are considered to be medical waste?\nMost effective methods of disposal\nWhat Wastes are Considered to be Medical Waste?\nAccording to the World Health Organization, there are eight types of medical waste:\nInfectious waste: waste contaminated with blood and other bodily fluids (e.g. from discarded diagnostic samples), cultures and stocks of infectious agents from laboratory work (e.g. waste from autopsies and infected animals from laboratories), or waste from patients with infections (e.g. swabs, bandages and disposable medical devices);\nPathological waste: human tissues, organs or fluids, body parts and contaminated animal carcasses;\nSharps waste: syringes, needles, disposable scalpels and blades, etc.;\nChemical waste: for example solvents and reagents used for laboratory preparations, disinfectants, sterilants and heavy metals contained in medical devices (e.g. mercury in broken thermometers) and batteries;\nPharmaceutical waste: expired, unused and contaminated drugs and vaccines;\nCytotoxic waste: waste containing substances with genotoxic properties (i.e. highly hazardous substances that are, mutagenic, teratogenic or carcinogenic), such as cytotoxic drugs used in cancer treatment and their metabolites;\nRadioactive waste: such as products contaminated by radionuclides including radioactive diagnostic material or radiotherapeutic materials; and\nNon-hazardous or general waste: waste that does not pose any particular biological, chemical, radioactive or physical hazard.\nOut of all the waste created by healthcare facilities, only about 15% is actually considered hazardous. This means that a facility could potentially be overpaying for a medical waste disposal system, simply due to over-classification of its waste. Each state has clear definitions for what materials qualify as hazardous, so it’s vital to an organization to clearly understand the expectations put before them when it comes to properly disposing of medical waste. To view any state’s regulatory requirements for medical waste disposal, click HERE.\nMost Effective Methods of Disposal\nDisposed medical waste must be treated in a way that prevents the spread of possible pathogens. Obviously, it does not require sterilization, but it must be disposed of in a way that does not harm healthcare workers or the environment.\n1. Chemical Disinfection\nSome biohazardous wastes carry harmful and infectious microorganisms that should not be released into the environment once the waste has been discarded. For that reason, these wastes are chemically disinfected prior to leaving a healthcare facility and being deposited in a landfill. This method requires a facility to have a full area dedicated solely to the treatment and disinfection of medical waste, as well as packaging solutions for the transportation of that waste.\nThis method of medical waste disposal involves steam sterilization. According to the Center for Disease Control (CDC), exposure of the waste for up to 90 minutes at 250°F in a autoclave may be necessary to ensure an adequate decontamination cycle. After steam sterilization, the waste can be safely handled and discarded with all other nonhazardous solid waste. These wastes can then be incinerated, provided the incinerator is capable of burning these wastes completely and can stay within Environmental Protection Agency (EPA) emissions standards.\nCertain medical wastes such as sharps pose the greatest risk of injury to those involved with their disposal. Many sharps (needles, scalpels, syringes, lancets, auto-injectors, etc.) end up in the trash or flushed down the toilet, as users are often unaware of the dangers of accidental needlesticks. Due to this high level of risk involved with accidental needlesticks, the U.S. Food and Drug Administration (FDA) has developed regulations for proper sharps disposal. Disposal containers must display a biohazardous symbol indicating that the material inside is hazardous. When a container is about 3/4 full, it must be disposed of properly at sharps collection sites or through the use of a mail-back program.\nEncapsulation of medical wastes can prevent healthcare facilities from spending money on expensive incineration or disinfection tools. Once waste has been encapsulated, it is sent off to a separate facility for treatment and disposal, eliminating the need for those solutions to be accomplished in-house. Medical waste disposal doesn’t have to be an expensive endeavor for any facility that handles bio-hazardous material. Mail-back systems can significantly minimize the cost of medical waste disposal. To find solutions for mail-back waste disposal, click HERE.","Medical Waste Disposal Questions & Answers\nWhat is considered medical waste?\nAny kind of waste that contains pathogens that can cause disease. It is inclusive of waste produced by hospitals, surgi-centers, medical and dental offices, labs dialysis centers, plasma centers and veterinarian practices.\nWhat are the most common methods of disposing of medical waste?\nThere are four major categories for medical waste disposal. All medical waste must be regulated and be in compliance with Federal and State laws.\n1. General Medical Waste produced in medical offices such as paper, plastics and regular office waste all of which may be disposed in regular waste containers.\n2. Infectious Medical Waste, this type of waste may contain or propose infection that would be harmful to humans, animals and the environment. Infectious waste has strict requirements for storage, transport, disposal, licensing, and processing.\n3. Hazardous Medical Waste poses threat of infection inclusive of sharps that have not been or have been used, because they have the ability to puncture or harm the user. Chemotherapy agents, as well as chemicals, such as solvents, mercury in thermometers, and lead in paint.\n4. Radioactive Medical waste inclusive of all sharps that have not been used, because they have the ability to puncture or harm the user. Chemotherapy agents fall into this category, as well as chemicals, such as solvents, mercury in thermometers, and lead in paint.\nWho is responsible for the disposal of the medical waste after it has been taken away from the producers of the waste?\nIn 1988, Congress enacted the Medical Waste Tracking Act of 1988, a United States federal law that addressed the handling and disposal of medical waste in coastal areas. It was designed primarily to monitor the treatment of medical wastes through their creation, transportation and destruction, i.e. from \"cradle-to-grave.\" Four requirements were primarily identified; first, to provide a means of monitoring \"the transportation of waste from the generator to the disposal facility\" unless said waste had previously been incinerated. Secondly, to be able to ensure the \"generator of the waste\" that the waste had been \"received by the disposal facility.\" Next to develop a uniform form for the tracking of materials across states and finally to develop a means to label and contain the wastes for the safety of the handlers.\nHow does medical waste effect the environment?\nMedical waste airborne pollutants can effect our environment; radioactive pollutants, ground water pollutants and wildlife hazards posed by pharmaceutical ingestion and pricks from sharps (needles) if not disposed of properly also pose a huge problem. Most methods of disposal that include incineration and autoclaving produce c02 emissions even after proper disposal.\nCan medical waste be recycled?\nUsually medical waste is sterilized and then disposed in a sanitary landfill. There are other items that can easily be recycled including plastic items, such as IV bags, syringes, dialysis tubes and plasma tubing, which can be treated, either by melting them down or by chemical sanitation, therefore sterilized, and now ready to be made anew.\nWhat do we do with 2 billion pounds of potentially infectious medical waste?\nThere are three primary treatment methods used to dispose of medical waste, each uses either heat, chemical reactions, or a combination of both to decontaminate bio hazardous wastes. All ending up in our landfills. In addition to disinfection, some states and landfills require that medical waste be shredded to make the contents unrecognizable.\nHow long can biomedical waste be stored?\nStorage of biomedical waste in a place other than at the generating facility shall not exceed 30 days. The 30-day storage period shall begin on the day the waste is collected from the generator.\nHow is medical waste collected?\nDue to recent regulation, biohazard waste disposal companies must come to pick up the waste and take it to a treatment facility to be rendered safe and non-hazardous.\nWhat is the importance of environmentally friendly medical waste disposal?\nEnvironmentally safe waste treatment centers not only use materials and processes that are eco-friendly, but they also help to significantly decrease the amount of toxic waste that leaks into the environment helping to preserve our earth.\nHow does segregation of medical waste help the environment?\nSegregation reduces the amount of waste that needs special handling and treatment and prevents the mixture of medical waste like sharps with the general waste. It also provides the opportunity of recycling, and reduces the cost of disposal and treatment.\nAre there ecofriendly ways to reduce medical waste?\nStart by proper segregation of the waste. Reduce the packaging size as warranted and reuse single use devises as long as it is in compliance and an option of your state and federal law. Have a medical waste management plan and last but not least, be sure to use a disposal management company that understands and is compliant with medical waste disposal laws."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:0031ee60-e4ae-4dd4-a80c-218877b27a40>","<urn:uuid:0fb89704-868b-4f0b-b86a-190af62e2ac4>"],"error":null}
{"question":"What similarities exist between the environmental education initiatives in Canadian schools and the storytelling approach used in the Secret Path Garden to raise awareness about important issues?","answer":"Both approaches use educational spaces to raise awareness about critical issues affecting Canada. The environmental education initiatives integrate various subjects like math, science, and art to teach students about climate change, offering hands-on experiences such as beach clean-ups and water treatment facility tours. Similarly, the Secret Path Garden uses an immersive natural setting with water features and innovative landscape techniques to educate visitors about Indigenous history and reconciliation. Both methods aim to engage their audiences through interactive and collaborative approaches while addressing significant national challenges.","context":["Genoscape Feature Garden – 2017 Canada Blooms\nThis coming year, will be the 6th consecutive year that we will have a feature garden at the Canada Blooms Flower and Garden Festival. We have had great experiences over the years with the show as it allows us to present our most creative work to the public.\nTrying to come up with different, unique ideas from year to year is a challenge, to say the least. We have to find a balance between presenting functional landscape and exhibiting over the top elements to give the show’s patrons the ‘wow’ factor they’re seeking. We must also base our design on the Show’s theme for the year. In the past, this has proven to be the most difficult aspect to the design process, until this year…\nThe theme for 2017 is “Oh! Canada” in honour of Canada’s sesquicentennial. Coming up with a design for a Canadian theme would be simple! All we have to do is include a bunch of hockey related items and perhaps a landscaped doughnut shop, right? Well unfortunately, the typical stereotypes that embodies Canada were not sitting well with me on a creative level. I needed something deeper. Something more representative of who we, all of us, are. I needed to exhibit where we’ve come from and where we can go, as a nation. And I only have 4000 sq/ft to do it!\nThis summer, The Tragically Hip band made a historic tour across Canada. Gord Downie, the bands lead singer and songwriter, was recently diagnosed with cancer. Many believe that the tour of 2016 may be the Hip’s last as a band. At the last stop of their tour on August 20th, the band played a nationally televised concert from their hometown of Kingston, Ontario. It was here that Gord Downie asked the nation to look to the North. It’s time for us to acknowledge communities white Canadians have been trained for decades to ignore. It’s time to do something. It’s time to start a new relationship with Indigenous Peoples. As soon as Gord engraved these possibilities in my head, via the CBC, I knew what we needed to do for our 2017 Feature Garden.\nThe Story of Chanie Wenjak\nSTATEMENT BY GORD DOWNIE\nOgoki Post, Ontario\nSeptember 9, 2016\nMike Downie introduced me to Chanie Wenjack; he gave me the story from Ian Adam’s Maclean’s magazine story dating back to February 6, 1967, “The Lonely Death of Charlie Wenjack.”\nChanie was a young boy who died on October 22, 1966, walking the railroad tracks, trying to escape from the Cecilia Jeffrey Indian Residential School to walk home. Chanie’s home was 400 miles away. He didn’t know that. He didn’t know where it was, nor know how to find it, but, like so many kids – more than anyone will be able to imagine – he tried. I never knew Chanie, the child his teachers misnamed Charlie, but I will always love him.\nChanie haunts me. His story is Canada’s story. This is about Canada. We are not the country we thought we were. History will be re-written. We are all accountable, but this begins in the late 1800s and goes to 1996. “White” Canada knew – on somebody’s purpose – nothing about this. We weren’t taught it; it was hardly ever mentioned.\nAll of those Governments, and all of those Churches, for all of those years, misused themselves. They hurt many children. They broke up many families. They erased entire communities. It will take seven generations to fix this. Seven. Seven is not arbitrary. This is far from over. Things up north have never been harder. Canada is not Canada. We are not the country we think we are.\nI am trying in this small way to help spread what Murray Sinclair said, “This is not an aboriginal problem. This is a Canadian problem. Because at the same time that aboriginal people were being demeaned in the schools and their culture and language were being taken away from them and they were being told that they were inferior, they were pagans, that they were heathens and savages and that they were unworthy of being respected — that very same message was being given to the non-aboriginal children in the public schools as well…They need to know that history includes them.” (Murray Sinclair, Ottawa Citizen, May 24, 2015)\nI have always wondered why, even as a kid, I never thought of Canada as a country – It’s not a popular thought; you keep it to yourself – I never wrote of it as so. The next hundred years are going to be painful as we come to know Chanie Wenjack and thousands like him – as we find out about ourselves, about all of us – but only when we do can we truly call ourselves, “Canada.”\n“Do we want to live in a haunted house the rest of our lives?” – Joseph Boyden\nThe Secret Path Garden\nWithin our garden, we will be illustrating the story of Chanie Wenjack. We will tell his story, and also exhibit reconciliation efforts that we can make. We will also be accepting donations on behalf of The Gord Downie/ Chanie Wenjak Fund. We have contacted several First People who are artisans, craftsmen and just general public who want to be a part of this. This will truly be a collaborative effort between The First People of our nation and the rest of us who make up our great country. This is what Canada should be about.\nPlease don’t be mistaken, this will still be a Genoscape Feature garden. Our patrons will be immersed in a natural setting with various water features and innovative landscape techniques. This will not only be our largest garden to date, but it will also be the one with the most significance.\nThe show runs from March 10 – 19, 2017 at the Enercare Centre, Toronto. Please visit the Canada Blooms site for more info.\nPlease visit The Gord Downie/ Chanie Wenjak fund page for info on the fund or if you would like to make a donation.","Last summer, heavy smoke due to wildfires blanketed most of British Columbia, causing thousands of children to grieve over lost months of outdoor activities. This kind of phenomenon impacts the environment and the lives of everyone, and youth are noticing!\nIn January, the Victoria Times Colonist featured Rebecca Wolf Gage’s actions to combat climate change. As well as joining the movement, “Hands Up For Climate Justice,” becoming vegetarian, and riding public transportation, this grade 7 student at Shoreline Community Middle School has helped arrange for guest speakers on climate change and has organized regular strike action for youth to demonstrate at the BC legislature. Inspired by 16-year-old Greta Thunberg of Sweden, who has taken similar actions, Gage stated, “I’m kind of scared, but I’m also really hopeful we will find a solution.” On March 15, thousands of students around the world walked out of school to protest government inaction on climate change. Thankfully, while youth are becoming more proactive, both mainstream media and everyday citizens are not only waking up to the reality of climate disruption, ocean pollution, and other environmental issues, but also talking about them.\nMany young people, like Rebecca, already engage in environmental fundraisers, eco-clubs, litter clean-ups, nature gardens, tree planting, and waste-free lunches. They also have proven that they are strong advocates for the environment, with successes in tackling issues such as disposable plastics.\nHowever, if climate change were a mandated topic in the curriculum, so much more could be done! Teachers and homeschoolers could integrate math, science, research, spelling, reading, and art subjects in units of study. Reports on environmental research could be presented to local businesses, city councillors, media, and the school community through an assembly or posted online.\nChallenging students to stand up for tackling climate change would develop their public speaking skills and give them confidence in creating a sustainable future for us all. School staffs could choose either to engage in a single project that involves all grades or allow each classroom to undertake its own independent assignment. To cover any expenses, grants such as the Climate Action Fund could be accessed. The World Wildlife Fund – Canada awarded a grant to Ontario’s Rideau Public School which enabled grade 4 teachers Anne Salter and Karen Orgee to explore the negative effects of plastic. Their students learned through hands-on experiences as they toured the city of Kingston’s water treatment facility, then travelled to nearby beaches to help gather litter. “It’s a grant to educate the students about micro-plastics and plastic in general in the oceans, how bad they can be, what the effects are, and what we can do to help clean up,” commented Salter. These classmates also engage in letter writing to share their opinions.\nOur individual and collective actions have an environmental carbon footprint and consequences that are now affecting weather patterns commonly referred to as climate change or climate disruption. Students are becoming keenly aware of the causes of environmental degradation and the extreme weather events the world is experiencing, and they are eager to learn methods to reduce the destructive impacts of human activity. Youth are becoming a powerful force and their skills and energy are definitely needed to help save the planet. Without a doubt, teachers and their students will have passionate issues to investigate, such as What causes oceans to warm? and How do we reduce greenhouse gases? The following are a few suggestions that could be developed as cross-curricular units or assignments at all school levels.\n• Celebrations and Festivals. Examine the types of items discarded, as well as the use of electricity and water. Students living in areas that host tourist events will have opportunities to conduct local research.\n• Clothing. Discover how “Fast Fashion,” washing clothes and using clothes dryers affect the environment, e.g., research how microfibres are affecting the Great Lakes.\n• Disposable Diapers. List the chemicals they contain and discover the amount of waste per child they produce annually. Compare the use of cloth and disposable diapers in terms of environmental impacts.\n• Idling Vehicles. Report on the impact of idling vehicles. List tips to save fuel. Post anti-idling posters in strategic locations.\n• Impacts on wildlife. Select a mammal, insect, or bird and investigate the effects that noise, pollution, pesticides, and/or climate change have on the species’ habitat.\n• Environmental Tourism. Look at encouraging environmental tourist stewardship. List eco-travelling tips and sustainability ideas for cruise ships, airplanes, resorts, and hotels. Plan methods to educate visitors to your area.\n• Construction Debris. Can a home be recycled? Discover what can be reused or recycled when building, demolishing, or renovating.\n• Composting. Research the benefits of recycling organics and returning compost to the soil as opposed to discarding organics in landfills, which creates greenhouse gases and leachate, and wastes resources.\n• Agriculture. Study damaging agriculture practices in areas around the world. How are soil and pollinators being affected? How can we help the pollinators?\n• Fossil Fuels. Debate the advantages and disadvantages of the energy produced by fossil fuels, nuclear, solar, and wind. Which of these should be government subsidized? List ways to be energy efficient.\n• Movies. Examine the influence of movies and advertising. Urge film producers to take environmental responsibility for the images they project through their props, scenery, and graphics.\n• The Circular Economy. For students with business and economic interests, explore the new circular economy—an industrial system that is restorative by intention with a focus on eliminating waste. Discover the products that now are being optimized for a cycle of disassembly and reuse.\n• Green Products and Practices. Undertake an assignment that highlights businesses who have begun “greening” their products and services.\n• Food Waste. Discover the amount of food wasted from farm to fork. Discuss how to be creative with leftovers. Explore the implications of our high rate of meat and dairy consumption.\n• Factory Farming. Research the pollution caused by factory farming methods.\n• Create Posters. Use climate change as a theme to practise art skills. “Recycle Right – Be A Good Sort” might be a suitable theme to demonstrate your local municipality’s recycling program.\n• Mining. A challenging project could be reporting on the toxicity of mine tailings and the research being done to tackle this issue.\n• Recycling. Studying the evolution of recycling and how we have amassed so much waste since WW II could serve as a social and history lesson.\nA recent study has confirmed that the oceans are warming 40% faster than previously estimated. For the past three decades, interested teachers have organized extracurricular eco-activities; however, imaginative solutions are now needed to tackle our changing climate, making it a concern that should be an integral part of today’s curriculum. Mobilized youth, who can’t afford to lose sight of the bigger picture, have the potential and are proving to be a powerful and influential group of galvanized individuals.\nLead by example! It’s not always what you say to students… students also learn by watching and observing! What will they learn tomorrow?\nABOUT THE AUTHOR\nLarraine writes children’s illustrated adventure books on composting and pollinating. castlecompost.com\nThis article is from Canadian Teacher Magazine’s Spring 2019 issue."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:a652b2fe-e06f-424a-a6e5-6365a104f8ef>","<urn:uuid:f0a4595b-3827-43c6-a27e-e45fff963e95>"],"error":null}
{"question":"As a researcher studying African governance, I'm curious: How do wealth levels affect the success of democracy in fighting corruption across different income brackets in Africa?","answer":"The impact of democracy on corruption control varies by income level. In Middle income countries, democracy increases corruption-control effectiveness, while in Low income countries, democracy actually decreases corruption-control. This suggests that corruption-control strategies need to be tailored based on a country's income bracket rather than applying blanket approaches across all nations.","context":["Simplice A, Asongu (2012): Fighting corruption when existing corruption-control levels count : what do wealth-effects tell us in Africa? Forthcoming in:\nDownload (216kB) | Preview\nWhy are some nations more effective at battling corruption than others? Are there different determinants in the fight against corruption across developing nations? How do wealth effects play-out when existing corruption-control levels matter in the corruption battle? To investigate these concerns we examine the determinants of corruption-control throughout the conditional distribution of the fight against corruption. The following broad findings are established. (1) Population growth is a (an) tool (impediment) in (to) the fight against corruption in Low (Middle) income countries. (2) Democracy increases (decreases) corruption-control in Middle (Low) income countries. As a policy implication, blanket corruption-control strategies are unlikely to succeed equally across countries with different income-levels and political wills in the fight against corruption. Thus to be effective, corruption policies should be contingent on the prevailing levels of corruption-control and income-bracket.\n|Item Type:||MPRA Paper|\n|Original Title:||Fighting corruption when existing corruption-control levels count : what do wealth-effects tell us in Africa?|\n|Keywords:||Corruption, Democracy, Government quality, Quantile regression, Africa|\n|Subjects:||H - Public Economics > H1 - Structure and Scope of Government > H10 - General\nC - Mathematical and Quantitative Methods > C1 - Econometric and Statistical Methods and Methodology: General > C10 - General\nO - Economic Development, Technological Change, and Growth > O5 - Economywide Country Studies > O55 - Africa\nO - Economic Development, Technological Change, and Growth > O1 - Economic Development > O10 - General\nK - Law and Economics > K1 - Basic Areas of Law > K10 - General\n|Depositing User:||Simplice Anutechia Asongu|\n|Date Deposited:||25. Oct 2012 08:59|\n|Last Modified:||14. Feb 2013 12:01|\nAbed, G. T., & Gupta, S. (2002) Governance, corruption and economic performance. Washington: International Monetary Fund.\nAfrican Development Bank (2006) “Combating Corruption in Africa: Issues and Challenges”. Concept note paper for the 2006 Annual Meetings, Ouagadougou.\nAidt, T. S. (2003) “Economic analysis of corruption: a survey”, Economic Journal, 113, F632–F652.\nAsongu, S. A. (2011) “Law, democracy and the quality of government in Africa”, MPRA Paper No 35502. http://econpapers.repec.org/paper/pramprapa/35502.htm (accessed: 11/10/2012).\nAsongu, S. A. (2012a) “On the effect of foreign aid on corruption”, Economics Bulletin, 32(3): 2174-2180.\nAsongu, S. A. (2012b) “The political economy of development assistance: peril to government quality dynamics in Africa” MPRA Paper No. 36543. http://econpapers.repec.org/paper/pramprapa/36543.htm (accessed: 11/10/2012).\nAsongu, S. A., (2012c) “Fighting corruption in Africa: do existing corruption-control levels matter?”, International Journal of Development Issues: Forthcoming.\nAsongu, S. A. (2012d) “Politics and Consumer Prices in Africa”, Global Journal of Human Social Sciences: in Sociology, Economics and Political Science, 12(11): 48-53.\nAsongu, S. A., & Jingwa, B. A. (2012) “Population growth and forest sustainability in Africa”, International Journal of Green Economics: Forthcoming.\nAuyo, M. A. (1998) “Corruption and its Control in Public and Private Corporate”, Paper Presented at a Seminar organized on Fraud Prevention and Control by Kag-Gift Consult, Kano, Nigeria.\nBanerjee, A. V. (1997) “A theory of misgovernance”, Quarterly Journal of Economics, 112: 1289-1332.\nBardhan, P. (1997) “Corruption and development: a review of issues”, Journal of Economic Literature, 35: 1020-1046.\nBecker, G. S. (1968) “Crime and punishment: an economic approach”, Journal of Political Economy, 76: 169-217.\nBillger, S. M., & Goel, R. K. (2009) “Do existing corruption levels matter in controlling corruption? Cross-country quantile regression estimates”, Journal of Development Economics, 90: 299-305.\nBradhan, P. (1997) “Corruption and development: A review of issues”, Journal of Economic Literature, 35: 1320-1346.\nCallaghy, T. (1986) “Politics and Vision in Africa: The Interplay of Dominion, Equality and Liberty”, in Chabal, P. (ed.), Political Domination in Africa: Reflections on the Limits of Power, Cambridge: Cambridge University Press.\nChowdhury, S. K. (2004) “The effect of democracy and press freedom on corruption: an empirical test”, Economic Letters, 85: 93-101.\nCoolidge, J., & Rose-Ackerman, S. (1997) “High-level rent-seeking and corruption in African regimes”, World Bank Policy Research Working Paper No. 1780.\nDong, B., Dulleck, U., & Torgler, B. (2012) “Conditional Corruption”, Journal of Economic Psychology, Article in Press.\nGoel, R. K., & Nelson, M. A. (2005) “Economic freedom versus political freedom: cross country influences on corruption”, Australian Economic Papers, 44: 121-133.\nGroenendijk, N. S. (1997) “A Principal-Agent Model of Corruption”, Crime, Law and Social Change, 27: 217-218.\nGrossman, G. M., & Helpman, E. (1994) “Protection for sale”, American Economic Review, 84(4): 833-850.\nGuriev, S. (2004) “Red tape and corruption”, Journal of Development Economics, 73: 489–504.\nHuntington, S. (1968) Political Order in Changing Societies. New Haven: Yale University Press.\nIsa, K. D. (2009) Combating Corruption in Africa: The Role of Whistle Blowers, DSM Business Review, 1(1): 25-36.\nJain, A. K. (2001) “Corruption: A review”, Journal of Economic Surveys, 15: 71-121.\nJohnston, M. (1982) Political Corruption and Public Policy in America. Monterey, CA: Brooks-Cole, 1982.\nKaliannan, M., Awang, H., Raman, M. (2010) “Public-Private Partnerships for E-Government Services: Lessons from Malaysia” International Journal of Institutions and Economies, 2(2): 207-220.\nKatz, J., & Iizuka, M. (2011) “Natural Resources Industries, ‘Tragedy of the Commons’ and the Case of Chilean Salmon Farming”, International Journal of Institutions and Economies, 3(2): 259-286.\nKoenker, R., & Bassett, Jr. G. (1978) “Regression quantiles“, Econometrica, 46: 33-50.\nKoenker, R., & Hallock, F. K. (2001) “Quantile regression”, Journal of Economic Perspectives, 15: 143-156.\nKpundeh, S. J. (1998) Political Will in Fighting Corruption. In Corruption and Integrity, Improvement Initiatives in Developing Countries. UNDP, OECD.\nKrueger, A. O. (1993a) Political Economy of Policy Reform in Developing Countries, Mass: MIT Press.\nKrueger, A. O. (1993b) “Virtuous and vicious cycles in economic development”, American Economic Review, 83(2): 351-355.\nKunicova, J., & Rose-Ackerman, S. (2005) “Electoral rules and constitutional structures as constraints on corruption”, British Journal of Political Science, 35: 573-606.\nLaffont, J., & Tirole, J. (1993) A Theory of Incentives in Procurement and Regulation, MIT Press.\nLambsdorff, J. G. (2006) “Causes and consequences of corruption: what do we know from a cross-section of countries? In: Rose-Ackerman, S. (Ed.), International Handbook of the Economics of Corruption. Edward Elgar, Cheltenham, UK: 3-51.\nLeff, N. H. (1964) “Economic Development Through Bureaucratic Corruption”, The American Behavior Scientist, 8(2): 8-14.\nMcAdam, P., & Rummel, O. (2004) “Corruption: a non-parametric analysis”, Journal of Economic Studies, 31: 509–523.\nNukunya, G. K. (1992) “Tribalism, Bribery and Corruption” in Tradition and Change in Ghana, Accra: Ghana University Press (p. 239).\nOkada, K., & Samreth, S. (2012) “The effect of foreign aid on corruption: A quantile regression approach”, Economic Letters, 11: 240-243.\nOsei, J. (1999), “Fraud and Traditional African Ethics”, in Rossouw, G. J. and Carabine, D. (eds), Fraud and the African Renaissance, Kampala, UMU Press: 25-41.\nRasiah, R. (2011) “The Role of Institutions and Linkages in Learning and Innovation”, International Journal of Institutions and Economies, 3(2): 165-172.\nRose-Ankerman, S. (1978) Corruption: A study in political economy, New York: Academic Press.\nRose-Ankerman, S. (1997) The political economy of corruption. In K.A. Elliott (Ed.), Corruption and the global economy (pp; 31-60). Washington, D.C: Institute for International Economics.\nRose-Ankerman, S. (1999) Corruption and government: causes, consequence and reform. Cambridge: Cambridge University Press.\nRossouw, G. J. (1999) “Defining and Understanding Fraud”, in Rossouw, G. J. and Carabine, D. (eds), Fraud and the African Renaissance, Kampala, UMU Press: 13-24.\nSerra, D. (2006) “Empirical determinants of corruption: a sensitivity analysis”, Public Choice, 126: 225-256.\nShleifer, A., & Vishny, R. W. (1993) “Corruption”, The Quarterly Journal of Economics, 108(3): 599-617.\nTreisman, D. (2000) “The causes of corruption: a cross-national study”, Journal of Public Economics, 76: 399-457.\nUnited Nations Economic Commission for Africa (2005) “Measuring and Monitoring Progress towards good governance”, African Governance Report II.\nUnited Nations Economic Commission for Africa (2009) “Governance and the fight against corruption in Africa”, Parliamentary documentation for the first meeting of the Committee on Governance and Popular Participation (9-10 December).\nWaliggo, J. M. (1999) “The Historical Roots of Unethical Economic Practices in Africa”, in Rossouw, G. J. and Carabine, D. (eds), Fraud and the African Renaissance, Kampala: UMU Press: 43-53."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:1bd313c1-ed5b-455b-be57-1f1ddfbf6a9b>"],"error":null}
{"question":"As a software developer interested in both technical and psychological aspects, I'm curious about how object-oriented programming principles relate to social media design. What are the key benefits of encapsulation in software development, and how does this concept connect to the psychological effects of social media dissociation?","answer":"Encapsulation in software development offers several key benefits, including protecting the internal state of objects, improving code modularity, increasing usability, and promoting easier maintenance since code changes can be made independently. It helps prevent objects from interacting in unexpected ways by hiding attributes that are likely to change. When it comes to social media design and psychological effects, this principle of hiding implementation details relates to how social media platforms manage user attention and behavior. Research shows that 42% of users experience dissociation while using social media, becoming disconnected from their actions and losing track of time. This dissociation occurs because platforms are designed with infinite scrolling and reward systems that keep users engaged, similar to how encapsulation controls access to internal states. The psychological impact can be mitigated through design interventions that provide better control and visibility, such as customized lists and reading history labels, which help users maintain awareness of their usage patterns.","context":["Object Oriented Concepts\nObject oriented approach conceptualize the problem solution in real-world object which are easier to reuse across the application. For example Chair, Fan, Dog, computer etc. Java is based on Object Oriented concepts, which permits higher level of abstraction to solve any problem in realistic way.\nIn Java, a class is a blueprints, template or prototype that define common behavior of object of same kind. An instance is realization of a particular class and all instances of a class have similar properties, as described in the class definition. For example, you can define a class called House with number of room as attribute and create instances such as house with 2 rooms, house with 3 rooms etc.\nBelow are few advantages of object oriented software development:\n- Less maintenance cost mostly because it is modular.\n- Better code reusability due to features such as inheritance and hence faster development.\n- Improved code reliability and flexibility\n- Easy to understand due to real-world modeling.\n- Better abstraction at object level.\n- Reduced complexity during the transitions from one development phase to another.\nThere are four main features of OOPS:\nEncapsulate provides contract to other object to what to hide and what to expose which can be accessed other objects. In java we use private access modifier to hide method and variable to restrict from outer world. Java also provide different access modifier such as public, default, protected and private, which use to hide the visibility on different level but end goal is to encapsulate the things, which need not to change. As per best practice A class should have only one reason to change and Encapsulate bring the reality to achieve “one-reason” design principle.\nAs per best practices in Encapsulation means hiding things that are expected to change often so to avoid breaking other classes.\nBenefits: Below are few advantages of Encapsulation:\n- We can protect the internal state on objects by hiding its attribute.\n- It Improves code modularity by preventing objects interacting with each other in an unexpected way.\n- Increases usability\n- It Maintain the contracts of specific object\n- Encapsulation promotes maintenance\n- Code changes can be made independently\nPolymorphism is the ability (in programming) to present the same interface for differing underlying forms (data types). That means classes have different functionality while sharing a common interface and can be invoked dynamically by passing specific class reference.\nThe classic example is the Shape class and all the classes that can inherit from it (square, circle, dodecahedron, irregular polygon, splat and so on).\nIn this example, every class would have its own Draw () function and the client code could simply do:\nShape shape=new Square ();\nShape.area() to get the correct behavior for any shape.\nThe beauty of polymorphism is that the code working with the different classes does not need to know which class it is using since they’re all used the same way.\nThe process used by object-oriented programming language to implement run-time polymorphism is called dynamic binding.\nNote: Polymorphism is the ability to select more specialized methods in runtime depending on the object being used to call it. Polymorphism could occur with no abstract classes involved.\n- Create Reusable code: It means once classes create, implemented and tested then it can be easily used without caring what written in the class.\n- It provides more generic and loosely coupled code.\n- Compile time is much lower and allow faster development.\n- Dynamic binding:\n- Same interface could be used for creating methods with different implementations\n- Complete implementation can be replaced by using same method signatures\nMethod Overriding to achieve Polymorphism: Overriding deals with two methods; one in the parent class and the other one in the child class and have the same name and signatures.\nOverriding lets you define the same operation in different ways for different object types\nShape s = (Shape) it.next();\ntotalArea += s.area(dim); //polymorphic method call. Will call right object method\nMethod Overloading or Ad-hoc polymorphism or static polymorphism:\nOverloading deals with multiple methods in the same class with the same name but different method signatures. Overloading lets you define the same operation in different ways for different data. Some time it says as static polymorphism but actually it is not polymorphism.\nMethod overloading is nothing more than having two methods with the same name but different argument lists. It has nothing to do with inheritance and polymorphism. An overloaded method is not the same as an overridden method. [Head First Java]\nParametric polymorphism through generics in Java:\nWithin a class declaration, a field name can associate with different types and a method name can associate with different parameter and return types. Java supports parametric polymorphism via generics.\nAn example is a list, which can accept the type of data it contains through generics.\nList<String> list = new ArrayList<String>();\nWhy we can’t override a static method in Java?\nOverriding depends on having an instance of a class. The point of polymorphism is that you can subclass a class and the objects implementing those subclasses will have different behaviors for the same methods defined in the superclass (and overridden in the subclasses). A static method is not associated with any instance of a class so the concept is not applicable.\nThere were two considerations driving Java’s design that impacted this. One was a concern with performance: there had been a lot of criticism of Smalltalk about it being too slow (garbage collection and polymorphic calls being part of that) and Java’s creators were determined to avoid that. Another was the decision that the target audience for Java was C++ developers. Making static methods work the way they do had the benefit of familiarity for C++ programmers and was also very fast, because there’s no going up the class hierarchy to figure out which method to call, you go straight to the class and call the specified method. [Stack overflow]\nIt is the inclusion of behavior (i.e. methods) and state (i.e. variables) of a base class in a derived class so that they are accessible in that derived class. The key benefit of Inheritance is that it provides the formal mechanism for code reuse and avoids duplication\nInherited class extends application’s functionality by reusing parent behavior and adding new functionalities. This will make the design tight coupled because if you want to change the superclass, you must know all the details of the subclasses to avoid breaking\nIt is form of software reusability where new class (sub class) are created from already existing class (super class) which enhance the functionalities while using some of the properties from super class.\nSo if you have a Parents class, then you have a Child class that extends Parent, Child inherits all the things that Person has.\n- Improve reusability\n- Establishes logically “is a” relationship: e.g. Dog is a animal\n- Modularize code\n- Avoid duplicity\n- Tightly coupled: Subclass depends on parent class implementation that’s why tight couple.\nAbstraction means develop class in terms of their interfaces and functionality, instead of their implementation details. Abstract class expose interfaces without including actual implementation. It separates the object implementation from its behavior or implementation. Abstraction reduces the complexity by hiding irrelevant detail.\n- By using abstraction, we can separate the things that can be grouped to another type.\n- Frequently changing properties and methods can be grouped to a separate type so that the main type need not under go changes. This adds strength to the OOAD principle -“Code should be open for Extension but closed for Modification”.\n- Simplifies the representation of the domain models.\nDifference between Abstraction and Encapsulation\nEncapsulation is a strategy used as part of abstraction. Encapsulation refers to the state of objects – objects encapsulate their state and hide it from the outside; outside users of the class interact with it through its methods, but cannot access the classes state directly. So the class abstracts away the implementation details related to its state.\nAbstraction is a more generic term; it can also be achieved by (amongst others) sub classing. For example, the class List in the standard library is an abstraction for a sequence of items, indexed by their position, concrete examples of a List are an ArrayList or a LinkedList. Code that interacts with a List abstracts over the detail of which kind of a list it is using [Stack overflow]\nAbstraction is often not possible without hiding underlying state by encapsulation – if a class exposes its internal state, it can’t change its inner workings, and thus cannot be abstracted\nWhat is abstract class and abstract method?\nIn design, you want the base class to present only an interface for its derived classes. This means, you don’t want anyone to actually instantiate an object of the base class. You only want to upcast to it (implicit upcasting, which gives you polymorphic behavior), so that its interface can be used. This is accomplished by making that class abstract using the abstract keyword.\nProvide some restriction on to not to instantiate the abstract class and whoever use should implement the abstract method. And provide polymorphism\nAbstract class can contain both abstract methods and concrete methods. In a class, if one method is declared abstract, the class must be declared abstract. However, reverse of this is not necessarily true. If class is declared abstract class, it may not have abstract method in it.\nIf a method does not provide actual implementation but just provides method signature, it is called abstract method. Actual implementation is left for the sub classes who extend abstract class.\nAbstract method cannot be instantiated; another class can only extend it.\nWhen to use an abstract class?\nAbstract classes let you define some default behavior and force subclasses to provide any specific behavior.\nFor example: List is interface whereas AbstractList provide default behavior of List which can be used as is or refined in subclass e.g. ArrayList.\nWhat is Interface?\nThe interface keyword takes this concept of an abstract class a step further by preventing any method or function implementation at all. You can only declare a method or function but not provide the implementation. The class, which is implementing the interface, should provide the actual implementation. The interface is a very useful and commonly used aspect in OO design, as it provides the separation of interface and implementation and enables you to:\nBenefits on interface:\n- Multiple inheritance\n- Loose coupling-defined abstraction of operation as separate layer-underline implementation could be anything, JDBC, JPA, JTA etc.\n- Program to interface not implement\n- Polymorphism with dynamic binding – Reveal an object’s programming interface without revealing its actual implementation.\n- Abstract Layer: Separation concerns\nDifference between interface and abstract class:\n- An interface is a contract to ask classes (whoever going to implement interface) to implement the interface the way it defines in interface. It is an empty shell with method declaration.\n- Abstract class define some common behavior and ask subclass to define uncommon or specific behavior to that class\n- Methods and members of an abstract class can be defined with any visibility, whereas all methods of an interface must be defined as public\n- When inheriting an abstract class, the child class must define the abstract methods, whereas an interface can extend another interface and methods don’t have to be defined\n- A child class can only extend a single abstract (or any other) class, whereas an interface can extend or a class can implement multiple other interfaces.\n- A child class can define abstract methods with the same or less restrictive visibility, whereas a class implementing an interface must define the methods with the exact same visibility\n- Interface doesn’t contain constructor whereas Abstract class does.\n- Variables declared in a Java interface is by default final. An abstract class may contain non-final variables\n- Members of a Java interface are public by default. A Java abstract class can have the usual flavors of class members like private, protected, etc\nMarker interfaces: The interfaces with no defined methods act like markers. They just tell the compiler that the objects of the classes implementing the interfaces with no defined methods need to be treated differently.\nExample: java.io.Serializable, java.lang.Cloneable, java.util.EventListener etc.\nCode reusability could be achieved by implementing inheritance or composition but the composition approach to code reuse provides stronger encapsulation than inheritance, because a change to a back-end class needn’t break any code that relies only on the front-end class.\nComposition is the design technique to implement has-a relationship in classes. We can use java inheritance or Object composition for code reuse\nComposition is about expressing relationships between objects. Think about the chair example. A chair has a Seat. A chair has a back. And a chair has a set of legs. The phrase “has a” implies a relationship where the chair owns, or at minimum, uses, another object. It is this “has a” relationship which is the basis for composition\n- Control the visibility\n- Implementation can replace run-tim\n- Loose coupled as interface class doesn’t depends on implementation.\nDifference between Composition and Inheritance?\n|No.||Composition (has a)||Inheritance (is a)|\n|1||Advocates polymorphism and code reuse||Advocates polymorphism and code reuse|\n|2||Object is acquired at Done at run- time||Object is acquired dynamically at compile-time|\n|3||Implementation can be replaced at run-time||Implementation can be replaced at compile-time|\n|4||Subclass doesn’t depends parent class and favors loose coupling (specifically in interface driven)||Subclass depends on parent class implementation that’s why tight couple|\n|5||Used when House has a Bathroom. It is incorrect to say House is a bathroom||Inheritance is Uni-directional. e.g. House is a Building. But Building is not a House|\nNote: Don’t use inheritance just to get code reuse. If there is no ‘is a’ relationship then use composition for code reuse.\nDifference between Composition and aggregation in Object Relationship\nAggregation: Aggregation is an association in which one class belongs to a collection. This is a part of a whole relationship where a part can exist without a whole. It is weaker relationship. No cyclic dependency. Example: Order and product\nComposition: Composition is an association in which one class belongs to a collection. This is a part of a whole relationship where a part cannot exist without a whole. If a whole is deleted then all parts are deleted. It is stronger relationship. e.g. Polygon and points, order and order detail\nWhat are the non-final methods in Java Object class, which are meant primarily for extension?\nThe non-final methods are:\n• finalize ().\nThe other methods like wait (), notify (), notifyAll (), getClass () etc. are final methods and therefore cannot be overridden.\nNote: The equals () and hashCode () methods prove to be very important, when objects implementing these two methods are added to collections. If implemented incorrectly or not implemented at all then your objects stored in a collection like a Set, List or Map may behave strangely and also is hard to debug","Disrupted sleep, decrease life satisfaction and poor vanity are just some of the adverse psychological well being penalties that researchers have linked to social media. In some way the identical platforms that may assist folks really feel extra linked and educated additionally contribute to loneliness and disinformation. What succeeds and fails, scientists say, is a perform of how these platforms are designed. Amanda Baughan, a graduate pupil specializing in human-computer interplay on the College of Washington, research how social media triggers what psychologists name dissociation, or a state of diminished self-reflection and narrowed consideration. She offered outcomes on the 2022 Affiliation for Computing Equipment Laptop-Human Interplay Convention on Human Elements in Computing Techniques. Baughan spoke with Thoughts Issues editor Daisy Yuhas to elucidate how and why apps want to alter to present the individuals who use them better energy.\n[An edited transcript of the interview follows.]\nYou’ve proven how altering social media cues and shows may enhance well-being, even when folks strongly disagree on points. Are you able to give an instance?\nThe design of social media can have quite a lot of energy in how folks work together with each other and the way they really feel about their on-line experiences. For instance, we’ve discovered that social media design can truly assist folks really feel extra supportive and type in moments of on-line battle, offered there’s a bit little bit of a nudge to behave that method. In a single examine, we designed an intervention that inspired individuals who begin speaking about one thing contentious in a remark thread to change to direct messaging. Folks actually preferred it. It helped to resolve their battle and replicated an answer we use in-person: folks having a public argument transfer to a personal area to work issues out.\nYou’ve additionally tackled a unique downside popping out of social media utilization known as the 30-Minute Ick Issue. What’s that?\nWe in a short time lose ourselves on social media. When folks encounter a platform the place they will infinitely scroll for extra data, it may set off an identical neurocognitive reward system as in anticipating a profitable lottery ticket or getting meals. It’s a robust method that these apps are designed to maintain us checking and scrolling.\nThe 30-Minute Ick Issue is when folks imply to examine their social media briefly however then discover that half-hour have handed, and once they notice how a lot time they’ve spent, they’ve this sense of disgust and disappointment in themselves. Analysis has proven that individuals are dissatisfied with this ordinary social media use. Lots of people body it as meaningless, unproductive or addictive.\nYou’ve argued this expertise is much less a matter of dependancy and extra a problem of dissociation. Why?\nDissociation is a psychological course of that is available in many varieties. In the most typical, on a regular basis dissociation, your thoughts is so absorbed that you’re disconnected out of your actions. You could possibly be doing the dishes, begin daydreaming and never take note of how you might be doing the dishes. Otherwise you would possibly search immersive experiences—watching a film, studying a e-book or taking part in a recreation—that move the time and trigger you to overlook the place you might be.\nThroughout these actions, your sense of reflective self-consciousness and the passage of time is diminished. Folks solely notice that they dissociated in hindsight. Consideration is restored with the sense of “What simply occurred?” or “My leg fell asleep whereas we had been watching that film!”\nDissociation generally is a constructive factor, particularly if it’s an absorbing expertise, significant exercise or a wanted break. But it surely can be dangerous in sure instances, as in playing, or are available in battle with folks’s time-management targets, as with social media scrolling.\nHow do you measure folks’s dissociation on social media?\nWe labored with 43 contributors who used a customized cell app that we created known as Chirp to entry their Twitter accounts. The app let folks work together with Twitter content material whereas permitting us to ask them questions and take a look at interventions. So when folks had been utilizing Chirp, after a given variety of minutes, we’d ship them a questionnaire primarily based on a psychological scale for measuring dissociation. We requested how a lot they agreed with the assertion “I’m presently utilizing Chirp with out actually listening to what I’m doing” on a scale of 1 to five. We additionally did interviews with 11 folks to be taught extra. The outcomes confirmed dissociation occurred in 42 p.c of our contributors, they usually usually reported shedding observe of time or feeling “all-consumed.”\nYou designed 4 interventions that changed folks’s Twitter expertise on Chirp to scale back dissociation. What labored?\nProbably the most profitable had been customized lists and studying historical past labels. In customized lists, we pressured customers to categorize the content material they adopted, comparable to “sports activities” or “information” or “buddies.” Then, as an alternative of interacting with Twitter’s major feed, they engaged solely with content material on these lists. This method was coupled with a studying historical past intervention through which folks acquired a message once they had been caught up on the most recent tweets. Moderately than persevering with to scroll, they had been alerted to what that they had already seen, and they also targeted on simply the most recent content material. These interventions diminished dissociation, and once we did interviews, folks stated they felt safer checking their social media accounts when these modifications had been current.\nIn one other design, folks acquired timed messages letting them know the way lengthy that they had been on Chirp and suggesting they go away. In addition they had the choice of viewing a utilization web page that confirmed them statistics comparable to how a lot time they’d spent on Chirp prior to now seven days. These two options had been efficient if folks opted to make use of them. Many individuals ignored them, nevertheless. Additionally, they thought the timed messages had been annoying. These findings are fascinating as a result of quite a lot of the favored time-management instruments obtainable to folks appear like these time-out and utilization notifications.\nSo what may social media firms be doing in a different way? And is there any incentive for them to alter?\nProper now there’s a lot working towards individuals who use social media. It’s unimaginable to ever totally compensate for a social media feed, particularly when you think about the algorithmically inserted content material comparable to Twitter’s trending tweets or TikTok’s “For You” web page. However I feel that there’s hope that comparatively easy tweaks to social media design, comparable to customized lists, could make a distinction. It’s essential to notice that the customized lists considerably diminished dissociation for folks—however they did not considerably have an effect on time spent utilizing the app. To me, that factors out that lowering folks’s dissociation will not be as antithetical to social media firms’ income targets as we’d intuitively suppose.\nWhat’s most essential for folks utilizing social media now to know?\nFirst, don’t pile a bunch of disgrace onto your social media habits. Hundreds of individuals are employed to make you swipe your thumb up on that display screen and maintain you doing what you’re doing. Let’s shift the duty of designing protected and fulfilling experiences from customers to the businesses.\nSecond, get conversant in the well-being instruments which are already supplied. TikTok has a function that, each hour, will inform you that you simply’ve been scrolling for some time and may contemplate a break. On Twitter, customized lists are a function that already exists; it’s simply not the default choice. If extra folks begin utilizing these instruments, it may persuade these firms to refine them.\nMost essential, vote for people who find themselves occupied with regulating expertise as a result of I feel that’s the place we’re going to see the largest adjustments made."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:205facf7-ce37-44b7-9094-17fdb3f7dfa2>","<urn:uuid:28ea44cd-4054-4290-8fcb-a13be7579900>"],"error":null}
{"question":"What is the significance of braking action measurements on runways, and how did poor braking conditions affect the Boeing 737 incident at Prague airport?","answer":"Braking action measurements are crucial for aviation safety and can be reported in various formats including μ numbers, RCR (Runway Condition Readings), or qualitative terms like 'good, fair, poor.' The weight of aircraft can affect braking effectiveness - larger, heavier aircraft may actually find it easier to stop than smaller ones due to more weight on the wheels. In the Prague airport incident, deteriorating runway conditions severely impacted operations. While initial measurements showed good braking action (71/65/80), conditions worsened due to continuous snowfall, leading to a 5mm layer of slush and snow. This resulted in the Boeing 737 crew being unable to maintain lateral control during takeoff at 80 knots, forcing them to reject the takeoff and report 'poor' braking conditions. Subsequent measurements showed drastically reduced braking values of 16/17/18.","context":["There doesn't seem to be any shortage of braking action reports out there, but how much of it is usable? If presented with a μ number, an RCR, or just plain text \"good, fair, poor\" or something similar, how do you translate that to getting the airplane stopped?\nMost of the answer relies in your aircraft flight manual, but it helps to understand what the rest of the world is talking about.\nWhat follows are quotes from the relevant regulatory documents, listed below, as well as my comments in blue.\n[Aeronautical Information Manual §4−3−8]\nWhen considering pilot reports, consider the aircraft type. It may seem counter intuitive, but it may actually be easier to stop a larger, heavier aircraft than a smaller one. More weight on the wheels can make it easier for a Boeing 747 to stop than a Cessna 150.\n[U.S. FAA Order JO 7110.10W §4-4-3 ¶11] USAF has established RCR procedures for determining the average deceleration readings of runways under conditions of water, slush, ice, or snow. The use of RCR code is dependent upon the pilot's having a stopping capability chart specifically applicable to his/her aircraft. USAF offices furnish RCR information at airports serving USAF and ANG aircraft.\nOur Air Force flight manual charts had performance numbers with Runway Condition Readings (RCR). An RCR of 23 was considered dry, 9 was wet, and 4 was icy. The exact number tends to change a few points here and there, but those are close. If you are at an airport with military airplanes, they might just have an RCR for you. Can you enter your chart with an RCR? Probably not. But it is more information than you had before you asked.\n[Aeronautical Information Manual §4−3−9]\nThe Aeronautical Information Manual seems to discount any connection between MU and good/fair/poor/nil qualifiers and you hardly hear the term \"mu\" in the United States. But the ICAO calculated coefficient seems suspiciously similar.\nFigure: SNOWTAM Format, from ICAO Annex 15 Appendix 2.\nA SNOWTAM is a \"Special Series NOTAM\"\n[ICAO Annex 15] ¶5.2.3] Information concerning snow, slush, ice and standing water on aerodrome/heliport pavements shall, when reported by means of a SNOWTAM, contain the information in the SNOWTAM Format in Appendix 2.\n[14 CFR 25 §25.105(c)(1)(ii)] The takeoff data must be based on . . . At the option of the applicant, grooved or porous friction course wet, hard-surfaced runways.\n[14 CFR 25 §25.109(d)] Accelerate-stop distance. . . . At the option of the applicant, a higher wet runway braking coefficient of friction may be used for runway surfaces that have been grooved or treated with a porous friction course material.\n[14 CFR 25 §25.1533(3)] Additionally, at the option of the applicant, wet runway takeoff distances may be established for runway surfaces that have been grooved or treated with a porous friction course, and may be approved for use on runways where such surfaces have been designed constructed, and maintained in a manner acceptable to the Administrator.\nI've flown aircraft that allowed pilots to consider wet grooved runways to be essentially dry. The Gulfstream 450 does not. The performance section of that AFM does not mention runway grooves at all. The only thing in our books on the subject appears in G-450-OIS-02. On page 19 it says: \"For landing operations on a wet, grooved runway, data in this OIS will be conservative.\" This leads me to believe Gulfstream has not factored in grooved runways and wants you to use it as a safety pad. There are test results available which lead one to believe that grooved runways do bring balanced field lengths on wet runways almost to the level of a dry runway and that substantially reduce landing distances. But all that goes out the window with any amount of slush. More about this: Technical / Grooved Runways.\n14 CFR 25, Title 14: Aeronautics and Space, Airworthiness Standards: Transport Category Airplanes, Federal Aviation Administration, Department of Transportation\nFAA Air Traffic Organization Policy, Flight Services, Order JO 7110.10W, March 7, 2013\nGulfstream G450 Operational Information Supplement, G450-OIS-02, Contaminated Runway Performance, Revision 1, August 3, 2011\nICAO Annex 15 - Aeronautical Information Services, International Standards and Recommended Practices, Annex 15 to the Convention on International Civil Aviation, July 2010","AIR ACCIDENTS INVESTIGATION INSTITUTE Beranových 130 199 01 PRAHA 99\nRef. No 639/05/ZZ Copy No: 1\nInvestigation into the incident of aircraft B 737-3Q8, registration G-THOF, at LKPR on 28 December 2005\nPrague Jun 2006\nA) Introduction Operator: Thomsonfly Ltd. (UK) Aircraft type: Boeing, B 737-3Q8 Registration: G-THOF Place of Incident: Prague / Ruzyně (LKPR) Date and Time: 28. 12. 2005, 18:03 (All times in this report are UTC)\nB) Synopsis On 28 January 2006 Thomsonfly Ltd (UK) notified Air Accident Investigation Institute (AAII) of an B737 incident. The crew, which was to execute flight BY 444 from LKPR to Doncaster (EGCN), rejected the take-off from RWY 31 during the take-off run, because after increasing engine power to full T/O thrust and achieving a speed of 80 kts the captain could not maintain lateral control on the runway covered in sleet and slush. The crew braked the airplane to the taxi speed and vacated RWY 31 taking exit to TWY G. With regard to this event and a continuous slight snowfall, TWR EC suspended operation on RWY 31 and asked for a check of braking action (B/A). After the B/A had been measured and the situation of airplanes holding to land evaluated, clearing of RWY 31 got started.\nThe cause of the incident was investigated by an AAII commission comprising: Investigator in charge: Ing Stanislav Suchý Member: Ing. Jan Kadlec – Prague Airport\nThe Final report was released by: AIR ACCIDENTS INVESTIGATION INSTITUTE Beranových 130 199 01 PRAHA 99\nOn the 13 Jun 2006.\nC) The Final report includes the following main parts: 1) Factual information 2) Analysis 3) Conclusions 4) Safety recommendation 5) Annexes (to copy No.1 stored in AAII archive)\nThe present document is the translantion of the Czech Investigation Report. Although efforts are made to translate it as accurate as possible, discrepancies may occur. In this case the Czech version is authentic.\n1 Factual information\n1.1 History of the incident On 28 December 2005 a Boeing 737-3Q8 with 5 crewmembers and 65 passengers on board was on the flight GB294 from LKPR Airport to EGCN Airport. At the time the crew was getting ready for the flight, lots of aircraft were arriving at or leaving LKPR because the previous weather conditions were poor and RWYs 24 and 31 were being cleared.\nAt 17:10 ATIS “L” information was issued giving B/A values from the last 16:58 measurement by SFH. The following sequence of ATIS information “M, N, O, Q, R and K” gave the same B/A data 71/65/80 till 18:14.\nAt 17:15 the crew of the airplane, call sign TOM 444, established contact on the clearance delivery dispatcher Ruzyně DELIVERY frequency, acknowledged the ATIS “L” information and received a departure clearance.\nAt 17:30 the TOM 444 crew requested on the Ruzyně Ground frequency to taxi to the stand for de-icing.\nAt 17:44 the TOM 444 crew reported the end of de-icing and received the instruction to taxi to the holding possition of RWY 31. The TOM 444 crew commented that, prior departure and during de-icing, they regularly checked the current ATIS. At no time was the TOM 444 crew aware of an official braking action, received by ATIS, of less than was comparative to value “Good”. There was a snowfall all that time, RWY 31 being covered wholly by slush. On landing, TWR EC asked the CSA 917 crew to assess the RWY 31 braking action and got a “Medium” value. The TWR EC transmitted this assessment to the following arriving plane. At that time, the airport operations officer asked clearance for entering TWY L, C and RWY 06.\nAt 17:43 TWR EC gave permission to use the demanded route, advised the operations officer of the B/A assessment reported by the crew, and asked for check and measurement of B/A on RWY 31. At\n17:49 after landing, the DLH 3286 airplane´s crew reported on the TWR EC frequency that it assessed the B/A as “Medium to Poor”. The TWR EC passed this information to the landing airplane that followed next. Because of a great number of landing aircraft, the TWR EC discussed the situation with the airport operations officer at 17:50,with the result that the B/A measuring vehicle should be waiting on RWY 06 by THR 13 and he would find through APP a slot between the landing aircraft to get access to RWY 31 to measure the B/A effect.\nAt 17:51:28 the TOM 444 crew established contact on Ruzyně Tower frequency and got the instruction to taxi on TWY L to the RWY 31 holding bay.\nAt 17:53:13 TWR EC required the BAW 856 crew on landing to assess the B/A. The BAW 856 crew reported its B/A assessment as “Medium to poor”. TWR EC passed this information to the landing traffic CSA 761 and CSA 7KG. At that time the TOM 444 crew reported it was in front of RWY 31 holding possition.\nAt 17:56 the CSA 761 crew reported that B/A was in line with “Medium to poor” estimate.\nAt 17:58:40 the TOM 444 crew requested line up for RWY 31. But a CSA 7KG plane was on the final followed by a CSA 701 on approach, so TWR EC cancel lining up and transmitted that TOM must because of landing aircrafts hold another 2 to 3 minutes.\nAt 18:00:40 TWR EC advised the B/A measuring vehicle operator that in 3 minutes after the take-off of one aircraft in the slot before the landing of the next aircraft he would allow access to RWY 31 to measure B/A.\nAt 18:01, CSA 701 landed, TWR EC cleared TOM 444 to line up on the runway and transmitted to the landing CSA 665 information that B/A was “Medium to poor”.\nAt 18:02:20, as CSA 701 left RWY 31, TWR EC cleared the TOM 444 for take off. The TOM 444 crew started its take-off run using full T/O thrust at 18:03. The captain commented that, after passing a speed of 80 kts, he could not maintain lateral control of the aircraft on the runway covered in snow and slush.\nAt 18:03:13, having travelled around 300 m from the beginning of the take off run, the crew reported a rejected take off. TWR EC than gave the TOM 444 the instruction to vacate runway via TWY G. The TOM 444 crew commented that used full manual braking and idle reverse to slow the aircraft down to a taxi speed of 10 kts using about 5,000 ft of runway. The TOM 444 crew valued the B/A and advised TWR EC that B/A coefficient to be “Poor” and vacated RWY 31 taking exit to TWY G. TWR EC passed this information to the landing CSA 665 and at the same time informed the airport operations office that TOM 444 had not been able to take off from RWY 31.\nAt 18:05:50 TWR EC transmitted “Go around” instruction to CSA 665.\nAt 18:06:35 TWR EC issued the airport maintenance with instructions to go to RWY 13 and to conduct the B/A check. The accurate B/A coefficient obtained by check was 16/17/18; the runway was all covered in slush and dry snow up to 5 mm thick.\nAt 18:13 TWR EC coordinated further steps with APP, operation on RWY 31 was suspended and TWR EC ordered to clear the runway.\n1.2 Injuries to persons\nInjuries Crew Passengers Others Fatal 0 0 0 Serious 0 0 0 Minor/ None 0/5 0/65 0\n1.3 Damage to aircraft There was no damage to the aircraft.\n1.4 Other damage There was no other damage.\n1.5 Personnel information The PIC, aged 42, was a holder of ATPL(A), had a PIC qualification for the type B 737 and a valid medical certificate. He had a total of 14097 flying hours of which 8047 hours were as PIC. On the type B 737 he has flown 186 hours. The F/O, aged 23, was a holder of CPL(A), had a valid medical certificate. He had total of 463 flying hours, on the type B 737 of which 158 hours were on type.\n1.6 Aircraft information Type and Model: Boeing 737-3Q8 Registration: G-THOF Manufacturer: Boeing Serial number: 26314 Total flight time: 31 393 hours\nOperating cycles: 18 151 Certificate of Airworthiness: valid\n1.7 Meteorological information According METAR/SPECI was 28 Decenber 2005 about 17:00 – 18:00 during pre flight preparation at LKPR following meteorological conditions: The situation: snow bearing clouds with falls of snow The surface winds: 310 – 350°/ 8 - 12 kt The temperature: - 5° ~ -6°C Icing condition: thik frost at 2000 – 10 000 ft\n1.5 Aids to navigation Radio-navigation at LKPR had no effect on the incident.\n1.6 Communications The communication between the crew and air traffic services was on frequencies ATS Ruzyně Delivery 120,05 MHz, Ruzyně Ground 121,9 MHz and Ruzyně Tower 118,1 MHz. The communication was readable.\n1.10 Aerodrome information RWY 24 was in use at LKPR at 16:58 but the conditions worsened gradually to B/A 17/22/13 as measured with a high pressure tyre device (SHF). Regular winter maintenance work was being done on RWY 31, scheduled to be finished by 18:00. At 16:58 the runway was cleared, braking action measurements giving results of 71/65/80 SFH. RWY 31 was re-opened for operations and the SNOWTAM 0122 was issued. At 17:50 a co-ordination talk between TWR and the airport management was held with the result that the B/A measuring vehicle should be waiting on RWY 06 by THR 13 to take the measurement of B/A values in a window between landing aircraft. However the measurement was not taken until 18:04, giving B/A results of 16/17/18, the runway being all covered in wet and dry snow layer up to 5 mm thick.\n1.11 Flight recorders Flight recorders were not used in this investigation. The ATS records on TWR were used.\n1.12 Description of incident site NIL\n1.13 Medical and pathological information NIL\n1.14 Fire NIL\n1.15 Survival aspects NIL\n1.16 Tests and research NIL\n1.17 Organizational and management information Radio communications between the airport operation officer, the braking action measuring vehicle and TWR was maintained on the specific frequency of 121.7 MHz. Neither airport operation officer nor A/B measuring vehicle have a listener-in device to monitor communication on TWR traffic controller´s frequency and cannot hear information transmitted between TWR EC and aircraft crews.\n1.18 Additional information Immediately after the serious incident, the chief controller of the Prague Airport ATC and the manager of Prague Airport approach and aerodrome services adopted Operational Provisions concerning work of TWR controller and airport operation officer aimed at ensuring timely checks of movement areas and braking action by the use of A/B measuring vehicle.\n1.19 Useful or effective investigation techniques The serious incident has been investigated in accordance with Annex 13.\n2.1 The TOM 444 crew expected the conditions as reported in the ATIS “L”, giving B/A equal to 71/65/80 on RWY 31. After the end of de-icing as the plane taxied on TWY L, the crew was in contact from 17:51:28 with Ruzyně Tower on its frequency and could have heard the crews, which had just landed, report B/A coefficient “Medium to poor”. The crew could have heard the last information about the estimated B/A after the plane was cleared to enter RWY 31 and was waiting for the take-off clearance. At 18:01:37 TWR EC issued the CSA crew with the instruction to adjust the approach speed along with information about the airport conditions including the “Medium to poor” B/A estimate.\n2.2 The reason why TOM 444 rejected the take-off after it used around 300 m of runway and attained a speed of 80 kts was that the crew could not maintain lateral control in the RWY 31 axis. The TOM 444 crew mentioned no problem with different or unsymmetrical thrust. After the reject, it used full manual braking and idle reverse and slowed the plane to the taxi speed using about 5,000 ft of runway. The TOM 444 crew reported that it estimated B/A coefficient as “Poor”.\n2.3 After RWY 31 took over operation and particularly after the arrival of CSA 917, whose crew estimated B/A as “Medium”, the snow layer on RWY 31 was getting thicker due to a slight but continuous snowfall. Operators of the B/A measuring vehicle, who were not familiar with B/A figures reported by aircrews because there is no listen-in device for the TWR EC frequency in their car, waited for TWR EC´s instruction to let them enter RWY 31.\n2.4 The TWR EC, who had information from aircrews that RWY 31´s B/A got worse dramatically, thought that he would coordinate with APP creation of a slot between landing aircraft. However he failed to adjust suitable separation between the landing aircraft, so there was no slot long enough to check B/A on RWY 31 before the take-off of TOM 444. TWR EC failed to advise the TOM 444 crew of information about actual/worse airport conditions acquired from crews that had landed.\n3.1 The commission has come to the following conclusions: The crew had the valid licences and necessary qualifications; The airplane had a valid airworthy certificate, a maintenance certificate and operation permit; The TOM 444, based on regurerly checked the ATIS broadcast, at no time was aware of deterioration B/A on RWY 31 of less than Good. Befor take off the TOM 444 crew could have hear the assessed B/A by other aircrews that had landed before; TWR EC did not relay to the TOM 444 crew information about airport deteriorated conditions he had from the reports of aircrews that had landed before; There were small time intervals between aircraft landing at LKPR, in which TWR did not manage to arrange for the B/A measuring vehicle to go to RWY 31, in spite of the fact that B/A reports from aircrews indicated sharp deterioration of airport conditions; The staff of the A/B measuring vehicle, rather hesitant and lacking experience, ignorant of the crews´ reports, was ready on RWY 06 waiting for TWR instruction to access RWY 13; The aircrew commenced take-off from RWY 31 although it could see that the braking conditions were bad due to the RWY´s snowy surface. The crew itself estimated the conditions with the “Poor” coefficient; A five-millimetre thick layer of slush and snow on RWY 31, where the measured braking action gave results of 16/17/18 SFH, affected the plane´s capability to maintain lateral control with full t/o thrust during the take-off run to the extent that the crew rejected the take-off for safety reason.\nThe cause of the incident was deteriorated conditions on RWY 31, which was covered in snow, hampering airplane lateral control during the take-off run. The RWY 31 surface status was much worse than the crew had expected relying on ATIS ”L” report on the airport conditions.\n4 Safety recommendations\n4.1 The airport operation officer should have a possibility of receiving necessary information by listening of radio communications on corresponding frequency of TWR EC."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:54a575c7-e43a-4351-96b3-87819c95d983>","<urn:uuid:843c77f9-7170-489c-8be6-6025d40f4d7c>"],"error":null}
{"question":"What security features différentes sont between TACACS+ and RADIUS pour l'authorization et accounting?","answer":"RADIUS and TACACS+ differ in their authorization and accounting capabilities. In RADIUS, authorization is determined through network policies that specify who can access the network and how they can connect. RADIUS accounting tracks user connections through Accounting-Request messages that collect information about the user's IP address, connection method, and session identifier. TACACS+, however, provides more granular authorization control - it can specify exactly which commands a particular user is allowed to execute on network devices. For accounting, TACACS+ maintains mandatory audit logs of all actions executed by privileged users, providing detailed command-level accounting. In TACACS+ implementation, accounting scheme can be configured to log all executed commands by particular users to the TACACS+ server, allowing administrators to track who performs what actions on network devices.","context":["Last updated 06/10/2020\nIntroduction to NPS\nWith Network Policy Server you can create policies to determine who can access your network and how they can connect.\nNPS also includes an infrastructure to incorporate client system health checks and restrict access to systems that don’t meet minimum health requirements, such as not having up-to-date antivirus protection and the latest system and security updates installed.\nNetwork Policy Server is Microsoft’s implementation of the RADIUS protocol, a proposed IETF standard that’s widely used to centralize authentication , authorization, and accounting to network services.\n(The port values of 1812 for authentication and 1813 for accounting are RADIUS standard ports defined by the Internet Engineering Task Force (IETF) in RFCs 2865 and 2866.)\nProcess and types of messages in RADIUS:\n1. An access client (for example, a user on a laptop) makes a connection request to a network access server (NAS), which handles access to a network. An NAS can be, for example, a wireless access point, a VPN server, or a dial-up server. In the RADIUS infrastructure, an NAS is configured as a RADIUS client.\nThe term “client” can be a bit confusing. Only an NAS that’s already part of the network can be a RADIUS client. Access client devices, such as users’ desktops, laptops, or tablets that are requesting access to the network, aren’t RADIUS clients.\nAlso notice that the RADIUS clients configuration can vary between different vendors. For Cisco WLAN infrastructure, a wireless LAN controller is a RADIUS client, but for Ubiquiti, RADIUS client are APs.\n2. The RADIUS client sends an Access-Request message, including a username/password combination or a certificate from the user, to an NPS server acting as a RADIUS server. This message can include other information about the user, such as the network address.\n3. The NPS server evaluates the Access-Request message. This process can include authenticating the username and password (along with other user information) via a domain controller or client certificate.\n4. The NPS server can respond with one of three types of messages:\n• Access-Reject—The request is rejected, and access is denied to the network or resources.\n• Access-Challenge—More information is requested, such as a secondary password or other access code or credential.\n• Access-Accept—Access is granted, and authorization is given to certain resources, based on defined network policies.\n5. The connection is completed, and the NAS sends an Accounting-Request message to the NPS server to be logged. This message is sent to collect information about the user, such as his or her IP address, method of connecting to the network, and a session identifier, so that additional information that’s sent can be attributed to this user’s connection.\n6. The NPS server sends an Accounting-Response message, which acknowledges that the request was received, to the NAS.\n7. During the session, additional Accounting-Request messages containing information about the current session are sent. Each Accounting-Request message is acknowledged by an Accounting-Response message.\n8. When the user’s connection ends, one last Accounting-Request message with information about the overall use during the session is sent. This final message is acknowledged by an Accounting-Response message.\nTwo main reasons you should set up an NPS architecture with RADIUS when you have different connection paths to your network.\n- First, RADIUS centralizes control over authentication and authorization. No matter which path a user uses to access the network, a single point of contact—the NPS server acting as a RADIUS server—handles authenticating the user and determining the level of authorization.\n- Next, standardizing on RADIUS requires all NAS devices to be RADIUS clients so that only one protocol performs authentication and authorization, and only one standard configuration process is used, regardless of the kind of device connecting to the network.\nwhich NASs can connect and the authentication method each one uses. NPS gives you the choice of standard or advanced configuration options. The advanced configuration option requires you to set up the components for a RADIUS server or proxy. The standard configuration has wizards to walk you through these policy settings:\n• Network Access Protection (NAP)—This option configures NPS as an NAP policy server (covered later in the “Configuring Network Access Protection” section).\n• RADIUS server for Dial-Up or VPN Connections—This option defines network policies for authenticating and authorizing connections from these RADIUS clients: dial-up or VPN network access servers.\n• RADIUS server for 802.1X Wireless or Wired Connections—This option defines network policies for authenticating and authorizing connections from these RADIUS clients: wireless access points and authentication switches.\nAuthentication methods: password based and certificate based.\nFour password-based methods are supported:\n• Microsoft Challenge Handshake Authentication Protocol—Microsoft Challenge Handshake Authentication Protocol (MS-CHAP) starts with a challenge-response with the access client, and then sends the username and a password with a one-way encryption (meaning the password can’t be unencrypted) to be authenticated against the stored credentials.\n• Microsoft Challenge Handshake Authentication Protocol version 2—Microsoft Challenge Handshake Authentication Protocol version 2 (MS-CHAP v2) is an update to MS-CHAP with stronger security. Of the four password-based methods, it’s the preferred one.\n• Challenge Handshake Authentication Protocol—Challenge Handshake Authentication Protocol (CHAP) is similar to MS-CHAP, but the password must be able to be unencrypted, making it less secure than MS-CHAP.\n• Password Authentication Protocol—Password Authentication Protocol (PAP) is the least secure method. The password is sent in plaintext, and there’s no challenge and response. Because the password could be captured easily, PAP isn’t recommended.\nThe certificate-based authentication method is Extensible Authentication Protocol (EAP).\nCertificate-based authentication is more secure than password-based methods. Depending on the method you choose, there are two authentication types. The authentication type for EAP is Transport Layer Security (TLS). Certificates and options for using them are discussed later in “Using Certificates for Authentication.”\nProtected Extensible Authentication Protocol (PEAP) is a special way to encrypt a password being sent via MS-CHAP v2. With PEAP, you can check the server’s certificate, but user authentication is still done through passwords.\nBy default, it’s the domain where the NPS server is located. If connection requests require authentication from another domain controller, they can be sent to an NPS server acting as a RADIUS proxy, and the realm determines which server the request is routed to.\n- Lack of fault tolerance is the biggest disadvantage.\nIf the one and only RADIUS server goes down, no network connection requests can be authenticated, which makes the network inaccessible to users. To eliminate this single point of failure, you can deploy multiple RADIUS servers. RADIUS clients can be configured to use a primary server and alternates, so if the primary isn’t available, the client tries the alternates in turn.\n- Server’s load.\nIn a network with hundreds or thousands of requests in extremely short periods, a single RADIUS server could be overwhelmed. One solution is to use RADIUS proxies (having only one proxy reintroduces the single-point-of-failure problem) with multiple RADIUS servers. Requests received by a proxy are forwarded to a RADIUS server group, composed of one or more RADIUS servers, for handling.\nIn a server group of two or more RADIUS servers, the load can be balanced based on these properties:\n• Priority—Tells the NPS proxy the order of importance of this server group member when passing on requests. This setting is a non-zero integer number (such as 1, 2, 3). The lower the number, the higher the priority, so servers assigned a priority of 1 get requests first. If the Priority 1 server is unavailable, the request is sent to the Priority 2 server, and so on. Setting just the priority doesn’t result in load balancing because the lowest-priority server continues getting requests unless it becomes unavailable. However, a priority of 1 can be assigned to multiple servers, and the Weight setting can be used to force load balancing.\n• Weight—Determines what percentage of connection requests are sent to a server group member when the priority is the same as other members. This setting is also a non-zero integer number between 1 and 100. For example, to distribute the load between two serv- ers evenly, you could assign each a priority of 1 and a weight of 50 so that each server gets 50% of the connection requests. The sum of all weights in the server group must be 100.\n• Advanced settings—Determines whether a server group member is unavailable and whether connection requests need to be routed to another server in the group.\nCertificate base authentication\nFor a certificate to be used for authentication, the CA must be trusted by the client or server, and to be trusted, it must have a root certificate (also called the “CA certificate”) in the Trusted Root Certification Authorities certificate store. Think of the root certificate as the master certificate for a CA. After the root certificate is installed, all other certificates from this CA are trusted automatically by the client or server. The process of requesting a certificate, having it approved, and downloading it is called “enrollment.” Clients can be enrolled automatically for some certificates in a domain. For example, if the client is a member of the same domain as the CA, the CA certificate is auto-enrolled.\nBesides the root certificate, there are three other important certificate types:\n• Client computer certificate—This certificate verifies a client computer’s identity to an NPS server. It’s enrolled automatically for domain members and imported manually for non-domain members.\n• Server certificate—This certificate verifies a server’s identity to a client. It can be set for auto-enrollment in Active Directory.\n• User certificate—This certificate can be put on a smart card to verify a user’s identity, and the smart card reader is attached to the client computer. If you’re using smart cards, you don’t auto-enroll client computer certificates.\nWhen a certificate is presented for authentication, it must meet these three criteria for authentication to succeed:\n• It must be valid (for example, hasn’t expired).\n• It must be configured for the purpose it’s presented for. Eg. Certificate on a NPS server for Server Authentication, Certificate on a Workstation for Client Authentication.\n• It must be issued by a trusted CA.\nThe Server certificate must meet these requirements:\n• The subject name can’t be blank.\n• The certificate is linked to a trusted root CA.\n• The purpose of the certificate is Server Authentication. The object identifier for Server Authentication is 126.96.36.199.188.8.131.52.1.\n• The algorithm name is RSA, and the minimum key size is at least 2048.\n• The name in the Subject line of the server certificate matches the name that is configured on the client for the connection.\n• For wireless clients,If the subject alternative name (SubjectAltName) extension is used, which allows multiple servers to use the certificate, the certificate must contain the NPS server’s DNS name.\nClient certificate requirements:\nWith either EAP-TLS or PEAP with EAP-TLS, the server accepts the client’s authentication when the certificate meets the following requirements:\n- The client certificate is issued by an enterprise certification authority (CA), or it maps to a user account or to a computer account in the Active Directory directory service.\n- The user or the computer certificate on the client chains to a trusted root CA.\n- The user or the computer certificate on the client includes the Client Authentication purpose.\n- The user or the computer certificate does not fail any one of the checks that are performed by the CryptoAPI certificate store, and the certificate passes requirements in the remote access policy.\n- The user or the computer certificate does not fail any one of the certificate object identifier checks that are specified in the Internet Authentication Service (IAS) remote access policy.\n- The 802.1x client does not use registry-based certificates that are either smart-card certificates or certificates that are protected with a password.\n- The Subject Alternative Name (SubjectAltName) extension in the certificate contains the user principal name (UPN) of the user.\n- When clients use EAP-TLS or PEAP with EAP-TLS authentication, a list of all the installed certificates is displayed in the Certificates snap-in, with the following exceptions:\n- Wireless clients do not display registry-based certificates and smart card logon certificates.\n- Wireless clients and virtual private network (VPN) clients do not display certificates that are protected with a password.\n- Certificates that do not contain the Client Authentication purpose in EKU extensions are not displayed.\nYou can select certificate-based authentication—EAP—when you’re setting the authentication method. EAP requires both the server and the access client to present valid certificates, which is the most secure authentication method. However, in a large organization, maintaining potentially thousands of client certificates can be a daunting administrative job, even with auto-enrollment for new access clients. Selecting PEAP as the authentication method doesn’t involve using a client certificate; instead, it uses MS-CHAP v2 for client authentication. It’s not as secure, however, as a pure certificate-based authentication method (such as EAP) because users still enter passwords, which can be guessed or stolen.\nHowever, PEAP can be configured to require a server certificate. This method protects clients from connecting to a server that’s pretending to be the server they want to connect to, and PEAP encrypts the information it’s passing.\nFor a tutorial how to configure Certificate based authentication, see this post: https://frankfu.click/microsoft/70-411-administering-win-2012r2/70411-chapter6-tutorial-nps-with-computer-certificate-authentication-eap-tls.html","Tacacs Plus is a protocols for security with AAA services which are , authentication, authorization, accounting. It is used as a centralized authentication to network devices. It also can provide a specific authorization with centralized access to particular user to work with network devices. With accounting, it gives a mandatory audit logs by logging all actions executed by privileged users.\nIn this document will show how to configure Tacacs Plus security protocols on Huawei switch model S5700.\nIn this article how to configure Tacacs+ security protocols on Huawei switch model S5700, it is presumed that:\na. You had already installed a tacacs server. If you don’t please kindly check one of the following links.\n1. Configuring Tacacs Plus with Tacacs Plus User Authentication on RHEL/CentOS 7\n2. Configuring Tacacs Plus with Linux Systems Users Authentication on RHEL/CentOS 7\n3. Configuring Tacacs Plus with Active Directory User Authentication on RHEL/CentOS 7\nb. You had already configured SSH remote management on your Huawei switch. You would probably like to check this link SSH Configuration on Huawei Switch S5700.\n3. Create Console Login for Backup\nBefore you start doing Tacacs Plus protocols security configuration on Huawei switch, it is recommended to create a console login first. So, in case that Tacacs Plus centralized access server is not reachable, you still can work with Huawei switch via direct console login.\n]user-interface con 0 authentication-mode password set authentication password cipher 2222\nIn direct console login, you will be prompted to enter the password as the following.\n4. Configure Tacacs Plus Server\nThe following are the commands to configure Tacacs Plus centralized access server on Huawei switch model S5700. “ts-aaa” is just a name given to HWTacacs template and you can give any name you like.\n] hwtacacs-server template ts-aaa hwtacacs-server authentication 192.168.171.13 hwtacacs-server authorization 192.168.171.13 hwtacacs-server accounting 192.168.171.13 hwtacacs-server shared-key cipher TS@123\n5. Configure Authentication\nNow it is time to tell the Huawei switch to authenticate user with Tacacs Plus server. “hwtc-tc” is just a name given to authentication scheme of HWTacacs and you can give any name you like.\n] aaa authentication-scheme hwtc-ts authentication-mode hwtacacs ] ssh authentication-type default password\n6. Configure Authorization\nWhen a Huawei switch is applied with the authorization commands, the user who is able to login can only execute the amount of a specific commands that are allowed on Tacacs Plus protocols security server. “hwtc-tc” is just a name given to authorization scheme of HWTacacs and you can give any name you like.\n] aaa authorization-scheme hwtc-tc authorization-mode hwtacacs authorization-cmd 15 hwtacacs local\n7. Configure Accounting\nWhen we apply accounting command on Huawei switch it will start to log all executed command by a particular user to Tacacs Plus server. So, we can know who doing on our network devices. “hwtc-tc” is just a name given to accounting scheme of HWTacacs and you can give any name you like.\n] aaa accounting-scheme hwtc-tc accounting-mode hwtacacs recording-scheme hwtc-tc recording-mode hwtacacs ts-aaa cmd recording-scheme hwtc-tc\n8. Applying AAA Scheme to Domain\nAfter creating the authentication, authorization, and accounting scheme, we need to apply these AAA to the domain as the following.\n] aaa domain default_admin authentication-scheme hwtc-tc accounting-scheme hwtc-tc authorization-scheme hwtc-tc hwtacacs-server ts-aaa\nIt is strongly recommend to test Tacacs Plus configuration. There are three thing to test as the following.\n- Test login to your Huawei switch using a full privilege account from Tacacs Plus user databases.\n- Test login to your Huawei switch using a limited privilege account from Tacacs Plus user databases and make sure that this account can only execute the commands that are allowed on Tacacs Plus server only.\n- Test disconnect your Huawei switch from Tacacs Plus server and make sure that you still be able to work with your switch direct console with the password set in section 3, Create Console Login for Backup, above . This is extremely important because in case Tacacs Plus server is unavailable, we still be able to manage our network devices.\nYou should be able to configure Tacacs Plus on Huawei switch S5700 now. Tacacs+ is the only security protocols used to provide centralized access into networks. Hopefully, you can find this article informative. If you have any questions or suggestions you can always leave your comments below. I will try all of my best to review and reply them."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:05eb18cd-62e3-4512-8ab5-843960cf14ba>","<urn:uuid:7fde63a3-b426-4610-bc04-679bb2591e6d>"],"error":null}
{"question":"For my research on galaxy evolution, are there any similarities between how magnetic fields influence star formation in the Milky Way's nearby regions and the star formation patterns seen in distant galaxies?","answer":"In the Milky Way's nearby regions, there is a clear relationship between magnetic fields and star formation, where filaments in denser star-forming clouds tend to be perpendicular to the interstellar magnetic field, while less dense filaments align with the magnetic field direction. In distant galaxies, the star formation patterns are primarily influenced by galaxy collisions in the early Universe, which triggered intense bursts of star formation along with black hole growth. These different mechanisms show how star formation can be regulated by different factors depending on the galactic environment and epoch.","context":["Distant galaxies undergoing intense bursts of star formation have been shown by NASAs Chandra X-ray Observatory to be fertile growing grounds for the largest black holes in the Universe. Collisions between galaxies in the early Universe may be the ultimate cause for both the accelerated star formation and black hole growth.\nBy combining the deepest X-ray image ever obtained with submillimeter and optical observations, an international team of scientists has found evidence that some extremely luminous adolescent galaxies and their central black holes underwent a phenomenal spurt of growth more than 10 billion years ago. This concurrent black hole and galaxy growth spurt is only seen in these galaxies and may have set the stage for the birth of quasars – distant galaxies that contain the largest and most active black holes in the Universe.\n\"The extreme distances of these galaxies allow us to look back in time, and take a snapshot of how todays largest galaxies looked when they were producing most of their stars and growing black holes, \" said David Alexander of the University of Cambridge, UK, and lead author of a paper in the April 7, 2005 issue of Nature that describes this work.\nMegan Watzke | EurekAlert!\nAstronomers find unexpected, dust-obscured star formation in distant galaxy\n24.03.2017 | University of Massachusetts at Amherst\nGravitational wave kicks monster black hole out of galactic core\n24.03.2017 | NASA/Goddard Space Flight Center\nAstronomers from Bonn and Tautenburg in Thuringia (Germany) used the 100-m radio telescope at Effelsberg to observe several galaxy clusters. At the edges of these large accumulations of dark matter, stellar systems (galaxies), hot gas, and charged particles, they found magnetic fields that are exceptionally ordered over distances of many million light years. This makes them the most extended magnetic fields in the universe known so far.\nThe results will be published on March 22 in the journal „Astronomy & Astrophysics“.\nGalaxy clusters are the largest gravitationally bound structures in the universe. With a typical extent of about 10 million light years, i.e. 100 times the...\nResearchers at the Goethe University Frankfurt, together with partners from the University of Tübingen in Germany and Queen Mary University as well as Francis Crick Institute from London (UK) have developed a novel technology to decipher the secret ubiquitin code.\nUbiquitin is a small protein that can be linked to other cellular proteins, thereby controlling and modulating their functions. The attachment occurs in many...\nIn the eternal search for next generation high-efficiency solar cells and LEDs, scientists at Los Alamos National Laboratory and their partners are creating...\nSilicon nanosheets are thin, two-dimensional layers with exceptional optoelectronic properties very similar to those of graphene. Albeit, the nanosheets are less stable. Now researchers at the Technical University of Munich (TUM) have, for the first time ever, produced a composite material combining silicon nanosheets and a polymer that is both UV-resistant and easy to process. This brings the scientists a significant step closer to industrial applications like flexible displays and photosensors.\nSilicon nanosheets are thin, two-dimensional layers with exceptional optoelectronic properties very similar to those of graphene. Albeit, the nanosheets are...\nEnzymes behave differently in a test tube compared with the molecular scrum of a living cell. Chemists from the University of Basel have now been able to simulate these confined natural conditions in artificial vesicles for the first time. As reported in the academic journal Small, the results are offering better insight into the development of nanoreactors and artificial organelles.\nEnzymes behave differently in a test tube compared with the molecular scrum of a living cell. Chemists from the University of Basel have now been able to...\n20.03.2017 | Event News\n14.03.2017 | Event News\n07.03.2017 | Event News\n24.03.2017 | Materials Sciences\n24.03.2017 | Physics and Astronomy\n24.03.2017 | Physics and Astronomy","Portrayed in this image from ESA’s Planck satellite are the two Magellanic Clouds, among the nearest companions of our Milky Way galaxy. The Large Magellanic Cloud, about 160 000 light-years away, is the large red and orange blob close to the centre of the image. The Small Magellanic Cloud, some 200 000 light-years from us, is the vaguely triangular-shaped object to the lower left.\nAt around ten and seven billion times the mass of our Sun, respectively, these are classed as dwarf galaxies. As a comparison, the Milky Way and another of its neighbours, the Andromeda Galaxy, boast masses of a few hundred billion solar masses each.\nThe Magellanic Clouds are not visible from high northern latitudes and were introduced to European astronomy only at the turn of the 16th century. However, they were known long before by many civilisations in the Southern Hemisphere, as well as by Middle Eastern astronomers.\nPlanck detected the dust between the stars pervading the Magellanic Clouds while surveying the sky to study the cosmic microwave background – the most ancient light in the universe – in unprecedented detail. In fact, Planck detected emission from virtually anything that shone between itself and the cosmic background at its sensitive frequencies.\nThese foreground contributions include many galaxies, near and far, as well as interstellar material in the Milky Way. Astronomers need to remove them in order to access the wealth of cosmic information contained in the ancient light. But, as a bonus, they can use the foreground observations to learn more about how stars form in galaxies, including our own.\nInterstellar dust from the diffuse medium that permeates our Galaxy can be seen as the mixture of red, orange and yellow clouds in the upper part of this image, which belong to a large star-forming complex in the southern constellation of Chamaeleon.\nIn addition, a filament can also be seen stretching from the dense clouds of Chameleon, in the upper left, towards the opposite corner of the image.\nApparently located between the two Magellanic Clouds as viewed from Planck, this dusty filament is in fact much closer to us, only about 300 light-years away. The image shows how well this structure is aligned with the galaxy’s magnetic field, which is represented as the texture of the image and was estimated from Planck’s measurements.\nBy comparing the structure of the magnetic field and the distribution of interstellar dust in the Milky Way, scientists can study the relative distribution of interstellar clouds and the ambient magnetic field. While in the case of the filamentary cloud portrayed in this image, the structure is aligned with the direction of the magnetic field, in the denser clouds where stars form filaments tend to be perpendicular to the interstellar magnetic field.\nThe lower right part of the image is one of the faintest areas of the sky at Planck’s frequencies, with the blue hues indicating very low concentrations of cosmic dust. Similarly, the eddy-like structure of the texture is caused primarily by instrument noise rather than by actual features in the magnetic field.\nThe emission from dust is computed from a combination of Planck observations at 353, 545 and 857 GHz, whereas the direction of the magnetic field is based on Planck polarisation data at 353 GHz. The image spans about 40 degrees."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:81f982ad-24e1-4b6a-a3d2-6393e7aac142>","<urn:uuid:daa80b48-4188-4db2-a7ef-2a9cf326042a>"],"error":null}
{"question":"What is difference between moral rationality and ethics in Western philosophy?","answer":"Morality is the application of reason to moral decisions, while ethics deals with how one responds to the suffering of others. Morality involves rational procedures, whereas ethics is about sensibility rather than reason. In Western philosophy, there are three forms of moral rationality: utilitarianism (focusing on consequences), deontology (emphasizing intentions), and virtue theory (questioning the other two). Both utilitarianism and deontology begin with the self as a rational agent, while virtue theory interprets the self as existing within a concrete situation with embedded values. Ethics goes further by questioning whether we should begin with the self at all, suggesting we should start with others and prioritize sensibility over rationality.","context":["In this course I am making a distinction between morality and ethics. Morality is the application of reason to moral decisions. Ethics, on contrary, is not about procedures but how I respond, or fail to respond to the sufferings of others. This isn’t a matter of reason, but of sensibility, since it is perfectly possible to ‘reason’ oneself out of ethics simply by refusing the status of humanity to others.\nIn Western philosophy, at least, there are 3 standard form of moral rationality (though the third is really a critique of the other 2): utilitarianism, deontology and virtue theory. Utilitarianism focuses on the consequences of acts, whereas deontology emphasises the intentions of the agent. What is common to them both, however, is that they begin with the self and the self is primarily understood as a rational agent. It is this presupposition that will be questioned to some extent by the third theory, virtue theory, and fundamentally by ethics. In virtue theory, will still begin with the self, but the self is interpreted as existing in a concrete situation (a given community, society and history) whose values are embedded rather than deduced rationally, and what matter is not just the intentions or consequences of actions, but character and authenticity. Ethics, as we shall later in the course, goes even further than this, because it questions whether we should begin with the self at all, but rather with others, and that our commitment to others is first about sensibility, rather than rationality (in other words that the relation to other is different from the relation of the self to itself in moral reflection).\nIn this lecture, we are going to focus on utilitarianism, which is perhaps the most popular and well known, but also the one moral theory that pervades our everyday lives because it is the basis of public policy and government decisions that generally are taken on a utility basis. There are two version of utilitarianism. One by Bentham and the other by Mill, whose version can be seen as a correction of the formers. The basis of Bentham’s utilitarianism is the ‘happiness principle’. A policy or decision is moral if it contributes to the general happiness of everyone. Happiness, here, is a psychological category, and for Bentham is a quantifiable and calculable in terms of its intensity and duration. What is good is what gives us pleasure, what is bad, is what causes us pain. All moral arguments come down to the maximisation of happiness as opposed to personal preference or dogma.\nAn example of Bentham’s utilitarianism in action would be the planned creation of workhouses in England in the 19th Century, which luckily for the poor were never fully implemented. Bentham’s argument was that encountering the poor on the street was a public nuisance that lead to a decrease in the happiness of the majority so it would be better for them to be incarcerated in workhouses against their will. Moreover, it was better for society as whole if the poor were forced to work rather than being unproductive parasites, as he saw it, on society. By putting the poor to work they would in fact pay for the cost of the workhouses, and therefore not be a burden on the taxpayer. Although these ideas where never fully put into action, we can still here them loud and clear today.\nWhy might some find Bentham’s ideas morally dubious however unpractical they turned out to be? The fundamental problem is it sacrifices the freedom of the individual for the sake of society as a whole. The workhouse was repressive and cruel system that destroyed the lives of those who were incarcerated, as the novels of Dickens portray, and it seems hardly justifiable to argue that destroying a human life is justifiable for the sake of the happiness of the majority. If this were the case, as Sandel argues, why wouldn’t we justify the throwing of the Christians to the lions, since the majority obviously gained pleasure from this spectacle (2010, p. 37)? Can the pleasure of one, justify the pain of another? Doesn’t this go against our moral intuitions?\nAs Sandel goes onto write, some people have used this argument to justify torture. We might think that the suffering of an individual is not as important as the social good gained by torture. We could think of good utilitarian arguments, he adds, about why torture is wrong: that in the end you don’t gain much information from torturing people; that society itself, in the long run, would be undermined if we let systematic torture happen (what would be the difference between us and our enemies?); that our own soldiers and agents would be tortured. Yet there is also an argument on principle that torture is wrong. The dignity of the individual outweighs any utility (this is the same critique of Bentham’s workhouses and prisons).\nOne way that people justify torture is the ‘ticking time bomb’. The argument goes that if a nuclear device were to go off and we had a terrorist in our hands, then all of us would tortures the terrorist to find out the information and stop the bomb. The problem with this scenario, as Sandel points out, is that we are not describing like with like. It implies that the person being tortured is innocent like us and therefore we are willing to sacrifice one life for another, but of course the terrorist is not the same as us. The real example to see whether you think there could be a utilitarian defence of torture would be whether you think it would be worth sacrificing the innocent daughter of the terrorist to find out why the bomb is. Would the happiness of the majority justify the suffering and death of a child?\nOur worries about utilitarianism, at least in the crude form that it put forward by Bentham and public policy, is that it isn’t a moral philosophy at all but just a moral calculation, which reduced every human life to a common denominator. Sandel alludes to the famous example of the exploding gas tanks in the Ford Pinto (which was the basis of the scene in the film The Fight Club) (2010, p. 43). When Ford did a cost benefit analysis if found that the cost of fixing the fault was higher than the costs of people burning or dying. Is there not something morally repugnant about putting a value on someone’s life in this way, in the same way that Bentham only saw the lives of the poor in terms of an economic value?\nIt is for these reasons that Mill sought to improve Bentham’s utilitarianism. First of all he makes a distinction, though it is not always clear in his text, between act utilitarianism and rule utilitarianism. In act utilitarianism, a utility calculus is performed for every situation. Thus it is perfectly possible, that in a particular situation, the best cause of action would be to tell a lie since this promote the happiness of the greatest number. Rule utilitarianism does not focus on the consequence of an action, but a rule. The argument then would be about whether telling lies would benefit society as whole, as opposed to keeping promises. Rule utilitarianism would not justify, therefore the telling of lies in any situation, because constantly making exceptions to the rule would undermine social relations confidence and trust.\nMill’s fundamental reform of Bentham, however, is at the level of the psychology of pain and pleasure. For Bentham, this was a matter merely of quantity, intensity and duration. Every rational creature would seek pleasure and avoid pain. Mill’s argument is that it is psychological incorrect to reduce pain and pleasure to sensation and everyone knows this through introspection. We do not merely speak of quantity of a feeling but also the quality of one. Even when we speak of pain, we can think of a dull or a sharp pain. We can think of dull pain being more or less painful and the same with a share one, but the difference between them is qualitative not quantitative. As rational beings we are capable of ordering our desires qualitatively as well as quantitatively.\nEveryone knows Mill’s famous statement ‘It is better to be human dissatisfied than a pig satisfied; better to be Socrates dissatisfied than a fool satisfied’. When it comes to individual acts, this might be difficult to defend. It is really true that reading book is more pleasurable than sex? Even those who like reading books would hardly defend that. Moreover, is it true to say that in having sex I don’t use my mind at all? Mill’s dictum makes no sense if we think about it in this way, and is hardly convincing psychologically. When Mill is thinking about the quality of pleasure he is thinking about life lived as whole (this again is the important difference between act and rule utilitarianism). Would a life that was dedicated wholly to sex be better than a life that was not? Mill’s argument would be that it wouldn’t be if we thought about society as whole, for the one reason that person who dedicated their lives solely to sensual pleasures would essentially be selfish and egotistical. It is only through education that I would realise that society exists only because of the selfless acts of others who are willing to sacrifice their own advantage.\nIn some sense Mill could be seen as a utopian socialist, as opposed to the reactionary views of Bentham, and the revolutionary socialism of Marx. His utilitarianism is about social progress, which the major theme of his work On Liberty, and which should be seen as the context of his moral theory. What would benefit the majority rather than the minority? A morality that has its source in intuition or tradition tends to be authoritarian, reactionary and conservative. We ought to change the world so as make it better for the vast majority of people, and the two great wants in our word are poverty and disease, so we should change the world to rid ourselves from them. The problem is that we can certainly imagine a despotic society that could achieve these ends rationality without individual rights. Do we think this sacrifice is worth it, or does it undermine human dignity and respects for others beyond calculation for a future good? It seems the only way to save utilitarianism is through the idea of dignity, but the latter cannot be determined by a calculus. It is a principle.\nBahmueller, C.F., 1981. The National Charity Company: Jeremy Bentham’s silent revolution. University of California Press, Berkeley.\nKurer, O., 1992. J.S. Mill and Utopian Socialism. Economic Record 68, 222–32.\nSandel, M.J., 2010. Justice what’s the right thing to do ? Penguin books, London.\nSchiemann, J.W., 2016. Does torture work? Oxford University Press, New York.\n For a full historical account of Bentham’s ideas and implementation of Poor Law reform in England, see (Bahmueller, 1981).\n A separate and equally important issue is whether poverty is the fault of the individual. The real cause of poverty in England that the time was not the idleness of the working classes, but the Corn Laws, and industrialisation. Bentham’s incarceration of the poor stems from a fear of revolution not a concern with their welfare.\n This moral argument is different from the argument whether torture works or not, which it does not. The moral argument would be that even if torture did work, it would still be wrong. For an account of whether torture actually works, using game theory, see (Schiemann, 2016).\n For a detailed account of why Mill should be considered a utopian socialist, see (Kurer, 1992)"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"detailed"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_follow_up_likelihood","category_name":"unlikely_follow_up"}],"document_ids":["<urn:uuid:2c0081f4-c1e4-4991-a329-6b4e4d1038cf>"],"error":null}
{"question":"How do texture precision and material reflectivity affect the appearance of specular highlights in different lighting models?","answer":"In texture-based approaches like CLEAN mapping, the precision of textures directly impacts specular highlights - with 8-bit textures, the error range is 1/512 for 0-1 data and 1/256 for -1 to 1 data. The error increases with the square of maximum normal-map slope. For Blinn-Phong shading, the appearance is controlled by material properties - glossiness determines the size and sharpness of highlights (higher values create plastic-like appearance), while reflectivity determines the color and intensity of reflections, appearing as a scalar for non-metals and actual colors for metals like gold or silver.","context":["Doing my best impersonation of someone who blogs with more regularity than I really do…\nI glossed over (flubbed?) the error analysis a little in my last post, and should really do a better job. I’ll look at CLEAN/LEAN mapping, but the analysis methods are useful in lots of situations where you compute something from a texture.\nTo keep things simple, I’ll use a simplified form of the (C)LEAN variance computation:\nThe error in this expression is especially important in (C)LEAN mapping since it determines the maximum specular power you can use, and how shiny your objects can be. For specular power s, 1/s has to be bigger than the maximum error in V, or you’ll get some ugly artifacts.\nM and B come from a texture, so have inherent error of and due to the texture precision. The error in each will be 1/2 of the texel precision. For example, with texel values from 0 to 255, a raw texel of 2 could represent a true value anywhere from 1.5 to 2.5, all of which are within .5 of the texel value.\nIn general, we’ll scale and bias to use as much of the texture range as we can. The final error for an 8-bit texture then is range/512. For data that ranges from 0 to 1, the range is 1 and the representation error is 1/512; while for data that ranges from -1 to 1, the range is 2, so the representation error is 2/512 = 1/256.\nThe error in each parameter propagates into the final result scaled by the partial derivative. is 1, so error due to M is simple:\nThe error due to B is a little more complicated, since is 2 B. We’re interested in the magnitude of the error (since we don’t even know if was positive or negative to start with), and mostly interested in its largest possible value. That gives\nGenerally, you’re interested in whichever of these errors is biggest. The actual error is dependent on the maximum value of B, and how big the texel precision ends up being after whatever scale is used to map M and B into the texture range. So, for a couple of options:\n|B range||-1 to 1||-2 to 2||-1/2 to 1/2|\n|Max Bump Slope||45°||63.4°||26.6°|\n|M range||0 to 1||0 to 4||0 to 1/4|\nWe can make this all a little simpler if we recognize that, at least with the simple range-mapping scheme used here, and are also dependent on .\nSo, this says the error changes with the square of the max normal-map slope, and that the precision of B is always the limiting factor. In fact, if there were an appropriate texture format, M could be stored with two fewer bits than B. For 16-bit textures, rather than 2-9 for the texture precision, you’ve got 2-17, giving a maximum safe specular power of 215=32768 for bumps clamped to a slope of 1. There’s no need for the slope limit to be a power of 2, so you could fit it directly to the data, though it’s often better to be able to communicate a firm rule of thumb to your artists (spec powers less than x) rather than some complex relationship (steeper normal maps can’t be as shiny according to some fancy formula — yeah, that’ll go over well).","This blog series is a part of the write-up assignments of my Real-Time Game Rendering class in the Master of Entertainment Arts & Engineering program at University of Utah. The series will focus on C++, Direct3D 11 API and HLSL.\nIn this post, I will talk about how I added specular lighting to my rendering engine.\nBelow shows how specular lighting works. When an incoming light hit a reflective surface, there will be reflected light. If our view direction happens to align with the reflected light, then we should see the incoming light. Mathematically, this is impossible to happen for a single light source. In real life, what we see on a reflective surface is actually the result of countless incoming lights reflected by that surface. Because it is unrealistic to do calculate the reflected results realistically, we need some estimation of the specular light. This is where the Phong shading and Blinn-Phong shading come in.\nI will implement the Blinn-Phong shading model in this post instead of Phong shading. Despite the fact that Phong shading is an efficient approximation of lighting, its specular reflections can break down in certain conditions.\nFrom the image below, we can see that since Phong shading is doing its calculation according to the angle between the reflected light direction and the view direction. If we view the surface from a position with an angle to reflected light larger than 90 degrees, the specular reflections will be nullified.\nBlinn-Phong lighting model uses the angle between the surface’s normal and a half-vector which came from the light direction and the view direction. With this modification, the angle theta will never be larger than 90 degrees unless the light is coming from way under the surface so we won’t see the hard cutoff that appears in the Phone model.\nTo implement the Blinn-Phong model, I added 2 new more material properties, one is glossiness and one is reflectivity. Glossiness is the power we use in the equation, while reflectivity means the reflected color of that material. For non-metal material, reflectivity will just act like a scalar, but it will be a certain color for metal materials (such as silver and gold). You can see how these properties are used in the actual calculation below. Since specular lighting is additive, and won’t be affected by the material’s inherent color but only the light color and the material’s reflectivity. We will add the result of that function to the color result in the fragment shader.\nOf course, in order to make our builder pipeline to work. We need to build the material files into binary files from the source and take those new properties into consideration. However, we don’t want to have to go over all the previously made materials and add in the new properties if we don’t have to. Therefore, when building the materials, if the builder cannot find those properties, it will just put in some default values that we specified like below.\nBelow shows the result of adding the specular lighting into my scene. You can easily see that it is specular lighting because of the specular highlight and how it moves with the camera position.\nNow let’s take a look at how the material properties can affect the appearance of our specular lighting.\nHigh glossiness value, the object looks kind of like plastic\nLower glossiness, but with a blue-ish reflectivity\nWe don’t want our lighting to look the same when it is right in front of an object as when it is on the other side of the room. When we think about realistic lighting like a flashlight, we can always see that the surface that we are lighting will be brighter if we hold the flashlight really close, while the lit area will grow bigger but not as bright once we start moving the flashlight away. This is because of the fixed amount of energy generated by the flashlight is being distributed onto different sizes of space.\nUsing quadratic attenuation with 1.5 intensity\nUsing linear attenuation with 1.0 intensity"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"without premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"likely_follow_up"}],"document_ids":["<urn:uuid:beef8a59-1c62-4350-bc60-e9fb9e81dc6f>","<urn:uuid:42a263ad-11ce-4df1-a803-9a64840dadb1>"],"error":null}
{"question":"As someone interested in economic reporting, I want to know how media covers financial issues in different communities. What biases exist in economic news coverage, and how do actual economic conditions differ between urban and rural areas?","answer":"Economic news coverage typically focuses on how events impact stockholders rather than workers or consumers, showing a bias toward corporate perspectives. This skewed coverage often overlooks important economic realities in different communities. In reality, while rural areas have lower labor force participation (59% compared to 63% in urban areas) and haven't fully recovered jobs lost during the recession, some rural communities are actually outperforming urban areas in certain aspects. For instance, rural areas have higher rates of entrepreneurship, and businesses that export goods and services are thriving in rural communities. Additionally, rural areas in many states make outsized contributions to their states' GDP, though this fact often receives less media attention.","context":["Media have tremendous power in setting cultural guidelines and in shaping political discourse. It is essential that news media, along with other institutions, are challenged to be fair and accurate. The first step in challenging biased news coverage is documenting bias. Here are some questions to ask yourself about newspaper, TV and radio news.\nWho are the sources?\nBe aware of the political perspective of the sources used in a story. Media over-rely on \"official\" (government, corporate and establishment think tank) sources. For instance, FAIR found that in 40 months of Nightline programming, the most frequent guests were Henry Kissinger, Alexander Haig, Elliott Abrams and Jerry Falwell. Progressive and public interest voices were grossly underrepresented.\nTo portray issues fairly and accurately, media must broaden their spectrum of sources. Otherwise, they serve merely as megaphones for those in power\n- Count the number of corporate and government sources versus the number of progressive, public interest, female and minority voices. Demand mass media expand their rolodexes; better yet, give them lists of progressive and public interest experts in the community.\nIs there a lack of diversity?\nWhat is the race and gender diversity at the news outlet you watch compared to the communities it serves? How many producers, editors or decision-makers at news outlets are women, people of color or openly gay or lesbian? In order to fairly represent different communities, news outlets should have members of those communities in decision-making positions.\nHow many of the experts these news outlets cite are women and people of color? FAIR's 40-month survey of Nightline found its U.S. guests to be 92 percent white and 89 percent male. A similar survey of PBS's NewsHour found its guestlist was 90 percent white and 87 percent male.\n- Demand that the media you consume reflect the diversity of the public they serve. Call or write media outlets every time you see an all-male or all-white panel of experts discussing issues that affect women and people of color.\nFrom whose point of view is the news reported?\nPolitical coverage often focuses on how issues affect politicians or corporate executives rather than those directly affected by the issue. For example, many stories on parental notification of abortion emphasized the \"tough choice\" confronting male politicians while quoting no women under 18--those with the most at stake in the debate. Economics coverage usually looks at how events impact stockholders rather than workers or consumers.\n- Demand that those affected by the issue have a voice in coverage.\nAre there double standards?\nDo media hold some people to one standard while using a different standard for other groups? Youth of color who commit crimes are referred to as \"superpredators,\" whereas adult criminals who commit white-collar crimes are often portrayed as having been tragically been led astray. Think tanks partly funded by unions are often identified as \"labor-backed\" while think tanks heavily funded by business interests are usually not identified as \"corporate-backed.\"\n- Expose the double standard by coming up with a parallel example or citing similar stories that were covered differently.\nDo stereotypes skew coverage?\nDoes coverage of the drug crisis focus almost exclusively on African Americans, despite the fact that the vast majority of drug users are white? Does coverage of women on welfare focus overwhelmingly on African-American women, despite the fact that the majority of welfare recipients are not black? Are lesbians portrayed as \"man-hating\" and gay men portrayed as \"sexual predators\" (even though a child is 100 times more likely to be molested by a family member than by an unrelated gay adult—Denver Post, 9/28/92)?\n- Educate journalists about misconceptions involved in stereotypes, and about how stereotypes characterize individuals unfairly.\nWhat are the unchallenged assumptions?\nOften the most important message of a story is not explicitly stated. For instance, in coverage of women on welfare, the age at which a woman had her first child will often be reported—the implication being that the woman's sexual \"promiscuity,\" rather than institutional economic factors, are responsible for her plight.\nCoverage of rape trials will often focus on a woman's sexual history as though it calls her credibility into question. After the arrest of William Kennedy Smith, a New York Times article (4/17/91) dredged up a host of irrelevant personal details about his accuser, including the facts that she had skipped classes in the 9th grade, had received several speeding tickets and-when on a date-had talked to other men.\nIs the language loaded?\nWhen media adopt loaded terminology, they help shape public opinion. For instance, media often use the right-wing buzzword \"racial preference\" to refer to affirmative action programs. Polls show that this decision makes a huge difference in how the issue is perceived: A 1992 Louis Harris poll, for example, found that 70 percent said they favored \"affirmative action\" while only 46 percent favored \"racial preference programs.\"\n- Challenge the assumption directly. Often bringing assumptions to the surface will demonstrate their absurdity. Most reporters, for example, will not say directly that a woman deserved to be raped because of what she was wearing.\n- Demonstrate how the language chosen gives people an inaccurate impression of the issue, program or community.\nIs there a lack of context?\nCoverage of so-called \"reverse discrimination\" usually fails to focus on any of the institutional factors which gives power to prejudice—such as larger issues of economic inequality and institutional racism. Coverage of hate speech against gays and lesbians often fails to mention increases in gay-bashing and how the two might be related.\n- Provide the context. Communicate to the journalist, or write a letter to the editor that includes the relevant information.\nDo the headlines and stories match?\nUsually headlines are not written by the reporter. Since many people just skim headlines, misleading headlines have a significant impact. A classic case: In a New York Times article on the June 1988 U.S.-Soviet summit in Moscow, Margaret Thatcher was quoted as saying of Reagan, \"Poor dear, there's nothing between his ears.\" The Times headline: \"Thatcher Salute to the Reagan Years.\"\n- Call or write the newspaper and point out the contradiction.\nAre stories on important issues featured prominently?\nLook at where stories appear. Newspaper articles on the most widely read pages (the front pages and the editorial pages) and lead stories on television and radio will have the greatest influence on public opinion.\n- When you see a story on government officials engaged in activities that violate the Constitution on page A29, call the newspaper and object. Let the paper know how important you feel an issue is and demand that important stories get prominent coverage.","This is the fourth post in a series about reducing the divide between urban and rural communities.\nTo bridge the gap between urban and rural areas, we first need to understand what sets these communities apart and where they have common ground. Below are a few key stats about urban and rural populations, economies and housing, and the different types of critical challenges these communities face.\nDespite the vast amount of discussion about the urban-rural divide, there is actually little agreement about what these terms mean. The most common definitions are from the Census Bureau — “mostly urban,” “mostly rural” or “completely rural” — and the Office of Management and Budget (OMB) — “metropolitan” or “non-metropolitan.”\nThe problem with these definitions is that more than half of the country’s rural population, as defined by the Census, lives in less densely populated parts of OMB metropolitan areas.\nNo matter how you slice it though, the clear majority of Americans live in urban areas. This share continues to grow as people move from rural to urban regions. Those who live in rural communities tend to be older (with an average age of 51 years, versus 46 in urban communities) and less educated (20 percent with a bachelor’s degree versus 29 percent in urban communities).\nRural and urban unemployment rates have improved in recent years, but labor force participation — the share of the population working or seeking employment — remains below pre-recession levels. Specifically, the gap between urban (63 percent) and rural (59 percent) labor force participation is significant and largely attributed to an aging rural workforce. Additionally, most rural communities still have not recovered the jobs they lost during the recession.\nHowever, not all rural communities are the same, and some are outpacing the growth of urban areas on key economic indicators. For example, many rural areas have higher rates of entrepreneurship, and the National League of Cities’ (NLC) own research found that businesses that export their goods and services are thriving in rural communities. Rural areas in many states are also making outsized contributions to their states’ GDP.\nDespite their differences, affordable housing is a prevalent concern amongst both urban and rural communities. Across the U.S., only 46 units are available for every 100 extremely low-income renter households. The problem is more severe in cities, which typically have only 42 units per 100 low income renters. Rural area housing challenges are compounded by the fact that residents typically have lower median incomes and available affordable housing is often poor quality.\nRural residents have higher homeownership rates (81 percent) than urban residents (60 percent). Younger adults are both more likely to rent and more likely to live in urban areas. Rural areas have an older demographic, whom are both more likely to own their homes and age in place. Lack of mobility within rural housing markets contributes to an overall housing shortage in these communities, limiting business expansion and attraction opportunities.\nOver the years, several other differences have become prominent between urban areas and their rural counterparts:\nIn a world dependent on online communications, broadband access remains a challenge in rural areas. In all states, broadband access is higher in urban areas than in rural ones. While 63 percent of rural Americans say they have a broadband internet connection at home, increased from 35 percent in 2007, there are still many challenges to improving accessibility.\nThe cost of providing services is the most significant hurdle. Even where broadband is available, it is often prohibitively expensive, leading to gaps not only in access, but also in adoption. Lack of internet has widespread consequences, particularly for rural economic and educational opportunities.\nHealth and Opioids\nThere were more than 33,000 opioid-induced deaths in 2015, a fourfold increase from 2000. Although overall opioid mortality rates are higher in urban counties, mortality rates in rural areas have increased more quickly across all regions over the last two decades. Between 1999 and 2016, opioid death rates in rural areas have quadrupled among the 18 to 25 age group, and tripled for females. To treat and prevent opioid addiction, various healthcare services are required. Unfortunately, resources are more limited in rural areas.\nThe lack of improved access to healthcare services also has significant impacts on life expectancy. On average, from 2005-2009, the life expectancy in rural areas was 76.7, compared with 79.1 for urban dwellers, a gap that has widened significantly over the past 50 years. People living in rural areas are also more likely to die from the five leading causes of death, including heart disease, cancer and stroke, than their urban counterparts. In 2014, approximately 71,000 deaths among rural residents were potentially preventable.\nDespite the wide gulf between urban and rural communities, there are a number of challenges they share, from affordable housing to opioid addiction. These common challenges provide opportunities for shared solutions.\nAbout the Author: Rose Kim is a research associate in NLC’s Center for City Solutions."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:93227a52-da4b-435d-add4-629b480ef380>","<urn:uuid:8185aa9c-c26b-44ec-99aa-ee0ffaa16ac2>"],"error":null}
{"question":"As someone starting a blog monetization strategy, what's the connection between lead quality measurement and initial advertising pricing?","answer":"Lead quality measurement and initial advertising pricing are closely connected. For pricing, you should first analyze competitors' rates and initially offer discounted rates to break into tight markets. This helps establish your presence while you build credibility. Regarding lead quality, data shows that typically only 50% of leads are considered 'good quality' and ready for nurturing or sales. To demonstrate value to advertisers, you should implement lead scoring to assess lead quality, which involves assigning points to visitor interactions to rank leads. Additionally, you need to test ads on your site before selling them, gather reader feedback on implementation, and measure click-through ratios to show potential advertisers you can deliver results. This data becomes crucial for setting appropriate rates and convincing advertisers of your value proposition.","context":["How do I sell advertising on my blog? It is a question that I’m asked a lot so when Brandon J. Mendelson asked if he could write a post on this topic as someone who has sold a lot of advertising online and in TV I thought it’d make a great guest post.\nPutting together a media kit for your blog is an excellent start; However, unless you know how to navigate the competitive waters of advertising, the media kit will be useless.\nWhat’s Your Story?\nEveryone has one. Do you know what it is? Can you describe your blog in under a paragraph? Two sentences? Seven words? If you cannot, you are not ready to sell advertising.\nTake a few moments and condense your blog’s description into:\n-A paragraph, which you can use in your media kit\n-Two sentences, which you will use in your pitch email\n-Seven words, which you will use for your pitch’s email headline\nWait, Email? Shouldn’t I Call?\nHere you need to figure out what sector of the market you are looking for and what level the company finds itself at (local, regional, or national).The size of the company will determine the method of contact.\nFirst: Think of natural fits between what your blog is about and what product might best serve your audience. Today, it is not about advertising but adding value to your user’s experience. Advertisements are a reflection on you as much as they are on the advertiser, so choose wisely.\nSecond: How big is the company?\nEmailing a local store for advertising is a waste. You need to go in person or make a phone call. Small business owners do not have time to wade through sales emails; They need convincing when it comes to using their limited marketing dollars.\nA regional company may be more open to email, but most regionals started small and likely still posses a small business mindset of wanting to meet people first to gauge interest.\nA national corporation or international corporation? Don’t bother walking through the front door or making a phone call. Locate the marketing department’s email, which can usually be found by making a subtle, non-sales query to corporate communications, requesting that information.\nHow Much Information Is Too Much?\nYou want to use as little information as possible in an initial sales inquiry. This is who you are, this is what you do, this is what you are looking for. Are you interested? Include your contact information and move on to the next pitch.\nVolume is key, but automation will kill you since each letter must be personalized. You need to master the ability to effectively communicate with a minimal amount of effort and do it often to increase your odds of making a sale.\nThe same goes for phone conversations and stopping in person. You need to see if there is interest in what you are selling before proceeding.\nIn person or on the phone, you want to follow-up on interest by scheduling an appointment at a time that is convenient for the store owner. Call first, stop in second (if the store is local or regional), and email third.\nOnce you know someone is interested, then you can send your sales kit and other collateral. All of which should be kept brief. The odds are, if a party is interested they have already googled you and visited your website.\nMake sure your sales information is available on your website.\nWait, Won’t My Competitors See?\nYes, but if your competitor is any good, they will already know what you are charging. Charge what you think your services are worth, the only time your competitor’s rates matter is when you are first starting out. When starting out, you should see what your competition is charging and offer your services at a discounted rate. This will allow you to break into tight markets and get your name out there.\nHow Do I Know What To Charge?\nOnly you can decide how much your time is worth. Do not rely on Google Adsense or other online forms of measurement. Look at what the competition charges, ask yourself what an acceptable rate would be for your time and stick with it. Make sure to stay competitive by using stealth, but legal, methods to find out what your competition is charging.\nThink of it like this: There are no rules about sending a sales inquiry to your competitor or calling them to see what their rates are.\nWhen Can I Start?\nAdvertisers will come to you when you average 30,000 unique visitors a month without much drop off Until then you should factor:\nHow many subscribers do you have for your RSS feed? How many people follow you on Twitter? What is your Google, not Alexa, page rank? How often do you come up for key search terms for your niche? What your unique web traffic is?\nYou can go into the market and start charging for a new product at any time, but unless you have some sort of cross media access, it is best to firm up these numbers first.\nContracts And References\nIt is important to develop strong relationships with smaller advertisers who can vouch for: 1) Your character and 2) Your ability to deliver.\nCharacter is key. If you are not trusted, kiss access to bigger paydays goodbye.\nGet everything down on a sheet of paper that explains who gets what, when, and for how much. Deliver on what you promise, and serve as a resource for your advertisers.\nBy serving as a resource, you build credibility and positive relationships. These relationships are critical when it comes time to chase corporate sponsorship and they ask you to provide references from previous advertisers.\nBe prepared to be open as your business’s financial success to larger prospective advertisers. The more money on the line means more scrutiny.\nWho uses your website? When do they access it? How long are they on? What else do you know about your users? Marketing and demographic data is the linchpin of your entire sales kit.\nCorporations operate using systems such as Six Sigma to track department results in terms of their performance in utilizing resources (re: money).\nThe demographic and marketing information alleviates any concerns and allows for your advertising pitch to advance because marketing can show their superiors the resources are being allocated according to the corporate mission.\nHow do you do this? Surveys, soliciting feedback, conducting online focus groups are some examples to help compile this information. Read up on different qualitative and quantitative analysis methods to show that you know how to interpret the information.You do not need a consultant to do this for you.\nEven the simplest survey can tell you critical information as long as you know how to analyze it. This may sound daunting, but trust me, you will pick it up fast.\nHow do you know when to start advertising? When you are confident in your ability to deliver an acceptable amount of business to justify what you are charging.\nTest ads on your site before you sell them, ask for reader and user feedback on how to best implement them, see if you can get a high click through ratio or high awareness of imaginary post sponsors first.\nUse this information in your demographic data to share with advertisers and show them you can hold up your end of things.\nIf you are going to put up an advertisement when you say you are, do it. You are now responsible for someone’s money, and if you cannot hold up your end for just one client, you can expect others to find out quickly.\nGood luck, tread carefully, and be nice to everyone as you go through this process. It is easy to lose allies and resources than it is to make money.","What happens when you ask your team which KPIs indicate success for digital marketing? You gather a diversity of opinions that would make Google jealous.\nWithout a consensus around data, nothing gets measured and nothing can improve – yet nearly 50% of marketers struggle to align their KPIs to their overall business goals.\nSo, what are KPIs?\nKPIs are a measurable value that reflects a business objective and your company’s progress towards that end. They help you assess how successful you are in reaching a specific goal.\nTo avoid any confusion, KPIs are different than metrics. Metrics are simply data measurements whereas KPIs are used to assess strategy.\nHere are 10 digital marketing KPIs to help you evaluate the success of your campaigns.\n1. Revenue Driven by Digital Marketing Leads\nThis is the percentage of revenue that originated from digital marketing initiatives.\nTo calculate, total the revenue in a given period. Then determine how many of your closed leads were generated by the digital marketing team, and multiply by 100.\nThis will help you assess the campaign’s impact, optimally allocate your budget, and prove the ROI of your digital marketing.\nMarketing automation saves you time on this typically laborious task by automatically tracking each customer’s interactions across initiatives and campaigns until a final sale.\n2. Lead Quality\nLead quality shows you how aligned your lead generation efforts are with what your customers are actually looking for. According to Smart Insights, 48% of marketers say that only 50% of their leads are “good quality” and ready for nurturing or sales.\nIf you’re flush with quality leads, your digital marketing efforts are clearly resonating with your audience. But if lead quality is low, you should re-evaluate how your messaging is addressing your customers’ needs.\nLead scoring allows you to assess the quality of your leads. This methodology assigns points to visitor interactions to rank leads.\nScoring leads enables you to prioritize and engage the most qualified leads in your marketing funnel. To best determine what constitutes a qualified lead, get your sales and marketing teams in a room together and talk through it.\n3. Lead Volume\nThe number of leads you generate indicates the reach and quality of your digital marketing campaigns.\nLead generation is the top priority for B2B marketers, yet only leading brands are achieving their lead gen goals, according to Kapost.\nThis KPI is critical because a larger volume of leads translates to a greater number of sales opportunities. It shows you if your digital marketing campaign is reaching enough prospects to drive results.\n4. Customer Lifetime Value (LTV)\nCustomer lifetime value (LTV) is the projected value of a customer during their entire relationship with your brand.\nLTV is important because, for most marketers, it’s cheaper to sell to existing customers than to new customers.\nThe probability of converting a new customer is 5%-20%. However, the probability of selling to an existing customer is 60%–70%, according to the book Marketing Metrics.\nTo measure LTV, subtract the cost to acquire and serve the customer from the customer revenue. This is a simplified approach and your industry may contribute other variables worth considering.\nKnowing your LTV will help you to plan future marketing campaigns and improve customer interactions. It will also show you the optimal way to budget for customer acquisition and customer retention.\n5. Landing Page Conversion Rates\nThe value of your digital marketing operation is determined by its ability to translate leads into sales. Gauge the effectiveness of landing pages by the number of people who visit them and actually convert.\nTo find your conversion rate, divide the number of prospects in a given period by the number of customers acquired from landing pages.\nCollect these numbers from your website analytics or your automation database, then multiply by 100.\nIf conversion rates are coming out low, focus on your segmenting, channel alignment, and the perceived value of your gated resources.\n6. Website Traffic to Website Lead Ratio\nThis ratio helps you to measure the quality of website traffic and your website conversion rate.\nTo calculate, determine how many website visitors convert into leads.\nSeek first to find a baseline for your website. What is your current ratio? How can you improve it? Low conversions point to issues with the lead magnet, landing page copy, or user experience (UX) design of your website.\nThis graphic illustrates how high volumes of site traffic eventually become leads and customers.\nIf you know the ratio of web traffic to website leads, you can predict the total volume of traffic needed to reach your digital marketing goals.\n7. Website Traffic\nThe number of people visiting your website suggests the total numbers of available prospects. Comparing the volume of visitors against web traffic metrics can help you improve your lead generation efforts.\nSpecifically, look at metrics such as:\n- Bounce rate\n- Average session duration\n- Page views\n- Pages per session\nAny information gleaned from traffic interactions will help you discern what your visitors want from your site. Anticipating and addressing your visitors’ needs will allow you to target your audience segments more effectively.\n8. Customer Acquisition Cost (CAC)\nThe customer acquisition cost (CAC) is the amount needed to convert a prospect to a customer. For example, if your digital marketing budget is $10,000 and you close 10 new customers that quarter, your CAC is $1,000.\nWith CAC measured, you can set your goals for customer acquisition and budget accordingly. Be thorough in tabulating the costs per each acquisition, including any fees, expenses, or costs.\n9. Blog Post Visits\nThe performance of your blog posts indicates what your audience wants to read (and doesn’t). Clarity around your content assets means you can invest in resources that create brand equity and drive engagement with users.\nThe best-performing blogs are around 1,600 words in length, according to Buffer. They also feature high-quality, original images and other rich media to provide a positive user experience.\nTo encourage blog readership, invest in engaging and educational content that will hook and sustain the reader’s interest.\n10. Email Marketing Performance\nEmail is critical to digital marketing success, as a way to both engage users and drive revenue. Be sure to analyze each of your email marketing campaigns by multiple key metrics such as:\n- Delivery rate\n- Open rate\n- Click-through rate\n- Conversion rate\n- Unsubscribe rate\nFrom headlines and body copy to send rates and calls to action, effective email marketing includes many factors. Be sure to pay close attention to every element of your email marketing to ensure high opens and conversions.\nWinning with Digital Marketing KPIs\nWhy are best-in-class marketers so attuned to their data? Simply, because they know that effective campaigns are informed by real-time insights and data-driven optimization.\nWith ready access to digital marketing KPIs, you can achieve total clarity across your marketing and sales efforts – and marketing automation makes it easy to stay responsive and drive meaningful results."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"premise_categorization","category_name":"with premise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_follow_up_likelihood","category_name":"moderate_follow_up"}],"document_ids":["<urn:uuid:efe88c81-5d85-48e4-a088-5f2393144ed4>","<urn:uuid:9fcc0721-3447-4011-8bce-6aa76f4d87c8>"],"error":null}