{"question":"How does probation before judgment work as a first-time offender program, and what are its key advantages compared to traditional probation?","answer":"Probation before judgment (PBJ) works by allowing first offenders to avoid a conviction by entering a guilty plea or nolo contendere, after which the court defers proceedings and places the offender on probation with specific conditions. If they comply with all terms, no conviction is entered on their record. Compared to traditional probation, PBJ offers several advantages including reduced risk of criminal sanctions, better rehabilitation opportunities, increased employment prospects, and increased use of community services. However, eligibility is restricted to certain offenses and requires both state and court consent.","context":["What is probation before judgment?\nProbation before judgment (PBJ) provides a means for a first offender to avoid having a conviction entered against him or her. PBJ works as follows:\n- The offender enters a plea of guilty or nolo contendere.\n- The Court defers further proceedings and the entry of a judgment of conviction against the offender.\n- The Court places the offender on probation for a period of time with such terms and conditions as the Court decides are appropriate.\n- If the offender complies with the terms and conditions, at the end of the period of probation, no conviction will be entered on the record.\nAm I eligible for probation before judgment?\nYou may be eligible if you are charged with a violation or misdemeanor offense under Titles 4, 7, 11, or with certain violations or misdemeanors under title 21 (not violations of §§ 2701, 2756, 4103, 4175, 4177, 4201, 4202, or any violation of chapter 67, of Title 21). You are not eligible if your offense falls under the following programs: first offenders domestic violence diversion program (§ 1024 of title 10); conditional discharge for issuing a bad check as a first offense (§ 900A of Title 11); first offenders controlled substances diversion program (§ 4764 of Title 16); or first offenders program for driving while intoxicated (§ 4177B of Title 21).\nYou are not eligible if you are currently serving a sentence of incarceration, or are on probation, on parole, or on early release of any type imposed for another offense.\nYou are not eligible if you have entered the PBJ program for any offense within five years of the current offense.\nYou are not eligible if you have been convicted of certain offenses.\nIf you are otherwise eligible, you must still have the consent of the State and the Court to your entry into the PBJ program.\nWhat previous convictions make me ineligible for PBJ?\nIf you are presently charged with a TITLE 11 criminal offense, you are NOT eligible to enter into PBJ for that offense if:\n- You have ever been convicted of a violent felony, as defined by 11 Del.C. § 4201(c), or\n- You have been convicted of a non-violent felony within ten years of the date of the alleged offense, or\n- You have been convicted of a Title 11 misdemeanor offense within five years of the date of the alleged offense.\nIf you are charged with a violation of Title 21 which is otherwise eligible for PBJ (see above), you are NOT eligible for PBJ if you have been convicted of any Title 21 offense within five years of the date of the alleged offense.\nIf you are charged with a TITLE 4 offense, you are not eligible for PBJ if you have been convicted of a Title 4 offense within 5 years of the date of the alleged offense.\nIf you are charged with a TITLE 7 offense, you are not eligible for PBJ if you have been convicted of a Title 7 offense within five years of the date of the alleged offense.\nI think I am eligible for PBJ. What should I do?\nIf you meet all the requirements of PBJ as explained above, you should advise the Court that you wish to enter into the program. THE COURT HAS THE FINAL DECISION CONCERNING ENTRY INTO THE PROBATION BEFORE JUDGMENT PROGRAM. To enter into PBJ, the defendant's case may be scheduled for trial so that the State has the opportunity to consent or oppose the defendant's entry into PBJ. If you are admitted to PBJ, you will be required to sign a Probation Before Judgment Agreement. In signing this agreement, you give consent for the Court to enter a judgment of conviction and sentence against you in your absence, should you fail to provide timely proof that you complied with the terms and conditions of your probation.\nWhat types of terms and conditions will I have to comply with if I am offered PBJ?\nAll persons entering into PBJ must comply with the following:\n- Provide the Court with a current address\n- Promptly provide the Court with written notice of a change of address\n- Appear at a compliance hearing\nOther terms and conditions will depend on the specific case and will be ordered at the judge's discretion. Such terms and conditions may include ordering the defendant to:\n- Pay a monetary penalty and/or court costs\n- Pay restitution\n- Perform community service\n- Refrain from having contact with certain persons\n- Conduct themselves in a specified manner\nHow long will I be on probation?\nThe period of probation will be at the discretion of the judge, but cannot exceed the maximum time for commitment provided by law for the specific offense with which you are charged, or one year, whichever is greater.\nWill I have to report to a probation officer?\nNo. Probation under PBJ is handled by the Justice of the Peace Court itself and the terms and conditions are monitored by the Court.\nWhat happens at the end of my probation?\nYou will be scheduled for a compliance hearing (notice of the time and date of the hearing will be sent to you at the address you have given to the Court). At, or prior to the hearing, you must provide proof that you have complied with any conditions of probation. If you are found to have complied with all conditions, the Court will dismiss the action against you and you will not have a conviction on your record. If the Court finds that you have failed to comply with all conditions, a conviction will be entered against you and you will be sentenced as if you had not been placed on PBJ (except that you will be given credit for any monies already paid to the Court). If you fail to appear at the compliance hearing, a warrant for your arrest for failure to appear will be issued.","Community Corrections Also known as community-based corrections, community corrections: Refers to a wide range of sentences that depend on correctional resources available in the community. Permit convicted offenders to remainin the community under conditional supervision as an alternative to an active prison sentence. Community Corrections Examples include the following: Probation Parole Home confinement Electronic monitoring Probation A sentence of imprisonment that is suspended; instead, the sentence is served while under supervision in the community. This is conditional freedom granted by a judicial officer to a convicted offender, as long as the person meets certain conditions of behavior. History of Probation English Roots: By the fourteenth century, English courts began the practice of ?binding over for good behavior,? in which offenders were placed in the custody of willing citizens. History of Probation In the U.S.: The first probation officer was John Augustus (1784-1859), a Boston shoemaker who observed court proceedings and volunteered to take home drunkards. He supervised over 2,000 offenders. In 1878 Massachusetts enacted a statute that provided for the first paid probation officer. By 1925, all states and the federal government had similar legislation. The Extent of Probation Probation is the most commonly used form of sentencing. 20-60% of guilty individuals are placed on probation. The number of offenders supervised yearly on probation increased from slightly more than 1 million people to over 4 million today. States vary with regard to extent of use. Even violent offenders may receive probation. Probation Conditions Probationers must abide by court-mandated conditions or risk probation revocation. There are two types of conditions: general and specific. Probation Conditions General Conditions Apply to all probationers within the jurisdiction. Examples: Obey laws Maintain employment Remain within jurisdiction Allow probation officer to visit home or work place Pay court ordered fines Specific Conditions Judge-mandated for the specific probationer. Examples: Surrender driver?s license Pass GED test Do community service Curfew Complete a treatment plan Federal Probation Officers There are approximately 7,750 federal probation officers, also called community corrections officers. They have the statutory authority to arrest probationers for a violation, but are encouraged to get an arrest warrant and have it executed by the U.S. Marshals. Some carry weapons. What is Parole? Parole?a prisoner reentry strategy in which inmates receive supervised conditional early release from correctional confinement. Parole vs. Probation Parole Offenders spend time incarcerated before release. Parole is an administrative decision made by paroling authority. Parolees must abide by conditions or risk revocation. Probation Probationers generally avoid prison time. Probation is a sentencing decision made by a judge. Probationers must abide by conditions or risk revocation. Parole Decision-Making Mechanisms: Two Approaches Parole Boards Grant discretionary parole based on judgment and assessment by parole board. Statutory Decrees Produce mandatory parole, with release date set near sentence end, minus good time. * More common Extent of Parole There?s a growing reluctance to use parole. Only 25% of parolees are released via discretionary parole. Mandatory parole releases have increased 91% since 1991. Extent of Parole Of all parolees: 44% successfully complete parole. 26% return to prison for parole violations. 11% return to prison for new violations. Parole Conditions In discretionary parole jurisdictions, the conditions of parole are similar to probation conditions. Violations may result in parole revocation. Examples of conditions include: Periodically reporting to parole officer Maintaining employment Paying fines and restitution Sometimes paying a ?parole supervisory fee? Federal Parole Federal parole decisions are made by the U.S. Parole Commission. Commissioners consider an inmate?s readiness for parole. The U.S. Parole Commission must be periodically recertified by Congress. Advantages and Disadvantages of Probation and Parole Advantages Low cost Increased employment Restitution Community support Reduced risk of criminal sanctions Increased use of community services Better rehabilitation opportunities Disadvantages Relative lack of punishment Increased risk to community Higher social costs Discriminatory and unequal effects Griffin v. Wisconsin (1987) Supreme Court ruled that probation officers may conduct searches of a probationer?s residence without a search warrant or probable cause. Though the 4th Amendment normally provides for privacy, probation ?presents special needs beyond normal law enforcement that may justify departures.? Pennsylvania Board of Probation and Parole v. Scott (1998) Supreme Court declined to extend the exclusionary rule to searches done by parole officers. U.S. v. Knights (2001) Expanded the search authority normally reserved for probation and parole officers to police officers under certain circumstances. Sampson v. California (2006) The U.S. Supreme Court found that the Fourth Amendment does not prohibit police officers from conducting a warrantless search of a person who is subject to a parole search condition, even when there is no suspicion of criminal wrongdoing and the sole reason for the search is because the person is on parole. Revocation Hearings Revocation hearing?a hearing used to determine whether a parolee or probationer has violated the conditions and requirements of his or her parole or probation. Outcomes of Revocation Hearings Annually, about 25% of parolees and of probationers have their conditional release revoked. Most are for: Failure to report to probation or parole officer Failure to participate in a stipulated treatment program Alcohol or drug abuse while under supervision. Mempa v. Rhay (1967) U.S. Supreme Court held that in probation revocation decisions both notice and a fair hearing are required and probationer must have the opportunity to be represented by counsel. Morrissey v. Brewer (1972) U.S. Supreme Court held that parole revocation proceedings require the following: Written notice of specific alleged violation Disclosure of evidence of violation An impartial hearing body Opportunity to offer a defense A right to cross examine witnesses A written statement of the outcome Gagnon v. Scarpelli (1973) U.S. Supreme Court held that probationers are entitled to two hearings. A preliminary hearing to determine whether or not probable cause exists. A more comprehensive hearing prior to the final decision about revocation. Those hearings were to be done under the conditions specified in Morrissey. Greenholtz v. Nebraska Penal Inmates (1979) Parole boards do not have to specify the evidence used in deciding to deny parole. Bearden v. Georgia (1983) Probation cannot be revoked for failure to pay a fine and make restitution if it could not be shown that the defendant was responsible for the failure?alternative forms of punishment must be considered before imposing a prison sentence. Minnesota v. Murphy (1984) A probationer?s incriminating statements to a probation officer may be used as evidence if the probationer does not specifically claim a right against self-incrimination. The Job of Probation and Parole Officers Job Functions Presentence investigations Intake procedures Needs assessment/diagnosis Supervision of clients Job Challenges Balancing conflicting roles Large caseloads Frequent lack of opportunities for upward mobility Stress Intermediate Sanctions The use of non-traditional sentences in lieu of imprisonment and fines. These sentences offer alternatives that fall somewhere between simple probation and outright incarceration. Also called alternative sentencing strategies. Types of Intermediate Sanctions Examples include: Split sentences Shock probation/parole Shock incarceration Mixed sentences and community service Intensive supervision Home confinement and electronic monitoring Advantages of Intermediate Sanctions There are three distinct advantages: Less expensive, per offender, than prison They are ?socially cost effective? Provide flexibility in terms of resources, time, and place Split Sentencing Split sentencing involves a combination of brief incarceration followed by probation. Frequently used for minor drug offenders. Shock Probation/Parole With shock probation, offender is sentenced to prison and is allowed to apply for probationary release. Offender usually does not know if he will be released and expects to serve a long prison term. Shock parole is similar, but the decision is administrative rather than judicial. Shock Incarceration Shock incarceration programs use ?boot camps? to demonstrate reality of prison life. Mainly used for first time offenders. Involves strict discipline and physical training. Programs typically last from 90-180 days. ?Failures? return to general prison population. Appear ?tough on crime,? but research shows negligible impact on recidivism Mixed Sentencing Mixed sentencing?a sentence that required that a convicted offender serve weekends in a confinement facilities while undergoing probationary supervision in the community. Community Service Community service?requires offenders to spend time working for a community agency. Services can include washing of police cars, cleaning graffiti, and refurbishing public facilities. Intensive Supervision Intensive probation supervision (IPS) is the strictest form of probation. Frequent face-to-face contacts with probation officer Mandatory curfew Employment required Frequent check of local arrest records Unannounced drug testing Home Confinement and Electronic Monitoring Home confinement??house arrest??issometimes combined with electronic monitoring. People may be allowed to leave during work hours and in emergencies. Frequently used with certain types of offenders: pregnant women, geriatric offenders the terminally ill Future of Probation and Parole Criticized by many citizen groups, academics, some government officials, and even some prisoners. Parole advocates caution that eliminating parole can lead to public safety issues and wasting tax dollars. Some jurisdictions are moving toward a system of reentry courts with judges acting as reentry managers. Changes in Reentry Policies Most inmates will be released back into society. Barriers to successful reentry need to be addressed, including: Substance abuse Lack of education Poverty Diminished opportunities for employment Physical or mental disabilities Changes in Reentry Policies Successful reentry requires a multi-faceted, collaborative approach involving people and groups throughout the community, including: Corrections Public health workers State legislators Housing providers Workforce development staff The Serious Violent Offender Reentry Initiative (SVORI) Funding for SVORI began in 2003, with the goal of successfully reintegrating serious and violent offenders: Phase 1?Protect and Prepare: Institution-Based Programs Phase 2?Control and Restore: Community-Based Transition Programs. Phase 3?Sustain and Support: Community-Based Long-Term Support Programs Reinventing Probation The ?get tough? attitude of the 1990s increased funding for prisons but neglected to do the same for probation. Reinventing probation requires regaining public trust and reinvestment.\nWant to see the other 46 page(s) in cj+ch+12.ppt?JOIN TODAY FOR FREE!"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:2b74e5ee-7a77-42d2-a9b5-596d50cc465d>","<urn:uuid:36ffe809-01cd-4ba4-8c90-c5da94254e30>"],"error":null}
{"question":"How do mole drainage and vertical well drainage compare in terms of their soil type requirements and durability?","answer":"Mole drainage and vertical well drainage have different soil type requirements and durability characteristics. Mole drainage only works effectively in heavy, non-dispersive clay soils, as the soil must have sufficient cohesive strength to maintain the channel formed by the mole plough - in sandy soils, the channel would simply collapse. Mole drainage channels can last up to 10 years. In contrast, vertical well drainage through pumped wells requires the well filter to be placed in a permeable soil layer, making it suitable for areas with good aquifer properties. Well drainage systems can be more durable and flexible since they're constructed with proper infrastructure, though their effectiveness depends on the aquifer's properties and groundwater quality. They can be designed for long-term operation given proper maintenance and appropriate soil conditions.","context":["- Well drainage\nWell drainage means drainage of agricultural lands by wells. Agricultural land is drained by pumped wells (vertical drainage) to improve the soils by controlling water table levels and soil salinity.\nSubsurface (groundwater) drainage for water table and soil salinity in agricultural land can be done by horizontal and vertical drainage systems.\nHorizontal drainage systems are drainage systems using open ditches (trenches) or buried pipe drains.\nVertical drainage systems are drainage systems using pumped wells, either open dug wells or tube wells.\nBoth systems serve the same purposes, namely water table control and soil salinity control .\nBoth systems can facilitate the reuse of drainage water (e.g. for irrigation), but wells offer more flexibility.\nReuse is only feasible if the quality of the groundwater is acceptable and the salinity is low.\nAlthough one well may be sufficient to solve groundwater and soil salinity problems in a few hectares, one usually needs a number of wells, because the problems may be widely spread.\nThe wells may be arranged in a triangular, square or rectangular pattern.\nThe design of the well field concerns depth, capacity, discharge, and spacing of the wells.\n- The discharge is found from a water balance.\n- The depth is selected in accordance to aquifer properties. The well filter must be placed in a permeable soil layer.\n- The spacing can be calculated with a well spacing equation using discharge, aquifer properties, well depth and optimal depth of the water table.\nThe determination of the optimum depth of the water table is the realm of drainage research .\nFlow to wells\nThe basic, steady state, equation for flow to fully penetrating wells (i.e. wells reaching the impermeable base) in a regularly spaced well field in a uniform unconfined (preactic) aquifer with an hydraulic conductivity that is isotropic is  :\n- Q = 2π K (Db - Dm) (Dw - Dm) / ln (Ri/Rw)\nwhere Q = safe well discharge - i.e. the steady state discharge at which no overdraught or groundwater depletion occurs - (m3/day), K = uniform hydraulic conductivity of the soil (m/day), D = depth below soil surface, Db = depth of the bottom of the well equal to the depth of the impermeable base (m), Dm = depth of the watertable midway between the wells (m), Dw is the depth of the water level inside the well (m), Ri = radius of influence of the well (m), Rw=radius of the well (m), ln = natural logarithm, and π = the number pi.\nThe radius of influence of the wells depends on the pattern of the well field, which may be triangular, square, or rectangular. It can be found as:\n- Ri = sqrt (At/πN)\nwhere At = total surface area of the well field (m2), N = number of wells in the well field, and sqrt=square root.\nThe safe well discharge (Q) can also be found from:\n- Q = q At / N Fw\nwhere q is the safe yield or drainable surplus of the aquifer (m/day) and Fw is the operation intensity of the wells (hours/24 per day). Thus the basic equation can also be written as:\n- Dw - Dm = q At ln (Ri/Rw) / 2π K (Db - Dm) N Fw\nWith a well spacing equation one can calculate various design alternatives to arrive at the most attractive or economical solution for watertable control in agricultural land.\nThe basic flow equation cannot be used for determining the well spacing in a partially penetrating well-field in a non-uniform and anisotropic aquifer, but one needs a numerical solution of more complicated equations.\nThe costs of the most attractive solution can be compared with the costs of a horizontal drainage system - for which the drain spacing can be calculated with a drainage equation - serving the same purpose, to decide which system deserves preference.\nThe well design proper is described in \nAn illustration of the parameters involved is shown in the figure. The hydraulic conductivity can be found from an aquifer test.\nThe numerical computer program WellDrain  for well spacing calculations takes into account fully and partially penetrating wells, layered aquifers, anisotropy (different vertical and horizontal hydraulic conductivity or permeability) and entrance resistance.\nWith a groundwater model that includes the possibility to introduce wells, one can study the impact of a well drainage system on the hydrology of the project area. There are also models that give the opportunity to evaluate the water quality.\nSahysMod  is such a polygonal groundwater model permitting to assess the use of well water for irrigation, the effects on soil salinity and on depth of the water table.\nAgricultural water management IrrigationSurface irrigation · Tidal irrigation · Irrigation of alluvial fans · Irrigation statistics · Irrigation management · Irrigation environmental impacts Subsurface drainageTile drainage · Drainage equation · Drainage system (agriculture) · Watertable control · Drainage research · Drainage by wells Surface water/runoff GroundwaterGroundwater flow · Groundwater energy balance · Groundwater model · Hydraulic conductivity · Watertable Problem soils Agro-hydro-salinity groupHydrology (agriculture) · Soil salinity control · Leaching model (soil) · SaltMod integrated model · SahysMod polygonal model: Saltmod coupled to a groundwater model Related topicsSand dam ·\n- ^ a b c Boehmer, W.K., and J.Boonstra, 1994, Tubewell Drainage Systems, Chapter 22 in: H.P.Ritzema (ed.), Drainage Principles and Applications, Publ. 16, International Institute for Land Reclamation and Improvement (ILRI),Wageningen, The Netherlands. pp. 931-964, ISBN 90 70754 3 39 . On line : \n- ^ ILRI, 1999, Drainage and Hydrology/Salinity: Water and salt balances, 29 pp. Lecture notes of the International Course on Land Drainage (ICLD), International Institute for Land Reclamation and Improvement (ILRI), Wageningen, The Netherlands. On line : \n- ^ a b ILRI, 2000, Subsurface drainage by (tube)wells: Well spacing equations for fully an partially penetrating wells in uniform or layered aquifers with or without anisotropy and entrance resistance, 9 pp. Principles used in the \"WellDrain\" model. International Institute for Land Reclamation and Improvement (ILRI), Wageningen, The Netherlands \nDownload \"WellDrain\" software from :  , or from : \n- ^ SahysMod, Spatial Agro-Hydro-Salinity Model: Description of Principles, User Manual, and Case Studies. SahysMod working group of the International Institute for Land Reclamation and Improvement, Wageningen, the Netherlands. On line:  .\nDownload the model from :  , or from : \n- Salinity Control and Reclamation Program (SCARP) using wells in the Indus valley of Pakistan.\n- Website on waterlogging and land reclamation by horizontal and vertical drainage systems : \n- Hydraulic engineering\n- Land management\n- Land reclamation\n- Water and the environment\nWikimedia Foundation. 2010.","1 What causes land drainage problems – the principles of water movement in soils\nWhilst the effect of a functioning land drainage scheme can be observed by all, a basic understanding of the physical principles which govern this process enables the observer to both assess the effectiveness of a land-drainage scheme and also to appreciate why inappropriately or poorly designed drainage schemes fail to work.\nFigure 1 A diagram depicting a microscopic view of soil\nThe key to all of the following discussion is to understand what makes up a rootzone. The key ingredients are:\n1.Mineral particles (sand,silt,clay)\n4. Organic matter\nConsider for example the soil rootzone represented in Figure 1, mineral and organic particles are locked together to form the solid fraction of the soil, whilst the pores (the spaces between the solid particles) are occupied by either soil water or soil air. The combination of solids, water and air is critical for not only plant growth, turfgrasses need all three components, but also surface strength.\n1.1 Sports surface strength and soil moisture content\nThe resistance of a football pitch to wear by players and the ability of a pitch to provide a stable platform for quality football is highly dependent upon the turfgrass and the soil in which it grows. The grass plant provides a cushioned surface, with natural lubrication to reduce skin abrasion – its root network also provides a core structural function. The soil not only provides an anchorage for the grass plant but it is also the key load bearing component. The two components combined (grass and soil), must be of sufficient strength to resist damage from repeated use – both from running and sliding, but not of excessive strength so as to cause impact or musculoskeletal damage.\nFigure 2 The effect of soil moisture content and bulk density on rootzone strength. As moisture content increases, surface strength initially increases but then rapidly decreases. As bulk density increases from Bulk density 1 to Bulk density 2, the rootzone strength increases\nThe strength of a turfgrass plant is a function of agronomic factors related to plant health and growing environment. The strength of a natural soil or sand rootzone is a question of engineering and is closely related to the bulk density of the soil (how well packed the soil is) and its moisture content (how wet the soil is). Typically, as bulk density increases – soil strength increases and as moisture content increases – soil strength decreases (see Figure 2).\nThe principal target for groundstaff is to prepare surfaces that have a sufficiently high bulk density so as to provide strength to resist wear. The problem is that as bulk density increases, porosity (the amount of pores in a soil) decreases and restricts the amount of air in the soil available for the turfgrass; a balance is required.\n1.2 Water movement and retention in soils\nAs is shown in Figure 1, water occupies the pore space in a soil; it also illustrates the range of pore sizes in a soil. Water is held in a pore by capillary action, effectively sucking water into the pore – this is the same way in which a sponge absorbs a liquid. Large pores create a low amount of suction; small pores create high amounts of suction – therefore the size of pores is critical in water movement in soils.\nFigure 3 Unsaturated (a) and saturated (b) rootzones. In the saturated condition all the pores are full of water\nAll the water in a soil is being pulled downwards by gravity, large pores will drain because there is not enough suction to hold the water in the pore against gravity, meanwhile small pores, where the suction is greater than the pull of gravity do not drain. This is why sandy soils, where the particles are large, and hence the pores are large, drain easily under gravity, but clay soils, where the particles and pores are very small will hardly drain under gravity and require land drainage schemes. In fact in clay soils, it is very difficult to pull water out – it must be pushed out, this happens when the soil is saturated (see Figure 3).\nThe same physical property also means that water is pulled upwards (and sideways) to occupy dry pores – a phenomenon known as capillary rise.\nSaturation in a soil is defined as when all the pores are full of water. Note that any water applied to the top of the soil in Figure 3b will displace water out of the bottom of the soil by pushing it out as a head of water builds (see Figure 4a). The rate at which the water moves through and out of the soil is known as the saturated hydraulic conductivity. In a coarse grained soil such as a sand rootzone, the hydraulic conductivity is high; in finer clay soils, the hydraulic conductivity is orders of magnitude lower.\nFigure 4 Flooding due to high water table; (a) water added to the top of the saturated soil displaces water from the freely draining base of the profile; (b) when the water table is high, water cannot flow out of the soil and accumulates at the surface – flooding the pitch\nIf there is no exit for the water below (e.g. the water table lies directly below the soil) then water will accumulate at the surface, water logging and eventually flooding the pitch (Figure 4b). This situation is known as a ground water drainage problem and can be solved by lowering the water table with piped drainage so that the soil has a greater storage capacity for rain water (Figure 5).\nSuch groundwater problems in sports surfaces are actually quite rare. The majority of waterlogging and flooding of football pitches is actually caused by another problem entirely – requiring a different solution.\n1.3 Infiltration and surface drainage problems\nFlow of water in and out of the soil in Figure 4a assumes that water can get into the top of the soil in the first place. The entry of water into the top of a soil is termed infiltration. Typical infiltration rates for different soils and rootzones used in sports surfaces are shown in Figure 6. The difference between a high sand content rootzone, such as a 70/30 mix, and a compacted clay is of several orders of magnitude.\nFigure 5 The effect on a groundwater table of the installation of piped drainage. Note that at the drain locality, the water table is lowered, increasing the capacity of the soil to store rainwater and reducing the frequency of flooding. Note also, how the water table rises in-between the drains – the height to which it rises is a function of the depth of drains and their spacing. If the drains are too shallow or too far apart, they can actually cause flooding – a common indication of poor drainage design\nThe infiltration rate (how quickly water enters the soil) is a function of many factors but is governed by the pore space in the soil – if the soil has an open structure at the surface water can flow into the soil easily; if the soil is capped or has small pores, the infiltration rate is reduced (Figure 7).\nLow infiltration rate in sports surfaces is caused by:\n· small pore sizes (eg. clay soils)\n· compaction (wheeled traffic)\n· capping (silts or sliding feet)\n· some types of organic matter, including thatch\n· or a combination of all of these.\nThe inability to get water into a sports surface is one of the most common land drainage issues and is known as a surface drainage problem.\nFigure 6 Typical infiltration rates for different soil media\nConsideration of the above factors shows why clay soils are so susceptible to this problem – they have very small pores and the surface is easily smeared – providing a water tight seal over the soil. Installation of groundwater drains such as in Figure 5 will not solve this problem, the water cannot even get into the soil, let alone exit through the drains. If waterlogged and flooded pitches are to be avoided then it is necessary to bypass this impermeable surface completely using a surface drainage (or bypass) system. A surface drainage system uses bands of higher hydraulic conductivity / infiltration rate material to allow precipitation to bypass the low conductivity soil, straight from the surface to a piped drainage system. Such a scheme is detailed in Figure 8; the low conductivity soil (such as a heavy clay) has a very low infiltration rate and low hydraulic conductivity.\nFigure 7 The effect of particle size on infiltration rate: (a) coarse particles with wide pores allows water to infiltrate easily; (b) smaller particles with smaller pores restrict or prevent infiltration\nIn this system, some of the water from precipitation will pass slowly into the low conductivity soil – providing water to the grass plant. The majority of water, however, will flow across the surface and through the topdressing layer, into the vertical sand slits and then down into the collector drain and out to an outfall – completely bypassing the slowly permeable soil.\nThe system requires two key components for it to be effective:\n1. A high hydraulic conductivity connection to the surface – if a vertical slit becomes capped with fine textured soil, water cannot flow into the system and it will be redundant. For this reason it is necessary to provide frequent topdressing and careful devoting of the surface.\n2. An adequate collector drain network and outfall – if the water is not taken away, the material will become saturated rapidly and the system will not function.\n1.4 Review of the key principles in selecting land drainage design\nFor the design of effective drainage in natural turf pitches the following points must be considered:\nFigure 8 A cross section and plan view of a sand slit system as an example of a surface or bypass drainage system for a low conductivity soil football pitch\n1. An investigation to determine whether the problem is caused by a water table (groundwater drainage) or a low infiltration rate (surface drainage).\n2. An investigation to determine the physical properties of the native soil.\n3. Determination of the correct depth and spacing for any piped drainage infrastructure.\n4. Calculation of the correct capacity for any infrastructure.\n5. Selection of hydraulically compatible and appropriate materials.\n6. Connection to free flowing outfall.\n7. Provision for hydraulic connection to the surface for bypass systems\nToo many land drainage schemes fail because these points have not been addressed. The system must be designed to solve the problem in the field. As discussed above, the most common drainage problem is that of surface drainage in fine textured (clay) soils.\n2 Sand Slit Drainage\nIf designed correctly and well maintained, sand slit drainage systems, such as the one illustrated in Figure 8, will reduce the risk of flooding and fixture cancellation.\nThe benefit of sand slit drainage systems A typical system of 1 m spaced sand slits (350 m deep) over a perpendicular lateral pipe network of 80 mm diameter drainage pipe (at a spacing of ~ 6 m and depth of 0.6 m) will provide sufficient drainage to prevent waterlogging in all but the most extreme conditions; with the proviso that such a system is regularly topdressed with a compatible sand. Over a period of years, prevention of revenue loss from fixture cancellation will offset the cost of installation and maintenance of a sand slit system. Less tangible benefits might include, improved reputation, the opportunity to stage higher profile fixtures – such as county tournaments etc, and improved training and youth development.\nThe sand slit system is highly effective and can be installed at a lower cost than a sand carpet system, where the complete pitch area is excavated and replaced with a purchased high sand content rootzone. The ongoing maintenance of sand slits is relatively cheaper and more straightforward than a sand carpet system too.\nInvestment in a sand slit and pipe drainage system that is regularly top-dressed will provide an effective land drainage scheme that will provide a direct, significant improvement to any facility where it is installed. As such, funding bodies can feel reassured that sand slit and pipe drainage will provide an effective return on investment (again, with the proviso that the facility in receipt has sufficient resources to both top up and topdress the system).\n3 Mole drainage\n3.1 The principles of mole drainage\nMole drainage is achieved by pulling a bullet-shaped plough through the soil to create a contiguous channel at depth. This channel provides a high hydraulic conductivity bypass conduit for water flow. The Cranfield University Mole Plough is shown in Figure 9. It is pulled through the soil at a depth of at least 400 mm, with a slight grade to encourage water flow.\nAs the plough is pulled through the soil, at approximately 1-2 m spacing, a vertical leg slot is formed, in addition a number of cracks are formed from the foot of the plough up to the surface as the soil is disturbed. These cracks form the principal bypass for water flow, connecting the surface to the mole channel (Figure 10). In agricultural, mole drainage surface heave is encouraged to help loosen the soil. In the drainage of sports surfaces, however, this is undesirable as surface disturbance upsets ball roll and can be a trip hazard.\nThere is a limited range of soil types that are suitable for mole drainage – essentially heavy, non-dispersive clay soils. The mole channel is cut by the foot, but formed by the expander. The expander forces displaced soil into the walls of the channel. In a sandy soil, the soil would simply collapse following the expander; in a clay soil, the soil is smeared and has sufficient cohesive strength to hold the channel open. As the channel dries it sets to form a hard walled channel, which can last anything from to 10 years.\n3.2 The benefit of mole drainage in sports fields\nThe benefit of this approach to drainage is cost – there are no materials required. The principal costs are labour, time, fuel and wearing of parts. There are reduced costs for drainage pipe and backfill material if a lateral collector system is required. As discussed above, however, the drainage scheme must be both low cost and drainage effective.\n3.3 The cost of mole drainage in sports fields\nA critical factor in the drainage of sports surfaces is the time taken to return to play following completion of works. With mole drainage there are three principal concerns:\n1. Surface disturbance\n2. Dangerous leg crack widths\n3. Durability and collapse of moles\nSurface disturbance is caused by incorrect mole plough design, technique and soil conditions. Soil conditions are also responsible for short-lived moles too. Dangerous leg crack widths are a function of a soil property that affects clay soils and any drainage scheme. Due to the complex mineralogy of clay soils they exhibit shrink and swell properties. As the clay particles get wet they expand, as they dry out they shrink. This property causes the leg slot crack caused by the installation of the mole to expand as the soil dries through the summer – this expansion can reach a critical width whereby the risk of ankle joint or tendon injury is too high and fixtures are cancelled until the soil becomes wet and swells, closing the crack.\nCareful consideration of the factors must be taken into account when installing mole drains. The critical requirements are the operating parameters – such as depth of installation, soil moisture content at installation and post installation management.\nThe article is an extract from the final report of a Football Foundation funded research project entitled The physical and financial benefits of mole drainage as an alternative to sand slitting in slowly permeable soils.\nThe research was conducted by:\nContact and principal author: Dr Iain James\nCranfield Centre for Sports Surfaces\nSchool of Applied Sciences, Building 42a\nBedford MK43 0AL\nTel. No: +44 (0)1234 750111 ext 2736\nManagement Systems Ltd\nContact: Dr Richard Earl\nUnit 1, Highfield Parc\nBedford MK43 7TA\nTel. No: +44 (0)1234 821750\nShould you have any further questions please do not hesitate to contact us"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"future"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:cfaef3d7-bf8b-47a5-ab14-1b69c4a28f86>","<urn:uuid:67557ce9-d7ef-4963-8eb3-8f42118aa552>"],"error":null}
{"question":"How does groundwater recharge occur naturally in Oklahoma aquifers, and what methods are used for artificial recharge to enhance water storage?","answer":"Natural groundwater recharge in Oklahoma occurs primarily through drainage from soil profiles, with rates ranging from 0.2 inches per year in the Panhandle to 10.5 inches per year in northeast Oklahoma. On average, approximately 8% of rainfall in Oklahoma becomes drainage that can recharge aquifers. For artificial recharge, there are several common methods: spreading basins and ditches for near-surface applications, pits and shafts for penetrating below surface restrictive layers, and direct well injection into the unsaturated zone. The success of artificial recharge depends on site conditions - optimal areas should have high permeability soils, capacity for horizontal water movement, lack of impeding layers, and a thick unsaturated zone. Water should ideally reach the saturated zone and spread laterally rather than building up vertically.","context":["Statewide Estimates of Potential Groundwater Recharge\nGroundwater is water that is found naturally in aquifers, which are underground layers of permeable rock or unconsolidated materials. The depth at which these water reservoirs occur varies by location (spatially) as well as with time (temporally), and can range from the soil surface to many hundreds of feet below ground. There are three types of aquifers: 1) confined aquifers, 2) unconfined aquifers and 3) perched aquifers. Confined aquifers have a confining layer both above and below a saturated zone. A confining layer is any layer of material that restricts the movement of water. An unconfined aquifer is one that has a confining layer only at the bottom of the formation. Perched aquifers are unconfined aquifers of limited areal extent that retain water due to some restricting layer, such as a clay layer. For more information on the basics of groundwater hydrology, see Extension Fact Sheet WREC-104, “Introduction to Groundwater Hydrology and Management.”\nGroundwater aquifers are important sources of water for agricultural, municipal and household use across the world, sustaining one-fourth of the human population (Ford and Williams, 1989). It is estimated that there are more than 390 million acre-feet of groundwater in Oklahoma, most of which is held in the state’s 22 major aquifers (see Extension Fact Sheet WREC-104, “Introduction to Groundwater Hydrology and Management.”). These aquifers supply nearly half of all water used in Oklahoma and more than 70 percent of water used for agricultural irrigation (Oklahoma Water Resources Board, 2014).\nTo sustainably manage groundwater resources, it is necessary to know an aquifer’s recharge rate, or the rate at which water is being returned to the aquifer. Understanding an aquifer’s recharge rate allows water managers to know whether more water is being returned to or lost from the aquifer, either by pumping or by natural discharge. Rates of groundwater loss often exceed the rate of recharge due to excessive pumping or drought, which causes water levels in aquifers to drop. This disparity between recharge rates and groundwater losses led to water level declines during 2001-2006, ranging from 0.6 to more than 21 feet in many major Oklahoma aquifers, as shown in Figure 1.\nFigure 1. Water-level declines in Oklahoma aquifers from 2001-2006. Source: Oklahoma Water Resources Board, 2007.\nPrior Recharge Estimates\nMany prior studies have estimated recharge rates for individual Oklahoma aquifers (Table 1). However, factors such as data availability, climate during the study period (i.e., wet vs. dry conditions) and the duration of the study (i.e., short vs. long-term) can impact study results and can make comparing recharge rates between studies difficult. In contrast to aquifer-specific studies, very few state-wide estimates of groundwater recharge have been made. The most recent state-wide recharge rates were published nearly 40 years ago (Pettyjohn et al., 1983) (Figure 4). Because of the importance of groundwater in the state, accurate and up-to-date recharge rates are essential for the sustainable management and longevity of groundwater resources.\nTable 1. Summary of previously published recharge rates for select Oklahoma aquifers. Source: Oklahoma Comprehensive Water Plan 2012 Executive report.\n(inches per year)\n|Enid Isolated Terrace||Alluvial||2.3|\n|North Canadian River||Alluvial||1.0-5.0|\n|North Fork of the Red River||Alluvial||2.3|\n|Salt Fork of the Arkansas River||Alluvial||2.3|\nGroundwater recharge is often limited by the amount of water that drains from a soil profile, and the drainage rate is strongly influenced by soil moisture conditions. Because drainage limits the amount of recharge an aquifer may receive, it is helpful to think of the drainage rate as a potential recharge rate, or as an upper limit on actual recharge. Assuming water flow in soil is gravity-driven, it is possible to estimate the amount of drainage from the soil profile using soil moisture data from monitoring stations and soil property data. The Oklahoma Mesonet has provided daily soil moisture data at three depths (2 inches, 10 inches and 24 inches) for more than 100 stations since 1996 (Figure 2). These data were used to estimate annual drainage at 78 locations from 1998-2014 (Figure 3).\nUsing soil moisture data to estimate drainage rates has three distinct advantages over previous methods: 1) it incorporates long-term meteorological and soil moisture data that have been collected since 1996, including the effects of several extreme climatic events, 2) results can be updated any time as long as the soil moisture monitoring system is intact and 3) in addition to site-specific estimates of drainage, the large number of point measurements available may be used to indicate the spatial distribution of recharge across the entire state of Oklahoma, as opposed to single-aquifer studies that have been done in the past.\nFigure 2. Mesonet site name abbreviations and locations for sites where drainage estimates were made. Labels for three sites (Stillwater, Marena and Oklahoma City East) were excluded for clarity. Adapted from Wyatt et al. (2017).\nFigure 3. Statewide mean annual soil moisture-based drainage rates for the years 1998-2014. Drainage rate labels for the Stillwater, Oklahoma City East, Porter, and Marena sites were excluded for clarity, but were 8.4, 3.2, 6.5 and 2.6 inches per year, respectively.\nFigure 4. Prior state-wide groundwater recharge estimates published by Pettyjohn (1983).\nLong-term mean annual drainage (potential recharge) estimates found using soil moisture\ndata from the Oklahoma Mesonet are shown in Figure 3. Soil moisture-based drainage\nrates generally followed the precipitation gradient of the state, as expected, decreasing\nfrom east to west. Mean drainage estimates for the period from 1998-2014 agreed well\nwith prior recharge estimates, with drainage rates ranging from 0.2 inch per year\nat Boise City in the Oklahoma Panhandle to 10.5 inches per year at Bristow in northeast\nOklahoma. This is similar to the range of recharge values found by prior studies in\nOklahoma, with reported recharge rates ranging from 0.03 to 10.5 inches per\nyear. The median drainage rate for the study period was 2.64 inches per year, which is approximately 7.7 percent of the median state-wide rainfall of 34.3 inches per year for the same period. This means, on average, approximately 8 percent of rainfall falling in Oklahoma became drainage from 1998-2014.\nSoil moisture based drainage rates correspond fairly well with the most recent prior state-wide estimates of groundwater recharge (Figure 4). Although Pettyjohn et al. (1983) used a different method and data from the 1970’s, the maps are similar in several ways, including the trend that drainage and recharge rates decrease from east to west. Additionally, the maximum soil moisture-based drainage rate in this study (10.5 inches per year) and maximum Pettyjohn et al. (1983) recharge rate (10 inches per year) are comparable. However, there are also some differences between the two maps. For instance, calculated drainage rates in the Oklahoma Panhandle range from 0.2 to 1.1 inches per year and are higher than the recharge rate of 0.1 inch per year or less estimated for this region by Pettyjohn et al (1983).\nSoil moisture-based drainage estimates summarized by aquifer compare well with previous recharge estimates for major Oklahoma aquifers (Table 2). These drainage values were found by computing the median value of the mean annual drainage rate for aquifers with a minimum of three Mesonet sites above them, resulting in aquifer-scale drainage rate estimates for six Oklahoma aquifers. Aquifer-scale drainage rates fall within the range of previous recharge estimates, with the exception of the Arkansas River alluvial aquifer, which has only one prior recharge estimate. Though only one other study has estimated recharge for the Arkansas River alluvial aquifer, the soil moisture-based drainage estimate is within 30 percent of the estimated recharge rate found by that study. These results provide strong evidence that drainage estimates from a large-scale soil moisture monitoring network can be indicative of potential recharge rates at the spatial scales of an individual aquifer and an entire state.\nTable 2. Summary of soil moisture-based drainage rates by aquifer. Aquifer name, number of Mesonet sites located above the aquifer, median value of the mean annual soil moisture-based drainage rate, a range of previous recharge estimates, and the number of publications contributing to that range.\n(inches per year)\n(inches per year)\na Czarnecki et al. (2009); Dugan & Peckenpaugh (1985); Imes (1989); Imes and Emmett\nb Oklahoma Water Resources Board (2012).\nc Pettyjohn and Miller (1982); Mashburn et al. (2014); Parkhurst et al. (1996); Oklahoma Water Resources Board (2011).\nd Becker and Runkle (1998); Tanaka and Davis (1963); Pettyjohn et al. (1983); Oklahoma Water Resources Board (2012).\ne Oklahoma Water Resources Board (2012); Hart and Davis (1981); Morton (1992).\nf Luckey and Becker (1999); Hart et al. (1976); Morton (1980); Oklahoma Water Resources Board (2012).\nSoil moisture-based drainage estimates can be made by applying a simple unit-gradient assumption to daily soil moisture data from long-term in situ monitoring stations. The primary weaknesses of this approach in the present study were: 1) the relatively shallow measurement depth used (i.e., 24 inches) and 2) the increased uncertainty in the drainage estimates for wetter sites. Despite these weaknesses, the results provide evidence that, in many cases, the drainage rates at 24 inches are estimated with reasonable accuracy and that these drainage rates are indicative of potential groundwater recharge rates. Spatial patterns of the estimated drainage rates tend to follow the state’s precipitation gradient, decreasing from east to west. Additionally, aquifer-scale drainage rates compared well with previous estimates of recharge in all available cases. The maps of mean annual drainage rates across the state of Oklahoma, yearly drainage and other maps related to soil moisture conditions in Oklahoma, are available online at http://soilmoisture.okstate.edu under the “Projects” tab.\nThe following major points are discussed in this Fact Sheet:\n- Long-term soil moisture data, such as those available from the Oklahoma Mesonet, may be used in conjunction with soil property data to accurately estimate drainage rates from the soil profile.\n- These soil moisture-based drainage rates range from 0.2 inch to 10.5 inches per year for the years 1998-2014 and are indicative of potential recharge rates to underlying groundwater aquifers.\n- Estimated drainage rates compare well with estimates of recharge from many prior studies in Oklahoma and may be useful for water users, resource managers and decision makers.\nBecker, M. F. and D. L. Runkle. 1998. Hydrogeology, water quality, and geochemistry of the Rush Springs aquifer, western Oklahoma. US Geological Survey, Water Resources Division; Branch of Information Services.\nCzarnecki, J. B., J. A. Gillip, P. M. Jones, and D. S. Yeatts. 2009. Groundwater- flow model of the Ozark Plateaus aquifer system, northwest Arkansas, southeastern Kansas, southwestern Missouri, and northeastern Oklahoma. U.S. Geological Survey Scientific Investigations Report 2009-5148: 62p.\nDugan, J. and J. Peckenpaugh. 1986. The effects of climate on consumptive water use and ground-water recharge in parts of Arkansas, Colorado, Kansas, Missouri, Nebraska, Oklahoma, South Dakota, and Texas. U.S. Geological Survey Water-Resources Investigations Report: 85-4326.\nFord, D.C., and P.W. Williams. 1989. Karst geomorphology and hydrology. Unwin Hyman, London.\nHart, D. L. and R. E. Davis. 1981. Geohydrology of the Antlers aquifer (Cretaceous), southeastern Oklahoma, University of Oklahoma Press. 81.\nHart, D. L. Jr., G. L. Hoffman, and R. L Geomaat. 1976. Geohydrology of the Oklahoma Panhandle, Beaver, Cimarron and Texas Counties. U.S. Geological Survey Water Resources Investigation 25-75. 72p.\nImes, J. L. and L. F. Emmett. 1994. Geohydrology of the Ozark Plateaus aquifer system in parts of Missouri, Arkansas, Oklahoma, and Kansas. U.S. Geological Survey Professional Paper 1414-D. 127p.\nImes, J. L., 1989. Analysis of the effect of pumping on groundwater flow in the Springfield Plateau and Ozark aquifers near Springfield, Missouri: U.S. Geological Survey Water Resources Investigations Report 89-4079, 63p.\nKim, J. H. and R. B. Jackson. 2012. A global analysis of groundwater recharge for vegetation, climate and soils. Vadose Zone J. 11. doi:10.2136/vzj2011.0021RA.\nLuckey, R. L. and M. F. Becker. 1999. Hydrogeology, water use, and simulation of flow in the High Plains aquifer in northwestern Oklahoma, southeastern Colorado, southwestern Kansas, northeastern New Mexico, and northwestern Texas. U.S. Geological Survey, Water Resources Investigation Report 99-4104.\nMashburn, S. L., D. W. Ryter, C. R. Neel., S. J. Smith, and J. S. Magers. 2014. Hydrogeology and simulation of groundwater flow in the Central Oklahoma (Garber-Wellington) Aquifer, Oklahoma, 1987 to 2009, and simulation of available water in storage, 2010–2059. U.S. Geological Survey, Water Resources Investigations Report 2013-5219.\nMorton, R. B. 1980. Digital-model projection of saturated thickness and recoverable water in the Ogallala aquifer, Texas County, Oklahoma. U.S. Geological Survey Open-file Report 79-565. 34p.\nMorton, R. B. 1992. Simulation of ground-water flow in the Antlers aquifer in southeastern Oklahoma and northeastern Texas. US Department of the Interior, U.S. Geological Survey Water Resources Investigation.\nFox, G.A., S. Taghvaeian, and L. Sanders. Introduction to Groundwater Hydrology and Management. Oklahoma Cooperative Extension Service Fact Sheet WREC-104, Introduction to Groundwater Hydrology and Management.”\nOklahoma Water Resources Board (OWRB). 2007. Oklahoma Water News Quarterly Report.\nOklahoma Water Resources Board (OWRB). 2011. Oklahoma Comprehensive Water Plan Physical Water Supply Availability Report.\nOklahoma Water Resources Board (OWRB). 2012. Oklahoma Comprehensive Water Plan 2012 Executive Report.\nOklahoma Water Resources Board (OWRB). 2014. http:// www.owrb.ok.gov/util/waterfact.php. Accessed Jan 20, 2019.\nParkhurst, D. L., S. C. Christenson, and G. N. Breit. 1996. Ground-water-quality assessment of the central Oklahoma Aquifer, Oklahoma: geochemical and geohydrologic investigations. U.S. Geological Survey Water Supply Paper 2357-C. 101p.\nPettyjohn, W. A. and A. Miller. 1982. Preliminary estimate of effective ground-water recharge rates in central Oklahoma. Oklahoma Water Resources Research Institute.\nPettyjohn, W.A., H. White, and S. Dunn. 1983. Water Atlas of Oklahoma. University Center for Water Research, Oklahoma State University, Stillwater, OK.\nScanlon, B. R., R. W. Healy, and P. G. Cook. 2002. Choosing appropriate techniques for quantifying groundwater recharge. Hydrogeol. J. 10:18-39.\nTanaka, H. H. and L. V. Davis. 1963. Ground Water: Rush Springs Sandstone. Norman, Oklahoma: Oklahoma Geological Survey, Circular 61.\nWyatt, B.M., T.E. Ochsner, C.A. Fiebrich, C.R. Neel, and D.S. Wallace. 2017. Useful drainage estimates obtained from a large-scale soil moisture monitoring network by applying the unit-gradient assumption.Vadose Zone J. doi: 10.2136/vzj2017.01.0016.\nGraduate Research Associate\nAssistant Professor and Extension Specialist, Water Resources\nSarkey’s Distinguished Professor, Associate Professor of Applied Soil Physics","USGS Groundwater Information\nThe Role of Unsaturated Flow in Artifical Recharge Projects\nBy Alan L. Flint\nArtificial recharging an aquifer may be achieved by either surface spreading, injection in wells, or altering the natural conditions of stream channels to increase infiltration. Except for recharge using injection wells directly into an aquifer, artificially recharged water must first move through the unsaturated zone. For the most part, the unsaturated zone provides the underground storage space for recharge, although the amount of storage is dependent on the water retention characteristics and the natural recharge occurring at the site. The greater the natural recharge at a site, the greater the percent of porosity occupied by antecedent water moving through the unsaturated zone resulting in a smaller amount of available space for the artificially recharged water.\nThe hydrologic properties of an unsaturated zone help determine the suitability of a particular location for artificial recharge. Optimally, areas used for artificial recharge should have high permeability soils, the capacity for horizontal movement of water in the unsaturated zone and in the receiving aquifer, a lack of impeding layers, and a thick unsaturateded zone. Under optimal conditions, water should reach the top of the saturated zone and spread laterally rather than building up a column of water toward the surface, which would greatly reduce recharge (Freeze and Cherry, 1979). The suitability of a site is often determined by field and laboratory measurements of soil properties, field experiments, and numerical modeling.\nSeveral direct methods of artificial recharge commonly are used (Environmental and Water Resources Institute, 2001), including spreading basins and ditches for near-surface recharge applications, and pits and shafts for penetrating below near-surface restrictive layers. A third method, direct well injection into the unsaturated zone, is often used to penetrate below deeper restrictive layers. To highlight issues relating to the role of the unsaturated zone and unsaturated flow in recharging an aquifer, the following section discusses near-surface spreading basins being studied in the San Gorgonio Pass area in southern California.\nIn 1991, spreading basins were used to test the feasibility of artificially recharging an aquifer in alluvial fans in Cherry Valley, which is within the San Gorgonio Pass area in southern California, (Shaikh and others, 1995). In 1997, the U.S. Geological Survey (USGS) was asked to evaluate the suitability of the unsaturated zone for artificial recharge and to develop models of the unsaturated and saturated zones of the San Gorgonio Pass area. Although well-organized guidelines are available for developing recharge spreading basins (Environmental and Water Resources Institute, 2001), spreading basins at this site were established in the 1960's prior to full analysis of subsurface hydrogeologic conditions and properties. Hydrogeologic data are essential in siting recharge spreading basins, particularly in alluvial basins, where soils are highly stratified and contain continuous and discontinuous clay layers interbedded with sands and gravels (Flanigan, and others, 1995).\nAs part of the USGS evaluation, several test wells were cored in the unsaturated zone and instrumented with deep tensiometers, heat-dissipation matric-potential sensors, temperature sensors, and suction lysimeters. Core samples and cuttings were analyzed in the USGS laboratory to determine particle-size distribution, water content, permeability, and lithology. An interpretation of these data suggests that there are several alternating high and low permeability layers between the surface and the water table (approximately 600 feet deep). A perched water table is present above a very low permeability layer, 250 feet below the surface. Results of inverse modeling of borehole temperatures and water-level measurements, which show a slow decline in the water levels in the perched zone, indicates that the vertical hydraulic conductivity of the layer is less than 1 foot per year. Data from other boreholes in the area suggest that this perched layer is the top of an old, laterally extensive, geologic formation.\nSurface-seismic and surface-resistivity measurements were used to develop a conceptual model of the layering and faulting in the area (fig. 1A). The existence of a shallow water table north of the Banning Fault suggests that the fault is a barrier to lateral flow. Temperature data from several boreholes in the area indicate that the coldest water in the unsaturated zone is the perched water. Temperature measurements made directly from flowing water in a nearby stream (San Gorgonio Creek, fig. 1) suggest that water in the perched zone is from local stream recharge, and not from the shallow water table north of the fault, which supports the hypothesis that the Banning Fault is a barrier to flow.\nFigure 1. Conceptual cross section of the layered stratigraphy (A) and the relative location of the cross section and near-surface spreading basins to features of the San Gorgonio Pass area, California (B).\nThe conceptual model of the unsaturated zone at San Gorgonio Pass was used for a numerical model of the unsaturated zone to further analyze existing data and to develop workable scenarios for artificial recharge. TOUGH2, an integrated finite-difference numerical code (Pruess, 1991), was used to develop the three-dimensional model. This code simulates the flow of heat, air, water, and nitrate (assumed to be present in septic tank leach fields) in three dimensions under saturated or unsaturated conditions. The geometry of the site requires a three-dimensional approach because of down-dip migration of recharged water through the alluvial fan deposits (north to south), as well as lateral flow of natural recharge (generally east to west) from the nearby stream. The modeling domain is approximately 1.6 miles (east to west) by 0.8 miles by 600 feet deep and contains more than 50,000 grid elements. The north and south lateral boundaries of the model are located along faults and are assumed no-flow boundaries. The east and west boundaries represent the edges of the alluvial basin where they encounter the mountain block. The bottom boundary is the water table and the upper boundary is specified flux. The surface flux is temporally and spatially variable depending on the artificial recharge scenario, and the location and amount of streamflow, septic tank return flow, and natural recharge from precipitation.\nThe model was initially developed using the hydrologic properties measured or estimated from the laboratory data. The model was further refined and calibrated by matching borehole temperature, matric potential data, and the occurrence of perched water. The model was successfully used to simulate the artificial recharge experiment conducted in 1991 and described by Shaikh and others (1995). The model simulated the measured temperature profiles by adding cold-water infiltration along the stream channel. Once calibrated, the model was run to steady-state conditions assuming natural recharge from precipitation and streamflow based on the results of the calibration of the saturated zone flow model. The model was then used to simulate historical and future artificial recharge conditions from 1950-2005. The model simulated septic tank return flows that have 80 milligrams per liter nitrate-nitrogen (nitrate reported as nitrogen), the 1991 artificial experiment, and a proposed artificial recharge scenario. For the proposed artificial recharge scenario, 1,000 acre-ft of recharge was applied over a 50-day period each year from 2001 through 2005. The model simulation allowed comparison of measured and simulated data from 1991 to 2001, and predicted the response of the system to the proposed recharge scenario.\nBefore the application of artificial recharge in 1991, the simulated travel time from the surface to the water table was approximately 50 years for locations directly beneath the stream, increasing to more than 250 years for locations away from the stream. The simulated addition of artificial recharge from 2001-2005 decreased the unsaturated-zone travel time to less than 10 years directly beneath the spreading basins, but the amount of applied water that recharged the regional aquifer was less than 5 feet per year. The simulations suggest that little recharge will reach the regional water table under the spreading basin: further most of the artificially recharged water will remain above the perching layer at 250 ft below land surface, and will mound against the down-gradient no-flow boundary located about 4,000 feet south of the spreading basins. Although the recharged water intercepts nitrates from septic tank leach fields as it spreads laterally and vertically through the unsaturated zone, the simulated nitrate-nitrogen concentration of water in the perched water layer is less than 10 milligrams per liter.\nGenerally, artificial recharge projects apply water in surface and near-surface spreading basins, pits, and trenches, using the unsaturated zone to transport and store water. The hydrogeology of the unsaturated zone plays a critical role in transporting and storing artificially recharged water. Evaluating this zone will determine if the area is suitable for artificial recharge, as well as the most effective methods of surface or subsurface application of water. Field and laboratory data, measured data, and field experiments were used to develop a conceptual and a numerical model of the unsaturated zone at San Gorgonio Pass in southern California. The results of the model simulations were used to refine the conceptual model and to test scenarios for artificial recharge. Results of the numerical model simulations of this site indicate that little recharge will reach the regional aquifer beneath the spreading basins, and that most of the water will remain above a perching layer at 250 feet below land surface, and will mound along the assumed no-flow fault boundary located about 4,000 feet south of the spreading basins. Further work on the characteristics of the fault and extension of the modeling domain further down gradient of the fault are required to provide more conclusive results for the characterization of the site for the application of artificial recharge.\nEnvironmental and Water Resources Institute, 2001, Standard guidelines for artificial recharge of ground water: Reston, Va, American Society of Civil Engineers, 106 p.\nFlanigan, J.B., Sorensen, P.A., and Tucker, M.A., 1995, Use of hydrogeologic data in recharge pond design, vol. II in A.I. Johnson, and R.D. Pyne, eds., Artificial recharge of ground water;: New York, American Society of Civil Engineers, p.139-148.\nFreeze, R.A. and Cherry, J.A., 1979, Groundwater: Englewood Cliffs, New Jersey, Prentice-Hall, p. 367-370.\nPruess, K., 1991, TOUGH2-A general-purpose numerical simulator for multiphase fluid and heat flow: Lawrence Berkeley National Laboratory Rep. LBL-29400, 102 p.\nShaikh, A., Bell, R.B., Ford, M.E., and Stockton, S.P., 1995, Feasibility of recharge by surface spreading, vol. II in A.I. Johnson, and R.D. Pyne, eds., Artificial recharge of ground water: New York, American Society of Civil Engineers, p. 159-167.\nIn George R. Aiken and Eve L. Kuniansky, editors, 2002, U.S. Geological Survey Artificial Recharge Workshop Proceedings, Sacramento, California, April 2-4, 2002: USGS Open-File Report 02-89\nThe use of firm, trade, and brand names in this report is for identification purposes only and does not consitute endorsement by the U.S. Government."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"instructional"}],"document_ids":["<urn:uuid:25effb42-ccd5-434b-80e8-134babac8b54>","<urn:uuid:2b801d41-c32b-4f11-89cd-b378a17d73b6>"],"error":null}
{"question":"How can I reduce fuel costs for my business aviation operations? Need step-by-step money-saving tips.","answer":"Here are key steps to reduce fuel costs: 1) Join a fuel program that guarantees lower prices than pump rates in exchange for minimum commitments - verify the program is accepted at your frequent destinations. 2) Use fuel price tracking tools that provide updated prices at airports globally - make advance reservations for additional discounts. 3) Plan efficient routes by checking fuel prices along the way - sometimes a technical stop can yield significant savings. 4) Consider fuel tankering by uplifting more fuel where prices are lower, when weight and balance allow. 5) Fly at maximum-range cruise speed instead of maximum cruise speed - this can save 15-20% fuel with only small increases in trip time.","context":["It forms a big part of your annual operating budget, but how can operators better control their fuel purchase practices? Dave Higdon offers tips…\nFew are better placed to understand the relationship between cold hard cash and high-speed flight than those who pay the bills for your Flight Department. In these days of increasing costs, skilled managers add value to their flight operations by controlling all three major cost items: Flight crew staffing, maintenance and upkeep, and fuel costs.\nSetting an operating budget demands a working knowledge of all three items and how those factors interact. For example, budgeting for ‘X’ hours flying per year sets the bar for maintenance (based on hourly costs) and a concomitant estimate of fuel costs.\nThat’s simple enough, providing the person developing the budget recognizes that changing any one of those three factors automatically brings a related change to the other numbers.\nIn reality, plenty of people put tremendous effort into controlling their fuel spending. Though consumers lack any way to influence pump prices, they enjoy total control over when, how much and where they choose to fill their tanks.\nSince fuel costs account for the largest share of variable operation costs, managing fuel use and fuel purchases greatly influence the department’s budget.\nWithin this article, we’ll consider the steps needed to keep your operation on – or under – your fuel-budget estimate. Following are some of the best tips and practices…\nTip #1: Join a Fuel Program\nThe Business Aviation community includes numerous vendors and program operators offering fuel cost control tools for those who enroll with them and use their systems. By contracting with vendors, these tools guarantee a lower price than the posted pump price in exchange for a minimum commitment.\nDo check that a particular program (e.g., a card arrangement) is accepted among the FBOs and airports your operation typically frequents. You may find some adjustments are needed, dependent on the airports you use.\nBy taking these precautions, you will avoid penalizing your operation by paying for a fuel club membership that's not usable at the majority of the airports you visit.\nMost of these programs offer guidance to help you use their cards. Once you have one, use the tool even if it doesn't always get you the lowest price.\nTip #2: Use Fuel Price Trackers\nVarious tools and programs exist solely to track and report fuel prices at airports around the country and across the globe. The better of these trackers update daily, while the best update even more frequently.\nBy entering a route or point of origin and destination, these programs typically will produce a list of airports along the route as well as their fuel prices at the time of the last check. A quick internet check or phone call can then confirm whether the posted prices remain in effect.\nAs an added bonus, making an advanced reservation can get you an additional discount at some airports.\nTip #3: Consider the Most Efficient Route\nFlight planning for fuel costs may not be an everyday occurrence, but on occasion a slight change in the route flown can yield big savings without appreciably adding to the trip length (thereby offsetting any fuel savings).\nChecking route fuel prices – through programs like those noted above – may reveal potential savings by landing at a different airport for the meeting, without refueling, then, by refueling somewhere else.\nAs an example, a trip last fall required us to make a technical stop that yielded a saving of $1.40 per gallon. On a 280-gallon uplift of jet fuel, that $1.40 of per-gallon savings translated to spending $392 less! Imagine savings like that multiple times a year. The habit could almost become a profit center of its own.\nTip #4: How About Fuel Tankering?\nWhere weight-and-balance considerations allow, some benefit may come from uplifting more fuel than a trip requires. Yes, it will slow your climb and could limit what's carried in the cabin, but the chances are that it won't.\nMany pilots like to fly with the fuel level suggested by flight planning; that is, fuel needed plus reserves for weather and a diversion. Carrying the least called-for saves fuel, helps climb performance and gives cruise speed a bit of an edge.\nBut if home field fuel costs are the lowest – and the aircraft is capable – tankering extra fuel can reduce total fuel expenses for a trip.\nThat is especially the case when the fuel capacity allows for a round-trip flight without refueling. Even when an airplane can't tanker round-trip fuel, the destination fuel price may be less – which is an incentive to fully top off before returning to home base.\nTip #5: Slow Down, You Fly Too Fast…\nAll aircraft offer a published maximum cruise speed. Why do we fly if we don't want to go as fast as possible? The answer involves another book speed: Maximum-range cruise speed.\nThrottling back isn't solely for ‘tailwind days’. Flying at maximum-range speed (even though you're flying a much shorter trip) will provide a measurable decline in fuel costs, with only a small increase in the en route time.\nThe vast majority of our trips are between 350-500nm. Sacrificing 40 knots on a 500nm trip may add 15-20 minutes to the trip – with a savings of 15-20% in fuel not used.\nPutting these fuel-saving steps into effect this January brings the potential of a full year of fuel savings compared to posted prices – because fuel costs show little sign of declining as we saw earlier in the decade.\nDemand increases and supply adjustments have largely ended any semblance of a glut in petroleum supplies. The business turbine fleet continues to grow, and flight hours are up in many parts of the world.\nEven as OEMs continue to advance the fuel efficiency of their engines and aircraft, the changes fall short of offsetting the higher prices expected in the next decade. Start practicing fuel-saving habits today and help your bottom line tomorrow."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:820d32d5-a456-447b-a4e9-3cd0705f23a6>"],"error":null}
{"question":"Compare career backgrounds: Laurent Dubois vs Danika Littlechild - Caribbean expertise?","answer":"Both have expertise related to the Caribbean, but with different focuses. Laurent Dubois is a specialist in Caribbean and Atlantic History, having published works about revolution and slave emancipation in the French Caribbean, and is working on a general history of the Caribbean. Danika Littlechild's Caribbean experience comes through her work as general counsel for the International Indian Treaty Council, where she worked with Indigenous Peoples from the Caribbean, focusing on environmental issues, Indigenous rights, and conservation matters.","context":["|Degrees:||B.A. (Carleton), LL.B. (Toronto), LL.M. (Victoria)|\n|Phone:||613-520-2600 x 2678|\n|Office:||D487 Loeb Building|\nDanika Billie Littlechild is Cree from Ermineskin Cree Nation, Neyaskweyahk, Maskwacis (Alberta) in Treaty No. 6 territory. Prior to joining the Department of Law and Legal Studies in January of 2020, Danika practised law in Canada for almost two decades, advising Indigenous Peoples across Canada and internationally. Within Canada, Danika has served First Nations in the areas of environment, Indigenous Legal Orders, health and governance.\nDanika has advised Indigenous representative organizations such as the Assembly of First Nations, as well as regional treaty-based organizations and PTOs. Internationally, Danika served as an advisor and Indigenous Peoples Representative in various UN mechanisms, treaty bodies and special procedures including participation in treaty body mechanisms, and standard setting negotiations such as the development of the SDGs as a member of the Indigenous Peoples Major Group, and the intergovernmental process leading to the Minimata Convention on Mercury. She was an advisor to the North American representative on the Permanent Forum on Indigenous Issues for three years (2013-2016) and was general counsel for International Indian Treaty Council (www.treatycouncil.org) from 2011-2018, working internationally with Indigenous Peoples from the Caribbean, the Pacific and the Americas. Danika was the first Indigenous woman to be appointed as Vice-President of the Canadian Commission for UNESCO (2014-2018) after almost 15 years of working with CCUNESCO in various voluntary, leadership and advisory capacities.\nDanika has focused much of her efforts over the past few decades on issues related to environment, water, climate change, sustainability and more recently conservation and biodiversity. Danika was the Co-Chair of the Indigenous Circle of Experts under the Pathway to Canada Target 1 initiative, intended to contribute to the realization of Canada’s commitments under the United Nations Convention on Biological Diversity (https://www.conservation2020canada.ca/who-we-are).\nCurrent Research and Related Activities\nProf. Littlechild conducts research in the field of Ethical Space, an approach and concept introduced by Cree Scholar Willie Ermine. Ethical Space is an approach to relationality between and amongst Indigenous and non-Indigenous peoples and the natural world that facilitates transformative collaboration based on elevating Indigenous systems of knowledge, law, protocols and practices. Well established as a field of research in health, Danika is exploring its application in the areas of biodiversity conservation and environment.\nDanika is leading the Ethical Space Research Stream of the Conservation through Reconciliation Project (https://conservation-reconciliation.ca/ethical-space-stream). The Conservation through Reconciliation Partnership represents a seven year program of work hosted by the IISAAK OLAM Foundation, the Indigenous Leadership Initiative, and the University of Guelph that weaves together a wide range of partners including Indigenous thought leaders, organizations, youth and Elders; emerging and established scholars; prominent conservation agencies and organizations; Indigenous Peoples and Nations; and knowledge mobilization specialists, united in the goal of supporting Indigenous-led conservation in Canada.\nDanika is a collaborator on a project working towards an Ethical Space of engagement for bridging multiple ways of knowing in aquatic research and monitoring. This project is building on the growing theoretical and empirical work that has been done regarding Ethical Space in the context of decision making, with a focus on research and monitoring.\nDanika is a member of an Ethics Advisory and Stewardship Circle, convening Indigenous experts on Ethical Space from across Canada, to develop a seminal publication entitled “Ethical Guidance for Knowledge Sharing and Co-Creation” (Forthcoming)\nDanika is a member of the Advisory Committee for Biodiversity Pathways in Canada, a project of FutureEarth that aims to inform the development of potential pathways towards the attainment of Canada’s commitments to post-2020 global biodiversity framework and the SDGs.\nDanika is a contributing author to the Indigenous Resilience Report, a stand-alone report that will be released alongside the next National Climate Assessment. The report will centre on Indigenous Peoples as rights holders integral to climate policy decision making and will draw on Indigenous knowledge and explore multi-dimensional and intersecting aspects of climate impacts and actions.\nDanika recently completed a project entitled “Operationalizing Ethical Space and Two-Eyed Seeing in Indigenous Protected and Conserved Areas and Crown Protected and Conserved Areas”, providing guidance for Pathway to Canada Target 1 members to help understand potential methodology and application of Ethical Space in the context of conservation initiatives, in particular Indigenous Protected and Conserved Areas (IPCAs).\nProf. Littlechild teaches in the area of environmental and social justice, with a new course offering in Fall 2021 on Indigenous relations. She also frequently guest lectures in other Faculties at Carleton and in other universities. She has also taught at Indigenous post-secondary institutions including Maskwacis Cultural College in Treaty No. 6 territory.\n- Co-Author (Buxton, R. T., et al (2021).) Key information needs to move from knowledge to action for biodiversity conservation in Canada. Biological Conservation, 108983. Date of Acceptance: 26-Jan-2021 Available Online 18-Feb-2021 https://www.sciencedirect.com/science/article/pii/S0006320721000355\n- Co-Author (Littlechild, Danika, Finegan, Change and McGregor, Deb (Forthcoming) “Reconciliation” in Undergraduate Education in Canada: The Application of Indigenous Knowledge in Conservation. FACETS, Doi: 10.1139/facets-2020-0076 Date of Acceptance: 26-Jan-2021","401 Bellamy Bldg., Tallahassee, FL 32306-2200\nPhone: (850) 644-5888\nFax: (850) 644-6402\nFaculty Members & Biographies\nAffiliated Faculty at Florida State University\nDavid A. Bell - Andrew W. Mellon Professor in the Humanities, Johns Hopkins University (USA)\nDavid A. Bell - Andrew W. Mellon Professor in the Humanities, Johns Hopkins University (USA)\nDr. Bell is primarily a specialist in the political culture of early modern and revolutionary France. He is the author of The First Total War: Napoleon’s Europe and the Birth of Warfare as We Know It (New York: Houghton Mifflin, 2007), The Cult of the Nation in France: Inventing Nationalism 1680–1880 (Harvard University Press, 2003), and Lawyers and Citizens: The Making of a Political Elite in Old Regime Europe (New York: Oxford University Press, 1994). Professor Bell is a contributing editor to the New Republic and his essays and reviews appear regularly there, as well as in such publications as the London Review of Books and the New York Times Book Review.\nMichael Broers - Fellow of Lady Margaret Hall and Member of the History Faculty, Oxford University (UK)\nDr. Broers is a leading international scholar of Napoleonic Europe. He is the author of Europe Under Napoleon (1996), Europe after Napoleon (1996), Napoleonic Imperialism and the Savoyard Monarchy (1997), which won the prize of the International Napoleonic Society, The Politics of Religion in Napoleonic Italy, 1801-1814 (2002) and, most recently, The Napoleonic Empire in Italy (2004). He is currently writing a book provisionally entitled The Napoleonic Vision: A Regime and its Agendas.\nWilliam Cormack - Associate Professor, University of Guelph (Canada)\nDr. Cormack is an internationally-recognized specialist in the history of the French navy during the Revolutionary and Napoleonic period. His first book - Revolution and Political Conflict in the French Navy, 1789-1794 (Cambridge, 1995) - examined the politicization of the French navy during the early years of the Revolution. His current research project concerns the impact of the French Revolution on France's Caribbean colonies.\nClare Crowston - Associate Professor, Univeristy of Illinois at Urbana-Champaign (USA)\nDr. Crowston specializes in the social and cultural history of early modern France, the history of women and gender, and the history of work, economic exchange, and consumption. Her first book - Fabricating Women: The Seamstresses of Old Regime France, 1675-1791 (Duke, 2001) - won two awards, the Berkshire Prize and the Hagley Prize. Her articles have appeared in international scholarly journals including Annales: Histoire, Sciences Sociales, Gender and History, and French Historical Studies. She is currently engaged in two book projects. The first focuses on the intersection of credit, fashion, and sex in 18th century France. The other is a co-authored study of apprenticeship in France from the 17th to 19th centuries.\nSuzanne Desan - Professor, University of Wisconsin at Madison (USA)\nDr. Desan is a specialist in early modern France and the French Revolution. Her past research has focused primarily on popular politics and social activism during the French Revolution. Her first book - Reclaiming the Sacred: Lay Religion and Popular Politics in Revolutionary France (Cornell, 1990) - concentrated on the intersection of religion and popular culture during the French Revolution. Her second book - The Family on Trial in Revolutionary France (Berkeley, 2004) - examined how revolutionary political change transformed gender dynamics within French families. Her current book project will look at foreigners and émigrés in the French Revolution, and aims to rethink French revolutionary politics, identity, and mobility in a transatlantic and Europe-wide context.\nLaurent Dubois - Associate Professor, Michigan State University (USA)\nDr. Dubois is a specialist in Caribbean and Atlantic History. He has published Les esclaves de la République: l’histoire oubliée de la première emancipation, 1789-1794 (Calmann-Lévy, 1998), Avengers of the New World: The Story of the Haitian Revolution (Harvard, 2004), the prize-winning A Colony of Citizens: Revolution and Slave Emancipation in the French Caribbean, 1789-1804 (North Carolina, 2004), and, with John Garrigus, Revolution in the Caribbean, 1789-1804: A Brief History with Documents (Bedford, 2006). He is currently working on a general history of the Caribbean, as well as a history of the banjo.\nPascal Dupuy - Maître de Conférence, Université de Rouen (France)\nDr. Dupuy is the author, with Claude Mazauric, of La Révolution française (Paris: Vuibert, 2005), and, with Michael Biard, of La Revolution française: Dynamiques, influences, débats 1789-1804 (Paris: Armand Colin, 2004), and Calais vu par Hogarth (Calais: Musée des beaux arts, 2003). Professor Dupuy will publish in 2007 a study of political cartoon and caricatures of the French Revolution in the eighteenth and nineteenth centuries. He is currently at work on a study of fête de la federation during the French Revolution.\nPhilip Dwyer - Senior Lecturer, University of Newcastle (Australia)\nDr. Dwyer is a specialist in Revolutionary and Napoleonic Europe. He is the editor of Napoleon and Europe (London, 2001), and has co-edited several volumes: The French Revolution and Napoleon: A Sourcebook (London, 2002) with Peter McPhee, and Napoleon and His Empire: Europe, 1804-1814 (London, 2007) with Alan Forrest. Dr. Dwyer is also the author of Talleyrand (London, 2001) and Napoleon: The Path to Power, 1769-1799 (London, 2007). He is currently working on the sequel, Napoleon: The Universal Monarchy, 1800-1821.\nAlan Forrest - Professor, University of York (UK)\nDr. Forrest has published widely on the social history of the French Revolution. His many books have treated subjects as diverse as revolutionary Bordeaux, the French Revolution and the poor, military conscription and desertion during the Revolution and Empire, the common soldiers’ experience in the armies of the Revolution and Napoleon, and the Revolution in the provinces. His current research projects include studies of propaganda under Napoleon, British caricature of Napoleon France, the French Atlantic, and the myth of the levy in mass during the 19th century.\nJohn Garrigus - Associate Professor, University of Texas at Arlington (USA)\nDr. Garrigus is a historian specializing in France’s Caribbean colonies, with a special interest in slavery and the construction of race during the period of the French Revolution. He is the author of Before Haiti: Race and Citizenship in Saint-Domingue (Palgrave-MacMillan, 2006) and, with Laurent Dubois, Slave Revolution in the Caribbean, 1789-1804: A Brief History with Documents (Bedford, 2006). He is General Editor of the forthcoming Encyclopedia of the Caribbean and is editing a new edition of the anonymous novel La Mulâtre comme il y a beaucoup de blanches.\nAlexander Grab - Professor, University of Maine (USA)\nDr. Grab is a specialist in the history of Napoleonic Italy. His first book, La Politica del pane. Le riforme annonarie nell età teresiana e giuseppina (Milan, 1986) examined the politics of subsistence in 18th century Italy. His prize-winning second book, Napoleon and the Transformation of Europe (Palgrave-MacMillan, 2003), explores the Napoleonic impact on Europe. He has published numerous articles in scholarly journals including The Journal of Modern History, The European History Quarterly, and The Journal of Modern Italian Studies. His current research focuses on education in Napoleonic Italy.\nKaren Hagemann - Professor, University of North Carolina at Chapel Hill (USA)\nDr. Hagemann is an internationally-recognized authority on Modern German and European history, as well as Women’s and Gender history (18th-20th century). Her publications have concerned the history of welfare states, social and population policy, labor history, family history, and the history of everyday lives, as well as the history of the women’s movement. Her current research projects include a gendered cultural history of the military, war and the nation, the history of masculinity and citizenship, and a comparative gender history of welfare and education systems. Her most recent publications are Masculinity in Politics and War (Manchester, 2004) and Frieden –Gewalt – Geschlect. Friedens- und Konfliktforschung als Geschlechterforschung (Essen, 2005).\nJennifer Heuer - Assistant Professor, University of Massachusetts at Amherst (USA)\nDr. Heuer is the author of The Family and the Nation: Gender and Citizenship in Revolutionary France (Cornell, 2005). She has published articles on related topics, including the role of clothing as a symbol of competing visions of national identity, comparative categorizations of enemy foreigners and ex-nobles during the French Revolution, and the use of familial metaphors for portraying the power of the state. She is currently researching a ban on interracial marriages in early 19th-century France, and in a longer-term project, the dynamics of love, family, and war in Napoleonic Europe.\nAnnie Jourdan - Professor, University of Amsterdam (The Netherlands)\nDr. Jourdan is a specialist in the Revolutionary and Napoleonic era, with particular expertise in cultural aspects of the revolutionary era. She is the author of many books, including Napoléon, le monde, et les Anglais: Guerre des mots et des images (Paris, 2004), Napoléon. Mythes et légendes (Toulouse, 2004), La Révolution, une exception française? (Paris, 2004), L'empire de Napoléon (Paris, 2000), Napoléon. Héros, Imperator, Mécéne (Paris, 1998), and Les monuments de la Révolution (Paris, 1997). She is currently working on a comparative history of revolution in France and the Netherlands.\nMichael Leggiere - Associate Professor, Louisiana State University in Shreveport (USA)\nProfessor Leggiere is Associate Professor and Chair of the Department of History and Social Sciences at Louisiana State University in Shreveport. He is also an Adjunct Professor of Strategy and Policy for the U.S. Naval War College's Distance Education program. His first book, Napoleon and Berlin: The Franco-Prussian War in North Germany, 1813 (2002) won the Société Napoléonienne Internationale's 2002 Literary Award. His next book, The Fall of Napoleon, is a two-volume work being published by CambridgeUniversity Press. The first volume, The Allied Invasion of France, 1813-1814, will be released in October 2007. Volume two, The War in France, 1814, will be published in 2009. Other works in progress include a biography of the Prussian Field-Marshal von Blücher and a history of the Battle of Waterloo commissioned by Yale University Press.\nThierry Lentz - Director, Fondation Napoléon (France)\nDr. Lentz is an international leader in the field of Napoleonic studies. In addition to directing the Fondation Napoléon in Paris, he has published moret han fifteen books on different aspects of the Napoleonic period in Europe and the Atlantic world. His most recent publications include Napoléon, l'esclavage et les colonies (Paris, 2006), Napoléon et l'Europe (Paris, 2005), Le Sacre de Napoléon (Paris, 2003), and Napoléon (Paris, 2003).\nLaura Mason - Associate Professor, University of Georgia (USA)\nDr. Mason is a specialist in the politics of popular culture during the French Revolution. Her first book, Singing the French Revolution: Popular Culture and Revolutionary Politics, 1787-1799 (Cornell, 1996) examines the politics of song during the revolutionary decade. Her second book, co-authored with Tracey Rizzo, is entitled The French Revolution: A Document Collection (Houghton-Mifflin, 1998). She has published a number of articles in edited volumes and The Journal of Modern History. She is currently writing a book about the impact of the trial of Gracchus Babeuf and the Equals on the political culture of the Directory.\nPeter McPhee - Professor and Deputy Vice-Chancellor, University of Melbourne (Australia)\nAn historian of Revolutionary France, Dr. McPhee's research interests focus particularly on change and continuity in rural society during the 18th and 19th centuries. He is also interested in more general questions about historical theory and methodology. He has published many books on France since 1780, including A Social History of France, 1789-1914 (London, 2004), The French Revolution (Oxford, 2002), Revolution and Environment in Southern France (Oxford, 1999), and The Politics of Rural Life (Oxford, 1992).\nMichael Rowe - Lecturer in Modern History, King’s College London (UK)\nA fellow of the Royal Historical Society, Dr. Rowe’s research interests are focused on Continental Europe in the era spanning the French Revolution and Napoleon, with particular focus on the German-speaking lands. Thematically, he has ranged widely, looking in particular at modernization and state/nation building, and matters associated with these broad processes: administrative structures, propaganda, the formation of identities, concepts of citizenship, centre-periphery conflicts, the ole of military conscription in integrating new populations, to name some of the more important. Publications include the award-winning book From Reich to State: The Rhineland in the Revolutionary Age, 1780-1830 (Cambridge University Press, 2003) and the edited volume Collaboration and Resistance in Napoleonic Europe. State-Formation in an Age of Upheaval, c.1800-1815 (Palgrave, 2003), as well as numerous chapters and articles devoted to the Napoleonic period.\nNatalie Petiteau - Professor, Université d'Avignon (France)\nDr. Petiteau specializes in the social history of Napoleonic France and the impact of the Napoleonic period on French social developments in the 19th century. Among her many publications are Elites et mobilités: la noblesse d'Empire au XIXè siècle, 1808-1914 (Paris, 1997), Lendemains d'Empire: les soldats de Napoléon dans la France du XIXè siécle (Paris, 2003), and Napoléon, de la mythologie à l'histoire (Paris, 2004).\nIsser Woloch - Moore Collegiate Professor, Columbia University (USA)\nDr. Woloch is a specialist in French history during the Revolutionary and Napoleonic era. His many books and writings include Eighteenth-Century Europe: Tradition and Progress, 1715-1789 (1984), The New Regime: Transformations of the French Civic Order, 1789–1820s (1994), (Ed.) Revolution and the Meanings of Freedom in the Nineteenth Century (1996), and Napoleon and His Collaborators: The Making of a Dictatorship (2001)."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"comparison"}],"document_ids":["<urn:uuid:ae647527-03a6-43c9-b494-3d3a95eea5b0>","<urn:uuid:eeca0843-8ff8-4dfb-a7b8-e3c937049ae0>"],"error":null}
{"question":"What's the difference between how bats and assassin bugs hunt their insect prey? Please explain their hunting methods.","answer":"Bats and assassin bugs use very different methods to hunt insects. Bats use echolocation, a sonar-like system where they emit high frequency sounds that bounce off objects, allowing them to determine the location and size of prey by listening to the returning echo. In contrast, assassin bugs are stealthy ambush predators that lie in wait at the base of a leaf or inside flowers. They have modified front legs to grab prey and use piercing mouthparts to stab their captured prey, injecting toxic saliva that liquefies the prey's internal organs, which they then suck up.","context":["Contrary to what you may think, bats don’t always live in caves. In fact, many call your backyard home, often roosting in tree cavities or under tree bark during the summer where they give birth and rear their young. Bat populations are disappearing all over the world due to habitat loss so a bat house is the perfect way for you to show your commitment to nature. In return, bats will eat thousands of insects that inhabit your backyard. It’s a win-win!\nThe Perfect House\nTypical bat houses are made of wood. Look for a house with interior nylon mesh or grooves in the wood to allow bats a place to hang. A long landing area allows for easy entrance. Bats like tight and warm spaces (80-100 degrees in July when they have their young) so be sure to place in an area that receives lots of sunlight.\nWhere to Install\nWhen deciding on a place to mount your bat house look for an area with lots of sun (at least 6-8 hours of direct sunlight); at least 15 feet off the ground (to protect against predators); and ideally with a water source nearby (so the mother bat doesn’t have to leave her young for too long). Bat houses can be mounted on trees, poles or structures. If pole mounted, use a 40-galvanized steel pole with inside diameter of 2” or more or a 4” x 6” treated wooden post. If mounting on a structure, choose the East or South facing side for placement. Keep clear of doors or windows for peaceful nesting and to stay clear of bat droppings.\nWinter is the best time to inspect your bat houses to be sure everything is in working order. Inspect the seams to be sure they are tight and no sunlight is able to enter the top. A flashlight works great for this. Check for any pests or old spider webs. Winter is a perfect time to clean the inside of the bat house as bats will abandon the house if overtaken by bees or wasps. Modern bat houses are thankfully self-cleaning. Droppings accumulate on the ground directly under the bat house. This material naturally biodegrades and there is not much need to remove it.\nDid You Know?\nSave yourself the bug spray! According to Bat Conservation International, one little brown bat can eat 60 medium-sized moths or over 1000 mosquito-sized insects in one night! To locate their prey, most insect-eating bats use a system called echolocation. This super sense is similar to sonar used in ships. The bat emits a high frequency sound that bounces off of objects in their environment. They can then determine the location and size of prey by listening to the sound echo that returns to them.\nBats are the only mammal capable of true flight. The Brown Bat, the most common bat in America, is very small with an overall size from 2.5” to 4.” The span of their wings when outstretched can be up to 11.”","When an insect pest moves into your garden, there are alternative methods of controlling it rather than reaching for the insecticide. Integrated pest control management calls for deciding what population levels need to be reached before control is necessary, deciding whether control is actually needed and preventing the pest's occurrence by cultural methods. One means of prevention is to maintain a varied environment around your gardening space, encouraging natural predators and parasites to be on hand to act on potential pest insects.\nThe Enemy Within\nSeldom observed in action are the small parasitic wasps that lay eggs inside or on plant-eating caterpillars. Also called parasitoid wasps if they kill the insect they lay eggs in, the wasps attack aphids, caterpillars, white flies, beetles, flies, sawflies, scale insects and true bugs. Female wasps have pointed ovipositors at the ends of their abdomens that they use to inject eggs into the bodies of the hosts. The larvae that hatch from the eggs eat the internal structures of the host insect. Most adult parasitic wasps range from the size of a printed period to about an inch long. There are many different kinds, including chalcids, ichneumonids, braconids, and trichogrammatids. Tachinid flies also oviposit eggs in or on pest insects.\nThe Ravenous Youngsters\nA silent but raging battle occurs amid the leaves when immature stages of predatory insects move in on herbivorous pests. The purplish-black and orange larvae of ladybugs, resembling miniature alligators, stalk and devour aphids, as do their parents. Lacewing larvae with elongated gray abdomens and a long, curved pair of forward-projecting sucking mouthparts also ravage aphids. The larvae of some syrphid flower flies eat aphids, as many as 400 during the lifetime of the sluglike greenish larval fly.\nStealthy Blood Suckers\nLying in wait at the base of a leaf or inside a flower are predators in the true bug family (Hemiptera). Called assassin bugs, both wingless immature nymphs and winged adults feed on pests. Assassin bugs have long, slender antennae and sucking piercing mouthparts normally tucked under their bodies. The first pair of legs is modified to grab the prey. The assassin bug unfolds its mouthparts, stabbing them into the captured bug. It injects a toxic saliva that liquefies the prey's interior organs. The bug sucks up the resulting liquid. Spiders are also stealthy predators, most building webs to capture prey. Some spiders, such as crab spiders and jumping spiders, don't spin webs but jump on their prey to inject digestive saliva. Assassin bugs and spiders can inflict painful bites.\nThey Swallow Them Whole\nLarger, vertebrate animals can destroy a lot of bugs. An American toad (Bufo americanus) can eat up to 1,000 insects a day, using its sticky tongue and front feet to gather them into its mouth. Adult leopard frogs eat adult and larval insects, slugs, snails, earthworms and spiders. Many lizards, such as geckos, fence lizards and whiptailed lizards, are primarily insectivorous, and horned lizards eat only ants. Birds also consume insects, some more than others. Carolina wrens eat a diet consisting of about 94 percent animals, mostly insects. Tree swallows eat flying insects for about 80 percent of their food. A nursing little brown bat female eats more than her body weight in insects a night, or around 4,500 insects.\n- U.S. Environmental Protection Agency: Pesticides: Topical & Chemical Fact Sheets: Integrated Pest Management Principles\n- Symbiont Biological Pest Management: Parasitic Wasps\n- Bees, Wasps, and Ants: The Indispensable Role of Hymenoptera in Gardens; Eric Grissell\n- Mother Earth News: Tachinid Flies\n- University of Kentucky College of Agriculture, Food and Environment: Ladybugs\n- Bugs; Sarah Goodman\n- Oregon State University: Integrated Pest Management on Peppermint: Syrphid Fly Predators\n- SoftSchools.com: Assassin Bug Facts\n- University of Michigan: BioKIDS: Crab Spiders Thomisidae\n- BBC Nature Wildlife: Jumping Spiders\n- Photo Credit Jupiterimages/Photos.com/Getty Images\n- University of Michigan: BioKIDS: American Toad Bufo Americanus\n- University of Michigan: BioKIDS: Northern Leopard Frog Rana Pipiens\n- University of Michigan: BioKIDS: Carolina Wren Thryothorus Ludovicianus\n- University of Michigan: BioKIDS: Tree Swallow Tachycineta Bicolor\n- Bat Rescue.org: Amazing Bat Facts"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:a4a6c7ad-91cb-4afb-b49d-f4a46eba0078>","<urn:uuid:1c96cda0-af1d-4202-a0a4-d0cd3b4e4b1e>"],"error":null}
{"question":"difference between Pierce and educational pragmatism view on practice?","answer":"Peirce and educational pragmatism have different interpretations of 'practical.' For Peirce, 'practical' derives from practice or praxis, meaning how we shall act, focusing on habits of responsive action and effects on a person. It's not about objective or testable outcomes. In contrast, educational pragmatism takes a more direct approach to practical application, focusing on concrete activities like physical work, project methods, and direct experiences in learning. Educational pragmatism emphasizes learning by doing and solving real problems, while Peirce's view was more focused on how ideas influence habits of action and response.","context":["The 3rd rule for GSOT and philosophy is – Unless it makes a difference in somebody’s disposition to act, then it makes no difference.\nEvery sentence, idea, or conception is in some respect a message. Rule #1 was concerned with the origin of the message. Rule #3 is concerned with its impact.\nThis rule derives from pragmatism as originally outlined in 1878 by Charles Peirce (pronounced “purse”). Today many consider Peirce to be the greatest American philosopher. He was a path-breaking logician who, in addition to founding pragmatism, made wide-ranging contributions from statistical sampling theory to evolutionary love, which he called “agapeism.” Though highly productive in logic and philosophy, he seldom held a university post due to lapses in his personal finances and departures from social mores. He earned his living not as a professor, but as a practicing scientist with the U.S. Coastal and Geodesic Survey. In his final years, he begged and received handouts from friends including the Harvard professor, William James.\nJohn Dewey and William James, both closely influenced by Peirce, brought pragmatism into academic and even popular culture in the United States, but they also veered from the initial logical conception. By 1905 Peirce felt that his own version of pragmatism had been corrupted, and he curtly proposed renaming it “pragmaticism,” hence the title of this blog. Philosophers today mostly agree that Peirce hit the mark. They accept his original conception of pragmatism as arguably the greatest contribution of any American to philosophical thought. We’ll simply call it pragmatism henceforth.\nPut aside, then, whatever offhand descriptions of pragmatism you may have heard, and let’s see how Charles Peirce defined it. Here is the most commonly quoted statement from his 1878 paper:\nThe rule for attaining…clearness of apprehension is as follows: consider what effects, which might conceivably have practical bearings, we conceive the object of our conception to have. Then, our conception of these effects is the whole of our conception of the object.\n“Effects… [with] practical bearings” or more concisely practical effects are the words we tend to remember. Practical, instead of pointing toward Peirce’s initial concept of practice or habits of response, came to signify in the writings of James and Dewey “real-world” or “this-world” applicability. James almost equated pragmatism with empiricism. “Practical” evolved to mean almost the same thing as “objective” or even “testable,” and pragmatism morphed heedlessly into an on-the-street version of positivism. It became a kind of self-centered utilitarianism, focused on tangible goods and prone to crass compromise of principle.\nBut what exactly did Peirce mean by his use of the word “practical”? We can look back to another passage in his same 1878 article on “How to Make Our Ideas Clear”:\nFrom all these sophisms we shall be perfectly safe so long as we reflect that the whole function of thought is to produce habits of action; and that whatever there is connected with a thought, but irrelevant to its purpose, is an accretion to it, but no part of it. If there be a unity among our sensations which has no reference to how we shall act on a given occasion, as when we listen to a piece of music, why, we do not call that thinking. To develop its meaning, we have, therefore, simply to determine what habits it produces, for what a thing means is simply what habits it involves. Now, the identity of a habit depends on how it might lead us to act, not merely under such circumstances as are likely to arise, but under such as might possibly occur, no matter how improbable they may be. What the habit is depends on when and how it causes us to act. As for the when, every stimulus to action is derived from perception; as for the how, every purpose of action is to produce some sensible result. Thus, we come down to what is tangible and practical as the root of every real distinction of thought, no matter how subtile it may be; and there is no distinction of meaning so fine as to consist in anything but a possible difference of practice.\n“Practical” in Peirce’s language is not to be conflated with “objective” or “testable.” Instead it derives its meaning from practice or the Greek praxis, signifying “how we shall act.” Pragmatism, therefore, means that a thought is known only through the impetus it provides to a person to form a habit of responsive action. Notice that the effects described in the passage are decidedly effects on a person, not effects on some set of natural objects.\nAs an example, Peirce turned to the doctrine of transubstantiation, which is affirmed by Roman Catholics, but denied by Protestants. Catholics, he said, believe that the elements of the Eucharist taste like bread and wine, but their effects on the recipient are completely as if they are the body and blood of Christ, and furthermore, they are at that moment the body and blood of Christ. Protestants believe that the elements taste like bread and wine, but their effects on the recipient are completely as if they are the body and blood of Christ, and even so, actually they are just bread and wine.\nBy the pragmatic criterion, all that follows “and furthermore…” and “and even so, actually…” bears no distinction of meaning, because all of the effects on the participant have already been described.\nIt was hardly a momentous example, but it served to introduce the principle. The Catholic and Protestant views on transubstantiation are an example of what we might call a pragmatic pair. Let’s define a pragmatic pair as two answers to a question (“Are the elements really the body and blood of Christ?”) that seem to be distinct, but lead to no difference in practice – that is, no change in the way someone acts.\nThe Peircean notion of pragmatic pairs is a stunning contribution to philosophy, an extraordinarily powerful tool for putting useless arguments to rest. When you start to look around, pragmatic pairs begin to pop up everywhere. Here is a question, for which I think the answers compose a pragmatic pair:\nDoes God exist?\nI’m referring here not to the God of Abraham, Isaac, and Ishmael, nor to the God of Christians, Muslims, or Bahá’is. Instead I’m referring to the God of Mortimer Adler. In the next blog we’ll look at Adler’s God, and you can decide for yourself whether the existence of such a God is meaningful.\nPrevious post: Agreement Not Required\nNext post: Does God Exist?\nSearching for GSOT outline: Home\n How to Make Our Ideas Clear, first published in Popular Science Monthly (Jan. 1878), pp. 286-302, reproduced in Charles S. Peirce: Selected Writings ed. Wiener, P.P., Dover, New York, p. 124.\n Ibid. p 123.\n Notice also the Peirce uses first person language. This principle is not cast in the language of “publicly available,” third person, objective language.","Pragmatism- Its concept and meaning\nThe philosophy of pragmatism is relatively new in the educational theory and practice, which was propounded in the first half on 20th Century. The philosophers like William James, John Dewey, C.B. Pierce etc are responsible for propounding and propagating the philosophy of pragmatism. So the term doing, making, accomplishing are used whenever referring to pragmatism.\nPragmatism and Aims of Education\nPragmatism does not provide a fixed aims of education. The creation of new values is what is to be achieved through education. However, the following aims can be enlisted for the convenience of the study:-\n1. Creation of new values:– The main purpose of education is to provide variety of activities to the pupils so that they can create some new values out of the works or activities.\n2. Activity and experience:- Education should provide physical, intellectual, social and aesthetic activities so that they create some new values.\n3. Personal and social adjustment:- Education should be enable the child to fulfil his felt needs in the environment.\n4. Reconstruction of experience:– The cultivation of a resourceful, enterprising and creative mind should be the aim of education.\n5. All round development:- Education should enable the child to develop physically, mentally, socially, morally and aesthetically.\nContribution of Pragmatism towards Educational theory and Practice\nThe contribution of pragmatism to the field of educational theory and practice is innumerous. The modern education bears the imprint of philosophy of pragmatism in different aspects of it. However, the major contribution made by pragmatism toward education may be enlisted as below-\n1. Freeing the over-burden child :- Pragmatism saves the child from the burden of education which is too much book centered. Pragmatism is against bookish culture.\n2. Due emphasis on experience :- Pragmatism lays adequate importance on experience. Thus pragmatism helps us to realizing the value of present life by experiencing it.\n3. Balanced Approach :- Pragmatism guides us to have a balanced approach towards the past, present and future. the past may be glorious and rich, but it must guide for living a glorious and rich life in the present. Thus, too much emphasis on cultural heritage should not be laid.\n4. Learning how to learn :- According to pragmatism, the focus of teaching learning process is to enable the child how to learn.\n5. Flexible and dynamic method of teaching :- In pragmatism, method of teaching are flexible and dynamic, not static. They are based on utility and fulfil to the demands of the child and the society.\n6. Co-operative learning :- Pragmatism advocates that, children should get real experience of group life.\n7. Co-relation and integration :- Pragmatism stresses that, in order to progressive method of teaching effective, there is the need of the co-relation of studies, integration of subjects, use of audio-visual aids, organization of curriculum and co-curricular activities, learning by doing, direct experience and proper training of senses.\n8. Project method :- Project method is the most important contribution of pragmatism. This method incorporates all the principles, aims and method of teaching.\n9. More stress on action :- Pragmatism lays stress on action, rather than reflection. A child does not learn much from books. he learns from his own experience, new situations and activities. Learning by doing is given more importance in pragmatism. By giving practical work, a child can be put into real situations, so that he may himself solve the problems arising out of them.\n10. Social discipline and moral education :- According to pragmatism, discipline should be social in character. Social discipline is made possible through the co-operative and purposive activities in the school. The pursuits of such activities will foster social discipline. the students will gain moral and character training as well.\nThus, it is clear from the above discussion that the philosophy of pragmatism has tremendous educational implications."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:a005744d-e028-49e5-b6cd-27bfceb452fc>","<urn:uuid:e98abadd-4336-4475-af3a-7aea6604b8db>"],"error":null}
{"question":"What surprising fact did the NHL discover about their fan base location? Need this for a sports marketing project!","answer":"The NHL discovered that 60 percent of their fans don't live near their favorite teams. This led them to implement a geographical segmentation strategy for their email marketing, which helped increase single ticket game sales.","context":["E-commerce Link: Divide and Conquer\nSegmented, targeted emails can improve results up to nine times, according to Jupiter Research. As a marketer, you want to be more relevant to your customers, and segmentation should allow you to speak more directly to them, make them feel unique and enhance relevance. For marketers who are seeing stagnant or declining results, segmentation will definitely help. If you don't have a segmentation strategy, you're leaving money on the table. Let's look at five approaches to segmentation.\n1. Preference Center\nThe first place to look when working on a segmentation strategy is the information provided or updated within a preference center. The preference center is a valuable resource to use to successfully segment your customer base. For example, IKEA asks what rooms a new email signup are most interested in receiving information about. Some e-tailers allow their subscribers to decide whether they want to get messages about sales and clearance offers or new product and service offerings, while e-newsletter publishers often ask for content preferences.\n2. Demographics, Geography and Personal Information\nThis can be information email signups provided, or marketers could overlay information from one of the many data companies to learn more about their lists. Personal information might include information such as presence of children, home ownership, lifestyle interests and buying behavior. This also works for B-to-B, where marketers might segment on job function, industry and more.\nThe NHL has a large fan base, but it's interesting to note that 60 percent of fans don't live near their favorite teams. So, the organization segments its emails based on a subscriber's ZIP code and favorite team.\nFor example, a Boston Bruins fan who lives near Boston receives emails that feature upcoming home game schedules. However, if a Bruins fan lives in Philadelphia, he or she will get a similar email, but only when the Bruins are playing in Philly. The NHL knows this geographical segmentation strategy has increased single ticket game sales.\n3. Email Behavior\nLook at who regularly opens and clicks on your emails and what product categories or promotions they click on. For example, Barnes & Noble might regularly feature the latest bestselling fiction, mysteries, biographies and self-help books. If a group of recipients consistently click on mysteries—Barnes & Noble can create a mystery buff segment and market to them. The featured title might be a mystery, although the email message may also promote other genres.\nAmerican Meadows sells flowers and bulbs online, and used to regularly send one email per week. The company's email service provider (ESP), Bronto, suggested a change in strategy, and now American Meadows sends two emails per week. The first email promotes a variety of products. If recipients click on a particular product, they receive a second email later in the week featuring the product clicked. Those who did not click receive an email based on which item was the overall winner in terms of clicks.\n4. Past Purchase History and RFM\nDirect marketers know that if someone has purchased from you, they are much more pre-disposed to purchase from you again. This is a valuable segment. Typically, marketers will either promote other products in the same category or complementary products. For example, Amazon often sends emails based on past purchases and suggests other products based on the premise of \"those who purchased this product also bought …\"\nClare Florist, a U.K. company, knows if customers made previous purchases, they will buy again. Originally the florist thought a past purchaser might like to order different items. So, in addition to the product most recently ordered, the company provided two other additional items. However, sometimes simple is better; too many choices may paralyze the consumer. The florist tested featuring just the product category of the past purchase. And the test won—by a wide margin.\n5. Clicks and Time Spent Onsite\nYou also can segment based on who clicked on an email and spent time on your site. This requires tight integration between your website and ESP.\nSmartPak sells vitamins and supplements for horses. The company's ESP is integrated with its site-tracking platform. This allows SmartPak to send emails when someone browses a particular category presented in their emails.\nIf someone browses horse supplements, SmartPak will send an email featuring its supplement wizard that lets people easily figure out what's right for their horses. A company spokesperson reported that opens were 37.6 percent, clicks were 7.35 percent and revenue per delivered email was $0.44.\nAnd for good measure, here are four additional segmentation techniques to keep in mind:\n- Emails to inactives who have not opened or clicked on emails for months.\n- Use of sophisticated modeling to present the right product and offer combination to readers based on profile information and email and site behavior.\n- Messages with dynamic personalization are, by their very nature, customized to individual subscribers.\n- Triggered messages are extremely relevant, because a trigger is usually based on a user's activity.\nLet's close with a few recommendations for future action. If you haven't done any segmentation, don't bite off more than you can chew. Start with two to four segments. Carefully plan how your messaging will be differentiated and take the time to track results. And keep at it! A one-time test is not enough. Make the commitment to regularly employ segmentation for a few months to determine the lift in response. That doesn't mean that every email you send should use segmentation. But the enhanced relevance of these messages should also improve your other email results."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:d1625e78-cf56-497b-a6a3-ac48d8d5f97d>"],"error":null}
{"question":"How do the reproductive health approaches differ between the 1994 ICPD framework and current global health strategies in terms of their focus and implementation?","answer":"The 1994 ICPD framework emphasized shifting from using family planning purely for population stabilization to a broader approach including healthy sexuality and childbearing, with focus on reducing gender discrimination in education, healthcare, and income generation. The current global health strategy, while building on these principles, has evolved to be more targeted and quantifiable, with specific cost-effective interventions. These include universal access to sexual and reproductive health services (costing $3.6 billion annually), along with concrete goals like reducing newborn mortality by 70% and diminishing cervical cancer risk by 40% through HPV vaccination. The current approach also emphasizes coordinated action between public, private, and civil society sectors across various areas including nutrition, water and sanitation, and education.","context":["The International Conference of Population and Development (ICPD) 1994 established an International consensus on a new approach to policies to achieve population stabilisation. Fertility reduction should be addressed at the level of broad social policy, including reduction of gender discrimination in education, health care and income generation. Reproductive health programmes should focus the needs of actual and potential clients, not only for limiting births but also for healthy sexuality and child bearing. In India, the implications of the reproductive health approach would be to shift the focus from the use of family planning as a tool intended essentially for population stabilisation, to use family planning as one among a constellation of interventions that would enable women and men to achieve their personal reproductive goals without being subjected to additional burdens of disease and death associated with their reproduction.\nWorld Health Organization (WHO) has defined reproductive health as follows:\n\"Within the framework of WHO's definition of health as a state of complete physical, mental, and social well-being, and not merely the absence of disease or infirmity; reproductive health addresses the reproductive processes, functions and systems at all stages of life. Reproductive health therefore implies that people are able to have a responsible, satisfying and safe sex life and that they have the capability to reproduce and the freedom to decide, if when, and how often to do so. This definition focus on right of men and women to be informed of and to have access to safe, effective, affordable, and acceptable methods of fertility regulation of their choice, and the right to access to appropriate health care services that will enable women to go safely through pregnancy and childbirth and provide couples with the best chance of having a healthy infant\".\nEssential Components of RCH Programme\n1. Prevention and management of unwanted pregnancy.\n2. Maternal care that includes antenatal, delivery and postpartum services.\n3. Child survival services for newborns and infants.\n4. Management of Reproductive Tract Infection (TRIs) and Sexually Transmitted Infections (STIs).\nThe Government have power to restrict any unit, and to take samples of effluents and to get them analysed in Central or State laboratories. Whoever fails to comply with any provision of this Act is punishable with the imprisonment or with fine or with both. Second or third time breaking of the law is further punishable. Under the provision of this Act Central Pollution Control Board was established to fulfill its object.\nMajor Elements of RCH Programme\nA. Reproductive Health Elements\nResponsible and healthy sexual behaviour\nInterventions to Promote Safe Motherhood\nEssential Obstetric Care for All\nPrevention of Unwanted Pregnancies: Increase Access to Contraceptives\nPregnancy and Delivery Services\nFirst Referral Units (FRUs) for Emergency Obstetric Care\nManagement of RTIs/STDs\nInfertility & Gynecological Disorders\nReferral facilities by Government /Private Sector for Pregnant Woman at Risk\nReproductive Health Services for Adolescent Health\nGlobal Reproductive Health Strategy\nB. Child Survival Element\nEssential New Born Care\nPrevention and Management of Vaccine Preventable Disease\nUrban Measles Campaign\nElimination of Neonatal Tetanus\nCold Chain System\nPolio Eradication: Pulse Polio Programmes\nHepatitis B Vaccine\nGlobal Alliance for Vaccine and Immunisation (GAVI)\nDiarrhea Control Programme and ORS Programme\nPrevention and Control of Vitamin A deficiency among children","We would be wise to target neonatal deaths and cervical cancer\nTime.com has published Bjorn Lomborg’s new op-ed discussing the results from two health perspective papers written for the Post-2015 Consensus.\nHealth - Women & Children\nHow can we improve women’s health and save more than 14m children from dying before 2030? New research points to three development targets underpinned by cost effective strategies that can achieve this amazing ambition.\nProviding universal access to sexual and reproductive health services and eliminating the unmet need for contraception will result in 640,000 fewer newborn deaths, 150,000 fewer maternal deaths and 600,000 fewer children who lose their mother. At the same time, societies will enjoy a demographic dividend, with few dependents and many in the work force, driving faster economic growth. The costs will be about $3.6 billion/year, but the benefits will be more than $400B annually. In total, each dollar spent will do $120 of benefits.\nSecond, aiming to reduce newborn mortality by 70% will prevent 2m child deaths per year. This will involve providing expecting mothers with nutrients and protection from disease, having nurses and clean facilities at birth, and then ensuring best practice child care techniques immediately after, such as ‘kangaroo care’. Overall the benefits are $9 for every dollar spent, though the costs are very large at $14billion per year.\nFinally, diminishing the lifetime risk of cervical cancer by 40% in developing countries, by providing human papillomavirus vaccination (HPV) to young girls, will lead to 270,000 fewer deaths for every cohort vaccinated. Recent agreements to provide the HPV vaccination at very reduced prices in developing countries makes this outcome more achievable and cost effective, at $400m per year and returning $3 for every dollar spent.\nSummary Of The Targets From The Papers\n|Target||Annual Costs ($b)||Annual Benefits ($b)||Benefit for Every Dollar spent|\n|Universal access to sexual and reproductive health (SRH) services by 2030||$3.6||$433||$120|\n|Reduce neo-natal (0-27 days) mortality by 70% (2013-2030)||$14||$132||$9|\n|Diminish the lifetime risk of cervical cancer by 40% (representing nearly 3m avoided deaths)||$0.4||$1.4||$3|\nScroll down to read our set of reports examining women’s and children’s health targets for the post-2015 development agenda, written by leading economists and experts.\nWomen's Health Perspective\nIn this paper, Dara Lee Luca and David E. Bloom of the Harvard School of Public Health along with scholars from the University of Bergen and Vienna University of Technology examine the economic evidence behind interventions to improve women’s health. Noting that previous Copenhagen Consensus analysis already estimates the value of sexual and reproductive health rights, the authors decide to focus on another crucial women’s health issue: reducing deaths and disability from cervical cancer. Recent agreements to lower the cost of the human papillomavirus (HPV) vaccination in developing countries, enables large scale (70% coverage) vaccine rollout which the authors show returns $3 for every dollar spent.\n…scaling up HPV vaccination – in conjunction with judicious screening guidelines – could be the key to reducing the burden of cervical cancer in developing countries.”\n- Dara Lee Luca et al.\nInfant Mortality Perspective\nGünther Fink, Associate Professor of International Health Economics at Harvard School of Public Health examines the costs and benefits of interventions to prevent the death of neo-natals, children less than 28 days old. He suggests that reducing neo-natal deaths by 70% or 2 million children, by 2030 is an effective target, returning $9 for every dollar spent through strategies such as nourishing pregnant mothers and providing clean birthing facilities. However, Fink cautions that these strategies would require significant upgrading of health systems around $14B per year in additional costs - a challenge given the current landscape of global health financing.\n…large further reductions in neonatal as well as child mortality are possible and should be targeted by the new development goals. Compared to other areas like diarrhea, malaria or HIV, achieving improvements in neonatal mortality will require more fundamental changes in health systems, and, accordingly, require substantially more resources.”\n- Günther Fink\nInfant Mortality Viewpoint\nPatrick Gerland, Senior Analyst, Department of Economic and Social Affairs, United Nations and Danzhen You, Statistics and Monitoring Specialist at UNICEF, acknowledge recent progress in reducing under-five mortality, but point out that 17,000 under-five year old children still die every day from preventable causes. They focus attention on the need for coordinated action by public, private and civil society sectors in a range of areas, including nutrition, water and sanitation, education and other sectors, all of which impact on health outcomes for both women and children.\nCountries need to turn their pledges into practical action to scale up progress on newborn and child survival by sharpening national strategies for reproductive, maternal, newborn and child health, setting costed targets and monitoring progress.\"\n- Patrick Gerland and Danzhen You\nWomen's Health Viewpoint\nAnn Starrs, President, Guttmacher Institute argues that the global community must recognizes the importance of universal access to sexual and reproductive health to all aspects of development goals from girls education to reducing poverty to enhancing sustainable economic growth.\nAddressing that unmet need (for contraceptives) is one of the most fundamental – and potentially far-reaching – challenges we face in public health. Helping women and families avoid an unwanted pregnancy saves lives and money.”\n– Ann Starrs\nThe Post-2015 Consensus project brings together 60 teams of economists with NGOs, international agencies and businesses to identify the targets with the greatest benefit-to-cost ratio for the UN's post-2015 development goals."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"}],"document_ids":["<urn:uuid:26b6b972-c4fe-4b43-9c52-1069fa5ec3eb>","<urn:uuid:5c0046f4-de68-461d-828b-4d91e3b43d2b>"],"error":null}
{"question":"Hey fitness experts! What are the physical risks of intense military training programs like BORTAC, and how do these risks specifically affect kidney function? Would love to understand both the immediate dangers and long-term health impacts! 🏃‍♂️💪","answer":"Intense military training programs like BORTAC can cause rhabdomyolysis, particularly in underprepared individuals or those with larger muscular frames. During these programs, which involve heavy load bearing and extensive rucking (80+ miles per week with 75-100lb loads), the physical strain can be extreme. This intense exercise can potentially impact kidney function, as kidneys are responsible for filtering blood 20-25 times daily and maintaining electrolyte balance. The risk becomes especially concerning because kidney damage can be asymptomatic until advanced stages. To prevent these risks, proper preparation is essential, including maintaining hydration with electrolytes, using compression socks, and following a progressive training program over 12-24 weeks. Additionally, incorporating non-impact cardio days and avoiding overtraining are crucial preventive measures.","context":["Tough selection programs in military special ops and SWAT law enforcement have training requirements that go above and beyond what the mind thinks the body can endure. Mind-over-body determines who will succeed and who will fail. In these type of training programs, rhabdomyolysis can occur. Your preparation and knowledge on this topic is critical to your ability to avoid it. Check out this email question and answer on the topic of both preparation and recovery for such hardcore training programs:\nStew, I am a Border Patrol Agent getting ready to apply for the BORTAC selection which is very challenging with rucking, load bearing, running, swimming, and PT smoke sessions that create a 25% graduation rate typically. In one week alone we do over 80 miles of load bearing / rucking with serious loads of 75-100lbs.\nProblem: How do you train for this? And many people who fail, fail because they get Rhabdomyolysis. How do I prevent that from happening? Thanks Darryl\nWow, that is a tough program! I have heard about it over the years and it really is a combo of BUD/S Hell week and SF Selection. A respectable challenge that should not be over-looked for sure. The best answer to be prepare yourself for months – maybe even have a solid high fitness level foundation for over a year. Building or maintaining the level of fitness takes time several days a week – even a few hours a day – and a few long days of work and training combined to build the type of all day endurance you need.\nTwo types of people get this ailment – those who are underprepared and those who have a bigger / more muscular frame for their body height.\nHere is a list of ideas for you to consider not only for preparation but daily recovery and nutrition / hydration / electrolytes requirements:\n- Thorough preparation with programs like Tactical Fitness - This is a good overall plan to build a generic high level of fitness that is both foundational and challenging. Now if a bigger person, the cardio / endurance sections should be repeated or with added miles to build that aerobic base they need to decrease the chances of rhabdo. However, the thinner / endurance types should consider the Tactical Strength programming to build the mass / strength needed to handle the heavy rucking / equipment carries.\n- Goals: I think you will seek two things – A) A decrease in injuries on the lighter / endurance guys if they focus on strength (with obvious cardio conditioning - run - ruck - swim). B) And a decrease in rhabdo with the below list of (nutrition, hydration, electrolytes, compression socks) and aerobic focused conditioning for the bigger power athletes. Losing some muscle mass but building endurance for the bigger athlete and adding some mass / strength on the endurance lighter athlete would be the goals to seek.\n- If I were to make a template for this program I would focus on both body types by creating a program that mixed in the option of strength exercises with TRX or calisthenics for the bigger power athletes along with lots of cardio options. AND the same program would have more weighted calisthenics, weight training / strength / core work for the endurance guys - along with a sufficient amount of cardio / load bearing options (aka rucking).\n- The key to success for such a challenging GUT CHECK as BORTAC is a longer progressive training program - something 12-24 weeks at a minimum with this Strength / Endurance focus for your candidates. Otherwise the quick progression of BORTAC will continue to crush the unprepared.\n- Selection PREP - Building up to 80 miles in a week is NOT necessary, building the foundation that allows for that type of gutcheck requires a significant time at a high volume of miles and long days of work with long strength / endurance (non impact cardio too) workouts. This may take morning sessions, lunch sessions, after work sessions to thoroughly progress up to have that kind of Work Capacity. In other words – putting in the time.\nThe rucks being 70-80lb and team building adding another 50-100lb to a candidate load require strength and mass. But with the average miles for the week being over 80 plus requires endurance. Having a combo of both is required. Since these candidates have to be current Border Patrol Agents, training should be done carrying extra loads during work, standing long periods of time, and still working out during the day. Getting both proper amounts of strength and endurance requires time training for both in a periodization format that could take a significant time to prepare. This is almost of lifetime of fitness requirement and you top it off with 6-12 months of specific training. Here are more tips to help:\n- Aerobic base being king for the long haul of selection\n- Don't train hell week to do hell week \"Over training being our worst enemy\"\n- Need for non-impact cardio days – Mix in bike, swimming, and other to avoid daily impact during training.\n- Learn about rhabdomyolysis and how to prevent it.\n- Proper hydration with electrolytes and nutrition (monitored and enforced/controlled)\n- Compression socks (2XU brand for example)","Symptoms, Consequences, and How to Reduce Your Risk\nA pair of fist-sized, bean-shaped organs, your kidneys sit on either side of your spine, just below the rib cage. Their main function is to filter your blood by removing waste and excess water to make urine. Dr. Christopher Poole, a partner at Nephrology Associates of Chattanooga, shares, “Our kidneys receive and process our entire blood volume 20 to 25 times each day.”\nIn addition to filtering blood, your kidneys also stabilize electrolytes like potassium, sodium, and phosphorus, and release hormones that help regulate blood pressure, create red blood cells, and produce an active form of vitamin D. In short, kidneys are vital organs that perform life-sustaining functions that the body requires. In the event they have some type of abnormality or become damaged, they lose the ability to perform their crucial functions, which results in kidney disease. “Kidney disease is defined as any damage to the kidneys that is found by laboratory testing,” explains Dr. Poole.\n“When function in the kidneys become irreversibly damaged, we call that chronic kidney disease, or CKD,” shares Dr. Rafael Duchesne, a nephrologist with Nephrology & Hypertension Specialists. With CKD, the kidneys cannot filter blood, which means excess fluid and waste build up in the body.\nThirty million people– that’s 15% of U.S. adults– likely have CKD, but many are entirely unaware, since the disease often doesn’t produce symptoms until it’s more advanced. In fact, nearly half of those who have severely reduced kidney function are unaware they have the disease, while 96% of people with some level of kidney damage or mildly reduced kidney function have no idea their kidneys aren’t healthy.\n“CKD is a progressive disease, and unfortunately, CKD symptoms are nonspecific and can go unnoticed until the disease has progressed to the later stages,” explains Dr. Duchesne.\nThe signs that might arise in later stages include fatigue, trouble concentrating, poor appetite, nausea and vomiting, dry and itchy skin, bloody urine, increased urination (particularly at night), painful urination, and swelling in the lower extremities.\nWho’s Most at Risk?\nApproximately 1 in 3 adults with diabetes and 1 in 5 adults with high blood pressure may have chronic kidney disease. CKD is more common in women than men and more prevalent in African Americans, Hispanics, Pacific Islanders, Asians, and Native Americans. Seniors over 60 are more likely to develop CKD due to the natural loss of kidney function, combined with an increased risk of diabetes and hypertension.\nCKD occurs when a disease or condition impairs kidney function, causing abnormalities or permanent damage. The leading cause of CKD is diabetes, which prevents your body from producing enough insulin or using it normally, resulting in a high blood sugar level. Over time, the high levels of glucose in the blood can damage the kidneys.\nHigh blood pressure, also known as hypertension, is the second leading cause of CKD. Uncontrolled hypertension can cause the arteries around the kidneys to narrow, weaken, or harden. This means that over time, they become unable to deliver enough blood to kidney tissues. “Diabetes and hypertension are responsible for two thirds of all CKD cases,” says Dr. Duchesne. “Anyone with either disorder should have a blood and urine test at least yearly.”\nThe third leading cause of kidney disease is glomerulonephritis, an inflammation of the tiny filters in your kidneys. This condition may arise on its own, or as part of another disease like diabetes or lupus.\nOther conditions that can affect your kidneys include kidney stones and infections, diseases that affect the body’s immune system, acute kidney injury (which can results from injuries, major blood loss, or reactions to some medicines), or genetic diseases such as polycystic kidney disease, which causes large cysts to form on the kidneys and damage the surrounding tissue.\nWhile the damage done to your kidneys cannot be reversed, there are treatments that can help your kidneys perform their functions.\nDialysis: Typically, when kidney function is reduced to 10-15%, dialysis becomes a viable treatment option. There are two versions, depending on severity and other factors.\nHemodialysis: With this form of dialysis, a patient is connected to a dialysis machine and an artificial kidney, called a dialyzer, which pumps blood, filters it, and returns it to the body. This method, which is usually done three times a week for approximately four hours, is most often completed at a hospital or dialysis center.\nPeritoneal dialysis: With this form of dialysis, a catheter is surgically implanted in the abdomen, and a sterile cleansing fluid, called dialysate, is sent through to filter and wash. Treatments can be done at home, at work, or while traveling. However, peritoneal dialysis isn’t possible for some patients. Those who are obese or who have had multiple prior abdominal surgeries may not be ideal candidates.\nKidney Transplant: For people whose CKD has advanced to the point of complete kidney failure, a kidney transplant may be the best option. The kidney can be donated from a living relative or friend, or from a stranger who wished to donate their organs upon death. Studies show that people with kidney transplants live longer than those who remain on dialysis. However, Dr. Duchesne explains, “It is important to note that transplantation is not a cure, but another treatment.” Those considered for a transplant must be healthy enough for operation and cancer- and infection-free.\nEarly detection is crucial to slow or prevent the progression of kidney disease. If you are 60 or older, have a family history of kidney disease, or have any high-risk conditions that are likely to cause CKD like diabetes or hypertension, it’s important to discuss prevention methods with your doctor.\nMost likely, you’ll need to undergo two simple tests as a part of your annual physical. Dr. Poole explains, “The lack of any outward symptoms is why seeing your primary care provider regularly to have blood work and urine studies done is vital to diagnosing and managing chronic kidney disease.”\nA urine test can identify the amount of the protein called albumin in your urine; too much of this type of protein indicates damage. Dr. Poole explains, “The filters in the kidneys are set up to retain almost all of the protein they are exposed to. If the filters are damaged, protein will leak out and will appear in the urine.”\nThe second test, a blood test, can measure kidney function by checking your creatinine (a waste product that is removed by the kidneys) levels to determine how well the kidneys are removing waste.\nIt is also important to manage blood pressure and blood sugar levels. Even pre-hypertension and pre-diabetes (slightly elevated blood pressure or blood sugar levels) can cause damage to your kidneys. Quitting smoking will help keep levels in check.\nMaintaining a healthy weight, incorporating regular exercise, and making good food choices reduce your risk of developing not only kidney disease but many other health ailments that are closely linked to CKD.\nExercise caution when taking both over-the-counter and prescription pain medications. Part of the kidneys’ job is to filter these types of medications from your body, meaning they have to work especially hard when pain medication is ingested on a regular basis. Take care to avoid excessive use of non-steroidal anti-inflammatory drugs such as ibuprofen and naproxen, as NSAIDs can lower kidney function over time.\nSince kidney disease is often asymptomatic, it’s vital to be vigilant and visit your doctor regularly. Don’t be afraid to ask questions if you fall into a risk category, and don’t ignore any signs that don’t sit well with you. With early diagnosis and proper treatment, you can continue a happy, healthy life for years to come."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"future"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"comparison"}],"document_ids":["<urn:uuid:beaf36fa-0e94-4877-b742-e1078359d35f>","<urn:uuid:7f233ce4-9a2c-41a2-a6ee-ed6c4aa33c70>"],"error":null}
{"question":"What was the status of women's representation in literature historically, and how has their political representation evolved in modern times?","answer":"Historically, women were severely underrepresented in literature, with men having greater advantages in education and writing opportunities. As noted in Austen's 1818 work, 'the pen has been in their hands.' This underrepresentation has continued into modern political spheres, though with some improvement. As of 2019, while women make up about half the US population, only 24% of US Congress members were women, and state legislatures averaged 30% female representation. There has been progress - since 1971, the number of women in state legislatures has more than quintupled. Notable milestones include Jeannette Rankin becoming the first woman in the US House of Representatives in 1916, and Nevada's state legislature achieving over 50% female representation by 2019.","context":["Writing about the significance of gender roles at GCSE\nUnderstanding the significance of context and then embedding relevant aspects of it within a response is something that is very difficult to teach, especially to youngsters who are yet to build much of their own context, let alone understand that of a 19th century poet. I knew that I had to tackle how my students were dealing with context, particularly the way in which they were writing about gender roles, when I kept seeing phrases like…\n“Back in those days when…”\n“In that era, women were not treated equally…”\n“Men were in control during this time…”\nI approached this with several layers of strategy and have seen a marked improvement in not only their confidence of expression, but also in the concise nature of their assertions.\nKey vocabulary and phrases\nAs a class we discussed and developed our own vocabulary list that expresses clearly what ideas students have about gender roles from the 18th-19th century. For centuries, societies have developed and assigned different roles and codes of behaviour to men and women – much of this students understand, but struggle to express.\nIn pairs, students listed these roles and ideas associated with them and we then wrote them in a column on the board. We discussed how these ideas could be articulated in a more concise way. Here are some of the key words and phrases that we are now using:\nCodes of behaviour\nStandards of masculinity and femininity\nMoral codes of sexual purity\nMen seen as ‘guardians’\nMoral virtues, social graces\nEconomically, educationally, legally and socially disadvantaged\nThe Male Gaze (an excellent article on this here).\nHaving completed the list, as a class, we divided the words into two columns – those we associated with women and those we associated with men. Students were asked to redraft a piece of work using the more precise terminology.\nThe Separate Spheres\nClassroom activity: Students draw their two spheres across a whole page, slightly overlapping the middle (or, I’d suggest printing them). In each sphere, one for men, one for women, students make notes on the gender roles and expectations relevant to the texts they are studying. They can then explore how these roles and expectations are painted in the text around the edge of the spheres.\nI’ve written more on the separate spheres using An Inspector Calls as an example here.\nLinks to Literature\n“Men have had every advantage of us in telling their own story. Education has been theirs in so much higher a degree; the pen has been in their hands,” Anne Elliot in Austen’s Persuasion (1818).\nGiving students the opportunity to research and create a literary timeline is also a key aspect of developing confidence in their writing and ensuring that they are secure in the assertions that they make about context. Creating a timeline that has links to Literary movements and the impact of women writers on literature which maps out the ever-changing roles of both men and women in society is invaluable. This creates a strong springboard from which students can make inferences and show understanding of certain characters and themes as they read and study.\nThe British Library have a series of excellent pages on women and writing. I found the below particularly relevant:\n- Female education, reading and Jane Austen\n- Elizabeth Barrett Browning and the Woman Question\n- Gender roles in the 19th century\nThank you for reading.","By Jennifer Nicoll Victor, Ph.D., George Mason University\nAmerica was established as a democracy, but it was a particularly weak one. We credit the American civil rights movement as helping to significantly expand democracy and civil rights in the country. Let us take a look at the policy of affirmative action and the women’s suffrage movement that can be seen as a precursor of the civil rights movement in America.\nThe End of the Jim Crow Era in America\nThe election of 1960, between John F. Kennedy and Richard Nixon, was a turning point in the struggle against racial discrimination. To win the election, Kennedy supported civil rights as a central theme of his campaign. Kennedy won the election but was assassinated in November 1963 before civil rights legislation could be enacted.\nWith a promise to carry out Kennedy’s legacy, his Vice President, Lyndon Johnson, a southerner (from Texas) himself, oversaw the passage of the 1964 Civil Rights Act and the 1965 Voting Rights Act—landmark policies that fundamentally changed the course of American history.\nThese laws effectively ended the Jim Crow era in the South. Moreover, the strategic choice of elite Democrats to help end systematic disenfranchisement of African Americans created a strong bond of partisan loyalty between the Democratic Party and the African American community that remains to this day.\nThis is a transcript from the video series Understanding the US Government. Watch it now, on The Great Courses Plus.\nThe Rise of Affirmative Action\nAffirmative Action refers to a policy that uses some form of preferential weighing of individuals in order to achieve diversity.\nIn an attempt to achieve a more diverse employee or student population, companies or universities enacted policies that provided some preferential treatment to candidates from minority backgrounds.\nThere were three key Supreme Court cases that addressed the legality of affirmative action.\nRegents of University of California v. Bakke Case\nIn 1978, a white student sued the university for racial discrimination upon being twice denied admission to medical school at the University of California, Davis.\nThe Supreme Court agreed with Bakke that using race as a criterion was “suspect”. The Court ruled that schools could not set aside seats for students using a race-based quota system to achieve a diverse student body, they also found that the use of race as a criterion in admissions decisions in higher education was constitutionally permissible.\nHopwood v. Texas Case\nIn 1996, a case was decided not in the Supreme Court, but in the Fifth Circuit Federal Court of Appeals—one step below the Supreme Court.\nThe Fifth Circuit Court ruled that race could not be considered at all as a factor in university admissions. The Supreme Court declined to hear the case on appeal, which meant that the ruling of the Fifth Circuit became the legal standard for all states under its jurisdiction.\nGrutter v. Bollinger Case\nIn 2003, the Supreme Court gave a ruling in a case that has put affirmative action on its strongest footing yet. The ruling stated that racial considerations can sometimes be utilized to serve a compelling state interest.\nIn upholding the University of Michigan Law School’s affirmative action program that took race into account (minus quotas), the Supreme Court provided a legal blessing to a key system many companies/universities utilized to help achieve racial diversity goals.\nLearn more about the Supreme Court’s role in politics and government.\nThe Revolution of Women’s Rights Movement\nThroughout the late 1800s, thanks to Lucretia Mott and Elizabeth Cady Stanton, two key figures in the women’s suffrage movement, some states granted women the right to vote. However, women did not gain federal protection for their right to vote until 1920, with the ratification of the 19th amendment.\nAfter securing voting rights, the women’s rights movement sought further civil rights (protection from discrimination based on sex) and advocated that the US adopt an Equal Rights Amendment to the Constitution. Section One of the proposed amendment reads:\nEquality of rights under the law shall not be denied or abridged by the United States or by any State on account of sex.\nThe proposal became known as the ERA.\nFeminism vs. Anti-Feminism and the Fate of ERA\nIn 1972, during the peak of the movement known as second wave feminism, the House of Representatives passed the ERA by an overwhelming 354 – 24 vote, and the Senate passed it with a vote of 84 – 8. Once passed by Congress, a constitutional amendment had to be ratified by three-quarters of state legislatures.\nHence, the ERA had to be ratified by at least 38 states, and 30 did so within the first full year. By 1978, 35 states had ratified. At that point, anti-feminist organizations such as Eagle Forum Led by Phyllis Schlafly generated intense pressure against ratification.\nThey argued that the amendment would be detrimental to American families and communities and would encourage women to eschew their traditional roles as caretakers or homemakers. Pro-ERA feminist groups became ineffective advocates for ratification because they were divided over the issue of abortion.\nBut when the landmark Supreme Court case, Roe v. Wade was handed down in 1973, America’s focus on women’s issues heightened. In 1978, Congress extended the ratification deadline to 1982.\nNo new states ratified the ERA during this extension period, but some states rescinded their previous ratification, and ultimately the 10-year clock ran out. On January 27, 2020, however, Virginia became the 38th state to ratify the ERA.\nLearn more about American Democracy.\nThe Effects of ERA on Women’s Political and Social Status\nWomen continue to be underrepresented in political office. While about half the US population is female, in 2019, only 24% of US Congress members were women (30% for state legislators).\nSince 1971, however, the number of women serving in state legislatures has more than quintupled. Notably, as of 2019, the Nevada state legislature is more than 50% female, but in Mississippi, only 14% of state legislators are women.\nThe first woman to serve in the US House of Representatives was Jeannette Rankin, elected as a Republican from Montana in 1916—before her right to vote was federally protected.\nA Renewal of Feminist Social Movement\nIn recent years, women’s issues have gained increased public attention, leading some to suggest that we are entering a period of renewed feminist social movements. Various campaigns have led many victims of sexual harassment to go public about the abuses they’ve experienced.\nSeveral high-profile and powerful male executives have lost their jobs as a consequence of being exposed. Most were top news and entertainment heavy-hitters as well as several politicians.\nCommon Questions about Social Movements in America: The Fight for Equality\nTo win the elections in 1960, John F. Kennedy made the civil rights his focus point during the presidential campaign.\nAfter securing voting rights, the women’s rights movement sought further civil rights (protection from discrimination based on sex) and advocated that the US adopt an Equal Rights Amendment to the Constitution. The proposal became known as the ERA.\nIn the mid-1800s, women began their movement for civil rights."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:721be744-3a9f-4c71-8077-66bae50fcc96>","<urn:uuid:4fb09f35-46fe-4a7c-b15c-9b3f7df6eafc>"],"error":null}
{"question":"Could you explain the similarities between segmentation mechanisms in beetles and humans, and what are the potential evolutionary implications?","answer":"The genetic developmental mechanism controlling body segment formation in Tribolium shows striking similarities to the mechanism that creates repeated internal body structures in humans, such as vertebrae/ribs and associated muscle. Both arthropods and vertebrates form segmented structures under the control of a 'segmentation clock' gene network. This similarity suggests either that both mechanisms were inherited from a common ancestor that lived over 550 million years ago, or that they represent parallel evolution where similar gene networks evolved independently to pattern reiterated morphological structures.","context":["Dr. Andrew Peel\n- Position: Lecturer in Animal Biology\n- Areas of expertise: Evolutionary Developmental Biology (evodevo); Arthropod Developmental Biology; Insect Body Segmentation; Insect Head Development; Developmental Gene Networks; CRISPR/Cas9 Genome Editing.\n- Email: A.D.Peel@leeds.ac.uk\n- Location: 8.22 Miall\n- Website: Peel Laboratory for Evolution & Development\nI joined the University of Leeds as a Lecturer in Animal Biology in 2012\nI obtained my PhD from the University of Cambridge in 2006, before undertaking postdoctoral research at the Institute of Molecular Biology & Biotechnology (IMBB), Heraklion, Crete, Greece (2006-2012).\n- Academic Examinations Officer; School of Biology\n- Academic Integrity Officer; School of Biology\n- Module Manager\nI am interested in how animal evolution occurs at different levels of biological complexity; i.e. genetic, cellular, organismal and ecological. My research efforts to date have focused on understanding how diversity in animal body plans evolved. Animals obtain their species-specific morphological characteristics during embryonic development and/or metamorphosis. My work therefore compares the genetic and cellular mechanisms controlling embryogenesis in different animal species in order to identify the molecular changes that underpinned divergence in animal body plans during evolution.\nThe red flour beetle Tribolium castaneum\nMy research currently focuses on a laboratory model insect species, the red flour beetle Tribolium castaneum. This is a holometabolous insect species, meaning that it exhibits 'complete metamorphosis', passing from larva to adult via a pupal stage. I study Tribolium because it is becoming increasing amenable to genetic manipulation in the laboratory and has retained a number of interesting ancestral developmental traits, such as the sequential formation of body segments during embryogenesis.\nThe evolution of segmentation mechanisms in holometabolous insects\nOne of the aims of my work is to provide important insights into how developmental gene networks evolve. This can be achieved by gaining a deep understanding of the developmental genetic mechanisms operating in Tribolium, and identifying how these are similar or different to the development genetic mechanisms operating in other holometabolous insect species; e.g. the parasitic wasp Nasonia vitripennis, the honeybee Apis mellifera, the moths Bombyx mori and Manduca sexta, and the fruit fly Drosophila melanogaster (see Peel, 2008. Philos. Trans. R. Soc. Lond. B. Biol. Sci.). I am particularly interested in using comparative developmental biology to understand how the gene networks controlling body segment formation have evolved (see Peel, Chipman & Akam, 2005. Nat. Rev. Genet.). Ancestrally, insects developed their trunk segments sequentially, in an anterior-to-posterior progression. This developmental trait is found in more primitive, non-holometabolous, insect species, such as grasshoppers and true bugs, as well as non-insect arthropods such as centipedes and spiders. The beetle Tribolium is an example of a holometabolous insect species that has also retained this ancestral trait during evolution. However, many other holometaoblous insects, including Nasonia, Apis and Drosophila, have evolved a faster mode of development in which all body segments form more-or-less simultaneously. By studying the genetic and cellular mechanisms underlying Tribolium body segment specification I explore how this evolutionary transition from sequential to simultaneous segmentation might have occurred.\nThe origin and evolution of segmentation mechanisms in animals\nI also make comparisons between much more distantly related animals. My recent work has helped to prove that the genetic developmental mechanism controlling the formation of body segments in Tribolium shows striking similarities to the developmental mechanism that gives rise to repeated internal body structures in humans, such as our vertebrate/ribs and their associated muscle (see Sarrazin*, Peel* & Averof, 2012. Science). Segmented structures in arthropods and vertebrates both form under the control of a 'segmentation clock' gene network. I am currently investigating whether the arthropod and vertebrate segmentation clocks are sufficiently similar at the genetic level to suggest that they were both inherited from the common ancestor of arthropods and vertebrates. This ancestral animal lived over 550 million years ago. The alternative possibility is that arthropod and vertebrate segmentation clocks represent an interesting case of parallel evolution, in which similar gene networks have evolved, or been recruited, independently, to pattern reiterated morphological structures. Either way, my work promises to offer important insights into some of the earliest events in the evolution of animal developmental mechanisms.\nFlour beetles are also a classical laboratory model system for studying intra- and interspecific ecological interactions, and among many significant beetle pests of stored food products. In collaboration with other members of the School of Biology I am currently developing a number of projects investigating the genetic factors that influence Tribolium behaviour and community ecology, with a view to improving beetle pest management and understanding the factors involved in the maintenance of species diversity.\nRahul Sharma (Research Fellow - BBSRC)\nMatthew Dooley (BBSRC/Fera PhD student; Oct 2014 - Sept 2018)\nDescription of Images:\nTop panel: Tribolium castaneum oogenesis and early embryonic development.\nFrom left-to-right:  Tribolium ovariole showing oocytes (unlaid eggs) at different stages of development; taken from a transgenic beetle in which nuclear localized green-fluorescent protein (nGFP) is ubiquitously expressed (green). Acetylated tubulin is stained red.  Tribolium terminal oocyte, now filled with yoke, and almost ready to be laid – green and red show the same as in . Note the asymmetric position of the oocyte nucleus – its migration to one side of the oocyte helps set the ventral-dorsal (front-to-back) body axis (see Lynch et al., 2010).  View down on the anterior pole of a recently laid (1-2 hours old) Tribolium egg showing anteriorly localized mRNA of the gene Tc-pangolin (red) associated with a cortical microtubule network (green) (see Peel & Averof, 2010).  A mitotic wave sweeping across a Tribolium blastoderm embryo (from bottom left to top right). Note the leakage of nGFP (green) when the nuclear envelope (red) breaks down prior to mitosis.  An early germband embryo, with nuclear membranes stained red, at the beginning of axis elongation and the formation of abdominal segments. The developing head lobes are at the top.\nMiddle panel: Developmental gene expression in Drosophila and Tribolium embryos.\nFrom left-to-right:  Early Tribolium germband embryo showing expression of two genes (Tc-even-skipped and Tc-odd-skipped) involved in segment formation that are expressed out-of-phase with one another (see Sarrazin et al., 2012). . An elongating Tribolium embryo showing expression of the segmentation gene Tc-engrailed (blue) and the Hox gene Tc-Deformed (red) (see Peel et al., 2013). . Abdominal region of a Drosophila embryo showing expression of the engrailed-family genes engrailed (red) and invected (green) (see Peel et al., 2006). Nuclei are stained blue.  Anterior end of a fully extended Tribolium embryo showing expression of the segmentation gene Tc-engrailed (blue) and the head development gene Tc-collier (see Peel et al., 2013). . Drosophila blastoderm embryo showing expression of the segmentation gene fushi-tarazu (yellow). Nuclei are stained grey.\nBottom panel: Oscillating segmentation gene expression in Tribolium.\nFrom left-to-right: [1-5] Embryos of increasing age showing germband elongation and dynamic expression of the segmentation gene Tc-odd-skipped. Expression of Tc-odd-skipped oscillates in the posterior most cells of the embryo (see Sarrazin et al., 2012).\nCurrent Research Projects:\nInvestigating the gene regulatory network underlying the segmentation clock of the flour beetle Tribolium castaneum (2015-2019). Funded by a BBSRC New Investigator Research Grant (BB/L020092/1)\nRecent Research Projects:\nInvestigating the Arthropod Segmentation Clock that controls Sequential Segment Formation during Arthropod Development and its Potentially Ancient Evolutionary Origins (2013-2017). Funded by a Marie Curie CIG (PCIG12-GA-2012-333650).\n<h4>Research projects</h4> <p>Any research projects I'm currently working on will be listed below. Our list of all <a href=\"https://biologicalsciences.leeds.ac.uk/dir/research-projects\">research projects</a> allows you to view and search the full list of projects in the faculty.</p>\n- BSc Zoology, Edinburgh (2000)\n- PhD Zoology, Cambridge (2006)\n- European Society for Evolutionary Developmental Biology (EURO EVO DEVO)\n- British Society for Developmental Biology (BSDB)\n- Genetics Society\nPostgraduate studentship areas:\n- Investigations into the genes and regulatory interactions underlying the Tribolium segmentation clock\n- Investigations into the genetic and cytoskeletal mechanisms controlling mRNA localization during axis specification in Tribolium\n- Investigations into the genetic factors that influence Tribolium spp. ecology and behaviour\n- Faculty Graduate School\n- FindaPhD Project details:\nUndergraduate Modules managed\nBLGY2223 - Organismal Evolution\nBLGY3245 - Advanced Topics in Evolution\nUndergraduate Modules taught\nBLGY1124/1128 - The Diversity of Life/Living Planet\nBLGY1128 - Living Planet\nBLGY1303 - Tutorials for Biology and Genetics\nBLGY2100/2301 - Level 2 Tutorials\nBLGY2223 - Organismal Evolution\nBLGY2262 - Animal Developmental Biology\nBLGY2301 - Research Experience and Skills Level 2\nBLGY3245 - Advanced Topics in Evolution\nBLGY3251 - Animal Developmental Biology\nExaminations Officer for PGT Programmes - School of Biology\nExaminations Officer for UG Programmes - School of Biology\nMember of Masters Taught Student Education Committee (Exams Officer: Biodiversity and Conservation)\nMember of Undergraduate School Taught Student Education Committee\nResearch groups and institutes\n- Ecology and Evolution\n- Heredity, Development and Disease"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"future"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_intent","category_name":"instructional"}],"document_ids":["<urn:uuid:198d320d-3444-414d-8eb3-7c6b8595d861>"],"error":null}
{"question":"What are the essential rules to make a proper risotto that I should never skip? 📝","answer":"There are 8 key rules for perfect risotto: 1) Use the right rice variety - Carnaroli, Vialone Nano, or Arborio, and never rinse it. 2) Use a proper pan about 3\\\" tall, avoiding non-stick. 3) Use appropriate base ingredients: right fat (olive oil/butter), soffritto (usually shallots/onion), hot stock, and dry white wine. 4) Always toast the rice before adding liquid. 5) Don't overmix - stirring too much breaks grains and makes it gluey. 6) Pay constant attention for about 20 minutes, adding stock gradually. 7) Never skip the 'mantecatura' - finishing with fat (butter/oil) and cheese off the heat. 8) Achieve 'l'onda' consistency - the risotto should create a wave when served, neither too loose nor too thick.","context":["As the sun started to set Veneto’s fields on fire with its first faint rays of sunrise, the line of women at the gates was already very long. Those who got there first would get the job for the day. The girls, whose dresses poorly reproduced flowers looking as withered as their sunburned faces, elbowed each other to get in front and secure a spot. The ones who got there late would have sworn that if there were a feeling more powerful than love, that was hunger. The workers would get their feet wet, their backs wrecked and their skin flaked. They would get their hands wrinkled, pricked and cramped. Their eyes sagged, their legs ached, their hearts burned. All they would get in return was a bag of rice they picked themselves as a paycheck for 12 hours of work.\nThe Mondine, the rice pickers, were not allowed to speak, to avoid distractions from working. But they could sing. As the rising sun set the sky ablaze, and dispelled the low layer of fog over the water in the rice fields between Verona, Venice and Vicenza into a cloud of gilded hues, hundreds of voices of women in pain rose in a chant. I am a Mondina, I am taken advantage of. They have killed and enchained me, But jail and violence could not stop me. Our bodies on the train tracks Stopped our jailers. There is a lot of mud in the rice fields, But we do not call ourselves dirty, as it is dirt that comes from work. We will fight for our jobs, For our bread, our peace and our freedom. We will create a better, more civil world. Risotto was brought to our tables with a fight. Risotto is a very opinionated dish. This clip from the movie ‘Bitter Rice’ (Riso Amaro) describes the scene above quite well. I am not sure if it is because of my Venetian ancestry, but I can say that risotto is my favorite italian dish along with pizza. In fact, it is probably one of my favorite dishes ever. Which is not surprising at all, as few things are as satisfying as a nice bowl of properly made risotto. it is just good, but like all good things it takes a bit of effort. It is not laborious, but it requires your undivided attention during the whole process, which means that you’ll have to commit some full 30 mins of your time to it (which s not that long, in the grand scheme of things). It’s a perfect dish for when you can take some time for cooking, or for a nice dinner at home with friends or a significant other. Here’s a guide to the main rules for making a basic risotto. These rules apply to all the risotto recipes you’ll come across. Now that our rice is not stained of blood anymore, let us take advantage of this beautiful product of the earth and make it shine on our tables!\n8 RULES FOR PERFECT RISOTTO\n#1 PICK THE RIGHT RICE QUALITY You can’t make risotto with just any rice. Truth is, in their own homes people do as they please (of course) and I personally like the half-a$$ed risotto I get with brown Italian rice. But, if you want to make things properly, these are the main varieties of risotto to have at hand:\nCarnaroli – The main variety of rice used for most kinds of risotto. It has medium, plump, starchy grains, which blend wonderfully with every ingredient and produce a luscious creaminess.\nVialone Nano – This iconic quality of rice that is only cultivated in Veneto is the quintessential risotto rice. Its plump, round, extra-white grains are coated in a dense layer of starch and produce the thickest, richest risottos. It is key in preparing Pumpkin Risotto.\nArborio – With its slightly longer, slightly more transparent grains, this variety of rice is not as good as the previous two, but it is still a great choice for risotto. It is a great fit for risottos that tend to remain on the soupy side. Amongst other Italian rice varieties, you might hear about Roma, Originario, Baldo…Though some can produce good risottos, these other varieties are best left for other preparations. Whatever your choice, do NOT, by any means, rinse your rice. If you dip a finger into a box of rice for risotto, it should come out white with starch.\n#2 PICK THE RIGHT PAN In an ideal world, the pot or pan used for risotto should be about 3″ tall and quite large. Possibly aluminum or stainless steel (purists are all about copper casseroles, but let’s be real).It would be best to avoid nonstick pots. Alternatively, a tall-ish pot also does the job wonderfully – especially if you’re not cooking large amounts of risotto. This and this are good examples. The reason why a slanted pan will not work is that it will probably not grant uniform cooking, and the reason why non-stick will not work is that the rice won’t toast properly. Risotto experts say that you should be prepared to scrape bits of risotto off your pan once you’re done…but this is not necessarily true.\n#3 EACH RECIPE HAS ITS BASE Risotto needs for key ingredients, which need to be changed according to the recipe: the right wine, the right stock, the right soffritto, and the right fat.\nThe fat – some sort of fat is used both to start the risotto in the initial stir fry, and for finishing it (see ‘mantecatura’ below). This can be olive oil, butter or both. If you are going to pick an oil that is not olive or that is subpar, just go with butter. Risotto stir-fry needs to cook at a very low temperature, so the olive oil won’t be ruined by the heat. I’d go with olive oil when making fish risottos, but you can pick you favorite fat with no specific rules. If you can, use extra virgin olive oil. Yes, really. DO NOT use shortening or margarine. Just DO NOT. I will come to your place and slap your hands with a leather belt if you do.\nThe soffritto – ‘soffritto’ is, technically, a very light stir-fry of very finely minced onion, carrot and celery – similar to french mirepoix. For risotto, the best choice is white onion alone, or, even better, shallots. you will probably never use a soffritto made with carrot and celery for risotto, because it could be overpowering. Go with all shallots for fish risotto, a mixture of onion and shallot for vegetable risotto, and all onion for risottos containing meats or strong flavors like porcini. Whatever you pick, mince it as finely as you can.\nThe stock – Use fish stock for fish risottos, meat stock for risottos with meats or strong flavors like porcini. Vegetable stock works well for pretty much everything. Just make sure the stock is ready and hot before you start preparing the risotto.\nThe wine – Dry white wine is the way to go for risotto. While it totally doesn’t need to be premium quality, it shouldn’t be wine from a carton, either. Last time I made risotto in New York I found these really good bottles of wine from Veneto at 3$ each, which is a great price considering that you can drink the rest and/or use it for more cooking.\n#4 TOAST IT! The rice should be toasted before adding the liquid. You are not just gonna throw all the ingredients in the pot and let it cook.\n#5 NEVER OVERMIX While risotto needs to be constantly tended, it shouldn’t be overworked. There’s no need to keep stirring or stirring it too often, or it won’t absorb the liquid properly.Furthermore, stirring too much will break the grains and might cause the starch to turn gluey. This is why some people might even prefer to let the rice stick to the bottom of the pan rather than stirring it (I wouldn’t, though).\n#6 BE PATIENT AND LOVE IT Risotto is not a kind of preparation that can be left unattended. It will require some 20 minutes of undivided attention. Stock must be added one ladleful at a time, and you should eye the amount you add especially towards the end, to reach the perfect creaminess without overcooking it.\n#7 NEVER SKIP THE ‘MANTECATURA’ ‘Mantecare’ is an Italian word that has no direct translation. It is the process of adding fat at the end of a preparation (off-fire) to make it creamier and finish it off with the right touch. Mantecatura applies mostly to risotto, pastas and thick soups Classic risottos are finished off with butter and Parmigiano, but this is not always the case. For fish risottos, it is preferred to finish with olive oil and butter, or olive oil alone (which is also the case for vegan risottos). You can also finish it off with any cheese of choice that goes well with the recipe.\n#8 ‘L’ONDA’ Risotto, when served, should be ‘all’onda’ which roughly means that it should ‘create a wave’. This means that it shouldn’t be too loose or too thick, but I’d say that you should adjust it to your own liking. If it is too thick, add a little stock at the end, but always be careful to not overcook it. Risotto connoisseurs even pour it on the dish straight from the pan! And now, on to the recipe!\nBasic Risotto – Saffron Risotto\n320g Italian Rice (Carnaroli or Vialone Nano)\n40g Butter, or 2 tbsps Olive oil\nA small onion, or half a medium one\n1/4 cup dry white wine\nAbout 4 cups flavorful stock\nParmigiano, or good quality cheese, grated\nVariation for SAFFRON RISOTTO: 1 g powdered saffron (one bag)\n1. Make sure your stock is hot and at the ready.\n2. Start by mincing the onion very finely. Add it to the pan with your fat of choice, and very lightly stir fry on low until the onion is translucent, about 3-5 minutes. The onion should be ‘stewed’ rather than fried, so if it colors too quickly add a bit of stock. NOTE: If adding other vegetables to risotto, add them now. Or, you can half-cook the vegetables in a separate pan with more onion stir fry and add them to the rice after you it has been toasted and before adding the wine.\n3. Add the rice, and mix if with the onion to toast it for a couple minutes. The grains should turn translucent and well coated with the base of oil, stock and onion. Add the wine, and stir well. Let the wine fully reduce.\n4. At this point, start adding a couple ladlefuls of stock, along with a pinch of salt. Stir everything well and scrape the grains that might stick to the sides of the pan, and let the stock absorb. Occasionally shake the pan, as to mix the rice without really stirring it with the spoon. Keep the flame low, it should simmer very gently.\n5. Once the stock is absorbed, the risotto will have already turned quite creamy. Add another ladleful, stir well and let it absorb. Make sure that by the end of cooking time the stock will be fully absorbed, so just eye the amount of liquid to reach the right consistency. Taste the rice 2-3 minuted before the time indicated in the box, and add more salt or liquid to finish cooking.\n6. Turn off the fire a couple of minutes before the risotto is fully cooked. Finish it off with a good amount of grated Parmigiano, Grana or other well seasoned cheese, according to your taste. Make sure to adjust the salt according to the cheese, as well. Finish it off with a tad more butter or olive oil, and stir it well. If making saffron risotto, melt the powder in a bit of hot stock and dissolve it, then add it at the very end. Saffron is a very delicate spice and could not withstand long cooking or excessively high temperatures.\nSome people even serve risotto by pouring it from the pan, as it should be ‘all’onda’, as said above. However you decide to dish it, do not let it sit for too long, as it will continue to cook and get a bit clumpier. Like every italian person and every regular person as well, I actually love risotto even better the day after. Risotto is one of those dishes that develop a ton of flavor while sitting overnight in the fridge, and there is just something about the consistency of cold risotto that is like a charm to me. I love eating it with a fork, and I love how it glues together the day after. The leftovers can be transformed in countless ways, the most famous being Arancini di Riso (which I have no idea why americans eat with tomato sauce). They can also be turned into the all-Roman Suppli al Telefono. You can stuff vegetables with it (just pack rice in them AND add some Romagna breadcrumb mixture on top – works even better with tomatoes), you can turn it into a frittata, or you can turn it into a baked casserole of sorts.\nWhat is your favorite risotto? Did you ever come across an exceptionally good or exceptionally bad risotto? Do you like it looser or thicker? Let me know!"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:583e6dd2-5820-4168-a82c-6c3afce17b6e>"],"error":null}
{"question":"what's the difference between active and passive belay devices in climbing?","answer":"Passive belay devices require action from the belayer to lock the rope during a fall. Examples include the 'Eight' and ATC belay devices. Active belay devices, like the GriGri, have a built-in mechanism that automatically locks the rope when it slips at high speed through the mechanism. While active devices are very safe, they can lead to less alert belayers.","context":["Safety first is really much more first when you are 10 meters or higher up in the air falling is not an option. Injuries, luckily, don’t happen often in climbing, but when they do they are relatively much more serious and even fatal than many other sports.\nWith the advent of belay devices, the risk of a fall is very much reduced. With a such a device, your climbing partner can secure you as both your climbing harnesses are connected through your climbing rope. Through friction on the rope, your partner can block he rope when you fall. And at the end of the climb belay you down again.\nPassive belay devices\nA passive belay devices requires action from the belayer to lock the rope in the event of a fall. One of the most traditonal of such devices is the “Eight”.\nAn eight is the simplest and for a long time was by far the most commonly used tool for securing someone. The rope is pulled through the eight-form so that as it moves along the steel, friction is induced. So much so that with minimal effort the rope can be locked. In addition to belaying it can also be used for rapelling.\nAnother good example of passive device is the ATC belay device. One of the many tubular devices that also relay on action from the belayer to lock the rope.\nActive belaying devices\nThe most well known of these devices is the GriGri. This kind of device has a built-in mechanism that locks off the rope automatically when the rope slips at high speed through the mechanism. A very safe device but one that can lead to less alert belayers. So whichever device you use, the life of your climbing buddy is, quite literally, in your hands!\nCarabiners are metal loops that connect everything together. Most often made from aluminium alloy and with spring-loaded gates (openings). There are several types of carabiners, such as: ordinary carabiner, HMS carabiner, twistlock (quick release), etc. The choice of karabiner depends on what you are going to use.\nFor the belayer, a curved karabiner is the most convenient due the larger top side. HMS carabiners can carry 3-sided loads instead of 2-sided and are therefore suitable for anchors with weight pulling in different directions.\nA good carabiner should:\n- have an ideal ratio between weight and breaking force (minimum standard is 2000 kg)\n- not slip out of your hand to easily.\n- open and close smoothly\n- not have any sharp edges that can damage yourself or your rope\nIf you intend to use the harness often in the high mountain, choose for lined and adjustable leg loops Lined harnesses have less stress on your legs and are more comfortable when you wear them over longer periods of time.\nAdjustability is important to fit the leg loops to thicker or thinner clothes.\nImage: Arc’teryx B 360a Men’s\nIf you focus mainlyon sports climbing on rocks, choose the comfort of a wide, possibly padded hip belt with or without polished leg loops. For indoor climbing there are special ultra-light belts.\nThere are two types of harnesses:\nReguar hip harnesses\nThe most widely used, they are preferred choice due to their comfort and greater freedom of movement.\nFull body harnesses\nThis also has shoulder straps, and are safer as the point where the rope is attached is higher than the climber’s center of gravity, reducing the risk of a back injury in an uncontrolled fall.\nWithout getting to technical as far as climbing technique is concerned, we can state that your legs and feet are the foundation of your climbing. So your shoes are essential to your effort.\nOn the smaller footholds you will encounter, you will generally climbin with the edge of your shoes, a lot of which will be on the toe edge (this is called “edging”). That means the soles of climbing shoes need to add to the stability of your foot. Climbing shoes will generally have quite a stiff vulcanized rubber sole that adds this much needed stiffness. Besides that, the rubber also delivers heaps of friction on the wall. In the climbing technique know a “smearing” where you climb on friction rather than on the edges of your shoes, mostly because there are no footholds.\nGiven that climbing shoes need to add stability and stiffness to your foot, you will generally need to buy shoes that fit quite snug, if not really tight. It should not be painful.\nThere are three categories of shoes:\nThese shoes have a relatively relaxed and straight footbed. Your toes are straight in the shoe. The fit is more comfortable and relaxed, making them great for beginning climbers or for more experienced climbers doing all day climbs. The sole is thicker and stiffer.\nThe shape of these shoes is slightly downturned with a light camber in them. There is more pressure to your toes, enabling you to climb more technical and challenging routes with smaller footholds. Stickier rubber and slightly thinner soles for more grip and feel.\nShoes with a very strong camber to them and a lot of tension on your foot directed to the toes. Not very comfortable, but very good for those really difficult routes. Again stickier and thinner soles.\nTake your time to choose what kind of shoe would fit your foot, but also the kind of climbing you do.\nA good rope is essential for climbing. These kind of ropes are not only very strong, but also slightly elastic to absorb a part of the force of a fall. This especially true for so called dynamic ropes that are used for top roping or lead climbing.\nImage: Mammut Tusk Dry klimtouw\nThe ideal climbing rope combines the following properties: it will be strong, light, abrasion resistant, flexible, easy to use, low strain when body weight, low retention.\nThere are many variations in rope diameter and length, as well as safety ratings. This will indicate what kind of climbing the rope is good for.\nStatic ropes are ropes that have less elasticity and are used for ascending on a rope, or pulling expedition materials up a rock face, or any situation in which you do not want the rope to stretch."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:fa2f5373-8c8b-4588-8719-c83300765f8c>"],"error":null}
{"question":"How do extremophiles survive in high osmolarity environments, and what is the current market segmentation for industrial enzymes derived from such organisms?","answer":"Extremophiles survive in high osmolarity environments through enzymes that resist precipitation or denaturation in high salt conditions - some can survive up to 5 molar sodium chloride, equivalent to 240 atmospheres of pressure. These specialized enzymes remain stable at high osmolarity, preventing the formation of harmful inclusion bodies within cells. Regarding market segmentation, industrial enzymes are primarily sourced from microorganisms and are categorized into types including Carbohydrases, Amylases, Cellulases, Proteases, and Lipases. These are used across various applications including Bio-fuel, Cleaning Products, Food, Animal Feed, Textile, and Specialty industries. The market is geographically segmented into North America, Asia-Pacific, Europe, and Rest of the World, with Asia-Pacific expected to show the highest growth.","context":["Spring: the final frontier. These are the voyages of extremophiles on Earth. Their ongoing missions: to explore extreme new worlds, to seek out new nutrient resources and new metabolisms, and to boldly go any places where no microorganisms have gone before!\nLast month I went on a road trip from San Francisco to Chicago with a college friend and the Yellowstone National Park was the highlight of our trip. The best part of Yellowstone was not the beautiful sunsets, the predictable geysers or the free-roaming buffalos, but was the incredibly beautiful hot springs. The Grand Prismatic Spring, the largest hot spring in North America, displayed vivid shades of red, yellow, green against a crystalline blue pool that looks more like a surrealistic Monet painting than reality.\nTourists around us speculated on the origin of the colors. Since the hot springs, as implied in their names, can easily exceed 90ºC, many of them guessed: “it must be some sort of metal” that causes the formation of colors. This would not be a bad assumption as metals are routinely used to tint windows and fireworks. However, it is actually due to the production of carotenoids and chlorophyll by the microorganisms. Then the organic pigments, naturally blended in different ratios, create gorgeous color gradients.\nMore astonishing than the colors themselves is the fact that the microorganisms form those colors. But how? In the Grand Prismatic Spring, for example, a scientist would be able to find archaea, fungal, algal, protozoa and bacterial communities known as extremophiles that can survive high temperatures in low nutrient conditions. Because of this adverse condition, those microorganisms require unconventional avenues to obtain energy. For instance, while most microorganisms use glycolysis as a catabolic pathway for glucose, extremophiles tend to use the Entner-Doudoroff pathway to oxidize glucose to pyruvate. If alternative glucose metabolism is not rare enough, some extremophiles are even able to use syngas (a mixture of hydrogen and carbon monoxide/dioxide) through the Wood-Ljungdahl pathway in which the final electron acceptor, instead of oxygen, is carbon dioxide. In other words, this latter pathway allows extremophiles to live without air and sugars, an inhospitable environment for most microorganisms.\nAlthough alternative metabolic pathways are interesting, they have also been scrutinized in the industry because petrochemical processes produce copious amounts of syngas and the potential to convert a cheap stream into a specialty chemical can be a profitable endeavor (although it is not commercially viable yet).\nExtremophiles not only can survive without air and sugars, but they can also survive at high temperatures. If ordinary microorganisms were subjected to 90ºC, proteins would denature and stop functioning instantaneously (not surprisingly: a common protocol for protein denaturation before running an SDS PAGE requires incubation at high temperatures). However, extremophiles tend to have proteins that are extremely heat stable. At a molecular level, this is achieved by having intramolecular bonds that enable the protein to stay intact at high temperatures. Can you imagine what would the applications of these proteins be? Imagining no more because universities and industries are reaping the benefits of these properties already. Thermostable proteases are being used routinely in detergents to degrade proteinaceous stains as well as to withstand hot wash cycles. Additionally, thermostable amylases are employed in textile processing to desize fabrics but can be subjected to hot process temperatures, and taq polymerase is an enzyme isolated from Thermus Aquaticus in Yellowstone that is used in PCR because it can polymerize DNA while it can withstand the DNA melting temperatures.\nBesides aforementioned commercial applications, there are efforts to explore if thermostable enzymes can be used to convert hot gas and methane into biological feedstocks for chemicals and fuels or if these can be used to reduce viscosity of the cellulose-rich mud that is formed in shale-gas drilling sites (commonly known as fracking). Undoubtedly, the ongoing search for thermostable enzymes and their industrial applications will continue for the years to come.\nYet, thermostability is not the only property to be harnessed to create products. Active enzymes at low temperatures are important as well because heating a process in an aqueous environment is energy intensive due to water’s high heat capacity. Thus, having enzymes that work at lower temperature means lower environmental impact. An example of this enzyme would be Optisize® Cool, which I developed the fermentation for in Palo Alto, transferred to one of DuPont’s manufacturing plants and was commercially launched a couple of years ago.\nTemperature is not the only condition that extremophiles tolerate. Extremophiles are adept in environments with high osmolarity, which is not trivial. To calculate the osmotic pressure, the Van’t Hoff factor is multiplied by the molarity, the gas constant, and absolute temperature (Osmotic Pressure = iMRT). A 1 molar sodium chloride difference between the inside and outside of the microorganism at 20ºC will exercise 48 atmospheres of gauge pressure on the microorganism, which is roughly equivalent to a 1500 feet pool dive. For the record, extremophiles that can survive up to 5 molar sodium chloride have been reported and that roughly equates to 240 atmospheres or 8000 feet pool dive.\nIt is known that one of the mechanisms for survival in high osmolarity is through the use of enzymes that are recalcitrant to precipitation or denaturation in high osmolarity conditions. Recalling from undergraduate chemistry/biochemistry courses, those enzymes, like some chemicals, can be salted-out of solution. Precipitation of enzymes inside a cell would be catastrophic as those can form inclusion bodies which stress microorganisms immensely to the point that some will lyse. Thus, extremophiles have developed enzymes that are stable at high osmolarity and that can be useful in applications where enzymes are needed in industrial processes with high solute concentration.\nHarsh environments are not limited to high temperatures and salinity or to low nutrient and oxygen, but also include high radiation and pressures or low humidity and temperatures. The quest for finding better enzymes bioprospecting in hot springs and Arctic glaciers will continue in the years to come. The challenge, however, is to find application to enzymes with unique properties.\nAlthough the global market for enzymes is relatively small, at around $3 billion, compared to the biopharmaceutical market, enzymes are present in many consumer products. Products that are already being made with enzymes include clothing, detergents, ethanol, dishwashing soap, paper, animal feed, bread, cheese, denim trousers, wine, juices, yogurt and sugars. Yet, the list keeps expanding yearly. Who would have thought that something as scientifically inconspicuous as a Yellowstone hot spring held promises for such diverse industries? Who could have imagined that there are more surprises behind the beauty of hot springs? Who would have thought that microorganisms’ enzymes could be the next innovation in the biotech industry?","Enzymes are biological catalysts; they accelerate a chemical reaction. Globally, enzymes are used in industries like Biofuel, cleaning products/detergents, food, animal feed, textile and speciality. Further, the market for industrial enzymes is continuously rising, owing to the growing need for sustainable solutions. Advancement in biotechnology, especially in protein engineering, has also brought in new probiotic products, driving the industrial enzymes market to the next level. According to Renub Research, the Global Enzymes Market is projected to reach US$ 17.4 Billion by 2027.\nindustrial enzymes market\nCarbohydrases, Amylases, Cellulases, Proteases and Lipases are major variants existing in the global Enzymes Market. By Types, these enzymes are used in numerous industries. For instance, the food industry primarily uses carbohydrases in baking for manufacturing fruit juices, winemaking and cheese manufacturing. Similarly, other applications of Carbohydrases are detergents, textiles & leather, and bioethanol. Carbohydrases also have added advantages to various industrial applications due to their low cost, less time & space consumption, and ease in modifying and optimizing the process. The Industrial Enzymes Market Size was estimated at US$ 10.6 Billion in 2020.\nBesides, protease enzymes are widely used in the Speciality Industries. The Speciality Industry uses protease enzymes in a large quantity in the manufacturing of medicines. Protease enzymes treat multiple diseases such as lungs, heart, eye abnormalities, digestive tract, skin ulcers, and soreness. Thus, the Speciality Industry is expected to fuel the demand for protease enzymes in the foreseeable future. Also, with the help of developing science and technology, protease enzymes are used in the several bio-meditation process and leather treatments.\nFurthermore, the Industrial Enzymes Market in North America is influenced by rising demand for enzymes from the food industry and significantly has a large consumer base by countries in the region. Nonetheless, the market in Asia-Pacific is owing to sound growth opportunities induced by soaring demand for carbohydrase and proteases in the applications of the pharmaceutical and food industry, remarkably in emerging countries such as China, India, and Japan. These countries have started investing in the biotech sector to introduce more effective global enzyme products.\nAdditionally, expanding investment in the food and beverage and pharmaceutical industry is anticipated to stimulate the overall industrial enzymes market. With improving disposable income, customer can now afford expensive food product, which is further expected to increase the demand for industrial enzymes products. As per our analysis, The Industrial Enzymes Industry will likely grow at a CAGR of 7.34% from 2020-2027.\nNevertheless, stringent supervision and controlled temperature & PH levels of enzymes await to restrict the market’s growth to some extent. On the other hand, concerns associated with quality, safety, and consumer perception towards enzymes is the key challenge of this market.\nBy Sources, the Industrial Enzymes Market has been fragmented through microorganisms, plants and animals. The microorganism is the most common source of industrial enzymes holding one of the highest shares in the market.\nBy Application, the Global Enzymes Market has been segregated into Bio-fuel Enzymes, Cleaning Product Enzymes, Food Enzymes, Animal Feed Enzymes, Textile Enzymes and Specialty Enzymes. Amongst the segments, Specialty Enzymes Market holds a significant market existence.\nBy Region, we have covered North America, Asia-Pacific, Europe and the Rest of the World.. Furthermore, the Asia-Pacific region is expected to witness the highest growth in the forecasted period and is anticipated to nurture its dominance in the future years.\nSome major companies operating in the industrial enzymes market are BASF SE, Advanced EnzymeTechnologies, Novozymes, DuPont Danisco, DSM and Kerry Group PLC.\nCOVID-19 Impact on Global Enzymes Market\nThe spread of COVID-19 across the globe has positively impacted the overall Industries. The rising adoption of enzymes in multiple industries such as Cleaning Product, Food, Animal Feeds, and Specialty has to propel the market growth during the COVID-19 pandemic as consumers across the world have become more alert and conscious towards their health and lifestyle.\nHowever, Biofuel and Textile Enzymes Market’s growth has been hampered by the COVID-19 pandemic. The lockdowns, social distances, and the shutdown of production plants globally have impacted the automotive industry, which in turn, negatively influenced the biofuel industry.\nSimilarly, the Textile Enzymes Market is no different; the operations of numerous textile industries had either been temporarily halted or were functioning with a minimal workforce due to enforced lockdowns and imposed restrictions by respective governing bodies. This factor has a significantly negative impact on the revenue growth of the Textile Enzymes Market.\nRenub Research latest report “Industrial Enzymes Market Global Forecast by Types (Carbohydrases, Amylases, Cellulases, Proteases, Lipases), Source (Microorganism, Plant, Animal), Application(Bio fuel, Cleaning Product, Food, Animal Feed, Textile, Specialty), Region (North America, Europe, Asia Pacific, Rest of the World), Company (BASF SE, Advanced Enzyme Technologies, Novozymes, DuPont Danisco, DSM, Kerry Group PLC)” provides a detailed analysis of Enzymes Market.\nRequest a Free Sample Copy of the Report: https://www.renub.com/request-sample-page.php?gturl=industrial-enzymes-market-p.php\nBy Types market has been covered from 5 viewpoints:\nBy Source market has been covered from 3 viewpoints:\nBy Application market has been covered from 6 viewpoints:\n- Bio fuel Enzymes\n- Cleaning Product Enzymes\n- Food Enzymes\n- Animal Feed Enzymes\n- Textile Enzymes\n- Specialty Enzymes\nglobal enzymes market\nBy Regions market has been covered from 4 viewpoints:\n- North America\n• Company Initiatives\n• Sales Analysis\n- BASF SE\n- Advanced Enzyme Technologies\n- DuPont Danisco\n- Kerry Group PLC\nAbout the Company:\nRenub Research is a Market Research and Consulting Company. We have more than 10 years of experience especially in international Business-to-Business Researches, Surveys and Consulting. We provide a wide range of business research solutions that helps companies in making better business decisions. We partner with clients in all sectors and regions to identify their highest-value opportunities, address their most critical challenges, and transform their businesses. Our wide clientele comprises major players in Healthcare, Travel and Tourism, Food & Beverages, Power & Energy, Information Technology, Telecom & Internet, Chemical, Logistics & Automotive, Consumer Goods & Retail, Building and Construction, & Agriculture. Our clients rely on our market analysis and data to make informed knowledgeable decisions. We are regarded as one of the best providers of knowledge. Our pertinent analysis helps consultants, bankers and executives to make informed and correct decisions.\nOur core team is comprised of experienced people holding graduate, postgraduate and PhD degrees in Finance, Marketing, Human Resource, Bio-Technology, Medicine, Information Technology, Environmental Science and many more. Our research helps to make business decisions: on strategy, organization, operations, technology, mergers & acquisitions etc. We support many blue chip companies by providing them with findings and perspectives across a wide range of markets. Our research reports offer a blend of information insight, analysis and forecasting that is essential in today’s ultra-competitive markets."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"temporal_focus","category_name":"future"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:941d0d9e-cf45-4619-b1a5-c01d4e84fefb>","<urn:uuid:8c719086-e8a5-48a2-928d-a1410b39d9bd>"],"error":null}
{"question":"Can you explain the cultural control methods for vegetation management and the minimum safe distances for planting near power infrastructure?","answer":"Cultural control methods modify habitat to establish early successional plant communities that naturally resist tree growth. This includes the wire-border zone technique, where the wire zone (directly under lines plus 10ft each side) maintains vegetation under 3ft tall, while the border zone allows growth up to 25ft tall. For safe planting distances, shrubs up to 3.5m can grow within the 6m easement as long as they don't block access. Trees over 8m should be planted at least 12m away from infrastructure. There must always be at least 3m clearance from uninsulated distribution lines and 1m from insulated lines. Around transmission lines, only vegetation under 3m height is permitted within the easement, which can extend up to 60m.","context":["A panel of 23 experts from the Internation Society of Arboriculture (ISA) is crafting a best management practive (BMP) for integrated vegetation management (IVM) to serve as a field guide for front-line supervision, as well as an aid for managers to help facilitate planning.\nThe need for a BMP for utility rights of way (ROW) became evident in the Federal Energy Regulatory Commission's (FERC) 2004 Utility Vegetation Management Final Report. Researchers concluded that current industry requirements and standards are inadequate to require utility companies to achieve the level of utility vegetation management necessary to improve reliability by reducing tree-caused transmission outages.\nThe BMP will equip practitioners with techniques that they can apply to electric ROW projects in order to exceed the requirements of the North American Electric Reliability Council (NERC). The NERC 2006 Standard FAC 003-1 Transmission Vegetation Management Program is designed to protect the transmission electric grid from tree-caused outages.\nBEST MANAGEMENT PRACTICES\nThe ISA developed BMPs as companions to the American National Standards Institute (ANSI) standards. ANSI A300 is the standard for tree-care operations and tree, shrub and other woody plant maintenance. It also provides minimum performance standards for use in arboricultural specifications. ANSI A300 provides direction on what to do, while the ISA BMPs offer information on how to do it. The IVM BMP is designed to supplement ANSI A300 Part 7, which deals with IVM. It can also be used to fulfill other objectives, such as vegetation control on gas pipeline ROW and activities outside the scope of utility ROW management, including restoring ecosystems, controlling invasive weeds and other actions. The BMP will contain sections on safety, communication, planning and implementation, and application.\nPLANNING AND IMPLEMENTATION\nBMPs call for a systematic way of planning and implementing a vegetation- management program that complies with the NERC standard. It is applicable to distribution as well as transmission projects and consists of six elements:\n- Set objectives\n- Evaluate the site\n- Define action thresholds\n- Evaluate and select control methods\n- Implement IVM\n- Monitor treatment and quality assurance.\nDecisions are required in setting objectives, defining action thresholds, and evaluating and selecting control methods. The process is cyclical and ongoing because vegetation is dynamic, and managers must have the flexibility to adjust their plans at each stage as new information becomes available.\nObjectives should be clearly defined and documented. Examples of objectives include promoting safety, preventing outages caused by vegetation growing into electric facilities and minimizing outages from trees growing outside the ROW. Other sample objectives are maintaining regulatory compliance, restoring electric service during emergencies, protecting structures and security, maintaining access and clear lines of sight, protecting the environment and facilitating cost effectiveness.\nObjectives should be based on specific site factors such as workload and vegetation type, in addition to human, equipment and financial resources. The overriding focus should be on the environmentally sound, cost-effective control of species that potentially conflict with electric facilities, while promoting compatible, early successional, sustainable plant communities.\nWorkload evaluations are inventories of vegetation that could have a bearing on management objectives. Workload assessments can draw data on an array of vegetation characteristics, such as location, height, density, species, size and condition, hazard status and clearance from conductors. Assessments should be conducted with voltage, conductor sag from ambient temperatures and loading, and the potential influence of wind-on-line sway in mind.\nComprehensive program-level evaluations can be made of all target vegetation on a system, while project-level evaluations focus on vegetation relevant to a specific job. On one hand, comprehensive evaluations provide the advantage of supplying a complete set of data upon which to base management decisions. On the other hand, the surveys can be impractical for utilities with large numbers of trees, limited human and financial resources, or both.\nPoint sampling offers an alternative for utilities for which comprehensive inventories are impractical. It involves dividing a management area (a system or project) into equal-sized units and selecting a random sample sufficient to statistically represent the total work quantity. Every plant or plant community of interest within each selected area is inventoried, with collected data used to forecast the total workload.\nManagers have a variety of control methods from which to choose, including manual, mechanical, herbicide and tree-growth regulators, biological and cultural options.\nManual methods employ workers with hand-carried tools, including chain saws, handsaws, pruning shears and other devices to control incompatible vegetation. The advantage of manual techniques is that they are selective and can be used where others may not be. However, manual techniques can be inefficient and expensive compared to other methods.\nMechanical controls are done with machines. Although mechanical control methods are efficient and cost effective — particularly for clearing dense vegetation during initial establishment or reclaiming neglected or overgrown ROW — they can be nonselective and disturb sensitive sites.\nTree-growth regulators and herbicides are essential for effective vegetation management. Tree-growth regulators are designed to reduce growth rates by interfering with natural plant processes. They can be helpful by reducing the growth rates of some fast-growing species where removals are prohibited or impractical.\nHerbicides control plants by interfering with specific botanical biochemical pathways. Herbicide use can control individual plants that are prone to resprout or sucker after removal. When trees that resprout or sucker are removed without herbicide treatment, dense thickets develop, impeding access, swelling workloads, increasing costs, blocking lines of site and deteriorating wildlife habitat. Treating suckering plants allows early successional, compatible species to dominate the ROW and out-compete incompatible species, ultimately reducing work.\nHerbicides can be selective or nonselective depending on their type. Selective herbicides only control specific kinds of plants, when applied according to the label. By contrast, non-selective herbicides work against most plants. Nonselective herbicides can be effective where a wide variety of target plant species are present, such as during initial clearing or reclaiming dense stands of invasive or other undesirable plants.\nApplication techniques also can be either selective or nonselective. Selective applications are used against specific plants or pockets of plants. Nonselective techniques target areas rather than individual plants. Nonselective use of nonselective herbicides eliminates all plants in the application area. Nonselective use of a selective herbicide controls treated plants that are sensitive to the herbicide without differentiating between compatible or incompatible species. Selective use of either would only control targeted vegetation. Selective use is preferable unless target vegetation density is high.\nHERBICIDE APPLICATION METHODS\nHerbicide application methods are categorized by the quantity of herbicide used, the character of the target, vegetation density and site parameters. Treatments include individual stem, broadcast and aerial treatments.\nIndividual stem treatments are selective applications. They include stump, basal, injection, frill, selective foliar and side-pruning applications. Due to their specific nature, proper individual stem applications work well to avoid damage to sensitive or off-target plants. However, they are impractical against broad areas or for sites dominated by undesirable species.\nBroadcast treatments are nonselective because they control all plants sensitive to a particular herbicide in a treatment area. They can provide a degree of selectivity with proper herbicides. Broadcasting is particularly useful to control large infestations of incompatible vegetation (including invasive species) in ROW or along access roads.\nAerial control methods are also nonselective but can provide a level of selectivity with proper herbicides. Aerial applications are useful in remote or difficult-to-access sites, and can be cost effective and quick, especially if large areas need to be treated. They also can be used where incompatible vegetation dominates a ROW. The primary disadvantage of an aerial application is that it carries the threat of off-target drift, so it must be performed under low-wind conditions with low-toxicity herbicides.\nCULTURAL CONTROL METHODS\nCultural methods modify habitat to discourage incompatible vegetation and establish and manage desirable, early successional plant communities. Cultural methods take advantage of seed banks of native, compatible species lying dormant on site. In the long run, cultural control is the most desirable method where it is applicable.\nCultural control, also known as cover-type conversion, provides a competitive advantage to short-growing early successional plants, allowing them to thrive and eventually out-compete unwanted tree species for sunlight, essential elements and water. The early successional plant community is relatively stable, tree-resistant and reduces the amount of work, including herbicide application, with each successive treatment.\nThe wire-border zone technique is a management philosophy that can be applied through cultural control.\nThe wire zone is the section of a utility transmission ROW directly under the wires and extending outward about 10 ft on each side. The wire zone is managed to promote a low-growing plant community dominated by grasses, herbs and small shrubs (under 3 ft [1 m] in height at maturity). The border zone is the remainder of the ROW. It is managed to establish small trees and tall shrubs (under 25 ft [7.6 m] in height at maturity). When properly managed, diverse, tree-resistant plant communities develop in wire and border zones. The communities not only protect the electric facility and reduce long-term maintenance, but also enhance wildlife habitat, forest ecology and aesthetic values.\nThe wire-border zone is a best practice in many instances but is not suitable in all situations. For example, standard wire-border zone prescriptions may be unnecessary where lines are high off the ground, such as across low valleys or canyons. One way to accommodate variances in topography is to establish different regions based on wire height.\nFor example, over canyon bottoms or other areas where conductors are 100 ft (30 m) or more above the ground, only a few trees are likely to be tall enough to conflict with the lines. In those cases, trees that potentially interfere with the transmission lines can be removed selectively on a case-by-case basis. In areas where the wire is lower, perhaps between 50 ft to 100 ft (15 m to 30 m) from the ground, a border zone community can be developed throughout the ROW. Where the line is less than 50 ft off the ground, managers could apply a full wire-border zone prescription.\nStream protection is an environmental advantage of this type of modification. Streams often course through the valleys and canyons where lines are likely to be elevated. Leaving timber or border-zone communities in canyon bottoms helps shelter this valuable habitat, enabling managers to achieve environmentally sensitive objectives.\nAll laws and regulations governing IVM practices, and specifications written by qualified vegetation managers must be followed. IVM control methods should be implemented on regular work schedules, which are based on established objectives and completed assessments. Work should progress systematically, using control measures determined to be best for varying conditions at specific locations along a ROW. Some considerations used in developing schedules include the importance and type of line, vegetation clearances, workloads, growth rate of predominant vegetation, geography, accessibility and in some cases, time lapsed since the last scheduled work.\nCLEARANCES FOLLOWING WORK\nThe transmission owner should establish and document appropriate minimum-clearance distances to be achieved at the time of work. These clearances are defined and required as clearance 1 in the NERC transmission vegetation-management program standard. A qualified vegetation manager should determine appropriate clearances for the vegetation type on a system. Clearances following work should be sufficient to meet management objectives, including reducing electric safety risks, service-reliability threats and cost. At the very least, post-work clearances should be sufficient to maintain minimum NERC-mandated clearances until the next systematic work.\nMONITOR TREATMENT AND QUALITY ASSURANCE\nVegetation-management programs should have systems and procedures in place for documenting and verifying that the vegetation-management work was completed to specifications. The NERC Transmission Vegetation Management Program requires transmission owners to follow these systems and procedures. Post-control reviews can be comprehensive or based on a statistically representative sample. This final review points back to the first step and the planning process begins again.\nManagers should select control options to best promote management objectives. Tree-resistant plant communities can help reduce long-term workloads and costs, because once established, they out-compete incompatible plants. When effectively implemented, IVM is a systematic, preventive strategy that results in site-specific treatments to meet management objectives. A sound program includes documented processes to evaluate results, which should involve both monitoring for quality assurance while work is underway and after it is completed. However, the overriding focus should be on environmentally sound, cost-effective control of species that potentially conflict with the electric facility while promoting compatible, early successional, sustainable plant communities where appropriate.\nRandall H. Miller is vice president of the Utility Arborist Association, past chair of the Edison Electric Institute Vegetation Management Task Force and an editorial board member of the Journal of Arboriculture and Urban Forestry. He has served on the International Society of Arboriculture's (ISA) Certification Test Committee and is past president of the Oregon Urban and Community Forest Council. Miller joined PacifiCorp in 1993 and has been system forester with them since March 1999. Miller earned his bachelor's degree in horticulture and master's degree in urban forestry. He is an ISA-certified arborist and certified utility specialist. Miller has more than 40 arboriculturally related writing credits and speaks widely on arboricultural, urban forestry and utility forestry-related topics. email@example.com","The following information can also be found in our safe growing brochure.\nTrees near distribution powerlines\nTrees and shrubs are an important part of our environment. But if they come in contact with a powerline they can bring the line down and disrupt your power or worse, cause a fire.\nTo ensure your safety, your neighbour’s safety and the safety of the community, it’s vital that you ensure there’s a safe distance between distribution powerlines and any foliage or any trees or shrubs that grow on your property. In fact it’s not just your responsibility, it’s also the law.\nKeeping your trees and shrubs clear of distribution powerlines will:\nPrevent power supply interruptions\nProtect your home, your neighbours’ home and the community from the threat of fire\nSave you the costs of having foliage removed by a professional\nThere are some situations where TasNetworks undertakes vegetation management on private property.\nThe diagram below illustrates some examples of where TasNetworks is responsible for keeping the lines clear.\nCustomer A is responsible for clearing vegetation inside their property boundary and underneath the TasNetworks owned distribution power line that takes the electricity supply from the pole in the street to their property.\nCustomer B is responsible for clearing vegetation inside their property boundary and underneath the TasNetworks distribution power line that directly supplies power to their house. However, TasNetworks is responsible for clearing the vegetation growing inside customer B’s property boundary underneath the TasNetworks owned distribution power line which supplies electricity to an adjoining property.\nCustomer C is responsible for clearing vegetation inside their property boundary and underneath TasNetworks’ distribution power line that takes the electricity supply from the pole in the street to their house.\nCustomer D is responsible for clearing vegetation inside their property boundary and underneath the TasNetworks owned distribution power line that takes the electricity supply from the pole in the street to their house.\nRemember – as well as any foliage needing to be at least 3m away from distribution powerlines, you need to stay at least 3m away from distribution powerlines. You should contact an authorised vegetation contractor to remove any foliage growing too close to powerlines.\nSafe distances to our distribution system?\nYou must ensure that trees are at least 3m away from uninsulated (bare) distribution powerlines at all times. However if the distribution line is insulated, the safe clearance is 1m.\nTasNetworks or an accredited vegetation contractor can advise you which type of powerline you have.\nPowerlines and trees may swing in high winds, while high temperatures may cause powerlines to sag. Mark sure these factors are accounted for when calculating the 3m clearance areas.\nShrubs and plants that grow to a maximum of 3.5m may be planted in the 6 metre easement provided they don’t inhibit access to the infrastructure. The height of shrubs and trees can then gradually increase. It’s advisable to plant trees that exceed 8m in height at least 12m from the infrastructure to eliminate the risk of vegetation overhanging the powerlines.\nGenerally speaking, we have an easement over land on which our distribution infrastructure is situated. These easements, together with associated legislation, give us the right to access your property and to clear the vegetation either side of our infrastructure. It’s the best way to reduce the risk of bushfire,ensuring your safety and your neighbour’s safety.\nTasNetworks distribution easements extend 6m either side of the infrastructure but it can be wider in some circumstances.\nTasNetworks takes into account the clearance space needed to protect everyone from fire risks and to ensure the continuity and reliability of your electricity supply. That’s why in some cases, for example where there are long spans of wires or very tall trees, we may be required to clear vegetation outside this easement.\nHow to ensure your trees are safely away from distribution powerlines\n1. Safe powerline alternatives\nIf the distribution powerline to your house or your privately owned powerline is uninsulated (bare), you can arrange to have it insulated.\nYour trees can then legally be within 1m of your line. You could also consider replacing the overhead distribution line with an underground cable. Check with your licensed electrical contractor to discuss these options. Any changes made to the powerline will be at your cost.\n2. Replace trees or shrubs with a suitable alternative\nTo avoid continual pruning, consider replacing unsuitable trees with a more appropriate species. Always check with your local nursery before selecting a tree to ensure that it will not exceed 3m in height when mature.\n3. Do it yourself — PLEASE READ CAREFULLY\nIn certain circumstances, you may trim your trees near distribution powerlines yourself but there are four very important restrictions:\nYou may not trim trees if:\nThe tree is closer than 500mm to your insulated house service line or could fall onto any part of the service line\nAny part of your body or equipment comes within 3m of a powerline\nThe tree is above a powerline, regardless of the distance between the tree and the powerline\nThe tree is in a transmission line easement\nA plant’s root system can interfere with underground power cables.\nIf your area has an underground power supply, remember that low voltage cables are approximately 500mm below the surface and high voltage cables are buried approximately 900mm. If you're in doubt about where cables are laid, contact Dial Before You Dig on 1100. For information on plants that won’t interfere with underground cables, talk to your local plant nursery.\n1. Exclusion Zone\nNo machine excavation to be undertaken in this zone.\nNo tree plantation is allowed.\n2. Hazard Zone\nObserved machine excavation only in this zone.\nSmall trees with a maximum height of 2m are allowed.\n3. Growth zone\nSeek advice from your local plant nursery before selecting a suitable tree. Remember - the roots of a fully grown tree must not enter within the 1m exclusion zone.\nWhat about transmission lines?\nCustomers can plant gardens near transmission lines provided that the trees, shrubs and plants don’t grow taller than 3m in height.\nTrees that grow too close to high voltage transmission lines can cause major electricity interruptions or even start a bushfire.\nTasNetworks conducts both aerial and ground patrols of their assets on a regular basis and have the responsibility of clearing any vegetation near transmission lines. This is done in conjunction with landowners. Under no circumstances should customers ever attempt to remove any vegetation within a transmission easement – which can be up to 60m.\nIf you are unsure about the type of powerline you have on your property or if you would like more information regarding transmission lines and easements please call us on 1300 137 008. You can also view our information sheet on transmission line easements."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:9edb9ba4-a183-4a9d-85ab-44591b3cc1a6>","<urn:uuid:83e8c617-ee93-4f01-a95d-2c7c18af9e22>"],"error":null}
{"question":"En el contexto de la toma de decisiones críticas, what are the key differences between an air traffic controller's quick decisions and end-of-life treatment choices?","answer":"Air traffic controllers must make immediate decisions managing multiple planes simultaneously, focusing on immediate safety and efficiency in a highly structured environment. Their decisions are based on clear protocols and visual/radar data. In contrast, end-of-life treatment decisions are more complex and long-term, involving personal choices about treatment aggressiveness, location of death, and quality of life considerations. These decisions are complicated by doctors' often optimistic prognoses (only 20% accuracy) and the emotional impact on family members, without the same kind of structured decision-making framework that exists in air traffic control.","context":["Originally published on Advisor Perspectives on February 6, 2017\nI used to think end-of-life discussions were fairly straightforward. All that was involved was ensuring my clients had a will and a health care proxy. I couldn’t have been more wrong.\nThese are very challenging times. Historically, the primary justification for fees was the ability to add value by managing an investment portfolio. But this has become more of a commodity, with the advent of robo-advisors and hybrid advisors like Charles Schwab and Vanguard, who compete directly for retail business, at a sharply reduced fee.\nFinancial planning is the next area likely to meet the same fate. There’s no end to the financial planning software available to advisors. It’s only a matter of time before similarly sophisticated software will be accessible directly by clients from easy-to-use platforms.\nThere’s one area where you can add value – and where even the most sophisticated software cannot succeed. It’s largely ignored and often misunderstood. It’s also a subject few want to confront, which is why you can play such an important role.\nEnd of life is complex\nI used to think end-of-life discussions were fairly straightforward. All that was involved was ensuring my clients had a will and a health care proxy.\nI couldn’t have been more wrong.\nMost people have an idealized vision of how they want to die. They would like to be at home, surrounded by friends and family, without pain and die quietly.\nThe reality is very different.\nAccording to an article in the New York Times, 50% of patients will die in hospitals “tethered to machines and feeding tubes” or in nursing homes. I’ve never met anyone who wanted to die that way.\nYou can have a major impact on your clients and their families by asking the following questions:\nIf you get a serious diagnosis, how aggressively do you want to be treated?\nClients should be aware that predictions by doctors are often overly optimistic. According to Nicholas A. Christakis, in his book Death Foretold, when doctors provide a prognosis, they are only correct about 20% of the time. They err on the side of optimism.\nI am aware of a number of situations where patients in their 70s had advanced cancer and were told there was a statistically small possibility of surviving for five years with aggressive treatment. In each case, the quality of their remaining life was destroyed due to the pernicious side effects of chemotherapy. They died within a year. In retrospect, they would have been better off avoiding treatment and treasuring the time they had left.\nDo you want the option to end your own life?\nAs of January 23, 2017, five states have enacted legislation permitting “death with dignity.” In these states, eligible individuals can legally obtain medications from their doctor to end their own life, on their own terms.\nFor religious and ethical reasons, some patients will not choose this option, which begs the question: Are they aware they have a choice?\nIt’s your job to be sure they know the facts.\nWhere do you want to die?\nThe quick reaction of most people will be “at home.” However, discussions with hospice nurses have given me another perspective.\nI want to stay at home – and be pain-free – for as long as possible. But I also don’t want to be a burden on my family. Few families have the ability to deal with patients at the very end of their lives when the patient experiences symptoms indicating death is at hand.\nI also learned that dying patients often don’t want to die in front of their loved ones. I‘ve heard many stories where the patient waited until everyone left the room for a few moments. When they came back, the patient had died.\nHospice care (either in-home or at a hospice facility) has many benefits. You should explore this issue with your clients.\nThis is a difficult subject for everyone. Few families will initiate it without outside intervention. If you want the satisfaction of adding immeasurable value, you will be the one to do so.","The National Airspace System (NAS) is a vast network of people and equipment that ensures the safe operation of commercial and private aircraft. Air traffic controllers work within the NAS to coordinate the movement of air traffic to make certain that planes stay a safe distance apart. Their immediate concern is safety, but controllers also must direct planes efficiently to minimize delays. Some regulate airport traffic through designated airspaces; others regulate airport arrivals and departures.\nTerminal controllers watch over all planes traveling in an airport's airspace. Their main responsibility is to organize the flow of aircraft into and out of the airport. They work in either the control tower or the terminal radar approach control (TRACON) room or building. Relying on visual observation, the tower local controllers sequence arrival aircraft for landing and issue departure clearances for those departing from the airport. Other controllers in the tower control the movement of aircraft on the taxiways, handle flight data, and provide flight plan clearances. Terminal radar controllers manage aircraft departing from or arriving to an airport by monitoring each aircraft’s movement on radar to ensure that a safe distance is maintained between all aircraft under their control. In addition, terminal controllers keep pilots informed about weather and runway conditions.\nMany different controllers are involved in the departure of an airplane. If the plane is flying under instrument flight rule conditions, a flight plan is filed prior to departure. The tower flight data controller receives the flight plan in the form of a flight strip, which is output from a computer, and arranges it in sequence. When an aircraft calls for clearance the clearance delivery controller issues the clearance and moves the strip over to the ground controller who manages the movement of aircraft on the airport surface, except the active runway. When the aircraft arrives at the active runway the strip is moved to the local controller who issues the departure clearance, observes the takeoff and turns the plane over to the departure controller. The TRACON departure controller identifies the plane on radar, climbs it, and directs it on course.\nAfter each plane departs, terminal controllers notify en route controllers, who take charge next. There are 20 air route traffic control centers located around the country, each employing 300 to 700 controllers, with more than 150 on duty during peak hours at the busiest facilities. Airplanes usually fly along designated routes; each center is assigned a certain airspace containing many different routes. En route controllers work either individually or in teams of two, depending on how heavy traffic is; each team is responsible for a sector of the center’s airspace.\nAs the plane proceeds on its flight plan to its destination it is handed off from sector to sector both within the center and to adjoining centers. To prepare for planes about to enter the team’s sector, the radar associate controller organizes flight plans output from a printer into strip bays. If two planes are scheduled to enter the team’s sector in conflict, the controller may arrange with the preceding sector unit for one plane to change its flight path or altitude. As a plane approaches a team’s airspace, the radar controller accepts responsibility for the plane from the previous sector. The controller also delegates responsibility for the plane to the next sector when the plane leaves the team’s airspace.\nWhen the plane is approximately 50 miles from the destination airport, it is handed off to that airport’s terminal radar arrival controller who sequences it with other arrivals, and issues an approach clearance. As the plane nears the runway, the pilot is issued a clearance to contact the tower. The local controller issues the landing clearance. Once the plane has landed, the ground controller directs it along the taxiways to its assigned gate. The local and ground controllers usually work entirely by sight, but may use airport surface radar if visibility is very poor.\nBoth airport tower and en route controllers usually control several planes at a time, often making quick decisions about completely different activities. For example, a controller might direct a plane on its landing approach and at the same time provide pilots entering the airport's airspace with information about conditions at the airport. While instructing these pilots, the controller also might observe other planes in the vicinity, such as those in a holding pattern waiting for permission to land, to ensure that they remain well separated.\nIn addition to airport towers and en route centers, air traffic controllers also work in flight service stations at 17 locations in Alaska. These flight service specialists provide pilots with preflight and in-flight weather information, suggested routes, and other aeronautical information important to the safety of a flight. Flight service specialists relay air traffic control clearances to pilots not in direct communications with a tower or center, assist pilots in emergency situations, and initiate and coordinate searches for missing or overdue aircraft. At certain locations where there is no airport tower or the tower has closed for the day, flight service specialists provide airport advisory services to landing and departing aircraft. However, they are not involved in actively managing and separating air traffic.\nSome air traffic controllers work at the FAA's Air Traffic Control Systems Command Center in Herndon, VA, where they oversee the entire system. They look for situations that will create bottlenecks or other problems in the system and then respond with a management plan for traffic into and out of the troubled sector. The objective is to keep traffic levels in the trouble spots manageable for the controllers working at en route centers.\nDuring busy times, controllers must work rapidly and efficiently. Total concentration is required to keep track of several planes at the same time and to make certain that all pilots receive correct instructions. The mental stress of being responsible for the safety of several aircraft and their passengers can be exhausting. Unlike tower controllers, radar controllers also have the extra stress of having to work in semi-darkness, never seeing the actual aircraft they control except as a small “blip” on the radarscope. Controllers who work in flight service stations work in offices close to the communications and computer equipment.\nControllers work a basic 40-hour week; however, they may work additional hours, for which they receive overtime, or premium pay, or equal time off. Because most control towers and centers operate 24 hours a day, 7 days a week, controllers rotate night and weekend shifts. Contract towers and flight service station working conditions may vary somewhat from the FAA.\nEducation & Training Required\nThere are three main pathways to become an air traffic controller with the FAA. The first is air traffic controllers with prior experience through either the FAA or the Department of Defense as a civilian or veteran. Second are applicants from the general public. These applicants must have 3 years of progressively responsible full-time work experience, have completed a full 4 years of college, or a combination of both. In combining education and experience, 1 year of undergraduate study—30 semester or 45 quarter hours—is equivalent to 9 months of work experience. The third way is for an applicant to have successfully completed an aviation-related program of study through the FAA’s Air Traffic-Collegiate Training Initiative (AT-CTI) program. In 2008, there were 31 schools in the AT-CTI program.\nAT-CTI program schools offer 2–year or 4-year non-engineering degrees that teach basic courses in aviation and air traffic control. In addition to graduation, AT-CTI candidates need a recommendation from their school before being considered for employment as an air traffic controller by the FAA.\nCandidates with prior experience as air traffic controllers are automatically qualified for FAA air traffic controller positions. However, applicants from the general public and the AT-CTI program must pass the FAA-authorized pre-employment test that measures their ability to learn the duties of a controller. The test is administered by computer and takes about 8 hours to complete. To take the test, an applicant must apply under an open advertisement for air traffic control positions and be chosen to take the examination. When there are many more applicants than available testing positions, applicants are selected randomly. However, the FAA guarantees that all AT-CTI students in good standing in their programs will be given the FAA pre-employment test. Those who achieve a qualifying score on the test become eligible for employment as an air traffic controller. Candidates must be granted security and medical clearance and are subject to drug screening. Additionally, applicants must meet other basic qualification requirements in accordance with Federal law. These requirements include United States citizenship and the ability to speak English.\nUpon selection, employees attend the FAA Academy in Oklahoma City, OK, for 12 weeks of training, during which they learn the fundamentals of the airway system, FAA regulations, controller equipment, and aircraft performance characteristics, as well as more specialized tasks. Graduates of the AT-CTI program are eligible to bypass the Air Traffic Basics Course, which is the first 5 weeks of qualification training at the FAA Academy.\nAfter graduation from the FAA Academy in Oklahoma City, candidates are assigned to an air traffic control facility and are classified as “developmental controllers” until they complete all requirements to be certified for all of the air traffic control positions within a defined area of a given facility. Generally, it takes new controllers with only initial controller training between 2 and 4 years, depending on the facility and the availability of facility staff or contractors to provide on-the-job training, to complete all the certification requirements to become certified professional controllers. Individuals who have had prior controller experience normally take less time to become fully certified. Controllers who fail to complete either the academy or the on-the-job portions of the training usually are dismissed. Controllers must pass a physical examination each year and a job performance examination twice each year. Failure to become certified in any position at a facility within a specified time also may result in dismissal. Controllers also are subject to drug screenings as a condition of continuing employment.\nOther Skills Required (Other qualifications)\nAir traffic controllers must be articulate to give pilots directions quickly and clearly. Intelligence and a good memory also are important because controllers constantly receive information that they must immediately grasp, interpret, and remember. Decisiveness also is required because controllers often have to make quick decisions. The ability to concentrate is crucial because controllers must make these decisions in the midst of noise and other distractions.\nAir Traffic Controllers - What They Do - Page 2\nAviation encompasses all the activities relating to airborne devices created by human ingenuity, generally known as aircraft. These activities include the organizations and regulatory bodies as well as the personnel related with the operation of aircraft and the industries involved in airplane manufacture, ...more"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:dbbf2000-0f24-492c-aa55-e576628278d3>","<urn:uuid:ae69bdd7-ca65-4a51-8032-dfafd5672b55>"],"error":null}
{"question":"What were the key benefits that Rome claimed to bring to conquered territories?","answer":"Rome claimed to bring several key benefits to conquered territories: they established peace by eliminating local rulers who caused internal wars, created public tranquility, and unified territories into 'a single well-joined body.' They also claimed to bring cultural advancement and civilization, particularly pointing to how they brought 'all the arts of civilization' to the Germans and transformed Italian peoples from being considered barbarians into becoming highly cultivated rulers.","context":["Bryn Mawr Classical Review 2011.09.29\nKingsbury, Straumann, and Lupher on Sutton on Kingsbury, Straumann, Lupher, Alberico Gentili. The Wars of the Romans. Response to BMCR 2011.07.48\nResponse by Benedict Kingsbury, New York University School of Law (Kingsbury@exchange.law.nyu.edu)\nBenjamin Straumann, New York University School of Law (firstname.lastname@example.org), and David Lupher, University of Puget Sound (email@example.com)\nWe'd like to thank Dana Sutton for his friendly review. His last paragraph exonerates us from what he takes to be an error, which he instead attributes to anonymous blurb writers. But we regard the blurb as entirely correct in the claim that Gentili developed arguments that became pivotal in debates on imperialism. Sutton denies the relevance of Alberico Gentili’s work for, as he puts it, “European settlement of the New World and subsequent colonization of other less culturally developed peoples” and its “cogency for debates about the legality or morality of modern colonialism.” But these topics are central themes in several contributions to the companion volume, mentioned by Sutton, The Roman Foundations of the Law of Nations: Alberico Gentili and the Justice of Empire (Oxford University Press, 2010). There, relations of Gentili's work to the sixteenth century context are addressed by David Lupher and Diego Panizza as well as in Chris Warren's essay on Gentili's poetics, and relations of Gentili's thought to wider debates on imperialism are discussed in the chapters by Anthony Pagden, Noel Malcolm and others. The following passage on p. xvi of the Introduction to our critical edition reviewed by Sutton deals with precisely the kind of civilizational claim in favor of imperialism made in The Wars of the Romans that Sutton says does not figure there:\nThe [...] civilizational claim made by Laelius in [Cicero’s] Republic, namely that Rome’s conquest and rule had made the conquered better off by taking away the right to do injury “from wicked people,” has equally important reverberations in Gentili’s late sixteenth-century framing of the debate on The Wars of the Romans. In the following passage, Picenus makes the case that, compared to the Roman empire, the Ottoman empire of his own day hardly qualifies as barbarian, then cites from Tacitus’ Agricola the Caledonian chieftain Calgacus’ famous anti-Roman speech [The Wars of the Romans 1.13, p. 117]:\n“Go off and tell me about Turkish barbarity! You hear of provinces conquered with the blood of provinces. Where they have made a solitude, there they used to allege that they had established peace, as the Briton [Calgacus] complained [Tac. Agr. 30.6]. Robbers of the whole world, whom neither the East nor the West will have satisfied, and who, although they have shut up the whole world in that city of theirs, nonetheless coveted the little huts of the Britons—as the Briton [Calgacus] cries out in the same place [cf. Tac. Agr.30.4-5]. ‘Like a stomach that can’t be filled is Rome, consuming everything and always hungry still, since into its lap are gathered the riches scraped away from all the overthrown cities and the denuded lands’—and so on. (The pious and religious witness Orosius writes these things [Orosius, Historiae adversus paganos 5.18.].) ‘The one and only state born for the destruction of the human race,’ says Arnobius [Disputationes adversus gentes], a holy man.” To answer this hyperbole, the defender in Book 2 [The Wars of the Romans 2.1, p. 129] asserts the civilizing effect of Roman rule. Far from making a solitude and calling it peace, the Romans had pacified the territories of the subjugated peoples by eliminating “kings and chieftains, who were the sources of internal wars there,” and, what is more, Rome thus established “public tranquility and, so to speak, the health of a single well-joined body.” The peoples of Italy, the defender maintains, “before the time of the Roman Empire ... were considered barbarians not only by the Greeks but even by the barbarians themselves, but soon emerged as the most cultivated people and rulers of everything.” To the Germans Roman rule had bestowed “all the arts of civilization,” turning them “from rude and rustic men into the most polished.”\nThe Carneadean debate, filtered through Cicero and Augustine, and the model of Roman imperialism were as important for Gentili as they were for the Valladolid debaters,1 and the arguments do have of course relevance—if not cogency—for debates about the legality or morality of modern imperialism.\n1. On the importance of the “Roman model” for the Spanish debate, see David Lupher, Romans in a New World. Classical Models in Sixteenth-Century Spanish America (Ann Arbor: The University of Michigan Press, 2003)."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:eaec655d-4526-46e2-86f5-b3740da4dc4f>"],"error":null}
{"question":"How do the nutrient acquisition methods compare between X. campestris in its natural environment versus bacteria grown in laboratory conditions? Please explain the key differences.","answer":"In nature, X. campestris, like other bacteria, takes up complex nutrients from their environment and breaks them down into simpler forms using secreted enzymes. However, in laboratory conditions, bacteria are provided with culture media containing nutrients already in simpler forms to promote rapid growth and multiplication. The documents specifically mention that X. campestris acquires carbon from its host plant and converts it to glucose through gluconeogenesis in natural conditions, while in laboratory settings, bacteria are given pre-simplified nutrients in culture media.","context":["From MicrobeWiki, the student-edited microbiology resource\nA Microbial Biorealm page on the genus Xanthomonas campestris\nHigher order taxa\n[Class] Gamma Proteobacteria\n[Species] Xanthomonas campestris\nDescription and significance\nXanthomonas campestris is an aerobic, Gram-negative rod known to cause the black rot in crucifers by darkening the vascular tissues. Host associated, over 20 different pathovars of X. campestris have been identified by their distinctive pathogenicity on a wide range of plants including crops and wild plants. This bacterium is mesophilic with optimal temperature at 25-30 degrees Celsius (77-85 degrees Fahrenheit) and inactive at temperatures below 10 degrees Celsius (50 degrees Fahrenheit) . X. campestris have Hypersensitive response and pathogenicity (Hrp) pili that help transfer effector proteins to decrease the host’s defense and glide through water [2, 3]. They can live in a soil for over a year and spread through any movement of water including rain, irrigation and surface water. Spraying healthy plants with copper fungicides may reduce the spread of the bacteria in the field . However, once the plant has been infected, X. campestris will eventually spread to the seed stalk inhibiting the growth of a healthy offspring.\nBy pure culture fermentation, X. campestris can produce an extracellular polysaccharide known as xanthan gum that is commercially manufactured as a stabilizing agent used in many everyday products including salad dressing or toothpaste . X. campestris is a model organism for studying interactions between plant and bacteria. Due to the deficit in crops, further research of this bactera is in progress in hopes of learning how to make plants resistant to this pathogen.\nThe genome structures of X. campestris contain variation depending on the pathovars. However, the different strains of X. campestris exhibit similar characteristics like circular chromosomes, the mobile genetic elements and protein coding sequences . In 2002, the complete genome of X. campestris pv campestris (Xcc) str. ATCC 33913 was completed containing over 5,076,188 nucleotides that encode for over 4200 protein coding and 61 structural RNAs . With over 548 unique coding sequences, X. campestris pv. vesicatoria (Xcv) is composed of a 5.17-Mb circular chromosome, four plasmids, and an essential type III protein secretion system for pathogenicity . Using Recominbase-based In Vivo Expression Technology to target tomato, Xcv has been found to have 61 genes that are involved in the interaction between pathogen and host including a necessary virulence transporter, citH homologue gene .\nCell structure and metabolism\nX. campestris is a rod-shaped Gram-negative bacteria characterized by its two cell walls and yellow pigment. It has a filamentous structure called hypersensitive response and pathogenicity (Hrp) pili that is attached to type III protein secretion system implementing the ability to transfer bacterial proteins to the plant and also motility in water .\nThis aerobic bacterium performs a number of metabolic pathways that are uniquely dependent on the pathovar. Entire genome sequencing of Xcv exhibit carbohydrate metabolisms that include: Glycolysis/ Gluconeogenesis, Citrate cycle (TCA cycle), Pentose phosphate pathway, and more. Xcv gains its energy source through oxidative phosphorylation, carbon fixation, methane, nitrogen, and sulfur metabolism .\nX. campestris acquire carbon from the host converting it to glucose through gluconeogenesis. Further research has shown that in gluconeogenesis, Xcc contain only the malic enzyme-PpsA route which is essential for virulence . In addition, this plant pathogen contain a type III secretion system (TTSS) that is necessary in order to attack the host . TTSS is important in pathogenesis because it transfers effector proteins in order to lower the host’s defense. Creating biofilm on plant surfaces, X. campestris exemplifies cell-cell communication through diffusible signal factor (DSF). .\nPossessing the ability to ferment, X. campestris creates an extracellular polysaccharide, xanthan, which is commercially produced and used in a variety of everyday products as a stabilizing agent . See Application to Biotechnology for more details.\nX. campestris causes great loss in agriculture due to their habitat in plants. It can live in the soil for over a year and spread through overhead irrigation and surface water . This bacterium thrive particularly during wet and warm weathers with optimal temperatures at 25-30 degrees Celsius (77-85 degrees Fahrenheit) . X. campestris depend on water for survival and movement to the next host. Due to contamination during cultural operations, affected plants usually occur in the same rows when farmed . See pathology for more details.\nX. campestris can be spotted by the black lesions that develop on plant surfaces when contaminated. The pathogen first interacts with the host by secreting an array of effector proteins including hypersensitive reaction using type III secretion system (TTSS) . These effectors may behave avirulently by disguising itself to secrete several hypersensitive reaction and outer proteins in order for interaction to occur with the host cells . X. campestris then targets the vascular tissue causing darkening and marginal leaf chlorosis . The bacteria seeps into the leaf towards the stomates, hydathodes, and to the epidermal cells initiating new lesion . Severe infection occurs in a young seedling. Since the disease advances throughout the plant, the main stem cannot form, stunting development and blackening the veins. Eventually, the bacteria proliferates throughout the vascular system and to the seed stalk causing the seed to become infected of future diseases .\nAppearing more during the wet seasons, X. campestris possess pili that accommodate a gliding movement through wet leaves. Covering an affected area in numerous numbers, once a plant is diseased, the pathogen will spread in any form of water movement including splashes of rain drop to a new host .\nVirulence factors consist of lytic enzymes that attack the plant's cell wall, excretion of proteases, amylases, cellulases and lipases that help lower the plant’s defense mechanisms . In addition, the Rpf gene cluster is also crucial for pathogenesis in order for X. campestris to moderate the production of these virulent factors .\nApplication to Biotechnology\nX. campestris ferments a stabilizing agent called xanthan gum that is used in many everyday products. It was first commercially produced at Kelco Company, a major pharmaceutical company. This polysaccharide is an ingredient in products like Kraft French dressing, Weight Watchers food, Wonder Bread products, and more . From carbohydrate fermentation by X. campestris, xanthan gum’s pseudoplastic, easily blended characteristic allows it to be used as a thickener by increasing viscosity of a liquid . In addition, xanthan gum also prolongs oil and gas wells even after production. Either pumped into the ground or using high pressure sandblasting, mixing water and xanthan gum into the wells will help thicken the liquid to release crude products of oil and cut through rocks in gas and oil wells. Xanthan gum costs $7 per pound compared to cornstarch for 89 cents per pound .\n8.1 Biological Control with strains of Bacillus\nGenome sequencing is being done in search of the essential genes needed in order to develop resistant plants. An experiment was done using Bacillus strains including B. cereus, B. lentimorbus, and B. pumilus as a rival for pathogen Xcc in cabbage. Evidence has shown some hope for biological control when the Bacillus strain was added in the roots .\n8.2 Regulatory network for cell-cell communication\nRecent studies demonstrate X. campestris use the diffusible signal factor (DSF) for cell-cell communication. In order for microcolonies to form structured biofilm, synthesis of DSF is required from the regulation of pathogenicity factor (Rpf) cluster. The Rpf cluster contains necessary genes for pathogenesis to occur. Without the critical DSF signaling, Xcc will create an unstructured biofilm of bacteria. Further research is being conducted to understand how the regulatory network is being monitored .\n8.3 Genetic Variation in wild crucifers\nResearchers have found genetic diversity in Xcc on wild crucifers. With the most diverse and abundant wild cruciferous plants in the world, studies was done in California to find any differences in genetic strains on Xcc in infected wild weeds. From both non-cultivated and cultivated areas, Xcc was isolated from different regions of California. Using Amplified fragment length polymorphism PCR (AFLP) to identify genetic variation in strains, over 72 strains were sequenced to show 7 unique genotypes that were limited to their respective sites. Non-cultivated wild weeds near the coast had strains of Xcc that were specific to the region and different from the weeds grown near produced crop areas. \n Averre, Charles W. \"Black Rot of Cabbage and Related Crops\" Accessed on August 16, 2007.\n Ritchie David F, Averre Charles W. \"Bacterial Spot of Pepper and Tomato\". North Carolina State University College of Agriculture and Life Sciences. Accessed on August 20, 2007.\n Weber E, Ojanen-Reuhs T, Huguet E, Hause G, Romantschuk M, Korhonen TK, Bonas U, Koebnik R. \"The type III-dependent Hrp pilus is required for productive interaction of Xanthomonas campestris pv. vesicatoria with pepper host plants\". Journal of Bacteriology. 2005. Volume 187(7) p.2458-69.\n Kuntz, L. “X is for Xanthan Gum”. Food Product Design. Accessed on August 26, 2007.\n Vorhölter FJ, Thias T, Meyer F, Bekel T, Kaiser O, Pühler A, Niehaus K. \"Comparison of two Xanthomonas campestris pv. campestris genomes revealed differences in their gene composition\". Journal Biotechnology. 2003. Volume 106(203). p.193-202.\n \"Xanthomonas campestris pv. campestris str. ATCC 33913, complete genome”. Public Library of Science Biology. 2002. Accessed on August 25, 2007.\n Thieme F, Koebnik R, Bekel T, Berger C, Boch J, Büttner D, Caldana C, Gaigalat L, Goesmann A, Kay S, Kirchner O, Lanz C, Linke B, McHardy AC, Meyer F, Mittenhuber G, Nies DH, Niesbach-Klösgen U, Patschkowski T, Rückert C, Rupp O, Schneiker S, Schuster SC, Vorhölter FJ, Weber E, Pühler A, Bonas U, Bartels D, Kaiser O. \"Insights into genome plasticity and pathogenicity of the plant pathogenic bacterium Xanthomonas campestris pv. vesicatoria revleaed by the complete genome sequence\". Journal of Bacteriology. 2005. Volume 187(21). p 7254-66.\nTamir Ariel D., Navon N, Burdman S. \"Identification of Xanthomonas campestris pv. vesicatoria genes induced in its interaction with tomato\". Journal of Bacteriology. 2007. Volume 189(17). P.6359-71.\n Weber E, Koebnik R. \"Domain structure of HrpE, the Hrp pilus subunit of Xanthomonas campestris pv. vesicatoria\". Journal of Bacteriology. 2005. Volume 187(17). p. 6175-86.\n \"Xanthomonas campestris pv. vesicatoria.\" Kyoto Encyclopedia of Genes and Genomes. Accessed on August 24, 2007.\n Tang DJ, He YQ, Feng JX, He BR, Jiang BL, Lu GT, Chen B, Tang JL. \"Xanthomonas campestris pv. campestris posesses a single gluconeogenic pathway that is required for virulence.\" Journal of Bacteriology. 2005. Volume 187(17). p 6231-7.\n Torres PS, Malamud F, Rigano LA, Russo DM, Marano MR, Castagnaro AP, Zorreguieta A, Bouarab K, Dow JM, Vojnov AA. \"Controlled synthesis of the DSF cell-cell signal is required for biofilm formation and virulence in Xanthomonas campestris.\" Environmental Microbiology. 2007. Volume 9(8). p. 2101-9.\n Wang L, Tang X, He C. \"The bifunctional effector AvrXccC of Xanthomonas campestris pv. campestris requires plasma membrane-anchoring for host recognition.\" Molecular Plant Pathology. 2007. Volume 8(4). p 491–501.\n Niehaus Karsten. \"The Xanthomonas campestris pv. campestris genome project.\" Accessed on August 20, 2007.\n Dow JM, Crossman L, Findlay K, He YQ, Feng JX, Tang JL. \"Biofilm dispersal in Xanthomonas campestris is controlled by cell-cell signaling and is required for full virulence to plants\". Proceedings of the National Academy of Sciences of the United States of America. 2003. Volume 100(19). p 10995-1000.\n \"Technologies in the Marketplace.\" United States Department of Agriculture, Agricultural Research Service (ARS). Accessed on August 21, 2007.\n Massomo S, Mortensen C, Mabagala R, Newman M, Hockenhull J. \"Biological control of black rot (Xanthomonas campestris pv. campestris) of Cabbage in Tanzania with Bacillus strains\". Journal of Phytopathology. 2004. Volume 152(2). p. 98-105.\n Torres PS, Malamud F, Rigano LA, Russo DM, Marano MR, Castagnaro AP, Zorreguieta A, Bouarab K, Dow JM, Vojnov AA. \"Controlled synthesis of the DSF cell-cell signal is required for biofilm formation and virulence in Xanthomonas campestris\". Environmental microbiology. 2007. Volume 9(8). p 2101-9.\n Ignatov, A., Sechler, A.J., Schuenzel, E., Agarkova, I.V., Vidaver, A.K., Oliver, B., Schaad, N.W. 2007. \"Genetic diversity in populations of Xanthomonas campestris pv. campestris in cruciferous weeds in central coastal California\". Phytopathology. 2007. Volume 97. p. 803-812.\nEdited by Tammie Chau, student of Rachel Larsen","Basic requirements for the cultivation of bacteria are: (I) Abundant Nutrients (II) Optimum Environmental Conditions\nBacteria are present universally almost everywhere; in soil, air, water and even inside mouth and intestine of all animals. ‘Cultivation of bacteria’ or ‘bacteria culture’ means growing these minute invisible bacteria in nutritionally rich substances and suitable environmental conditions, which support their rapid growth and multiplication.\nThis results in their manifestation as large population visible to naked eye (as colonies or turbid suspension). Thus, there are two basic requirements for the cultivation of bacteria, such as (I) Abundant nutrients and (II) Optimum environmental conditions.\n(I) Abundant Nutrients:\nIn nature, bacteria take up the complex nutrients available around them after degrading them into simpler forms by the enzymes secreted by them. But in laboratory, rapid growth is augmented by growing them in substances containing nutrients in simpler forms.\nThese substances containing adequate quantity of nutrients in simpler forms for rapid growth and multiplication of bacteria are called ‘culture media’. There are a number of culture media now available containing different ingredients. Culture media are obtained in the following three ‘physical forms’.\n1. Liquid Media or Broth:\nThese are clear liquids containing water and nutrients in simpler forms for growth of bacteria, which have been sterilized in autoclave. When bacteria is inoculated into them and incubated in conditions suitable for their growth, they grow profusely into thick suspensions of bacteria cells, due to which the media become turbid.\n2. Solid Media:\nThese are solidified substances, in which liquid broths have been supplemented with a solidifying agent called ‘agar’, at a level more than 1%. Agar is a powder (sometimes called agar) extracted from seaweeds and is a complex carbohydrate composed mainly of galactose.\nIt is important to note that; agar is a solidifying agent and has no nutritional value for bacteria. It serves as an excellent solidifying agent, as in aqueous solution it liquefies at 100°C and solidifies at 40°C. Most of the pathogenic bacteria of human are grown at 37°C (normal human body temperature).\nAgar does not melt at this temperature and provides a hard surface. On this nutritionally rich hard surface, each single bacterium grows, multiplies and gives rise to an isolated colony of those bacteria. Such isolation is not possible in liquid media, where bacteria grow in suspension.\nSolid agar media can be prepared in the following forms:\n(a) Agar Plates:\nAgar powder, at a level of more than 1%, is dissolved completely in liquid broth by warming. Then, it is sterilized in an autoclave. It remains liquid in hot condition and solidifies as it cools. In the warm liquid state, it is poured into sterilized petri dishes (20 ml in each petri dish) and allowed to cool, so that it forms a thick layer at the bottom of the petri dishes.\nThese petri dishes containing a thick layer of solidified agar media are called ‘agar plates’ or simply ‘plates’. Bacteria are grown as isolated colonies on these plates for their enumeration and isolation.\nThe characteristics of these colonies also help in the identification of bacteria. Petri dishes are available in different sizes to meet different experimental conditions. For routine purposes, however, petri dishes of 15 cm diameter are used.\n(b) Agar Slants:\nTo prepare ‘agar slants’ or simply ‘slants’, agar powder, at a level of more than 1%, is dissolved completely in liquid broth by warming. In the warm liquid state, it is distributed into test tubes (20 ml in each test tube), cotton-plugged and sterilized in autoclave.\nThe sterilized medium in test tubes is allowed to solidify in slanting position, so as to get the slants. The slants are used for maintenance of pure stock cultures of bacteria obtained by isolating on agar plates.\nThese are also used for maintenance of standard reference stock cultures obtained from international standard laboratories. Pure cultures and standard cultures are maintained by periodically (usually 15 days to 1 month) transferring to fresh slants aseptically. The growth characteristics on slants also help in identification of bacteria.\n(c) Agar Deep Tubes:\nAgar deep tubes are prepared following the same procedure as followed in the preparation of agar slants except that, here the media, after sterilization, are allowed to solidify in upright position. These are primarily used for study of gaseous requirements of bacteria.\n3. Semi Solid Media:\nThey contain agar at a level less than 1%, so that they remain in a semisolid state. They are used for specific studies.\n(II) Optimum Environmental Conditions:\nSeveral environmental conditions influence the growth of bacteria. To cultivate a bacteria, it should be provided with a set of optimum environmental conditions. The most important environmental conditions to be provided during cultivation of bacteria are given below.\n1. pH of the Media:\nEach species of bacteria can grow within a specific pH range. For most bacteria this range is between 4 and 9. However, the maximum growth of each species of bacteria occurs within a very narrow pH range. This optimum pH range for most bacteria is 6.5-7.5 and that for most of the fungi, molds and yeasts is 4-6, as they prefer acidic environments.\nFor maximum growth to occur, the pH of the culture media has to be adjusted to this pH during its preparation. Chemical substances that act as buffers (e.g. KH2P04, K2HP04) are also added to the media to prevent any shift in pH that may occur due to accumulation of acidic or basic metabolic end products produced by the bacteria during their growth.\n2. Temperature of Incubation:\nMesophiles are incubated at 37°C, thermophiles at 55°C and psychrophiles at 4°C."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"temporal_focus","category_name":"future"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"comparison"}],"document_ids":["<urn:uuid:28758c6c-eea8-4577-96c5-f1d5b4570b66>","<urn:uuid:b1feeac3-ce65-4a1a-8d52-75f26240fdb7>"],"error":null}
{"question":"What are the economic and maintenance implications of using galvanized steel troughs versus Douglas fir for raised garden beds in the long term?","answer":"Galvanized steel troughs cost about $240 for a 3x10 feet, 24-inch tall unit and require minimal maintenance, though they may eventually corrode, particularly in acidic conditions. Douglas fir is notably more economical, costing approximately one-third less than alternatives like cedar and redwood. While Douglas fir boards may need replacement sooner than other materials, the replacement cost remains lower than initial investment in more durable lumber. However, Douglas fir can experience warping and splitting over time due to shrinkage, requiring proper securing to prevent structural issues. Both materials offer different maintenance challenges - galvanized steel may develop corrosion byproducts in surrounding soil, while Douglas fir might require more frequent structural maintenance due to its tendency to warp and split in outdoor exposure.","context":["Anyone have experience with using galvanized steel livestock troughs as raised garden beds?\nI’ve been pricing materials for raised beds and searching online for what other gardeners have used: the costs and designs. One idea that caught my eye was using livestock troughs as planters.\nOnline, I’ve seen 20 gauge galvanized steel livestock watering troughs measuring 3 feet by 10 feet, 24 inches tall for about $240.\nAdvantages: Less expensive than using some long lasting wood boards, ready to use, taller beds make gardening easier for all. The height of the bed should discourage rabbits and the bottom should keep voles and moles out. Lifespan: 5 to 20 years.\nDisadvantages: Some websites posted concerns about zinc leaching into the soil. So I did what journalists do, I researched.\nAlana Hochstein, a corrosion Engineer with the American Galvanizers Association noted in an email “The Food and Drug Association (FDA) has approved the use of galvanized steel for food preparation and conveyance for all applications with the exception of foods that have a high acid content, such as tomatoes, oranges, limes, and other fruits. For more information, see our website:\nThe National Gardening Association (https://garden.org/about/intro/president)\nI emailed NGA President David Whitinger about whether zinc was a concern. He wrote: “Plenty of people use galvanized containers for gardening and I’ve never heard of anything to suggest that it’s not safe.”\nI also noted online that community gardens and restaurants are using galvanized steel as beds. Still, I needed more information.\nI looked for data from Cornell University. Cornell soil extension agent Robert R. Schindelbeck emailed: “The zinc can leach from the metal object into the soil. Generally this is OK as zinc is relatively “safe.” He referred me to this link titled Healthy Soils, Healthy Communities:\n“What levels of metals are acceptable in garden soils?\n“There are no standards protective of public health specifically for metals in garden soils in NYS, but there are guidance values developed for other purposes that gardeners can consider.”\nZinc is naturally occurring. The NYS Department of Environmental Conservation and the NYS Department of Health developed guidance values. The guidance values for zinc are 2200 parts per million (PPM). Levels found in NYS soils in rural areas were 10-140 ppm and in urban areas 64-380 ppm.\n“Human health: Small amounts of zinc in the diet are essential for good health.\n“Plant health: Zinc is an essential micronutrient for plants, but it can be toxic to plants at higher soil levels, even below those that are a concern for human health.”\nThat begs the question: What are the zinc levels for soil in a galvanized trough? This question gets answered by the fourth source: Rodale’s Organic Life article written by Deb Martin, November 13, 2014\nIs it safe to use galvanized sheet metal to build raised garden beds? —Susan Taylor, Monticello, Utah\nOver time, compounds used in the galvanizing process will leach from galvanized metal into surrounding soil. Climate and soil conditions such as moisture and salinity affect the rate and the amount of leaching. While the by-products of corrosion are unlikely to occur in amounts that pose any risk to human or plant health, gardeners who are considering growing in galvanized containers or metal-framed beds should be aware of the potential for zinc and other materials to transfer into the soil.\nZinc, the main ingredient in the galvanizing “bath” used to prolong the life of steel, is an essential micronutrient that occurs naturally in North American soils at an average background level of 0.07 milligrams of zinc per gram of soil. For the sake of comparison, the Daily Value (an approximation of our dietary need) for zinc established by the FDA for adults is 8 to 11 milligrams.\nWhile studies of zinc levels in the soil next to galvanized structures have found increased amounts of the element, those levels often are comparable to background levels and within EPA guidelines, says Dan Barlow, a corrosion engineer with the American Galvanizers Association.\nZinc does not migrate readily through soil, so elevated zinc levels tend to be found only in the immediate area of a galvanized container or structure. Soil pH, organic matter content, and other soil characteristics affect zinc’s ability to be taken up by plant roots. As much as 90 percent of zinc in soil may be unavailable for uptake by plants.\nDue to zinc’s limited bioavailability in soil, there is little chance of ingesting too much zinc through plants grown in proximity to galvanized metal, says Eric Van Genderen, Ph.D., manager of environment and sustainability for the International Zinc Association. “You will likely never get even your recommended daily allowance from your produce, much less too much,” he says.\nBecause galvanized metal corrodes faster as pH decreases, Van Genderen says it’s probably not the best container material for plants that require acidic conditions.\nOther corrosion by-products may show up in the surrounding soil, Van Genderen says. He notes that levels of other metals found in galvanized surfaces, such as nickel and bismuth, typically would be “so low that you’d probably never see a difference in the amount coming from the galvanized metal versus the background levels.”\nThe health of beneficial soil microorganisms that are exposed to galvanized metal is another consideration. “There is no question zinc can kill some of the soil’s microbes and that others love it,” says Jeff Lowenfels, author of Teaming with Microbes: The Organic Gardener’s Guide to the Soil Food Web, Revised Edition (Timber Press, 2010), and Teaming with Nutrients: The Organic Gardener’s Guide to Optimizing Plant Nutrition (Timber Press, 2013). “I am willing to let the arbuscular mycorrhizal fungi take up excess zinc, feed the plants what they need, and hold the rest,” Lowenfels says. His research has convinced him that “any damage done to the soil food web [by excess zinc] is quickly corrected by it if the soil food web is a healthy one.”\nTroughs in the Garden\nWant to see more?\nIf you search Google, you’ll find dozens of examples of troughs that have been painted and made pretty.\nThe nicest I’ve seen is at http://www.nwedible.com/the-most-attractive-veggie-garden-ever/. Check it out.\nTips on Painting a trough: https://www.gardenista.com/posts/steal-this-look-water-troughs-as-raised-garden-beds/\nTips on making a trough self-watering.","The desire for local fresh food has given a boost to the practice of home gardens, and raised beds are a popular option--especially in areas with naturally occurring rocky soil or in small spaces. There are different materials kinds of wood and other materials, such as cinder blocks & metal tanks that you can choose from when building these raised garden beds. Is Douglas fir also an option?\nYes, you can use Douglas fir for building raised beds in your garden. Given its resistance to rot, Douglas fir is a durable wood, and can last as long as 10 to 15 years before needing replacement. Douglas fir is also one of the cheapest of the types of wood for building raised garden boxes.\nThere are some clear advantages to using Douglas fir for raised beds. First is its affordability, but there are other reasons as well. This article explores some of the traits that you should consider before using Douglas fir for the raised beds in your garden.\nDouglas fir is abundant & sustainable\nIt has become increasingly common for people to choose locally sourced and sustainable materials for their homes and gardens. Douglas fir forests can be found throughout the western coast of the United States. They are resilient as they can regrow after major events like timber harvests and wildfires. Using Douglas fir is not only environmentally friendly but is easy on the wallet too.\nDouglas fir is durable\nFor raised garden beds, Douglas fir wood is a very durable material. They last from 10 to 15 years as a raised bed. The moderate lifespan of the Douglas fir allows the gardener to change things up a bit every few years, or even moving houses without being guilty of wasting lumber.\nDouglas fir is an affordable option\nDouglas fir boards cost almost a third less than the other options available in cedar and redwood. There are several grades of Douglas fir available. The most cost-effective one is a mill-run grade that helps create tight knots in the wood. Tight knots ensure that the wood does not break open and create holes.\nAlthough you may need to replace boards made of Douglas fir sooner than the other ones, replacing Douglas fir boards will still be less expensive than any other lumber that is as durable as the Douglas fir.\nThese Construction Douglas Fir Board Stud Wood Lumber can be used to make raised garden beds in your home. They are not only affordable, but they also add beauty and structural integrity to your garden.\nNaturally Rot Resistant\nDouglas fir are naturally resistant to garden rot as the resins in this species help the trees to defend themselves against decay and pest infestations. The lumber sawn from this species will retain these desirable qualities making the Douglas fir rank higher in terms of return on investment.\nDouglas fir fares better vs. other woods & materials\nThere are many options for building raised garden beds available in the market today. While a cinder block is cheap and durable, it is heavy to lift and can hold heat. Retaining heat is probably a good thing in a winter garden, but for a summer garden, it does more harm than good to your plants.\nGarden beds made of rocks are heavy to lift and work with. They will also require frequent maintenance, so that weed and grass do not make their way in. Among the other options, steel, concrete, and galvanized metal tanks can be very expensive. Galvanized metal containers and steel containers also tend to rust over time and are not ideal for growing edible vegetables.\nPressure-treated wood may seem like a great choice too as it is readily available and can survive for years in the ground or in situations where it is constantly wet. However, pressure-treated wood contains heavy metal chemicals that are used to treat the wood to make it rot resistant and resistant to bugs and decay. These toxins will leach into the soil and be harmful to the plantings that you are growing in that soil.\nIn wood, there are some options such as cedar and redwood that last for more than ten years. Even though the Douglas fir does not last as long as ten years, it is a third less expensive than the other options available in wood. In Europe, Douglas fir is considered to be tougher and more drought resistant than its other alternatives.\nDouglas fir raised beds look great\nDouglas fir are tall, beautiful conifers that grow along the Pacific Northwest coast. The tree looks like a tall and slender triangle. It adds elegance and beauty to the landscape in which it grows. Young Douglas fir are often used as Christmas trees.\nThe straight trunk of a fully grown Douglas fir can be as much as four feet in diameter and sometimes even twice that wide. The lumber produced from these trees looks sturdy and beautiful as well.\nDouglas fir is a product of nature; therefore, variations in grain and color do exist. This becomes apparent in the lumber that is cut out from these trees. The variation in color and grain also adds to the aesthetic beauty of the wood. In a garden, raised beds made of this wood will only add to the garden’s beauty.\nHow long do Douglas fir raised beds last?\nGenerally, Douglas fir raised beds can last 10 to 15 years. However, the longevity depends on your climate, and other factors--chiefly, how wet the wood gets and for how long.\nFor example, in New Mexico where I live, we’re technically in a desert--which means we get roughly 10 inches of rain or less per year. Compare that to, say, the Pacific Northwest, where some places can get 100 - 200 inches of rain per year. So, chances are that Douglas fir raised beds are going to last several years longer in the dry Southwest than the Pacific Northwest.\nHow to make Douglas fir raised beds last longer\nWood burning or Yakisugi--an ancient Japanese form of wood preservation--can help make wood of any species last longer. Charring the wood without combusting the whole piece leads to carbonization. Carbonization further renders the wood water resistant, thereby making it more durable. Wood burning also makes the wood weather-resistant, bug resistant, and in some cases, even fire-resistant.\nAre Douglas fir raised beds safe for vegetables?\nThe wood that you will use for building the raised bed in your garden is likely to be constantly wet and will be in direct contact with the soil on which your plants will grow. You need to build your raised beds using a material that does not quickly decay due to the constant moisture and which is also safe for your produce.\nKeeping this in mind, Douglas fir are suited to build raised beds in your garden as they do not decompose even after prolonged exposure to wet surfaces, nor does it discharge toxic materials into the soil.\nRaised beds can warp and split over time\nRaised beds constructed from wood can warp and split over time. This is true for any wood--even a rot-resistant species like Douglas fir.\nAs a softwood species, Douglas fir boards tend to warp and split in outdoor exposure and must be secured properly to prevent a raised garden bed from falling apart. This happens because the fir wood experiences shrinkage over time. This shrinkage in the wood dimensions results in warping and splitting of the wood.\nDouglas fir has proven to be one of the top choices for building raised beds in the garden. It is also beneficial to use untreated wood. While the lumber industry has modified its processes in the past decade and no longer uses toxic chemicals to treat wood, untreated wood is still best. Douglas fir is durable, cost-effective, and safe for your produce."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"content_constrained"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"future"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:e7f4fbca-8c1b-481d-9525-c1dca4ff3b1c>","<urn:uuid:eabe3c99-2756-4713-b31e-6ab83850fb61>"],"error":null}
{"question":"How does regenerative braking work in electric vehicles, and what safety features are available to monitor driver behavior during braking events?","answer":"Regenerative braking works through an electric motor/generator that has the same power characteristics in both motor and generator modes. The system is controlled via dynamic adjustment of torque through a PID (proportional integral derivative) control algorithm, recalculating values every 2-10 milliseconds. For safety monitoring, systems like NexTraq provide driver scorecards and in-cab alerts that notify drivers when they engage in unsafe braking behavior. The system can track hard braking events and provide real-time alerts, while also offering dashcams to visually monitor driver behavior during these events.","context":["Forward / Reverse Switch\nWhat physically happens if the vehicle is in operation at 30km/h (speed limit in underground mines) with steady pressure on the accelerator and the switch is immediately switched to reverse?\nThe vehicle comes to a controlled stop exactly the same as if the accelerator has been released, and then begins to move in reverse.\nWhat physically happens if the vehicle is in operation but in the process of slowing down and the switch is immediately switched to reverse?\nAs above, if the vehicle is slowing because the accelerator has been released, it continues a controlled brake, and then stops completely before engaging reverse.\nObviously an electric motor (if not attached to a driveline) can slow down and spin in reverse very quickly. However, being attached to a LandCruiser driveline, do we assume it would slow down and start reversing at the same velocity and rate as the regenerative braking?\nYes – except that the motor is “tuned” differently for forward and reverse, and has different limits imposed on it so that the maximum speed in reverse is less than the maximum possible speed in drive.\nIs this rate adjusted through software tuning? If you adjust the rate of the regenerative braking, would this directly affect the rate of deceleration in the previous scenario?\nCorrect – this is adjusted via the ‘proportional integral derivative’ (PID) tuning of the motor. In general, the regenerative braking effect reduces as the vehicle speed approaches zero. If the opposite direction of travel is selected, then the braking action is sustained.\nIs it possible to electronically stop the reverse function from working until vehicle comes to a standstill?\nThere is no need. Especially with low speed maneuvering, it is a desirable feature to be able to switch direction of travel at any time.\nEven though there may be no need for this, if the company or mine site requires this function, can Voltra provide it?\nYes, Voltra could provide this, but it would not dramatically change the actual behaviour of the vehicle. It would still come to a controlled stop and then go into reverse (because reverse is selected). The only difference is that if the vehicle is in reverse, the regenerative braking is higher as the vehicle speed approaches zero.\nWhat is the science of regenerative braking and how does it provides charge back to the motor? How is it controlled and adjusted?\nThe electric motor is a motor/generator. It has the same power characteristics whether operating as a motor or as a generator and is direction of rotation agnostic. The control of the motor is via dynamic adjustment of the torque, which can be either a positive (driving) or negative (generating) value. The torque control is via a feedback loop being a ‘proportional integral derivative’ (PID) control algorithm. The motor/generator torque values are recalculated every 2 – 10 milliseconds.\nCurrently, diesel LandCruiser operators mostly use 3rd gear (low range) to ‘coast’ down the decline – could the regenerative braking on the Voltra be controlled to mirror and replicate that level or rate of braking?\nYes – that’s what it does now, no change required. The vehicle speed, whether driving or regenerating, is set by the throttle position. A variation in the speed relative to the throttle position when going uphill versus downhill will be present, as this is the value of the positive or negative value in the PID error. This difference in speed will not be detectable by any human operator.\nApart from diagnostics, what other information can we get from the software?\nData available includes: Position (GPS dependent), vehicle speed, condition of all electrical subsystems, temperatures of all cell groups, voltage of all cells, motor torque, motor RPM, battery capacity, odometer value, energy use driving, energy from charger, energy used for the A/C, park brake status, throttle position, drive selection, charger status, charger charge current and voltage, Diagnostic Trouble Codes (DTC)\nWhat are other inherent features available with the software?\nOther software features include: speed/power/torque limiting, charging status, location, ability to remotely disable, ability to update most vehicle software remotely, ability to link to fleet management systems, and vehicle operating history.","Editor’s Score: 84/100\nWhy NexTraq Is Best for Safety Features\nAlthough every GPS fleet tracking system offers basic driver safety features, NexTraq takes it to the next level with advanced tools. You can monitor your fleet’s performance with driver scorecards and dashcams, and then improve unsafe behavior with driver training courses. NexTraq also offers less common features, like in-cab alerts for when a driver engages in dangerous behavior and mobile phone blocking while the vehicle is in motion.\nDid you know? NexTraq offers more than 40 different driver training courses.\nDrivers are safer when their vehicles are well maintained and their routes optimized. NexTraq helps you ensure safe and efficient driving with fuel cards, vehicle health reports, and maintenance schedules. You can also keep a close eye on your drivers’ locations and safety with features like geofencing and mapping.\n- You can track all driver performance metrics using driver scorecards.\n- NexTraq has in-cab alerts to notify drivers when they are engaging in unsafe behavior.\n- You can visually monitor your drivers with dashcams.\n- NexTraq offers dozens of driver training courses.\n- You can choose how often the data refreshes (every 30 seconds to 15 minutes).\n- Online customer support is delayed at times.\n- You will need to contact a representative for a price quote.\nIt is easy to get started with NexTraq because the company will install the devices for you. The platform is cloud-based, so you can access your fleet data with a computer, tablet or smartphone. NexTraq also offers two separate mobile apps: Drivers can use NexTraq Connect, and managers can use NexTraq View.\nYou can view data in near-real time, which is the industry standard; however, NexTraq offers one unique feature here. Its standard refresh time is every two minutes, but you can customize it to the interval that works best for you. For example, you can choose every 30 seconds, 60 seconds, two minutes, five minutes, 10 minutes or 15 minutes. We didn’t see that level of customization in many of the systems we analyzed.\nHere are some of the services you can receive with NexTraq.\n|Driver safety||NexTraq offers safety features like driver scorecards, driver training courses, dashcams, in-cab buzzers and mobile phone blocking.|\n|Alerts and reporting||Managers can view reports and alerts, and drivers can receive in-cab alerts.|\n|Maintenance and optimization||NexTraq has fuel cards, vehicle health data, and maintenance schedules to ensure a safe and optimized fleet. You can also add on features for ELD compliance.|\n|Geofencing and mapping||You can track drivers by setting geofences and accessing a live map of driving conditions.|\n|Tracking hardware||NexTraq has plug-and-play devices, advanced hardware, asset trackers, trailer trackers, heavy equipment trackers, and dashcams. It also offers add-ons like driver ID sensors, power take-off sensors, temperature sensors, and pick-up and drop-off sensors.|\nNexTraq provides a host of safety features to keep you on top of your drivers’ performance. It offers detailed metrics on your fleet’s safety so you can cut down on aggressive driving and save money on fuel consumption. We especially like that you can view driver safety scorecards, which identify risky driving behaviors and improve employee accountability. By tracking driver behavior, you get a better understanding of how your fleet operates. You can also see if you need to prioritize driver safety education and develop strategies to boost your fleet’s performance. In case your drivers do require additional coaching, NexTraq offers 44 driver training courses – above industry average.\nLike many of its competitors, NexTraq offers dashboard cameras. We find these to be especially useful in identifying poor driving behavior, insurance fraud, staged accidents, and conflicting reports of actual events.\nNexTraq offers advanced safety features, like in-cab buzzers to alert drivers when they engage in poor driving behaviors. You can also sign up for MobileBlock, an advanced tool that blocks active drivers from unacceptable cell phone activity. This technology, which not many other GPS tracking systems offer, works through a pod that you can mount in company vehicles to coordinate with an app on the driver’s phone, locking the phone’s screen to help keep your drivers focused on the road.\nAlerts and Reporting\nWe found it easy to access reports through NexTraq’s cloud-based platform and mobile app. We like that you can schedule reports on your fleet to manage fuel usage better, understand vehicle history, and analyze overall fleet status. We also like that you can set live alerts to receive a text or email when a safety hazard occurs or when a vehicle needs maintenance based on diagnostic trouble codes (DTCs). These notifications ensure you know at all times when issues need tending to. There are more than 30 alerts to choose from. Drivers can also receive in-cab alerts when they engage in unsafe behavior, like hard braking, harsh acceleration, or aggressive cornering.\nMaintenance and Optimization\nNexTraq provides fuel cards that track, monitor and analyze your vehicles’ fuel consumption. Not every competitor offers this feature, and it can help you reduce inefficiencies and prioritize more fuel-efficient driving practices. NexTraq also provides data and insight on how you can optimize your fleet’s routes for efficiency and when your vehicles are ready for maintenance repairs. Keeping your drivers in healthy vehicles on optimal routes is a great way to keep them safe.\nYou can also keep your drivers and fleet safe and healthy with NexTraq’s electronic logging device (ELD) compliance features. With add-ons like NexTraq Vehicle Inspection and NexTraq Elogs, you can keep your vehicles up to code and access reports like hours of service (HOS), driver’s vehicle inspection reports (DVIR) and records of duty status (RODS).\nGeofencing and Mapping\nPart of keeping your drivers safe is limiting where they can go and informing them about what their route entails. NexTraq lets you do this by setting geofences, powered by Google Maps. You can ensure your drivers are in the correct locations by setting up alerts for when they enter and leave geofenced areas.\nManagers can use the mapping feature, also powered by Google Maps, to get a real-time view of the driving conditions their team encounters. For example, you can see how heavy or light the traffic is, what the weather is like, and a Doppler radar. If your drivers encounter severe weather or aggressive traffic, you’ll know.\nNexTraq provides several hardware options for small businesses, with plug-and-play devices, advanced hardware, electronic logging devices, asset trackers, trailer trackers, heavy equipment trackers, and dashcams. NexTraq devices are tamper-proof and provide minute-to-minute tracking. You can also enhance your fleet management system with features like driver ID sensors, power take-off sensors, temperature sensors, and pick-up and drop-off sensors.\nWe like that the company offers free installation, so you don’t have to worry about correctly installing devices in your vehicles.\nLike many telematics companies, NexTraq doesn’t list its pricing information online. If you want to find out how much NexTraq’s services will cost for your business, you’ll have to speak with its sales team for a custom quote. NexTraq requires a one- to three-year contract for its services, which is standard for the industry. It offers hardware installation free with any purchase, which is something that many competitors charge for.\nWhen we reached out to NexTraq about a standard GPS tracking plan for a fleet of 20 vehicles, we were quoted prices of $80 per unit, plus $16.96 per vehicle per month for a one-year plan, or $17.95 per vehicle per month (with no upfront costs) for a three-year plan.\nUsers looking for additional safety features can opt for NexTraq’s Driver Safety package, which includes features like driver’s vehicle inspection reports (DVIRs), in-cab buzzers and dashcams. We were told that a three-year plan would cost roughly $39.95 for outward-facing cameras or $42.95 for dual-facing cameras. These prices are just estimates based on our criteria, so you will need to contact a representative for a quote specific to your needs.\nKey takeaway: NexTraq offers customizable fleet management plans with one- to three-year contracts.\nYou can choose between plug-and-play and hardwired devices, and your installation time will depend on which type you select. However, NexTraq simplifies this setup process by offering free hardware installation with every purchase. This is a valuable offering that companies typically charge for. Having a professional install your devices not only makes the installation process easier for you, but also ensures that each device is installed correctly and securely. This way, you can rest assured that it will accurately record driver safety data.\nWe found NexTraq’s library of online resources to be quite valuable. It offers case studies, news and events, whitepapers, FAQs, blogs, and a savings calculator. If you need more personalized assistance, you can reach customer support by phone, email, webchat and ticketing. To get a feel for NexTraq’s customer support, we posed as fleet managers and reached out to its representatives. Their answers were thorough and helpful, but their online response took a little longer than we would have liked. Based on this experience, we recommend that you schedule a demo or call for immediate assistance. They’re available Monday through Friday between 7 a.m. and 8 p.m. EST, and Saturdays from 8 a.m. to 3 p.m.\nDid you know? NexTraq’s support team offers training. If you are looking for training on using NexTraq, you can call or email them to set up a time that works for you.\nAlthough NexTraq offers customer support in various ways, you may find its online support lacking. When we reached out to representatives, posing as fleet managers, we were disappointed that their online response was slightly delayed. We were ultimately pleased with the content and thoughtfulness of their answers, but the delayed response leads us to believe that users would be better supported by scheduling a live demo or calling. This is something to consider if you need a GPS tracking solution with instant online support. If customer support is your top priority, read our review of Azuga.\nAnother potential drawback to note is that NexTraq doesn’t list its pricing online. Instead, it offers custom quotes for custom fleet management plans. Although this is common in the industry, it can be a problem for businesses that need an immediate online cost estimate for fleet services. If you need a GPS fleet tracking service with preset plans and online pricing, check out our ClearPathGPS review.\nFinding a GPS fleet tracking system can be challenging. That’s why we did some of the heavy lifting for you. We spent countless hours researching and analyzing GPS fleet tracking systems to identify the top solutions on the market. We looked at hardware, features, pricing and contracts, usability, refresh times, and customer support, and we even got hands-on experience with demos and product videos when possible. When searching for the best GPS fleet tracking system for safety features specifically, we focused on features like driver scorecards, driver safety alerts, vehicle health alerts, dashcams, and driver training.\nWhat Is GPS Fleet Tracking?\nGPS tracking systems offer a combination of hardware and software that tracks and records various fleet information, such as location, driver safety and performance, vehicle health and maintenance, and fuel usage and optimization. Businesses often use fleet management systems to optimize their overall fleet performance, as well as to ensure their drivers, vehicles, and assets are safe and secure. The reports generated from GPS fleet tracking data can help fleet managers make educated business decisions and improve their processes.\nThe typical industries that benefit from GPS fleet tracking systems include construction, utilities, heavy equipment, agriculture, landscaping, retail, manufacturing, distribution, government, oil and gas, food and beverage, and rental fleets.\nWho are the typical users of NexTraq?\nNexTraq is a comprehensive fleet management platform that serves a variety of industries. Typical NexTraq users include those working in home services, transportation, food and beverage, utilities, manufacturing, government and public safety, oil, gas, mining, distribution, construction and heavy equipment, agriculture, cable and telecom, and enterprise and rental fleets.\nWhich mobile platforms does NexTraq support?\nThe NexTraq platform works on various mobile devices, and it even offers two different mobile apps for iOS and Android devices – one for drivers (NexTraq Connect) and one for managers (NexTraq View).\nWe recommend NexTraq for …\n- Businesses that want to improve and maintain driver safety.\n- Businesses that need to maintain ELD and DVIR compliance.\n- Businesses that want to optimize their fleet performance.\nWe don’t recommend NexTraq for …\n- Companies looking for transparent online pricing.\n- Companies that need quick customer support, available 24/7."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"comparison"}],"document_ids":["<urn:uuid:1abafcf0-9e79-4b72-b700-7a5875b5a783>","<urn:uuid:2272d381-3d83-4c0a-8910-a27e68bdebcb>"],"error":null}
{"question":"How does Liepaja showcase its rich maritime heritage through its tourist attractions, and what environmental challenges is this coastal city likely facing due to ocean changes?","answer":"Liepaja's maritime heritage is prominently displayed through several tourist attractions - its 8km long sandy beaches, the waterfront area with ships and seagulls, and the Cathedral of St. Joseph which houses a ship model donated by a crew that survived a storm. However, like other coastal cities, Liepaja faces significant environmental challenges due to oceanic changes. These include potential sea level rise (projected 1-3 meters by century's end), increasing ocean acidification (30% more acidic over 50 years), and more intense storms due to warming oceans (storm power has increased by 50% since the 1970s).","context":["One day is a short time for a tourist visit, so it’s worth to approach planning your vacation responsibly. That’s what you can do in the most romantic city of the Baltics within 24 hours.\nTake a ride on the Liepaja tram\nIn 1899, Liepaja became the first city in the Baltic States to have a tramway installed. You can jump into the tram at the bus station and ride it all the way through the city: it takes just half an hour to make a kind of a sightseeing tour around the city.\nGet a glimpse of Liepaja wooden Art Nouveau\nArt Nouveau style examples are not only those a few districts in Riga or Eisenstein’s works. Many fine examples of wooden Art Nouveau are waiting for you in Liepaja, too. Luxurious buildings are located in the Primorsky Park area. You can not say that you were in Liepaja, if you did not walk around these places and did not feel the color of the city.\nAscend to the tower of the Holy Trinity Cathedral\nVisiting churches and temples is one of the best ways for getting acquainted with almost every town. In Liepaja, one must certainly see several cathedrals. One of them is the Cathedral of the Holy Trinity, for it holds the largest mechanical organ in the world: 131 registers, 4 keyboards and more than 7000 pipes! Also, do not miss the opportunity to climb the stairs of the cathedral tower and take a look at Liepaja from above.\nTake a stroll along the waterfront\nFor many a tourist, a stroll along the bay is the main purpose of paying visits to Liepaja . The spirit of the port city is all here. Ships, seagulls voices, smells of the open sea, even buildings (these being examples of the architecture of the Bauhaus, once part of the industrial zone and now well-equipped for tourist needs). During the day, it is interesting to walk around the Liv market and to watch parents taking their children to walks, and tourists posing for photographs. It is also very romantic in the evening here, when the city lights flicker, reflected by the mirrorlike waters of the channel.\nMeditate on the beach\nLiepaja beaches have turned into a legend – the sandy part is about 50-80 m during windless times, and the coast’s length itself is about 8 km. Soft sand, salt-soaked air, open sea: what else does one need for happiness?\nRelax in the Seaside Park\nYetr another spectacular sight of Liepaja. The park was created in the late 19th century, and it is not only a spacious green area separating the city from the beach, but also a place of cultural rest. Situated here are the “Daugava” stadium, mini-golf courses, skatepark, concert hall and bathhouses (there is a pond in the park in addition to its proximity to the sea, by the way). In general, a walk in this park is going to prove interesting regardless of your goals and global vacation plans.\nView Liepaja Church of Luther\nThis is another church that is worth a closer look. The building was constructed during the first independence of Latvia, and it is built in the form of a cross, made of stone cut in Finland: this church allways attracts attention with the lightness and airiness of its architectural design.\nVisit the Cathedral of St. Joseph\nPay attention while walking inside: there is a model of the ship under the ceiling. It was presented to the Cathedral by the crew of the ship, which escaped a violent storm by a sole miracle. It is believed that they were saved only through diligent prayer.\nSee the altar in the church of St. Anne\nThis is the oldest church in the city – and it holds the greatest treasure, and a masterpiece of the Baroque era within: a 9.7 meters high and 5.8 meters wide altar created in 1697 by a woodcarver, Nicolas Sephrence.\nEnjoy the local cuisine\nThe proximity to the sea dictates an abundance of fish dishes encluded in the city’s quisine. Do not rob yourself of the pleasure of tasting the Liepaja-way-cod or other local delicacies. Though, if you do not want to spend your precious time sitting in restaurants, just take a stroll to Petrovsky market and buy some freshly-caught fish there.","Our oceans are an interconnected set of complex and dynamic systems. Rapid economic growth over the past 50 years has increased humanity's ecological footprint by several orders of magnitude, crossing several boundaries that represent stable conditions for modern civilisation.\nAround the globe, various chemical, physical and biological systems are changing on a planetary scale. Pressures such as fishing, large-scale coastal developments, pollution and climate change are increasing at an exponential rate, causing entire ocean systems to come perilously close to irreversible tipping points. This will have profound implications for the water we drink, the food we eat and stable global weather patterns.\nHere are 25 tipping points in the oceans that are concerning scientists today:\nGlobally, our oceans are losing oxygen, with low-oxygen areas rapidly expanding in deep waters, impacting ocean animals. Low oxygen areas have expanded by 1.7 million square miles over the past 50 years, decreasing the amount of oxygen in our oceans by 2% globally due to global warming. Each degree of ocean warming reduces the concentration of oxygen in the ocean by the same amount by drawing out the oxygen. By the end of the century there could be a 3-6% decline in ocean oxygen. This decrease in oxygen has had dramatic impacts on ocean animals, killing some and impacting how others live, especially those in deep water where oxygen levels are naturally low.\nOceans have become 30% more acidic over the past 50 years. When carbon dioxide (CO2) dissolves in seawater, carbonic acid is produced and the acidity of the oceans increases. Acidic seawater is already dissolving the calcium carbonate shells of planktonic species in the Southern Ocean. Unabated, increasing acidification could cause whole ecosystems to collapse from disrupted food chains.\nPlanktonic plants support the marine food web, generate half of the world’s oxygen and also slow climate change by absorbing CO2 from the air, but their populations have declined by 40% since 1950. Scientists believe warming surface temperatures are to blame for their decline by changing their metabolism in ways that reduce productivity.\nDisrupted thermohaline circulation\nA network of currents flow around the world's oceans, each of them driven by differences in water density (thermohaline circulation, or THC). Of these, the best known is the North Atlantic Gulf Stream. The Gulf Stream's flow has slowed 30% over the past 30 years as a result of rising temperatures. Disruption in the global THC could have dramatic and unpredictable impacts on weather, climate, agriculture and civilisation.\nMore extinctions and extirpations\nFifteen marine animals are now extinct due to humans - and more are at risk. Populations that show signs of collapse include tuna, sharks, large rays, sea turtles, marine mammals, deep sea fish, Antarctic krill, seabirds and others. Some species are iconic and have special cultural and even spiritual significance for people; the great success of efforts to 'save the whales’ gives hope that similar efforts could restore many such species to their former abundance and importance, while sound policy and science could help restore the solely commercial species.\nMelting glaciers and ice sheets (Greenland)\nGlobal warming has doubled melting rates in Greenland since the 1990s. Meltwater from Greenland - which contains the second-largest body of ice, after Antarctica - accounts for one-third of all sea-level rises. If all the 660,000-cubic miles of glacial ice on Greenland melted, the global sea level would rise by over 20 feet. Freshwater from the Greenland glacial melt could also disrupt thermohaline circulation, including the Gulf Stream.\nMelting glaciers and ice sheets (West Antarctica)\nThe Antarctic icecap, which is up to 9,000 feet thick, contains 70% of the world’s surface freshwater and more than 90% of the world’s freshwater ice. The 530,000-cubic mile West Antarctic Ice Sheet (WAIS), is particularly vulnerable to melting because much of it lies below sea level. Loss of the WAIS would raise the global sea level by more than 15 feet, with catastrophic social and economic effects.\nArctic melting (sea ice)\nArctic sea ice has decreased by 13% each decade. The region is expected to be ice-free in summer by 2025 for the first time in 100,000 years. A decrease in sea ice will dramatically disrupt marine ecosystems, especially ice-dependent wildlife such as polar bears and seals, and some fisheries.\nMore intense storms\nThe oceans' heat powers weather systems and storm formation. Warming oceans may have increased the power and duration of hurricanes, typhoons, and destructive storms generated over the tropics by 50% since the 1970s. Changing ocean surface temperatures are also causing more erratic weather patterns all over the planet with widespread effects on human health, agriculture and economic activities.\nAbout 30% of the world's fisheries are overexploited or depleted. Harmful fishery methods also destroy habitats and harm fish populations. The populations of some species, such as bluefin tuna, which can live to 20-50 years, have collapsed by over 90% in the past 40 years and will take decades to fully recover. A significant part of the problem is unreported and unregulated fishing practices account for more than 11 million tons of fish catch each year.\nPoleward migration of fish\nFish populations are moving toward cooler waters as sea temperatures rise. Given current forecasts for temperature rises, populations are estimated to shift about 10 miles further poleward every decade. Species that are unable to adapt or move will decline or disappear. Fish movements may have economic impacts on human communities that have traditionally depended on them.\nCoral reef extinction\nBy 2050, 90% of all tropical reefs will be threatened with extinction from heating, overfishing, and coastal development. Coral reefs may survive in special places, such as locations cooled by upwelling or currents, but they will suffer heavy losses in most tropical regions, as will the human communities dependent on them. In addition, increased ocean acidity (see above) may increasingly inhibit calcium carbonate formation that form coral.\nHave you read?\nBy the end of this century, global sea levels will likely have risen by 1-3 metres. Island nations with an average elevation of around 3 metres - such as Kiribati, the Maldives, the Marshall Islands, Tuvalu, and the New Zealand territory of Tokelau - will be uninhabitable due to submergence or over-wash from storms, unless radical adaptation strategies are employed. Globally, over one billion people will be displaced from low-lying coastal regions.\nBlack Sea ecosystem collapse\nOverfishing in the 1970s followed by pollution and the arrival of an epidemic invasive species in the 1980s caused the Black Sea ecosystem to collapse. More than 80 million people in six nations live around the Black Sea, a 436,400 square kilometre (km2) body of water separating eastern Europe and western Asia. Since the 1990s, pollution control and other management measures have had positive results.\nBaltic Sea ecosystem collapse\nThe Baltic Sea, the world’s largest brackish-water system, shares many similarities with the Black Sea and offers many of the same lessons. Nutrient pollution, cod fishing, the impacts of shipping, hazardous industrial pollution and the dangers posed by World War II munitions all plague the Baltic ecosystem.\nRare earth elements (nickel, cobalt, manganese and others) are in high demand by industry. They are also abundant and of higher ore quality on the seafloor than on the land. Extraction is challenging where mine sites are thousands of feet underwater and the environmental regime is still being developed. Already an area the size of Mexico has been licensed for seabed exploration including the Clarian Clipperton Fracture zone in the Pacific Ocean and around dormant hydrothermal vents.\nExpansion of ocean dead zones\nOcean dead zones have doubled in frequency every decade since the 1960s. Their main cause is land-based pollution, including runoff from agriculture, animal feedlots and human sewage, that stimulate planktonic plants in huge population blooms that eventually die, decompose and use up all the water’s dissolved oxygen, creating a dead zone. Global warming will likely worsen dead zones around the world.\nMore invasive species\nSpecies that are introduced into areas in which they are not native and which become ecologically established are invasive and can have negative ecological, economic or health consequences. Ships are a major vector for invasive marine species, primarily by ships taking on ballast water in one location and dumping it elsewhere. Species may also hitchhike on ships’ hulls, floating debris or litter. The recent growth of non-native and venomous lionfish in the Atlantic is one of the most well-known examples.\nArabian Gulf salinity\nThe 240,000 km2 Arabian Gulf lies at the northernmost end of the Arabian Sea, surrounded by Iran, Iraq, Kuwait, Saudi Arabia, Bahrain, Qatar and the United Arab Emirates. Desalinisation plants in these arid countries supply more than 5 million cubic metres of drinking water per day to the region’s 43 million citizens. Brine discharge from desalination could affect all marine life in the region.\nMore El Niño events\nThe number of El Niño events has risen each decade and is set to double in frequency as a result of global warming. El Niño begins as sunlight and ambient air temperature heats surface water in the western Pacific Ocean around Indonesia by 3-5 degrees Celsius above average. This warm pulse of water eventually moves east to the coast of South America where it disrupts upwelling that affects fisheries, seabird populations, and weather patterns on a global scale.\nShipping has increased four-fold in the past 20 years, with a corresponding increase in underwater noise. Intense sound is also produced during seismic surveys for oil and by military low-frequency sonar. Sound generated by seismic surveys in the Arctic is increasing as melting sea ice allows access for oil exploration. Without effective ‘quiet ocean’ initiatives, human-source noise will increase steadily throughout the ocean, affecting many large marine animals such as whales and dolphins.\nThere are over 5 trillion pieces of plastic trash in the oceans, a figure that is increasing at a rate of 8 million tons per year. The 20-fold increase over the past 50 years is expected to double in the next 20 years. Plastic slowly degrade to micro-plastic, which is ingested by ocean animals - some of which we eat. A recent study estimates there will be more pieces of plastic than fish in the ocean by 2050.\nThe collapse of coastal mangrove forests\nCoastal development has destroyed over 60% of the world’s mangroves. Each year we lose a further 1%. At this rate, all unprotected mangroves could be lost within the next 100 years. Since mangroves slow global warming by trapping carbon dioxide, provide nursery areas for ocean wildlife, and protect coastlines from erosion and flooding, their loss would have diverse negative implications.\nHarmful algal blooms\nHarmful algal blooms (HABs) have increased in frequency, severity and geographic distribution due to global warming. HABs produce dangerous toxins that kill marine organisms, taint shellfish, cause skin and lung irritations, and contaminate air. In 2016, HABs killed 20% of Chile’s farmed salmon, causing the world’s second-largest exporter of salmon to lose more than $1 billion.\nMethane gas release\nIntermediate-depth warming of ocean water could be enhancing methane release from ocean sediments around the world. One study in the Pacific Northwest shows that the warming ocean in that area is already causing the transformation of methane hydrates to gas in amounts that over the course of a year equal the methane released from the 2010 Deepwater Horizon blowout in the Gulf of Mexico. Methane is 30 times more potent as a warming greenhouse gas than CO2, and is also being explored as a possible source of offshore fuel.\nThe authors are grateful to Dr. Steven Katona for his review of this material"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:2c00d460-a179-41eb-8f67-297233a6f881>","<urn:uuid:1150cd73-56d5-4e17-87b9-dcbdd4d959f9>"],"error":null}
{"question":"Compare the youth engagement strategies for environmental protection between INMED's program in South Africa and the APONE project in Bangladesh.","answer":"INMED's program in South Africa focuses on training youth through e-learning and on-site training, targeting 18,000 individuals in three years to become commercial agricultural producers using climate-smart aquaponics. The program aims to transition historically disadvantaged populations, including youth, from subsistence to commercial agricultural production. In contrast, the APONE project in Bangladesh engages 2,000 adolescents and youths through solidarity clubs that participate in direct environmental actions such as reforestation, waste management, and street cleaning. These youth also receive Climate Change and Environmental Education (CCEE) integrated with life skills and are involved in installing community-managed early warning systems for natural disasters.","context":["INMED ASE Farm Manager Living His Passion for the Land\nFor Kararegra Mashava, Farm Manager of the first INMED Aquaponics® Social Enterprise (INMED ASE) in South Africa, the charm of agriculture lies in working with living organisms. “They teach you something new every day,” he says.\nThe INMED ASE in Vanderbijlpark houses commercial aquaponics systems that will be used for food production and training. It will also serve as a consolidation centre for the growing number of aquaponics farmers to sell their harvests at higher market rates, as well as purchase seedlings, fingerlings and other inputs at bulk prices. Ultimately, the INMED ASE will serve as a powerful catalyst in transitioning historically disadvantaged populations, including people with disabilities, women and youth, from subsistence to commercial agricultural production using climate-smart aquaponics.\nManaging this unique social enterprise is a big job. “Each day brings new challenges when you are dealing with living matter and this aspect of farming really excites me,” says Mashava. “The opportunity to learn always presents itself, and I was privileged to be given the opportunity to join the INMED South Africa team to manage the INMED Aquaponics® Social Enterprise–a new type of incubator of entrepreneurial agro-enterprises for climate-smart food production.”\nMashava explains that aquaponics is an intensive form of farming combining hydroponics and fish farming in a closed symbiotic system that produces at least 10 times more crops than traditional farming and, uses a tenth of the water and no chemical fertilisers or pesticides.\n“This model is very easy to build—and because it is made of locally available materials it is very easy to replicate in any other area,” he says.\nFormerly the farm manager at Gamtoos Flowers and Vegetables, an agricultural enterprise at Thornhill in the Eastern Cape, Mashava started his INMED ASE journey in November last year.\nHe holds a B.Sc. Natural Resources Management and Agriculture (Agronomy) honours degree and advanced-level studies in geography, agricultural sciences and biological sciences.\nLooking back on his tenure at Gamtoos, Mashava says he was fortunate to be part of the success of this enterprise and is grateful for everything he learnt there as farm manager.\n“The opportunity to oversee all farm operations, from inception, was a real eye-opener. I used every day to strengthen my innovative thinking skills and further my understanding of how aquaponics, hydroponics and aeroponics are designed and operate,” he says.\n“With the varied experiences at Gamtoos and keeping up with new trends, I felt ready and excited to take on the INMED ASE venture,” he continues.\nMashava is responsible for fully developing and establishing operations to steer this new enterprise forward to meet quarterly and annual targets. “My primary responsibilities include implementing and managing the ASE to maximise quality production and achieve growth and market performance through entrepreneurial approaches, and to implement innovative business concepts,” he says.\nIn the short time Mashava has been an INMED ASE farm manager, he has certainly been making hay while the sun shines.\nThe team has already developed an urban cultivator for microgreens production. “Microgreens are leafy green vegetables that are harvested just after the germination of seeds and are fully developed cotyledon leaves, along with one pair of very small partially developed true leaves. Seeds of green leafy vegetables, salad greens, herbs and seeds of plants with edible flowers can be used for raising microgreens,” Mashava explains. “Microgreens are considered ‘functional’ foods and are a dense source of many nutrients, such as minerals, vitamins and antioxidants that can prevent many diseases and deficiencies when consumed in small quantities. The nutritional values of microgreens are more quantitative than mature plants,” he says.\nThe role of farming, as he sees it, is becoming increasingly important and it is Mashava’s dream to see more youth becoming lovers of the land.\nThe fact that the world population continues to grow and that everyone needs food three times a day, makes agriculture relevant – right now and in the future. “I would love to see more young people join the sector—especially when they learn how diverse and interesting it is. You get to combine different disciplines, like commerce, engineering and biology, to name a few.”\nMashava says it is rational and appropriate for countries to place emphasis on the sustainability of the agricultural sector through initiatives like the INMED ASE.\nINMED’s vision is to make the INMED ASE technology and ideas transferrable to all communities to enable them to grow food and create employment. “This makes the training aspect very important,” says Mashava, noting that INMED South Africa will start e-learning and on-site training in a couple of months targeting at least 18 000 individuals in the next 3 years.\nThe key to success with the INMED ASE, Mashava concludes, is attitude. “I believe one has to be passionate about farming. I have also learnt that agriculture requires patience.”\nINMED ASE is made possible by seed funding from Mondelēz Global LLC, via the Mondelēz International Foundation, through its Sustainable Futures social impact investment programme.\nAbout INMED Partnerships for Children\nINMED Partnerships for Children is an international humanitarian development organization that has improved the lives of vulnerable people in more than 100 countries for 35 years. Through multisector partnerships and in-country affiliates, INMED builds effective systems that deliver innovative approaches to break complex cycles of poverty for current and future generations. INMED’s programs in climate-smart agriculture and aquaponics, maternal and child health and nutrition, and economic development have made a sustainable impact on the lives of millions of children and their families. For more information about INMED Partnerships for Children’s programs and partners, visit https://inmed.org.\nAbout INMED South Africa\nSince 2006, in-country affiliate INMED South Africa has been working in collaboration with a wide range of corporate, foundation and government partners to transform the health, lives and futures of South Africa’s most vulnerable children. INMED South Africa’s programs focus on food security, child and community health, and economic and social development via climate-smart agriculture and participatory education. Incorporated under Section 21, INMED South Africa is a registered non-profit organization (NPC/PBO) recognized by the Department of Social Development and the South African Revenue Service (SARS). For more information, visit: www.inmed.org.za.\nAbout the Mondelēz International Foundation\nThe Mondelēz International Foundation (MIF) is the charitable arm of global food and beverage conglomerate Mondelēz International. Through international partnerships with leading NGOs, MIF funds nutrition education, active play and fresh foods programs to empower more than one million children and their families around the world to lead healthier lives. Mondelēz is the first company to invest in the INMED ASE through its Sustainable Futures Programme. For information, visit: https://za.mondelezinternational.com/.\nPlease contact Jacqui Moloi at Cathy Findley PR email@example.com or Tel: 071 7648233 to schedule interviews with Dr. Linda Pfeiffer and other leaders of the INMED ASE in South Africa or to find out more.\nFor any Mondelēz International queries please contact: FleishmailHillard SA\nNatalie Francis: firstname.lastname@example.org","Adolescents’ and Youths’ Power to Protect and Own Native Environment (APONE) - Cox's Bazar, Bangladesh\nYoung people in communities hosting Rohingya refugees will adopt climate & social actions to protect & develop ownership of the environment.\nYoung people planting trees\nExplain your project idea (2,000 characters)\nCox’s Bazar is a coastal district of Bangladesh prone to disaster & conflict, bordering Myanmar. It currently hosts more than 1 million Rohingya refugees from Myanmar & is vulnerable to climate change, exacerbated by deforestation of reserve forests for refugee camps & their cooking fuel requirements. The district is also religiously more conservative, with several violent incidents motivated by extremism. When Rohingya refugees entered in August 2017, host communities welcomed them, but now tension also prevails as limited natural resources, such as land, are shared. In this context, the proposed project APONE (meaning “Own” in Bangla) will engage adolescents & youths in Cox’s Bazar to design & implement climate & social actions that protect & develop the sense of ownership of their native natural & social environment. Youths will form solidarity clubs within their own communities. Oxfam & partners will build their capacity through Climate Change & Environmental Education (CCEE) integrated with life skills that help them to understand climate change, protect themselves & adopt sustainable lifestyles through climate & social actions. The youth solidarity clubs will volunteer time on a reforestation campaign around the Rohingya camps & also engage in tree plantation to prevent land erosion & offset deforestation caused by building refugee camps. They will also organize youth action camps to clean the city through waste management, street cleaning, etc. & install community-managed early warning systems for landslides, flash floods & cyclones & disseminate messages through campaigns on disaster-risk reduction (DRR). They will organize sessions on nonviolent conflict resolution, & be more vigilant on prevention of child, early & forced marriage (CEFM) & violence against women & girls (VAWG). Systematic institutionalization of youth volunteerism will promote ownership & protection of their environment & strengthen the relationships shared with refugee communities.\nWho are the beneficiaries? (1,000 characters)\nDirect beneficiaries are 2000 adolescents & youths from host communities who will engage in relevant climate & social actions. Indirect beneficiaries are other members of host & Rohingya refugee communities & the local Government of Bangladesh. Adolescents & youths will benefit from CCEE & life skills, which prior work has proved to be very empowering. Reforestation will protect shared land on which host & refugee communities are based. In addition to contributing to cleaner & greener communities that are using less fossil fuels, eco-friendly waste management & use of clean, renewable energy solutions will reduce women’s unpaid care work burden as they switch to biogas digesters & solar panels, decreasing income inequalities between women & men. Community-managed early warning systems & messages on DRR will help save lives & strengthen local governance. Messages on nonviolent conflict resolution, CEFM & VAWG prevention will increase knowledge & change attitudes of community members.\nCampaigning to end violence against women and girls\nHow is your idea unique? (1,000 characters)\nThe idea is unique as it targets adolescents & youths of vulnerable & underserved host communities as channels to promote peace & prosperity among host & refugee communities, as well as tackle climate change & natural disasters. Currently, there is strong emphasis on supporting the Rohingya refugees in Cox’s Bazar. Since September 2017, Oxfam has reached 230,000 Rohingya people in Cox’s Bazar with life-saving aid. However, not much programming exists to address the needs of host communities, which APONE will address. Oxfam has significant experience in building climate resilience & engaging youth in Bangladesh through its flagship program REECALL 2021 & the Empower Youth for Work project, which incorporates climate actions into the life skills curriculum for youths. Oxfam also has a strong Gender & Women’s Leadership program where projects such as I am One & I am Many, Creating Spaces, etc. are working with young women, men & communities to prevent VAWG, CEFM & extremism in Bangladesh.\nIdea Proposal Stage (choose one)\nEarly Adoption: I have completed a pilot and analyzed the impact of that pilot on the intended users of the idea. I have begun to expand the pilot for early adoption.\nTell us more about your organization/company (1 sentence and website URL)\nIn Bangladesh, Oxfam implements programs & campaigns around gender & women’s leadership, economic justice & resilience, & humanitarian capacity building & response, working with partners to support Rohingya refugees in Cox's Bazar, provide life & job skills to youth, facilitate climate change adaptation & disaster risk reduction in rural areas, prevent & address VAWG/CEFM, provide WASH services & advocate for local & national policies to reduce poverty & inequality.\nOrganization Filing Status\nYes, we are a registered non-profit.\nIn 3-4 sentences, tell us the inspiration or story that encouraged you to start this project.\nOur success in providing life skills, integrated with climate action, to young people, & building resilience of rural, underserved communities has inspired us to start this project. The potential of young people must be tapped to make the most of the upcoming demographic dividend in Bangladesh. We are inspired by their energy & enthusiasm to protect the planet by finding sustainable solutions to climate change & natural disasters & promote peace & prosperity by reducing inequalities.\nPlease explain how your selected topic areas are influenced, in the local context of your project (1,000 characters).\nThe project works with young people from Cox's Bazar, which faces a host of interrelated issues threatening Peace, Prosperity & Planet. The recent rise in fundamentalist violence, as well as tensions between Rohingya refugee & host communities, have adversely affected peace in Cox's Bazar. Young people, facing poverty & uncertainty about their futures, & confronting a lack of life skills, are at times recruited by extremist groups. Thus, their potential to contribute to their communities' peace & prosperity, through social & economic engagement, has remained underutilized. Climate change, deforestation & natural disasters, such as floods and cyclones, have impacted the planet & therefore the natural environment of Cox's Bazar, which also serves as a major tourist hub. Thus, the economy of the area is closely tied with conservation of its natural environment. In ensuring that young people adopt social & climate actions, the project offers a holistic solution to these key problems.\nWho will work alongside your organization in the project idea? (1,000 characters)\nOxfam in Bangladesh has a long history of working closely with local partners. The local partners in Cox's Bazar have knowledge of the specific context in host and refugee communities, which will be crucial to the design and implementation of the project. Oxfam will lead and coordinate the project while local partners will be selected to mobilize adolescents and youths. The experienced team working on APONE will include the Economic Justice and Resilience Program Manager, the Project Coordinator and Program Officer for Oxfam’s Empower Youth for Work project, and Senior Program Officers working in the Gender and Rural programs. The experiences, needs and interests of the communities will be explored to ensure that the project is custom-made to address their priorities.\nPlease share some of the top strengths identified in the community which your project will serve (500 characters)\nThe large number of young people in Cox's Bazar present immense potential. The upcoming demographic dividend promises a boost in economic productivity, if these youths are equipped with the appropriate life skills. Many of them have been volunteering for Oxfam in Bangladesh to support the Rohingya refugee community in Cox's Bazar. The youth also feel proud of Cox's Bazar being one of the most visited tourist destinations of Bangladesh & therefore want to protect the natural environment as well.\nThe project works with host & Rohingya refugee communities in Cox's Bazar, Bangladesh.\nHow many months are required for the project idea? (500 characters)\nThe project idea, which will use Human-Centered Design principles to find solutions tailored to the communities' needs, requires 36 months involving observation, ideation, rapid prototyping, user feedback, iteration and implementation.\nDid you submit this idea to our 2017 BridgeBuilder Challenge? (Y/N)"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"future"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_intent","category_name":"instructional"}],"document_ids":["<urn:uuid:7c605cce-c32e-4554-9971-8fd45b4b42de>","<urn:uuid:9535ad2d-1558-4610-8d22-02720cccfe05>"],"error":null}
{"question":"How do ancient Sumerian brewing traditions compare with early Belgian brewing practices in terms of their historical timeline and documentation?","answer":"In Sumeria around 1800 BCE, we have early written evidence of beer production in the form of the Hymn to Ninkasi cuneiform tablet. During this period, Mesopotamian tablets indicate that most brewers were women who produced beer both domestically and for ritual purposes. In contrast, Belgian brewing history dates back approximately 2000 years, with the first documented use of hops in the nearby region coming from Picardy, France in 822 A.D. By the 1300s, hops were being cultivated in the Low Countries, including Belgium, showing a much later but well-documented brewing tradition.","context":["Some of the earliest written evidence for beer production called upon a woman—well, strictly speaking, a goddess—to ensure that the magic of fermentation occurred. The Hymn to Ninkasi, as it became known, was pressed into a cuneiform tablet in Sumeria around 1800 BCE, and it offers useful hints as to how beer was actually made at the time (if not a more fully-formed idea of where Ninkasi fit into the Sumerian pantheon). Ninkasi is remembered by beer fans today though an award given by the American Homebrewers Association, and by a delightful brewery in Oregon that was named in her honor.\nBut where do mortal women fit in the history of beer?\nOther tablets from Mesopotamia, ranging over a period of hundreds of years, suggest that most brewers were women, and that they undertook their occupation on both domestic and ritual scales. The Code of Hammurabi (c. 1700 BCE) indicates that tavern-keepers, who were likely producing the beer they sold, were women, and that they could be 'thrown in the river' if they cheated their customers—in short, their work was important enough to make laws about. Egyptian art also depicts women brewing, and perhaps this already-long history of women's involvement with beer-making is what led to What Happened Next: the rise of the Classical period, and a shift to a preference for wine over beer (at least, among the elites).\nThe Greeks viewed wine as a man's beverage, while beer was viewed as effeminate and thoroughly déclassé, and the Romans inherited this prejudice from them.\nOf course, beer was still being produced, especially in Europe; we have some good archaeological evidence of European beer production and consumption from the Neolithic period onward—but less of an idea of who, exactly, was doing the brewing—an area that could do with considerably more research.\nWe're on firmer ground if we skip ahead to the medieval period; women were very clearly the primary makers of beer across much of Europe then. These women brewers appeared in literature of the era as well, not just in civic documents—Betoun the Brewster even pops up in Piers Plowman. It has been noted that there is no male equivalent for 'alewife', although the masculine 'brewer' seems to have long been available for the (initially) small number of men in the industry, while women could choose to be called 'brewsters.'\nAs brewing became more professionalized and less of a domestic duty, those brewsters began disappearing; by the 15th century, England and Germany had developed strong guilds for brewers—and while there were women among their numbers, the trend was a downward one.\nBy the eighteenth century, women brewers seemed to have largely disappeared from the professional ranks—but it's worth noting that they still appeared in popular song. 'Mother Watkin's Ale' first appeared as a broadside in the late sixteenth century and it enjoyed a long life (in fact, it's still recorded today). Women still appeared as tavern-keepers (many of whom brewed their own beer)—in colonial America, a not inconsiderable percentage of tavern-keepers were women, but commercial brewing came to be seen as an almost exclusively male pursuit.\n\"Early representations of women by commercial breweries tended to focus on beer's wholesome, family-oriented image.\"\nWhile the nineteenth and twentieth centuries saw women appear in ever-increasing numbers of beer advertisements, their role in these ads shifted dramatically. Early representations of women by commercial breweries tended to focus on beer's wholesome, family-oriented image; these women were typically mothers serving beer to husbands or brothers, often with a baby in tow. That obviously changed - but while modern beer advertising seemed to become increasingly sexist (at least from the large brewers), women were quietly making their way back into the industry.\nCarol Stoudt began making craft beer in the late 1980s—and the Stoudt's brand continues to grow. In England, Sara Barton reclaimed the seemingly-almost-forgotten title of brewster when she founded her brewery in the late 1990s after years of brewing for companies like Courage. Another British brewster, Emma Gilleland, became the first female head brewer at Marston's when she took command in 2007. In Belgium, Hildegard van Ostaden creates a wide variety of unusual beers for Urthel, while Dominique Friart does the same for St. Feuillien. Back in America, the Pink Boots Society was founded by brewer Teri Fahrendorf to help other women in the industry network; it now includes more than 500 members around the world.\nSo what beer should we drink to toast to the brewsters? Luckily, there are now many options. New Belgium employs a number of women brewers&mdashand with CEO Kim Jordan at the helm, they are certainly one to consider if you're within their distribution area. Moylan's, Allagash, Abita, Live Oak and Victory all have brewsters among their ranks, and there are many more craft breweries with females owners, lab staff, marketing geniuses, saleswomen and everything in between.\nIt's well worth seeking out one of these brands to raise a glass to women brewers, past, present and future.\nAbout the Author: Lisa Grimm is a craft beer geek with a background in archaeology, historic research and technology. She blogs about beer at WeirdBeerGirl.com.","Nick Carr on October 14, 2016 2 Comments History of Belgian IPA Brewing in Belgium stretches back some 2000 years, and the first recorded use of hops in brewing comes from Picardy, France in 822 A.D, about 1200 years ago. Picardy, France is less than 125 miles from Belgium, making it possible, even likely, hops were being used in Belgian brewing around this same time period. By the 1300s, hops were being cultivated in some of the Low Countries, including Belgium. Belgian beer is often typecast as only lightly-hopped and not very bitter. This stereotype is true to some extent. Belgian beers are often light bodied and crisp, so they tend to need less balancing then fuller beers. But the stereotype is only partially accurate. Some older traditional Belgian beers carried a hoppy bite. As this article (a good one to read if you’re gonna brew anything Belgian) points out, things like brewing specialty beers in the face of the crisp lager craze, the popularity of sodas, and the novelty of exported sweeter Belgian brews at the beginning of the craft beer movement ensured the stereotype. An example of these hoppier Belgian brews can be found in the form of Brouwerij Van Eecke’s Poperings Hommel ale. This beer is made with four different kinds of hops and was first brewed in 1981, well before the IPA craze had taken hold. Its IBU rating is somewhere between thirty and forty, so not quite within Belgian IPA style guidelines, but some websites have taken to placing it within the style. There have always been a few hoppier Belgian beers like Poperings Hommel, but a new appreciation and popularity of the hop, largely fueled by America’s craft beer movement, has inspired Belgian brewers’ to embrace their hop-bittered past and build upon it. Urthel Hop-it was probably the first IPA-inspired hoppy Belgian. It was created after head brewer Hildegard van Ostaden returned from a 2005 trip to the U.S. De Rank XX Bitter and Houblon Chouffe followed in close secession in 2006. On the American end, Stone’s Cali-Belgique seems to be one of the first commercial American examples. It was released in 2008. Belgian IPA is a fledgling style, much like the rest of the specialty IPA category; and like most of the specialty IPA’s it stands at a crossroads between style lines. Some may ask whether it should even be its own beer style. Most of the true Belgian IPAs, those made from a Belgian recipe and then “hopped-up,” could easily find a place in other style categories, be it Golden, Tripel, or Saison. On the other hand, American-Belgian IPA’s, those using an American recipe and Belgian yeast, don’t fit under the current American IPA style guidelines. So, is a new category necessary? New additions to the BJCP style guidelines are mostly based on a beer’s popularity. Before they became popular, all of these beer styles would have fallen under the blanket of “specialty” or “mixed-style” guidelines. Then they become popular. IPA’s are very popular, thus much experimentation took place with hopping other styles, thus we get new hoppier versions of a given style. They gain some of their own popularity and get put under the IPA umbrella because, well, that’s how the public knows a beer is hoppy. How long the Belgian IPA lasts as its own distinct style will undoubtedly be decided by its own popularity and the continuing status of its mother style. But, for now we can celebrate the ingenuity and experimentation of the brewers’ art, its popularity, and a reimagining of the hoppier side of Belgian brewing history. Style Profile & Characteristics The guidelines for the Belgian IPA style are set by the Beer Judge Certification Program (BJCP) Style Committee. The below details are a summary of what a Belgian IPA should represent. BJCP Guidelines Color Range: 5 – 15 SRM Original Gravity: 1.058 – 1.080 OG Final Gravity: 1.008 – 1.016 FG IBU Range: 50 – 100 ABV Range: 6.2 – 9.5% Serving & Storage Temperature: 48 – 50°F Shelf Life: 3 to 6 months Suggested Glass: Tulip or IPA Glass The BJCP classifies the Belgian IPA beer style under category number 21, “IPA” and it can be found in the guidelines as sub-category (21B), “Specialty IPA.” Other Specialty IPA Styles: In total, there are six “Specialty IPA” styles included in the BJCP guidelines. Aside from Belgian IPA, these include the following: Black IPA Brown IPA Red IPA Rye IPA White IPA The only other sub-category within the IPA category is American IPA (21A). Appearance: A Belgian IPA will be light golden to amber in color. Clarity depends on dry-hopping and can range from good to very hazy. A long-lasting, moderate to somewhat large head of off-white foam should form. Aroma: Smooth, sweet-grain malt aromas, but only light caramel if present at all. Belgian candi sugar may add to the sense of sweetness. Hop aromas should be moderate to high and will often carry the qualities of American/New World hops; citrus, piney, stone and tropical fruit. The earthy, spicy, and herbal aromas of European hops may also be present. May have a grassy character, an effect of dry-hopping. Fruity esters of apples, bananas, and pear can be moderately high, while clove-like phenols remain light, but often are noticeable. Mouthfeel: Body will vary somewhat depending on carbonation level and the use of adjuncts, but ranges from light to medium in most examples. Carbonation can range from medium to high and some warming may be noticeable in higher alcohol examples. Taste: The Belgian yeast often contributes an initial flavor of spice and esters; spicy and clove-like, along with esters of banana, apple, and pear. Maltiness stays light with a sweet-grain quality back-lit by possible low notes of caramel and/or toast. Hop flavors run medium to high and show much the same qualities as the aroma; tropical, melon, pine, citrus, and stone fruit of New World hops and/or the floral, spicy, herbal notes of Noble hops. Bitterness can be quite high and may be further heightened by the spiciness contributed by the Belgian yeast. It finishes dry to moderately dry with the possibility of some lingering sweetness. Food Pairing: The dry crispness and high bitterness of this beer works well with spicy heat. Try rare peppercorn rubbed beef steak, herb rubbed rabbit, spicy shrimp pasta, or spicy fish tacos. It’s also a good companion to many spicy food cultures; Asian, Indian, Mexican. Think Vietnamese spring rolls, chicken quesadillas, or curry. Look to sharp and tangy cheeses to pair with a Belgian IPA; sharp aged cheddar, goat cheeses, or blue. When it comes time to discuss desserts lighter and fruity such as pineapple upside down cake, crème brûlée, or rhubarb strawberry pie. Serving & Storage: For best presentation and greatest appreciation a Belgian IPA should be served at 48-50°F in a tulip glass or IPA glass. They are best stored at refrigerator temperatures away from light and should be enjoyed with 3 to 6 months of purchase or brewing. *Reference: The 2015 BJCP Style Guidelines Examples of the Style To help get you started, below are few popular examples of the Belgian IPA style. To get a better idea of what to expect, we would recommend you track one of these down and give it a taste. Houblon Chouffe from Brasserie D’achouffe (Houffalize, Belgium) Urthel Hop-It from Urthel Brewery (Ruiselede, Belgium) Raging Bitch from Flying Dog Brewing Company (Frederick, MD) Bitter Monk from Anchorage Brewing Company (Anchorage, Alaska) Hopsinjoor from Brouwerij Het Anker (Mechelen, Belgium) XX Bitter from Brouwerij De Ranke (Wevelgem, Belgium) Reninge Bitter Blond from Seizoensbrouwerij Vandewalle (Lo-Reninge, Belgium) Le Freak from Green Flash Brewing Company (San Diego, CA) Live A Rich Life from 3 Floyds Brewing Company (Munster, IN) Cali-Belgique IPA from Stone Brewing Company (Escondido, CA) Poperings hommel from Brouwerij Van Eecke N.V. (Watou, Belgium) Audrey Hopburn from Great Lakes Brewery (Toronto, Canada) Pan Galactic Gargle Blaster from Shorts Brewing Company (Bellaire, MI) Tripel Hop from Duvel Moortgat (Puurs, Belgium) Triomphe from Brewery Vivant (Grand Rapids, MI) How To Brew A Belgian IPA Recipe The BJCP guidelines style comparison for the Belgian IPA sums it up this way: “A cross between an American IPA/Imperial IPA with a Belgian Golden Strong Ale or Tripel. This style may be spicier, stronger, drier and more fruity than an American IPA.” This seems to be describing the most common way to build this IPA; make a big American IPA and ferment with Belgian yeast. But it could just as easily be simply a Belgian Blond, Golden Strong Ale, or Tripel recipe, hopped to a higher level with European hops. This, to my mind, would truly be a Belgian IPA. The other is more along the lines of an American-Belgian IPA. And then, of course, there are combinations of the two that provide each country a closer-to-equal representation across the ingredients, i.e. using American grain with European hops or European grain with American hops. Really, the only inescapable constant is the Belgian yeast. Recipe Options for Belgian IPA: Start With An American IPA Recipe Or, Go With A Belgian Golden or Tripel Recipe If you’re thinking of trying your hand at brewing a Belgian IPA recipe, here’s a few tips to help you throughout the brewing process. Grain Bill: The grain bill is going to depend on what base style you’ve decided on. If making the American version, start with a strong American IPA recipe. Domestic 2-row or pale malt will likely make up, anywhere from 80 to 100 percent of your grain bill. You want some low malt flavors, but very few roaster tones. Keep use of specialty malts constrained. Crystal malt should be used sparingly, making up less than 5% of the grain bill. For a Belgian IPA, you can use any strong pale Belgian recipe; a Golden, Tripel, even some Saison recipes will work. In this case, your base malt will be either a Belgian pilsner and/or pale malt at 60 to 100 percent of your grain bill. As with the American recipe, specialty malts should be used with care; little to no crystal/caramel type malts, no darker roasty malts, low quantities of aromatic, light Munich, even Belgian biscuit can work. In both versions, you are looking for a drier beer to accentuate the hop profile. To this end, and especially, when making a higher alcohol version of the style, some sort of adjunct sugar is often used. In the case of the Belgian recipes, adjunct sugar is already an important part and can make up as much as 30% of a recipe’s bill. Adjunct sugars can also be used in the American version, often these sugars are already a part of a double IPA recipe, but usually only make up about 10% of the bill. And, if you really want to go off script totally, you could try an English-Belgian IPA. English grains, English hops, and Belgian yeast. For extract brewers, a good place to start is either with a Belgian Golden or Tripel recipe kit, or an American IPA kit. You than would add more hops to the Belgian kit and exchange the yeast in the American IPA kit for a Belgian yeast. It might also be necessary to buy some extra extract, depending on the strength of beer you’re looking to make. Be sure to buy high-quality extract made from the right kind of malt. You might also try a steep or mini-mash with a small portion of the appropriate specialty malts to add more character. Hops: Hop selection is a wide open door on this one. You can base the varieties on your chosen base beer, or veer off on some crazy inspired journey. One thing to keep in mind; certain hop varieties pair better with certain Belgian yeast strains. There’s a possibility of either hops or the Belgian yeast muting the other or clashing in some terrible way. Learn How to Brew Like A Monk Generally speaking, if you are looking at an American IPA recipe you’d use American hop varieties; but think nuanced, think in whispers and not shouts. It is more likely to be the bold intrusive flavors of many American hops muting the Belgian profile or setting the flavors to clashing. There are plenty of hop varieties out there and I’d hazard to say, in most cases, fruity/floral/spicy is going to play a whole lot better with Belgian yeast than piney/dank/pungent. This will be less of a problem if you’re using European hops. Most European hop varieties have something of the noble hop character, which is what’s found in many Belgian Ales. Use the noble hops or other Belgian or German varieties. Overall, you’re gonna be looking to use clean bittering varieties for your early additions and subtle aroma varieties in your later additions. The Mash: The mash is also going to depend on your grain bill. If you’ve gone the American route, you can likely get away with a single infusion mash. You may want to use a lower saccharification temperature to get more body and help with head formation; 145-149°F might be a good target. If you’re using European grains, it is a good idea to do a step mash. European grains are often less modified than American malts and can benefit from the extra temperature steps. Plus, you’re looking for that pillowy head and great body of a Belgian beer, and most Belgian brewers use a step mash to get these signature characteristics. For a multi-step mash, start with a slightly thicker grist 1 quart per pound of grain. A rest at 131-137°F for 20 to 30 minutes will help get some of the longer proteins broken down. Then add enough boiling water to raise the temperature to about 145°F — this will also thin the mash. Hold for another 15 to 20 minutes. Then raise the temperature up to 155°F for 15 to 20 minutes. Mash out at 168°F and sparge. Boil: The boil should range from a standard 60 minutes up to a slightly longer 90 minute boil, if your grain bill is heavy on the pilsner malt. Add any adjunct sugar here. Hop schedules vary widely, just like any other IPA recipe. All will contain at least one bittering addition (60 to 30 minutes), one flavor addition (30 to 15 minutes), and one aroma addition (within the last 5 minutes). Most will contain multiples of some or all of these additions, and many also take advantage of dry hopping. Be sure to maintain a vigorous boil and don’t lid it completely. Also, remember with a vigorous boil, you should expect to lose anywhere from 6% to 8% of your volume per hour. Account for this, so that at the end of your boil you hit your target fermentation volume. Yeast: Yeast is the one commonality across the Belgian IPA style. No matter what the rest of your recipe looks like, the yeast should be a Belgian variety. And again, one of the biggest challenges to getting a drinkable Belgian IPA is finding compatibility between the hops and the yeast. You want a dry fermenting yeast, because you want a drier beer to accentuate the hops. This character isn’t very hard to find among Belgian yeast strains. You’ll also want to look at their ester and phenol productions. You’ll want a more neutral yeast for an American interpretation. Remember though, ester and phenol production can be managed to some extent by pitch rate and fermentation temperature, so don’t completely discount a favorite Belgian yeast just because it’s known for having a high ester/phenol production. In most cases, the more healthy yeast you pitch and the cooler the fermentation temperatures, the more neutral the yeast profile. A few examples of yeasts that would work: Dry Yeast: Safbrew Abbaye (BE-256) or Mangrove Jack’s Belgian Tripel (M31) White Labs: Abbey Ale (WLP530) or Belgian Strong Ale (WLP545) Wyeast: Belgian Ardennes (3522) or Belgian Abbey (1214) Fermentation: Oxygenate your wort once you’ve cooled it down to pitching temperatures and pitch plenty of healthy yeast. Remember, you’re going to a higher alcohol which will stress the yeast more. If this is your first go at brewing this style, I’d suggest fermenting at the cooler end of your yeasts range to get a more neutral character, especially if using an American or Double IPA recipe. If using European hops, you may try going slightly warmer, but I’d still play it cool your first time out. Packaging: Bottle or keg, and carbonate to between 2.5 and 3.5 volumes. The higher carbonation levels should be used for the Belgian-style versions. You want to make sure you have thick bottles if carbonating at these higher levels. The high ABV and hop rate of this style lends itself to some aging, though you also have to keep in mind, hop flavor and aroma will degrade over time. If you have the inclination to let it age — or you made too much — don’t worry, your Belgian IPA can age gracefully for at least 3 to 6 months, if not longer. Cheers!"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:3aba65f8-5fdd-477b-b5eb-a30f5149580c>","<urn:uuid:eeddca45-ff49-4267-a1aa-eb97f7ec02ce>"],"error":null}
{"question":"What's so special about Carcassonne's defensive system, and how has its historical significance been recognized internationally? 🏰","answer":"Carcassonne has one of the most elaborate defensive designs, featuring multiple high walls, 52 towers, and a strategic hilltop location. The fortifications extend over 3 km with two lines of walls and a castle. The defenses include features like the Le Hourd (wooden walkway for dropping items on attackers) and narrow slit windows angled for archers. The city's historical significance was recognized when it was added to the UNESCO World Heritage Sites list in 1997, particularly noting its exceptional preservation through Viollet-le-Duc's restoration work in the 19th century.","context":["If you've ever played the popular board game Carcassonne, or the video game adaptation, you may have wondered what inspired it.\nHere it is, the Cité de Carcassonne, an epic citadel in all its medieval glory, seen here from a walking bridge in the French town of the same name.\nThough there are several ways to approach the castle, my route wound up the steep front hill.\nOnce inside, the first major building you see is the Keep. If you keep gunpowder out of your mind, the walls are quite imposing.\nMost of the castle is free to access, and there are restaurants and hotels throughout. You have to pay to enter the Keep, but that also gives you access to the castle walls.\nThere's not much in the Keep, though two large courtyards give some hint of what \"safe\" must have felt like all those years ago.\nHere you can see an overview (very over, as high as I could reach, in fact) of the layout of the fortress. The upper left is the keep, the lower right the church. The barbican got chopped off a little on the left. It really got chopped off in the citadel's restoration, but more on that later.\nPass the gift shop and a small museum with the history of the castle, and you get to walk along the Keep's walls.\nA quick peek above the walkway at the walled town.\nThis much larger courtyard made it easier to imagine people living here.\nOne of the many restaurants inside the walls. I had lunch and dinner at Carcassonne and the food was good, though expensive (unsurprisingly).\nThe walls are nearly 2 miles in length. You can't completely walk around them, as a few sections haven't been fully refurbished.\nNo longer fearing invading Visigoths, Carcassonne has spread to the land around the castle.\nWhere the church now stands was once the barbican. The path on the right was the walled stairs for defenders to use to get from the castle to the fortress-outside-the-fortress.\nThere are 52 towers along the walls, some small like this (about the size of a single room per floor), others are larger.\nOne of the many hotels inside the walls. I imagine walking around at night is equal parts spooky and awesome.\nThis is look back toward the Keep and the town below. Yes, that's the walk up.\nIn one corner is the huge Basilica of St. Nazaire and St. Celse. There's something about these angles and curves.\nShakespeare in the park? No, wait, this is France. Bergerac dans le parc?\nIt is southwest France after all, so it shouldn't be surprising to see vineyards from the walls.\nGiven that it's behind massive walls, the basilica is quite massive.\nInside are European stone and glass churchworks that are pretty typical, which is to say, incredibly gorgeous.\nThe Basilica is \"only\" about 200 years old, replacing the cathedral, which was about 800 years older.\nCarcassonne has one of the most elaborate and impressive defensive designs I've ever seen. Multiple high walls, plus being on a hill. Its greatest enemies were time, and the French government, which wanted to demolish it in the mid-1800s.\nApparently the roofs were often bright colors like these, at least during certain eras and in certain areas of France (controversially, not necessarily this area).\nIn other eras, the roofs were stone or slate for better protection against attacks involving fire.\nFor this picture, I'd made a loop back round near where I started, coming in under the keep. A small garden and benches are set up in the space that was once designed to be a murder zone during defense of the keep.\nLe Hourd, a wooden walkway from which defenders could drop heavy things on the heads of attackers. The narrow slit windows were angled internally so archers could aim at the ground.\nThis was the original entrance gate during the Middle Ages. If you go clockwise along the walls during your tour, you end here.\nSun catches the buttresses of the old Basilica. As the day winds down, the air grows cold and the streets empty.\nIt was actually impressive how quickly the town emptied out. Only the areas around the remaining open restaurants had people.\nThis probably shouldn't have been surprising since the vast majority of visitors were either old or parents with stroller-bound children. Not sure why that was the mix.\nDuring the day these are stores selling candy, ice cream and souvenirs.\nThe beige stones take on the warm glow of a French sunset.\nNo one lights buildings better than the French...though I look forward to when the yellow sodium vapors get replaced by more color-neutral LEDs.\nImagine facing this, trying to attack up.\nReturning to the train station via the road bridge yielded the view I'd longed for when I arrived. It had started to rain, but it didn't matter.\nA truly incredible experience. If you're in southwest France, don't miss it.\nFor the full story behind the tour, check out Take a tour of the Citadel of Carcassonne: a real-life castle from video games, TV, and more.","France’s fabled Riviera is a wondrous place – the time-honoured playground of...\nDiscover the Fortified City of Carcassonne…\nThe historic city of Carcassonne is an excellent example of a medieval fortified town whose massive defences were constructed on walls dating from late antiquity. It is of exceptional significance by virtue of the restoration work carried out in the second half of the 19th century by Viollet-le-Duc, which had a profound influence on subsequent developments in conservation principles and practice.\nSince the pre-Roman period, a fortified settlement has existed on the hill where Carcassonne now stands. The earliest known occupation of the site dates from the 6th century BC, when a protohistoric hill fort (oppidum ) was built on this rocky spur overlooking the valley of the Aude and the ancient routes linking the Atlantic with the Mediterranean and the Iberian peninsula with the rest of Europe. In the 1st century BC, this settlement, Carcaso Volcarum Tectosagum, became the Latin Colonia Iulia Carcaso in 27 BC. During the turbulent years of the late 3rd and early 4th centuries, it was protected by the construction of a defensive wall some 1,200 m long. The fortifications, consisting of two lines of walls and a castle, which is itself surrounded by fortifications, extend over a total length of 3 km. Their line largely follows that of the Roman defences, and these are clearly visible over two-thirds of the total length. The Roman walls were strengthened by horseshoe-shaped bastions at roughly regular intervals. The masonry is in characteristic late Roman style: rubble cores faced with courses of dressed ashlars intersected by courses of bricks and built on concrete foundations. The Porte Narbonnaise on the eastern side and the Porte de l’Aude on the west are particularly elaborate defensive works.\nIt came under Visigothic rule in the 5th century and resisted repeated attempts by the Franks to capture it. The Arabs were more successful in 724, but were driven out in 759, after a siege led by Pepin the Short. The Visigothic period saw the creation of a bishopric at Carcassonne, some time in the 6th century. It is probably that a cathedral was built here, on the site of the present Romanesque cathedral, on which work began in June 1096.\nThe 12th-century count’s castle was built over the western part of the Roman walls; it was surrounded by a rectangular fortified enclosure in 1226. By the end of the 13th century the town had assumed its definitive appearance as a medieval fortress. A local revolt in 1262 caused the king to expel most of the inhabitants. He allowed them to settle on the other side of the river, where the new town that they set up was itself fortified in 1347.\nThe main body of the cathedral, dedicated to St Nazaire and St Celse, consists of a central six-bayed nave with an interrupted barrel vault and two narrow side-aisles rising to almost the same height and fully vaulted. The transverse arches of the barrel vaulting spring alternately from square columns surrounded by embedded columns and round pillars. The original Romanesque choir was replaced in the later 13th century by an imposing High Gothic structure. This is a large transept with a six-sided apse at its eastern end. It is at variance with the practice in the High Gothic cathedrals of northern France, where the choir itself was stressed; accenting the transept is more in keeping with a Romanesque tradition, which here is gothicized. Its exterior, like that of most southern French Gothic churches, has no flying buttresses, stability being assured by means of the interior vaulting. It contains some important sculpture, notably the 13th-century tomb of Bishop Radulph. The stained glass in the windows of the apse and the transept is of exceptionally high quality. Three periods can be distinguished: late 13th century, early 14th century and 16th century.\nCarcassonne is also of exceptional importance because of the lengthy restoration campaign undertaken in the latter half of the 19th century by Eugène-Emmanuel Viollet-le-Duc, one of the founders of the modern science of conservation. Source: UNESCO/CLT/WHC\nCarcassonne was added to the UNESCO list of World Heritage Sites in 1997"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"atemporal"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:b8bea32a-5b22-4b39-80ba-fbf47042ef89>","<urn:uuid:ae82683b-2f42-4058-94f3-735a3b6ad66e>"],"error":null}
{"question":"What are the key differences in how demand curves work in oligopolistic versus monopolistically competitive markets?","answer":"In oligopolistic markets, firms face a kinked demand curve due to pricing interdependence - competitors won't follow price increases but will match price decreases, making demand more elastic above the kink and inelastic below it. This is illustrated by the Coke-Pepsi example where Pepsi won't match Coke's price increase but will match its decrease. In monopolistic competition, firms face their own individual demand curves that shift based on factors like advertising success, with increases in demand leading to higher prices and quantities in the short run, though these profits attract competition that eventually reduces demand.","context":["An oligopoly market has few sellers of a product and many buyers. These sellers are large players in their industry who determine the prices or quantities. For example, credit card companies such as Visa, MasterCard, and Amex.\nIf firms collude, the total market demand is divided among the individual participants. The firms act like a cartel and decide how to divide the demand, and what price to set for the products in order to maximize profit.\nIf firms do not collude, each firm faces an individual demand curve and a market demand curve. There are several models that try to explain pricing in oligopoly markets:\nPricing Interdependence – Kink Demand Curve\nAccording to this theory, a competitor will not follow a price increase, but will cut prices in response to a price decrease.\nExample: Let us assume a town has two cola suppliers: Coke and Pepsi. This type of oligopoly is called a duopoly. Now, assume the initial equilibrium price of 1 liter Coke bottle is 100 and the quantity is 5000.\nEffect of price increase: If Coke increases its price from 100 to 105, what will Pepsi do? According to the interdependence theory, Pepsi will not increase the price and consumers will switch from Coke to Pepsi. The quantity demanded of Coke will decrease (see the elastic portion of the demand curve).\nEffect of price decrease: Instead, if Coke decreases the price to 95, then Pepsi will also decrease the price to 95. The quantity demanded of Coke will increase when the price decreases, but not by much because there is no substitution effect. Consumers do not switch from Pepsi to Coke as both are selling at the same price. To the right of the kink, the demand curve is inelastic.\nSome important points:\nFirms compete simultaneously to determine a profit-maximizing output, based on the assumption that the other firms’ output will not change. In the long run, change in price or quantity will NOT increase profits. As the number of firms in an oligopoly increase, the equilibrium point moves closer to perfect competition.\nAssume there are two firms with the output levels q1 and q2 respectively. Firm 1 chooses its output as q1 to maximize profit based on the assumption that firm 2’s output level q2 is constant in the future. Similarly, firm 2 chooses its output as q2 to maximize profits by assuming that firm 1’s output level is constant. Firms choose q1 and q2 simultaneously. Let us now look at the price and quantity numbers associated with the Cournot assumption.\nThe Nash Equilibrium in a Duopoly Market\nUnlike perfect competition, in oligopoly there is a lot of strategic interdependence between firms. Since the number of firms are few, the actions one takes affects the others.\nNash Equilibrium: A set of choices/strategies among two or more participants is called a Nash equilibrium if, holding the strategies of all other participants constant, no participant has an incentive to choose a different strategy. In an oligopoly, firms arrive at an equilibrium strategy after considering the actions of other firms (interdependence). Once they arrive at equilibrium, no firm wants to change its strategy.\nAssumptions made in Nash equilibrium:\nExample: WesCo and RifCo sell a similar product. Each company can employ a high-price strategy or a low-price strategy. The profit for each strategy is shown. What is the Nash equilibrium?\nThe four possible strategies are shown in the four boxes. For example, box 1 on the top-left corner has WesCo adopting a low price strategy and RifCo adopting a low price strategy as well. The profit for WesCo is 50 and that for RifCo it is 70. At any point in time, the companies can be in only one box. It is not possible for WesCo to adopt a low price strategy with profit of 50 (box 1) and RifCo to adopt a high price strategy with profit of 0 (box 2).\nNo matter where the companies start, they will end up in box 4 (lower left box).\nLet’s start with box 1. The total profit of WesCo and RifCo is 120. They are both selling the products at a lower price. It is in WesCo’s best interest to increase prices, and their profits jump from 50 to 300 in box 4. It is in RifCo’s best interest as well if WesCo increases the price, as RifCo can also increase the price. RifCo’s profit jumps from 70 to 350. The combined profit of box 4 now is 650.\nThe combined profits are the highest in box 3, which is 800. Both the companies are charging high prices. Box 3 is in WesCo’s best interest as it earns its maximum profit of 500, but it’s possible only if RifCo also charges the high price. But RifCo is not happy here and would lower the prices to increase its profit from 300 (box 3) to 350 (box 4).\nWhen RifCo lowers its price to make a profit of 350 in box 4, WesCo’s profit falls from 500 to 300. The Nash equilibrium position in box 4 is what they arrive at finally.\nCan both companies be better if they collude? Yes, if both the companies agree to collude and charge high prices. If WesCo and RifCo agree to split the maximum profit of 800 equally, then each company makes a profit of 400, which is better than the Nash equilibrium profit of 300 and 350 profit respectively. Companies are said to form a cartel when they engage in collusive agreements openly.\nFactors that affect the chances of successful collusion:\nThere is one dominant large firm and many small firms. The large firm sets the price and has the first mover advantage.\nIn the Stackelberg model, the decision-making happens sequentially (recall it happens simultaneously in the Cournot assumption). The leader firm chooses the output first and then the follower firm chooses its output.\nThe curriculum discusses the supply analysis for only one type of oligopoly – the dominant firm oligopoly.\nExample: Say we have an oligopoly market where one firm has a significantly lower cost of production than its competitors and has a 40% market share. A dominant or leader firm is a firm with at least 40 % market share, greater capacity, lower cost structure, and is price maker. A follower firm is a small firm that is a price taker – i.e. it accepts the price set by the leader firm. Let us say there are five such firms in this market.\nThe graph below shows the quantity that will be supplied and the price charged by the market leader, as well as by the other firms.\nInterpretation of the graph:\nThere is no single optimum price and output model that works for all oligopoly market situations because of different strategies and pricing methods. The process for determining the optimal price for a few methods is listed below:\nLong-run economic profits are possible, but empirical evidence suggests that over time the market share of the dominant firm declines.","Suppose that, due to a successful advertising campaign, a monopolistic competitor experiences an increase in demand for its product. How will that affect the price it charges and the quantity it supplies?\nContinuing with the scenario outlined in question 1, in the long run, the positive economic profits earned by the monopolistic competitor will attract a response either from existing firms in the industry or firms outside. As those firms capture the original firm’s profit, what will happen to the original firm’s profit-maximizing price and output levels?\nWhat is the relationship between product differentiation and monopolistic competition?\nHow is the perceived demand curve for a monopolistically competitive firm different from the perceived demand curve for a monopoly or a perfectly competitive firm?\nHow does a monopolistic competitor choose its profit-maximizing quantity of output and price?\nHow can a monopolistic competitor tell whether the price it is charging will cause the firm to earn profits or experience losses?\nIf the firms in a monopolistically competitive market are earning economic profits or losses in the short run, would you expect them to continue doing so in the long run? Why?\nIs a monopolistically competitive firm productively efficient? Is it allocatively efficient? Why or why not?\nCritical Thinking Questions\nAside from advertising, how can monopolistically competitive firms increase demand for their products?\nMake a case for why monopolistically competitive industries never reach long-run equilibrium.\nWould you rather have efficiency or variety? That is, one opportunity cost of the variety of products we have is that each product costs more per unit than if there were only one kind of product of a given type, like shoes. Perhaps a better question is, “What is the right amount of variety? Can there be too many varieties of shoes, for example?”\nAndrea’s Day Spa began to offer a relaxing aromatherapy treatment. The firm asks you how much to charge to maximize profits. The demand curve for the treatments is given by the first two columns in Table below; its total costs are given in the third column. For each level of output, calculate total revenue, marginal revenue, average cost, and marginal cost. What is the profit-maximizing level of output for the treatments and how much will the firm earn in profits?\nAn increase in demand will manifest itself as a rightward shift in the demand curve, and a rightward shift in marginal revenue. The shift in marginal revenue will cause a movement up the marginal cost curve to the new intersection between \\(MR\\) and \\(MC\\) at a higher level of output. The new price can be read by drawing a line up from the new output level to the new demand curve, and then over to the vertical axis. The new price should be higher. The increase in quantity will cause a movement along the average cost curve to a possibly higher level of average cost. The price, though, will increase more, causing an increase in total profits.\nAs long as the original firm is earning positive economic profits, other firms will respond in ways that take away the original firm’s profits. This will manifest itself as a decrease in demand for the original firm’s product, a decrease in the firm’s profit-maximizing price and a decrease in the firm’s profit-maximizing level of output, essentially unwinding the process described in the answer to question 1. In the long-run equilibrium, all firms in monopolistically competitive markets will earn zero economic profits.\nConsider the curve shown in the figure below, which shows the market demand, marginal cost, and marginal revenue curve for firms in an oligopolistic industry. In this example, we assume firms have zero fixed costs.\n- Suppose the firms collude to form a cartel. What price will the cartel charge? What quantity will the cartel supply? How much profit will the cartel earn?\n- Suppose now that the cartel breaks up and the oligopolistic firms compete as vigorously as possible by cutting the price and increasing sales. What will the industry quantity and price be? What will the collective profits be of all firms in the industry?\n- Compare the equilibrium price, quantity, and profit for the cartel and cutthroat competition outcomes.\nSometimes oligopolies in the same industry are very different in size. Suppose we have a duopoly where one firm (Firm A) is large and the other firm (Firm B) is small, as shown in the prisoner’s dilemma box in Table below.\n|Firm B colludes with Firm A||Firm B cheats by selling more output|\n|Firm A colludes with Firm B||A gets $1,000, B gets $100||A gets $800, B gets $200|\n|Firm A cheats by selling more output||A gets $1,050, B gets $50||A gets $500, B gets $20|\nAssuming that the payoffs are known to both firms, what is the likely outcome in this case?\nWill the firms in an oligopoly act more like a monopoly or more like competitors? Briefly explain.\nDoes each individual in a prisoner’s dilemma benefit more from cooperation or from pursuing self-interest? Explain briefly.\nWhat stops oligopolists from acting together as a monopolist and earning the highest possible level of profits?\nCritical Thinking Questions\nWould you expect the kinked demand curve to be more extreme (like a right angle) or less extreme (like a normal demand curve) if each firm in the cartel produces a near-identical product like OPEC and petroleum? What if each firm produces a somewhat different product? Explain your reasoning.\nWhen OPEC raised the price of oil dramatically in the mid-1970s, experts said it was unlikely that the cartel could stay together over the long term—that the incentives for individual members to cheat would become too strong. More than forty years later, OPEC still exists. Why do you think OPEC has been able to beat the odds and continue to collude? Hint: You may wish to consider non-economic reasons.\nMary and Raj are the only two growers who provide organically grown corn to a local grocery store. They know that if they cooperated and produced less corn, they could raise the price of the corn. If they work independently, they will each earn \\(\\$100\\). If they decide to work together and both lower their output, they can each earn \\(\\$150\\). If one person lowers output and the other does not, the person who lowers output will earn \\(\\$0\\) and the other person will capture the entire market and will earn \\(\\$200\\). Table below represents the choices available to Mary and Raj. What is the best choice for Raj if he is sure that Mary will cooperate? If Mary thinks Raj will cheat, what should Mary do and why? What is the prisoner’s dilemma result? What is the preferred choice if they could ensure cooperation? A = Work independently; B = Cooperate and Lower Output. (Each results entry lists Raj’s earnings first, and Mary's earnings second.)\n|Raj||A||($100, $100)||($200, $0)|\n|B||($0, $200)||($150, $150)|\nJane and Bill are apprehended for a bank robbery. They are taken into separate rooms and questioned by the police about their involvement in the crime. The police tell them each that if they confess and turn the other person in, they will receive a lighter sentence. If they both confess, they will be each be sentenced to \\(30\\) years. If neither confesses, they will each receive a \\(20\\)-year sentence. If only one confesses, the confessor will receive \\(15\\) years and the one who stayed silent will receive \\(35\\) years. Table below represents the choices available to Jane and Bill. If Jane trusts Bill to stay silent, what should she do? If Jane thinks that Bill will confess, what should she do? Does Jane have a dominant strategy? Does Bill have a dominant strategy? A = Confess; B = Stay Silent. (Each results entry lists Jane’s sentence first (in years), and Bill's sentence second.)\n|Bill||A||(30, 30)||(15, 35)|\n|B||(35, 15)||(20, 20)|\n- If the firms form a cartel, they will act like a monopoly, choosing the quantity of output where \\(MR = MC\\). Drawing a line from the monopoly quantity up to the demand curve shows the monopoly price. Assuming that fixed costs are zero, and with an understanding of cost and profit, we can infer that when the marginal cost curve is horizontal, average cost is the same as marginal cost. Thus, the cartel will earn positive economic profits equal to the area of the rectangle, with a base equal to the monopoly quantity and a height equal to the difference between price (on the demand above the monopoly quantity) and average cost, as shown in the following figure.\n- The firms will expand output and cut price as long as there are profits remaining. The long-run equilibrium will occur at the point where average cost equals demand. As a result, the oligopoly will earn zero economic profits due to “cutthroat competition,” as shown in the next figure.\n- \\(Pc > Pcc\\). \\(Qc < Qcc\\). Profit for the cartel is positive and large. Profit for cutthroat competition is zero.\nFirm B reasons that if it cheats and Firm A does not notice, it will double its money. Since Firm A’s profits will decline substantially, however, it is likely that Firm A will notice and if so, Firm A will cheat also, with the result that Firm B will lose \\(90\\%\\) of what it gained by cheating. Firm A will reason that Firm B is unlikely to risk cheating. If neither firm cheats, Firm A earns \\(\\$1000\\). If Firm A cheats, assuming Firm B does not cheat, A can boost its profits only a little, since Firm B is so small. If both firms cheat, then Firm A loses at least \\(50\\%\\) of what it could have earned. The possibility of a small gain (\\(\\$50\\)) is probably not enough to induce Firm A to cheat, so in this case it is likely that both firms will collude."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"atemporal"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:fbed8c28-867f-448d-8b2e-be5b04c4d2e0>","<urn:uuid:87a128fe-da21-41a7-bbfb-6bffc88136ac>"],"error":null}
{"question":"I am learning about differences between American and British English. Why they spell some words different, like 'color' vs 'colour'? Please explain origin.","answer":"The spelling differences between American and British English largely came from Noah Webster's deliberate efforts to standardize and simplify American spelling. Webster specifically removed what he considered extraneous vowels, changing 'colour' to 'color' and 'favour' to 'favor'. He also changed word endings, transforming 'theatre' to 'theater' and 'centre' to 'center'. Webster viewed British English as corrupted by the English aristocracy and worked to create distinct American spellings, though some of his proposed changes (like 'croud', 'hed', 'giv', 'meen') did not survive.","context":["|On-line resources from the\nAmerican Studies Resources Centre at LJMU\nOr whose language is it anyway?\n|A porter in a\nBritish hotel comes upon an American tourist impatiently\njabbing at the button for the lift.\n\"Sir, the lift will be here in a moment.\"\n\"Lift? Lift?\" replies the American. \"Oh, you mean the elevator.\"\n\"No sir, here we call it a lift.\"\n\"Well, as it was invented in the United States, its called an elevator.\"\n\"Yes sir, but as the language was invented here, its called a lift.\"\nfrom The Readers Digest\nLinda Berube, currently a Fulbright scholar in Norwich, addresses the question of who is responsible for the world-wide dominance of the English language: the Americans or the British.\n\"This treatise is written with such elegance as the subject admits, tho not without some mixture of the American dialect, a tract[i.e., trace] of corruption to which every language widely diffused must always be exposed.\"\nTruly, the Yanks have been taking a beating on the language front for some time now. For H.L. Mencken, Samuel Johnsons observation sums up the \"tone [of] English criticism\" of the \"American dialect\" from colonial days right up until the time of Menckens own ground-breaking publication, The American Language, in the first half of this century. It should come as no surprise to Mencken that the \"tone\" has persisted, and will persist in all likelihood into the next century. Indeed, in the course of giving talks on the subject of American English to various British groups, I encounter a range of reaction, from good-natured teasing (\"what do you call that language you speak over there?\") to downright hostility. On a broader level, American English still warrants the attention of journalists, politicians, and scholars alike in the UK, not always in a kindly or objective way. Often it is regarded as an aberrant version of English. Most Americans would object to this latter classification, at least given the postwar global influence of American culture and vocabulary. Still, the rather vociferously-expressed comment from one audience member at a recent talk - \"We gave you a perfectly good language. Why cant you speak proper English?\" - seems not far removed from Johnsons tone in spirit, however remote in time.\nNevertheless, it has to be admitted, as Mencken and other scholars do, that a certain amount of this hostility Americans called down upon themselves, thanks to statements made by the likes of John Adams and Noah Webster. Adams was just as capable of adopting a superior tone as Johnson:\nOne cannot help but hear the slap of a gauntlet thrown down here. There was even some talk of an American Academy, along the lines of the Academie Française, charged with the task of preserving the purity of the language..\nThen there was Noah Webster, who regarded the form of English spoken in the British Isles as having been corrupted by the English aristocracy. Webster worked with dogged determination to standardise and simplify the spelling of American English. He excised extraneous vowels: colour/color; favour, favor (although he resisted this change for quite a while in the face of Johnsons example). And he transposed letters, most notably the final -re: theatre/theater; centre/center. Some of his changes remain an integral part of American spelling, where others have failed to survive (croud, hed, giv, meen etc.).\nAnd so the stand-off has continued, and despite the bickering between the two major factions, an international language has been born. And, of course, both sides would lay claim to its current world dominance. Exactly whose language is it, this current lingua franca?\nLong before the United States became a superpower, it could lay claim to being a \"land of light and freedom,\" there was the British Empire which set its cultural tone on many parts of the world. Earlier still, the British Isles themselves had been subject to invasion by Vikings and Normans/ But, as soon as the English experienced their first taste of relative freedom from foreign dominance, British English underwent a growth surge, most notably perhaps in the period immediately preceding the colonisation of America,. In some ways, the rapid changes in the language represent the movement toward a more unified English identity. If the Middle English of Chaucer in the late 1300s is compared to Shakespearean English and then again to what begins to be Modern English in the late 1700s, the language is virtually transformed in a matter of only 400 years. Current differences between British and American English pale in comparison: inflection is lost; verb conjugations become more uniform; thousands of new words flood the language, some 2000 alone attributed to Shakespeare. These are only some of the more prominent changes, as on many levels vocabulary, pronunciation, spelling and grammatical structure shift dramatically.\nAt about the time that England was experiencing this linguistic awakening, the spirit of exploration began to take hold. Of course, this exploration and colonization brought English to the Americas, to the southern hemisphere, to Africa, and to South Asia. In fact, India is exceeded only by the United States and the United Kingdom in numbers of English speakers.\nThe role that English literature played, both in its contribution to vocabulary and to its contribution to world literature, cannot be overemphasized when considering the importance of the language. The English Renaissance, Shakespeare, and the publication of the King James Bible particularly assisted the expansion and lent prestige to the language. And though the United States can lay claim to a literary tradition of its own, that of the British Isles remains unparalleled.\nYet, even if the birthplace of the language and the importance of cultural and social contributions are considered, its usefulness as a form of international communication depended on the number of English speakers. True enough, the United Kingdom alone has been in the process of producing these numbers. According to David Crystal, \"between the end of the reign of Elizabeth I (1588) and the beginning of the reign of Elizabeth II (1952) this figure [of five to seven million living within the British Isles] increased almost fifty-fold.\" to include emigrants and descendants. This is an impressive increase, but Americans can justifiably point out that the English language was not much used abroad before its introduction in North America. Only by turning their attention outward could the English make their full impression on the world culturally, linguistically, and politically. Perhaps Bill Bryson puts it a bit harshly when he states that \"...without Americas contribution English today would enjoy a global importance on a par with Portuguese,\" (would that make India the UKs Brazil?) but it seems reasonable that the almost exponential population growth of the United States, along with its own brand of English, coupled with the ever-expanding nationalistic and cultural activities of the English, were what gave the language its current status as a means of international communication.\nAnd what of the English exported to America? It has often been said that the English the colonists spoke was virtually Shakespearean or, more generally, Elizabethan. But, as J. L. Dillard points out, it would be difficult to define what exactly Shakespearean English is, considering Shakespeares own variation in spelling and vocabulary. That it is equally difficult to describe Elizabethan English is evidenced by the varieties of regional dialect which were even more firmly entrenched by the 17th century than they are currently. Actually, the English did not give America \"a perfectly good language,\" but rather a number of good languages or at least variations on a language, and those in a period of rather intense transition. Instead of the \"two streams\" or two separate languages that Mencken originally envisaged British and American English to be, it would be more accurate to consider Modern British English to be one result of that period of linguistic transition, and American English to be another.\nIn fact English was not immediately dominant in the colonies: other languages, such as Dutch and French, figured prominently. According to Dillard, English was a virtual \"interloper\" in some regions, and \"had to adapt linguistically.\" At one point during the colonial period, there were 18 different languages spoken in the Hudson River Valley alone. Scholars have frequently suggested that the later waves of immigration to the United States explain the disparity in vocabulary between British and American English. But it is plainly not the whole story. Nevertheless, with other languages along with the Pidgin English common among Native Americans, slaves, and sailors undoubtedly contributed toward making American English as a different branch from, and not a subset of, British English.\nAlthough the United States is not, geographically-speaking, the colonial power that England was, it had some direct role before this century in exporting its own brand of English. Dillard, citing Creole scholars, Berry and Hancock, maintains that, at least with the founding of Liberia by ex-slave repatriation, \"it seems inescapable that, in a real sense, a variety of English that was in some sense American was transported overseas before the period of British domination had ended.\" Of course, it is in the current century that American English has made its mark internationally. Marckwardt and Dillard highlight the efforts of such institutions and programs as the Fulbright Commission, the United States Information Agency, and the Peace Corps, as exporters of American culture and English. Technology has virtually assured the dominance of American English on a scientific as well as a popular level. With a 250 million-strong block of first language English speakers, and the rise of the United States as a military, industrial, and political superpower after World War II, Americans can certainly claim a prime responsibility for boosting English to world prominence.\nThe above is just an outline of how the two countries have ensured the position of English as the international language. There have been challengers to the title, none successful. As many gloom and doomsayers as there are predicting the demise of English as the predominant language in the United States, and with as much resistance to English as there is expressed in individual countries, no change in status seems imminent.\nSo, \"Whose language is it?\" appears to be a question of no pertinence. Crystal would give credit to the United States and its influence in the 20th century, \"much to the discomfiture of some in Britain who find the loss of historical linguistic preeminence unpalatable.\" But, the world dominance of the United States rests partially on what the British had achieved in the 19th century. With as many theories as there have been on the divergence of the \"two streams of English,\" it is still virtually impossible to consider them separately or even sequentially. It is true that the use of English predates the European settlement of America, but it has gained impetus concurrently with the rise of the United States to international status, as well as with the rise of the United Kingdom to that same status.\nBaugh, Albert C. and Thomas Cable. A History of the English Language. Routledge & Kegan Paul, 1978.\nBerry, Jack. English loan words and adoptions in Sierra Leone Krio. In Creole Language Studies\nBryson, Bill. Made in America. Martin Secker, 1995.\n---. Mother Tongue: The English Language. Penguin, 1990.\nCrystal, David. The Cambridge Encyclopedia of the English Language. Cambridge University Press, 1995.\nDillard, J.L. All-American English. Random House, 1975.\n---. A History of American English. Longman, 1992.\n---. Toward A Social History of American English. Moulton, 1985.\nKachru, Braj B. The Other Tongue: English across cultures. University of Illinois Press, 1982.\nMarckwardt, Albert H., revised by Dillard, J.L. American English. Oxford University Press, 1980\nMencken, Henry Louis. The American Language: An inquiry into the development of English in the United States. Knopf, 1919. Fourth Edition and Two Supplements, with annotations and new material by Raven I. McDavid Jr., 1986.\nPyles, Thomas. The Origins and Development of the English Language. Fourth edition. HB Coll Pubs, 1993.\nSpeck, W.A. British America, 1607-1763. BAAS, 1985.\nAmerican Studies Today Online is published by\nAmerican Studies Resources Centre, Aldham Robarts Library, Liverpool John Moores University, Maryland Street, Liverpool L1 9DE, United Kingdom\nTel 0151-231 3241\nThe views expressed are those of the contributors, and not necessarily those of the Centre or the College.\n© 1996, City of Liverpool College, Liverpool John MooresUniversity and the Contributors.\nArticles in this journal may be freely reproduced for use insubscribing institutions only, provided that the source isacknowledged."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:57375dcf-0fb3-4f44-8fdc-2ea50cfb631d>"],"error":null}
{"question":"What are the different body responses to stress - physical symptoms vs fight/flight response?","answer":"Both physical symptoms and fight/flight responses occur when under stress. Physical symptoms include increased heart rate, rising blood pressure, muscle tension, upset stomach, lack of sexual desire, and changes in appetite. The fight/flight response involves the release of hormones like adrenalin and cortisol through the sympathetic nervous system, causing increased heart rate, blood pressure and breathing rate. It typically takes 20-60 minutes for the body to return to normal after the fight/flight response is triggered. While occasional stress causes temporary symptoms, chronic stress can lead to more serious health problems like heart disease, gastrointestinal issues, and strokes.","context":["How Does Stress Affect The Body: Symptoms And Solutions\nUpdated August 27, 2020\nMedically Reviewed By: Lori Jones, LMHC\nAre you exhausted all the time? Do you have a lot of muscle tension and pain? Is your head or stomach bothering you? It could be stress. There is a long list of symptoms that falls under the question, “How does stress affect the body?” And, learning how to identify the symptoms can help you find the right solution.\nStress levels have been on the rise in Americans over recent years. It’s impacting people of all ages and spans a wide range of worries and concerns.\nThe Impact Of Chronic Stress\nEveryday stress can have a negative impact on multiple areas of your life. However, when the stressful situation passes, you may find that things return to normal even if you didn’t do anything to address your stress. This isn’t the healthiest way to get through stress, but it happens this way for some people.\nHowever, if you’re experiencing chronic stress, it’s not going to just go away. It may not be tied to a specific situation in your life. Instead, it might be the result of poor habits or not knowing how to deal with past trauma. It will not just go away if left untreated.\nThe Effect Of Stress On The Body\nStress can wreak havoc on your body if it’s left unchecked. Not only does occasional stress show up in your body, but chronic stress can also have long-term negative consequences for your physical health. When you are feeling stressed, you may experience:\n- Increased heart rate\n- Rising blood pressure\n- Muscle tension\n- Upset stomach\n- Lack of sexual desire\n- Change in appetite\nAnd these are just a few of the symptoms that you may experience. If you suffer from chronic stress, the symptoms above can start to turn into more serious health consequences.\nChronic stress can lead to health problems such as heart disease, high blood pressure, gastrointestinal problems, heart attack, and strokes, among others. These are clear indicators that allowing chronic stress to continue in your life can be detrimental to your physical health and well-being.\nHow Stress Affects Mental Health\nStress also impacts your mental health and wellness. It can lead to you experiencing many different negatives and difficult emotions such as sadness, anger, frustration, and fear.\nSome of the mental health symptoms that you may notice in your life from stress include:\n- Lack of motivation\n- Irritability and anger\n- Lack of concentration and focus\nThese are serious symptoms that should not be taken lightly. If you experience chronic stress, you may begin to think that these symptoms are just a normal part of life. But, they’re not. All of these symptoms can grow into more serious problems if you don’t work on addressing them.\nHow Stress Affects Behavior\nStress can also impact your behavior. If you look at the symptoms listed above under physical and mental health, it can be easier to understand how stress changes your behavior. If you’re living under constant overwhelm and anxiety and experiencing things like frequent headaches or stomach aches, it can be easy to lose your temper with your loved ones, for example. Here are some of the other behavioral changes that you may experience in your life as a result of stress:\n- Angry outbursts\n- Eating too much or not enough\n- Substance use or abuse\n- Social withdrawal\nThese behaviors can have a negative spiral effect on your life. For example, as your withdrawal from friends and family because of stress, you may find that you struggle even more to cope with stress in your life. This can lead to additional problems which keep you away from a social activity even more. This is why it’s important to learn to recognize and healthily address your stress.\nStress Management Tips To Overcome Chronic Stress\nThankfully there are many things that you can do to address your chronic stress and learn to overcome it. This doesn’t mean that you’ll never experience stress again. Instead, it means that when you do go through stressful situations, you’ll have tips and strategies that you can use to relieve stress and handle it healthily.\nSome of the stress management solutions you may benefit from include:\nLearn to identify your stress triggers\nWhen you start to feel stressed, it can be helpful to take time to identify where the feelings are coming from. This allows you to begin investigating what you can do to make to address it.\nWhile there will be some things causing you to stress that you can’t do anything about, there will be some things that you can address. For example, if a family member’s behavior is causing you to feel stressed, you probably aren’t going to be able to control how they are behaving. But you may be able to establish boundaries in your life that stop the other person’s behavior from having as large of a negative consequence on you.\nThere will be some things that you find are short term stressors. But there also might be habits that you identify that are causing you unnecessary stress. When you learn where the stress is coming from, you can start to take your first steps to address or removing it.\nPractice Deep Breathing\nWhen you’re starting to feel the stress and tension build up within your body, deep breathing can help to break up some of the physical symptoms that you’re experiencing. For example, you may notice that you start to breathe faster as your frustration grows. This can cause your heart to race, as well. And, as your heart beats faster, your blood pressure rises. These physical symptoms can continue to build and even lead to things like full-blown panic attacks.\nDeep breathing can help to stop your physical symptoms from progressing. As you start taking slow, deep breaths in and out, you may notice that it feels like your blood pressure is lowering, and your heart rate is returning to normal.\nYou may also find that deep breathing can help you to slow your thoughts. Your mind will be forced to temporarily shift from your stress and worry to the breathing technique that you’re using. This can help you to regain mental clarity and look for solutions to the stressful situation or problem that you’re facing.\nThere are multiple types of breathing techniques that you can use, so practice a few of them to find what works best for you. It can also help to practice them when you’re not under stress, so when you find your stress starting to build, you will know how to put the breathing exercise to use without too much thought.\nNot getting enough sleep can make it even harder to deal with stress. You may find that you struggle to be patient with others, and you cannot think clearly to look for solutions. If you’re having problems falling asleep or staying asleep due to stress, it’s an important symptom to address.\nMany different things may help improve sleep troubles. A few that you could try include:\n- Keeping a strict sleep schedule\n- Cutting out caffeine\n- Not exercising too close to bedtime.\n- Sleeping in a dark, cool room\n- Using white noise\nHowever, if you’re continuing to struggle, don’t be afraid to talk with your doctor to explore additional options.\nGet More Physical Activity\nPhysical activity and exercise can help you release tension that has built up from chronic stress. It also releases chemicals in your brain that work to boost your mood. But these chemicals also act as natural pain killers, which can help reduce some of the physical symptoms you’re experiencing.\nThere are other ways that physical activity and exercise can help with stress. You may find that you sleep better when you exercise. And, you may experience a boost in your self-esteem as well.\nThe Anxiety and Depression Association of America shares that you may start to experience these positive mental boosts after just five minutes of physical activity. So, if you’re feeling stressed, you don’t need to feel like you have to get in a full workout. Simply getting moving for a few minutes can start to help.\nTalk To Someone\nHaving a trusted person to turn to for support can help when you’re going through stressful situations or experiencing chronic stress. This could be a friend or family member. It could also be a support group. For example, if you’re under stress as a result of losing a loved one, you may benefit from connecting in a group for others experiencing grief from losing someone.\nIf you don’t have anyone to turn to or could use additional support in handling your stress, a licensed therapist is an effective option to consider. Not only can they listen as you talk through the stress in your life, but they also have education on how to help you overcome it. A therapist, like those at BetterHelp, can assist you in finding stress-relieving strategies that work for your specific situation.\nPrevious ArticleHow Stress Can Lead To Emotional Breakdowns And What You Can Do To Avoid It\nNext ArticleAre You Under Too Much Stress? Symptoms, Treatment And Tips\nLearn MoreWhat Is Online Therapy? About Online Counseling\nAbuse ADHD Adolescence Alzheimer's Ambition Anger Anxiety Attachment Attraction Behavior Bipolar Body Dysmorphic Disorder Body Language Bullying Careers Chat Childhood Counseling Dating Defense Mechanisms Dementia Depression Domestic Violence Eating Disorders Family Friendship General Grief Guilt Happiness How To Huntington's Disease Impulse Control Disorder Intimacy Loneliness Love Marriage Medication Memory Menopause MidLife Crisis Mindfulness Monogamy Morality Motivation Neuroticism Optimism Panic Attacks Paranoia Parenting Personality Personality Disorders Persuasion Pessimism Pheromones Phobias Pornography Procrastination Psychiatry Psychologists Psychopathy Psychosis Psychotherapy PTSD Punishment Rejection Relationships Resilience Schizophrenia Self Esteem Sleep Sociopathy Stage Fright Stereotypes Stress Success Stories Synesthesia Teamwork Teenagers Temperament Tests Therapy Time Management Trauma Visualization Willpower Wisdom Worry\nFeeling Overwhelmed? Learn These Stress Management Strategies How To Stop Stressing: 7 Tips To Find Balance And Relax How Stress Can Lead To Emotional Breakdowns And What You Can Do To Avoid It Are You Under Too Much Stress? Symptoms, Treatment And Tips 7 Tips On How To Handle Stressful Situations Stress Management That Works: How To Be Less Stressed","Flight or Fight: The Modern Stress Response\nOur lives are constructed with ease in mind. Modern conveniences minimise the effort we need to perform daily tasks and technological advances ensure that life should only get easier with each new year. Yet we work much longer hours, often forfeiting the extra time that the modern conveniences we work to pay for provide. All this extra desk time could be paying its toll, as statistically we are under more stress than ever with 526,000 workers suffering from work related stress, depression or anxiety (new or long-standing) in 2016/17.\nAnatomically we are not designed to sit at a desk for 8-10 hours every day, with additional seated time commuting to and from work. Over time we are seriously constricting our psoas muscle which has bigger implications that you might initially think. And for many this may be the first time that you’ve even heard of the psoas. So what is it and why is it so important?\nWhat Is The Psoas Muscle and Where Will You Find It?\nThe psoas is a rope-like muscle rooted deep in the stomach, stretching from the legs to the spinal column. In addition to connecting the legs to the spinal column the psoas is also connected to the diaphragm which modulates your breathing.\nThe psoas often referred to as the ‘fight or flight’ muscle due to its intrinsic connection to the body’s emotions. When the body is under duress (be it stress, anxiety or trauma), the psoas contracts. Pulling the body into a protective shape (think of a foetal shape, with knees bent and in toward the chest). Sitting for extended periods of time shortens the psoas and in its shortened state the psoas confuses the body into thinking it is under duress, triggering a ‘flight or fight’ response from the body.\nWhat happens during a Fight or Flight Response?\nThe term “fight or flight” describes a mechanism in the body that enables humans and animals to mobilise a lot of energy rapidly in order to cope with threats to survival. In this state the body releases hormones via the sympathetic nervous system such as adrenalin and cortisol, that cause changes to occur throughout the body. Changes include; an increase in heart rate, blood pressure and breathing rate. Typically it can take between 20 and 60 minutes for the body to normalise after the threat as gone.\nThis is all fine when the body is presented with real danger but the ‘fight or flight’ response is often triggered in situations where it isn’t appropriate such as heavy traffic or during a stressful day at work. These aren’t isolated events either, chances are if you’re suffering from work related stress its a daily or weekly occurrence. In normal circumstances the body will regulate itself following a trigger situation and return to normal function, but in our times of chronic stress, this isn’t allowed to happen, the result of which is long term and repeated damage to the body.\nHow to manage your response to stress\nOne of the ways the body manages stress is via the vagus nerve. Often referred to as the ‘wandering nerve’, the vagus nerve is a long rambling bundle of motor and sensory fibres that link the brain stem to most of the bodies vital organs, including; the heart, lungs, intestine, liver, spleen, gall bladder, ureter, kidney, female fertility organs, ears and tongue. Responsible for powering up the parasympathetic nervous system (the body’s involuntary nerve centre), the vagus nerve helps to regulate many of the body’s functions, from maintaining a healthy blood pressure to a constant heart rate.\nIf you have ever been told to trust your gut instinct you are essentially being told to trust your vagus nerve. The management and processing of emotions between the heart, brain and gut happens via the vagal nerve, which is why we have a strong gut reaction to intense mental and emotional states.\nHowever, poor vagal tone can lead to difficulties managing emotions in addition to responding appropriately to stress (among other things). Common triggers that impact negatively on the health of the vagus nerve include; cafeteria diets (such as high fat, high carb junk foods), diabetes, alcoholism, upper respiratory viral infections, stress, fatigue, anxiety and even poor posture.\nYoga for Stress Management\nThe good news however, is that yoga can help to both stretch your psoas muscle and tone your vagus nerve, working toward harmonic personal stress management. Warrior sequences incorporating crescent lunge all help to elongate the psoas undoing the damage of sitting for extended periods.\nLook at sequences that incorporate:\n- Virabhadrasana I (Warrior I)\n- Virabhadrasana II (Warrior II)\n- Crescent Lunge\n- Anjaneyasana (low lunge)\n- Parsvakonasana (side angle pose)\n- Paripurna Navasana (full boat pose)\n- Wind relieving pose (laying on your back, knees bent in to chest)\n- Sukhasana (Easy pose: sitting cross legged with a straight back)\nYou may be surprised to know that practicing yogic breathing or diaphragmatic breathing can help to tone/stimulate your vagus nerve.\n- Inhale for the count of 4 and\n- Exhale for the count of 6\nTry to keep your exhalation longer than your inhalation. As you inhale you activate you sympathetic response (the heart rate accelerates, and the vagus nerve is suppressed), as you exhale you activate the parasympathetic response (slowing the heart rate and activating the vagus nerve). Lengthening the exhalation activates the vagus nerve for longer, ultimately toning the nerve. Vagal tone refers to the variability between the heart rate on the inhale and the exhale. The higher your vagal tone, the greater the heart rate variability, which means that your body will find it easier to switch from fight or flight mode to rest and digest mode, reducing the impact of stress."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:1fe21db8-8096-462d-a9b3-85cbac331785>","<urn:uuid:f876c400-439b-4a5c-ab51-b37aa866cf7d>"],"error":null}
{"question":"What are the key differences between sidemount stage bottle management and PRISM 2 rebreather gas management in terms of their cylinder configuration and breathing systems?","answer":"Sidemount stage bottle management and PRISM 2 rebreather systems have distinct configurations. In sidemount, stages are managed using a leash system where bottles are attached via bolt snaps and rings, placed underneath the primary sidemount bottle on the left side, creating a streamlined profile. The PRISM 2, however, uses twin supply cylinders (oxygen and diluent) mounted vertically on a backplate between which sits a scrubber canister. While sidemount involves traditional open circuit SCUBA breathing where gas is exhausted into the water, the PRISM 2 is a closed circuit system that recycles the exhaled breath through a scrubber to remove CO2, allowing the diver to rebreathe the gas.","context":["Configuring Multiple Stages When Sidemounting\nDive Rite Ambassador and sidemount expert, James Toland, shows how he configures a leash for carrying multiple stages when sidemounting.by James Toland\nWhen sidemounting, one of the tools I like to use for carrying multiple stages is a stage bottle leash. It allows you to organize the limited amount of space you have available. There are several versions of the leash. What I find to work for me consists of a loop of rope, short piece of hose, a bolt snap, and a 1-inch ring. Cut the hose to whatever size you like. I use two different sizes, 3-inches and about 5-inches.\nThe shorter one is for two bottles or less the longer is for four bottles. Put the hose on a length of rope; tie the loop using a double fisherman’s knot. Leave enough slack to loop the ring and the bolt snap at each end.\nOnce these items are in place you want it to be kind of stiff so that it creates a handle in between the ring and bolt snap. Otherwise the ring and snap would slide back and forth. This helps keep the tanks together in a close, uniform way.\nDepending on where you mount the leash and what is comfortable to you determines the length of the leash. On my TransPac, I have a D-ring on the small of my back which is ideal for mounting reels and my leash.\nThis prevents the bottles from hanging too low between your legs or dragging on the floor of the cave. It puts the bottles in my slip stream for less drag. The bottles sit on top of the butt pad and this keeps my rails free for my primary sidemount tanks. You could add a ring to any TransPac by using a bail end with a ring of choice, which you then bolt to the TransPac through the top grommet of the lower back area. Ideal while scootering, but it is manageable to swim two on the leash while wearing one in place.\nPreferably I place my stage underneath my sidemount bottle on the left side as you would back mounting. This creates a more streamlined profile and allows me to see the pressure gauge without removing the bottle or stopping to check the gauge. Attach the stages to the leash by using the top bolt snap on the stage and clip it to the ring. Be sure to secure the bottom bolt snap on the stage under your hose straps if only towing one bottle so it’s not dangling and potentially catches a line. When using two or more bottles in tow, snap the bottom bolt snaps together. As you need, drop the used stage and pull the next stage off the leash and place on in the normal fashion. When going through tighter areas the leash allows you to pull the bottles up in front of you to handle so you don’t damage the cave. It is also great during deco to place all the bottles you are not using out of the way. Plus, it feels more comfortable and you can better manage what gases you are breathing by having only the bottle you need in place.","The PRISM 2 is an electronically or manually controlled, constant PO2, modular, closed circuit diving system.\nAs open circuit (SCUBA) divers we rely upon filling our lungs with air from a pressurized gas tank with every inhalation and then exhausting that volume of air into the surrounding water with every exhalation. As we descend deeper the water pressure around us increases and the volume required to fill our lungs increases; in other words, our air supply depletes more quickly the deeper we dive.\nA rebreather recycles rather than vents the exhaled breath. The exhaled breath passes into a closed loop, where it is pushed through a chemical absorbent (scrubber) to remove the carbon dioxide, and returns through the other side of the loop for the diver to re-breathe, hence the name \"closed circuit rebreather\" or CCR.\nIt’s breathing loop which is a keyed one way assembly consists of a closable mouthpiece assembly with mushroom/check valves either side, which ensure uni-directional flow.\nIndependent 3rd party testing has also rated the Prism 2 the lowest work of breathing of any mixed gas rebreather available today at 0.94J/L. Click here for actual test reports: ANSTI_Prism2WOB_review.pdf\nWith the electronics switched on, the secondary also provides a status check for the battery and displays the set point selected for the dive along with other critical information. The electronics vote between the three proprietary galvanic sensors and control the operation of a low wattage solenoid valve on the oxygen supply.\nA radial flow scrubber canister is mounted vertically on a backplate attached to the integrated BC, between twin supply cylinders (one each, oxygen and diluent).\nThe electronics, sensors and batteries are mounted in the electronics head assembly at the top of the scrubber, with supply hoses feeding over the diver’s shoulders into the top of the counterlungs. An analog LED primary display offers a quick reference of unit performance with status and alarm indicators while an independent digital OLED secondary display verifies the unit’s performance.\nCounter lungs (front or back mounted)\nDual, front or back mounted counterlungs provide the diver with a flexible reservoir equivalent to the maximum displacement of the diver’s own lung volume and ensures the lowest possible hydrostatic loading.\nThese counterlungs are fitted with both automatic and manual gas addition systems and a variable volume control valve (used upon ascent to vent excess expanding gas volume or to purge the loop). Diluent addition is automatically achieved as hydrostatic pressure increases and the counter lung collapses against the valve actuator.\nSecondary Display (COMPUTER)\nThe Shearwater Petrel 3 is the computer display on the Prism 2 and was chosen for this application as it is one of the most advanced mixed gas CCR computers available today. The Petrel 3 is designed to control the Prism 2 setpoint and uses a basic decompression algorithm known as Buhlmann ZHL-16C which has been modified by the use of gradient factors.\n- Depth, time and oxygen sensor display\n- Bühlmann decompression model with gradient factors conservatism\n- Optional VPM-B decompression model\n- Imperial and metric displays\n- DiveCAN communications for robust connections to rebreathers\n- A menu system that adapts to diving status\n- Automatic turn off after 15 minutes on the surface\n- Depth sensor rated to 450 feet/140 meters of seawater\n- Dive Planner\n- Any combination of oxygen, nitrogen, and helium (Air, Nitrox, Trimix)\n- Open and closed circuit, switchable during a dive\n- 5 CC and 5 OC gases\n- Gases can be changed and added during a dive\n- CNS tracking\n- No lockout from violating deco stops\n- Automatic PPO2 set-point switching (configurable)\n- Two PPO2 set-points, each of which can be set between .5 and 1.5\n- Flexible user replaceable battery. Almost any ‘AA’ type\n- Tilt compensated digital compass (Petrel 2 only)\n- 1000 hour dive log memory\n- Log downloads and firmware upgrades using Bluetooth\nPrimary Display (HUD)\nThe Primary Display (HUD) is a Shearwater DiveCAN Heads-Up Display mounted on either the right or left side of the DSV/BOV mouthpiece just below eye level. Each HUD provides a status indicator for its corresponding O2 sensor by using a “Smithers Code” flashing the status on a cycling 5-second loop during the dive.\n- PPO2 display from 3 oxygen sensors.\n- Modified Smither’s code blink pattern.\n- Bright light emitting diodes with vibrant colors.\n- Color-blind blink pattern (optional setting).\n- Wet contacts for automatic turn-on.\n- Option to flip orientation - can be positioned on either side of the rebreather mouthpiece.\n- DiveCAN® communications interface for robust data transmission and easy upgrades, disassembly and repairs.\n- Bright red end-cap LED for buddy warnings.\n- Automatic brightness control optimizes viewing in all conditions.\n- Red color only used for unsafe PPO2 warnings.\n- Rebreather Training\nEvery rebreather requires formal, model specific, training in order to competently dive with the equipment. Rebreather equipment pricing does not include training, and training is solely the responsibility of the purchaser. Training is available at Auckland Scuba for all models we sell. The typical full course training time is 3-7 days consisting of a classroom lecture, confined water session and at least four OW dives. Our recommendation to divers seeking rebreather training is to select an instructor having several hundred hours of rebreather dives and for whom rebreathers are their primary mode of diving.\nIf you are not already certified for the rebreather, per manufacturer requirements you will receive a disabled unit that can only be enabled by your instructor. Once you complete training, your instructor will permanently enable your unit.\nFor general information on rebreathers, transitioning to closed circuit diving, training logistics and cost estimates, plus other reference materials about rebreather training, please contact our staff senior rebreather instructor Grant Searancke.\n- Front or Back mounted counterlungs provide easy breathing with low hydrostatic loading\n- Lowest Work of Breathing in industry at 0.94 J/L - Tested at 100M by ANSTI\n- Unit weight when fully charged, in standard\nconfiguration - approx. 47lbs\n- 3.5 Liter split counterlungs allows inhale and exhale counterlungs for high work loads\n- Counterlung drains make it easy to remove water during a dive\n- All gas lines external to the breathing loop prevents leaks from affecting the PPO2\n- Automatic diluent addition valve adds diluent during descent or when the loop volume is low\n- Manual diluent addition valve adds on board or off board diluent for loop flushing\n- Gases - Air, Trimix, and Heliox\n- Manual oxygen addition valve allows for manually controlling oxygen PPO2\n- High performance open circuit Bail Out Valve option\n- Integral harness and BC or\nBackplate standard makes the Prism 2 ready to dive out of the box\n- Full range of wings/harness gives the ultimate customization\n- Accepts 13, 19, or 30 cu.ft. cylinders for flexible gas management\n- Eye level LED Primary display provides easy to monitor system status\n- Displays PPO2 for each oxygen sensor is used to control PPO2 manually & assure electronics system is nominal\n- External power switch is easy to power on\n- Easy calibration with a push button O2 calibration\n- Large OLED Secondary Display is easy to read, even for your buddy\n- PPO2 Monitoring of Three Sensors Continuous display of each sensor’s PPO2, mv reading easy to access\n- Closed Circuit & Open Circuit, 5 gases supports diluent switching & Multi-gas mix dive plans\n- 2 button push OC bailout - If you have to leave the loop, quickly switches to bailout support\n- CNS Tracking based on real time\n- Software Update via web\n- Dive Log download and software updates via Bluetooth"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:e8fa17d3-e285-44e4-8d66-2c1dbadc5030>","<urn:uuid:79edbe37-cd63-40d7-8671-c94ab088a3a2>"],"error":null}
{"question":"When was the white wine mouthfeel wheel published and how many terms did it include?","answer":"The white wine mouthfeel wheel was published by Gary Pickering and Pam DeMiglio in 2008. It included 54 terms to describe 33 discrete sensations and 21 integrated feelings.","context":["One of the fun parts of wine tasting is to share our experiences with others. A wine tasting wheel, such as the Wine Aroma Wheel, is a great tool to get started. But what about mouthfeel?\nIn a previous article, I shared why it is more challenging to describe wine mouthfeel than to describe aroma . These sensations are diffuse and difficult to decompose as singular sensations. It is also difficult to reproduce them with references that can mimic what you perceive in your mouth.\nThe first wine mouthfeel wheel was developed in Australia and focused on red wine mouthfeel that is quite complex. You may have noticed that wine critics tend to be more prolific on words to describe red wine mouthfeel: full-bodied, rich, structured, astringent, grainy, etc.\nThe second wine tasting wheel came out of Canadian research several years later and focused on white wine mouthfeel.\nLet's explore their findings and how you could use their wine tasting wheels to gain more confidence in describing wine mouthfeel.\nRichard Gawel and colleagues published the red wine mouthfeel wheel in 2000.\nThe team asked a panel of 14 sensory panelists to taste 140+ wines over six weeks. The wines were from Australia, France, and Italy, and included Shiraz, Cabernet Sauvignon, Pinot noir, and Grenache.\nThey developed a list of 53 terms divided into 13 categories, covering astringency and its nuances, and other tactile or non-tactile sensations.\nThe authors defined more specifically the 13 categories of mouthfeel sensations in their paper published in 2000.\nThe originality of this work was the development of tactile references or \"touch references\" to mimic sensations similar to what one could perceive in the mouth.\nIndeed they found out it was not easy to reproduce tactile feelings in mouth, and the selected \"feel references\" had side effects such as lingering in your mouth and making it challenging to taste anything else after them.\nTherefore, panelists used their fingers to touch the various tactile references and learned to associate these sensations with feelings in their mouth.\nA team in Canada used the wine tasting wheel to describe the mouthfeel of red wines from British Columbia, focusing only on astringency and its nuances.\nThey found it was difficult for trained tasters to be relatable in the use of mouthfeel descriptors. Even for trained wine tasters, the nuances of mouthfeel can be confusing.\nThe researchers concluded that all the descriptive terms off astringency were related and defined probably different levels of intensity rather than different sensations.\nIs it easier to describe white wine mouthfeel? Let's see.\nGary Pickering and Pam DeMiglio published a mouthfeel wheel for white wine in 2008. Inspired by the Australian mouthfeel wheel and recognizing that white wines could elicit mouthfeel sensations that red wines could not, they followed a similar process to generate their wheel.\nA panel of 11 trained tasters participated in 21 sessions. To develop descriptive terms, the tasters tasted 77 wines, including table, sparkling, low alcohol, dessert, or fortified wines.\nThrough discussions, tasting, use of references, 54 terms were selected to describe 33 discrete sensations (e.g., tingle) and 21 integrated feelings, combining different sensations (e.g., felt referring to \"an overall sensation of roughness and drying in the mouth.\")\nThe inclusion of sparkling wines led to a category of terms dedicated to the mousse — for example, its persistence in the mouth.\nNote as well that the wheel introduces the timing of the sensation appearance as a way to better characterize the feeling, whether it was early or towards the end of the tasting.\nSeveral terms describe the same sensation but at a different level of intensity; for example, roughness presents three intensity levels: fine emery, medium emery, and sharp. See the photo below.\nThe researchers make it more evident on the wheel to indicate the degree of intensity.\nThey also took particular attention to define all the terms with either tactile references or detailed definitions.\nAs you can appreciate through the two examples presented in this article, it takes a lot of time, a lot of wines, and in-depth and long discussions to get to the final versions of the wine tasting wheels.\nAs any tool, use the mouthfeel wheels as guides to learn how to describe wines. However, they are not exhaustive or absolute. As mentioned earlier, even trained tasters can be confused by the diversity and nuances of the mouthfeel terms. The use of references is one way of overcoming the confusion.\nI am sure, however, that describing mouthfeel with your tasting partners could become a lively conversation.\nPublished: December 2019 Revised July 19, 2020"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:fe4bcf03-24d1-49ba-aea1-35dc949d4a1f>"],"error":null}
{"question":"Could you compare the safety considerations between paragliding and yacht sailing for beginners? I'm interested in trying both sports but want to understand the risks.","answer":"Both sports prioritize safety but handle it differently. For paragliding, beginners are recommended to start in early or late season when thermals are less strong, and must progress to ParaPro 3 level before flying unsupervised. For sailing, safety is the number 1 priority - yachts are equipped with extensive safety equipment, have safety boats for dinghy activities, and won't go to sea in unsafe conditions. Yachts are designed to tilt up to 120° and still self-right, while paragliding requires proper training and supervision with a maximum ratio of 5 clients per instructor to ensure safety.","context":["Q. When is the best time to come?\nA. For beginners or very low airtime Pilots we recommend either early or late in the season - the weather is usually good with reasonable thermic activity but without the thermals being too strong for low airtime Pilots. January to May and September to end of October are prime times. More experienced Pilots can come anytime, but April to September are the very best for thermalling and XC flying with good thermic activity most days and a normally high cloudbase in the range 2500m - 4600m. We run trips at various times so why not join us.\nQ. If I get ParaPro2 (EP level) can I join a club and fly on my own?\nA. You can certainly join a club but you need to progress to ParaPro 3 level (Club Pilot) before you can fly unsupervised by an instructor - normally this can take 6 -13 days training, sometimes longer depending on the skill and confidence of the individual Pilot. Pilots normally do a brief assessment once back in their home country and sit the local airlaw exam before gaining the local license.\nQ. What kind of clothing do I need to bring?\nA. Good boots with ankle support together with warm outdoor clothing. In Spring and Autumn the Alps can be cold at night or whilst flying, long trousers and jacket as well as gloves are normal flying attire.\nQ. How soon will I be flying?\nA. You will probably be flying by the end of the 1st day of training. Initially you can expect to be doing low level flights, gaining height as competence, confidence and conditions allow.\nQ. Where can I stay?\nA. Self catered accommodation is offered by several local accommodation providers in provencial maisons du village with starter food hamper to get you going, for seven or fourteen nights. Available Saturday to Saturday from 1600 hrs onwards on arrival day until 0900 hrs approximately on departure day.\nShared room basis per person €315.00 per week\nPrivate room basis €420.00 per week\nSingle with private bathroom €490.00 per week\nDouble with private bathroom €665.00 per week\nOther options are available including low cost camping package Accommodation options\nQ. How many others will there be on my trip?\nA. Depends on our bookings but we never have more than 5 clients to 1 instructor - this means you always get the attention you need during the early stages of your flying career. Similarly with our thermalling and XC courses we normally keep class sizes to no more than 4 per instructor.\nQ. Why do I need repatriation/travel insurance?\nA. The insurance provided from within the national associations does not normally cover accident/illness repatriation so you should have a separate cover for this - We suggest Sportscover Direct or Worldwide both of whom have links from our downloads page. You can find links to suitable insurers in your home country by using Google or other search engine.\nRegular progressive ongoing training is the key to successful Pilot development - from ridge soaring onto thermalling then XC flying. You can learn to thermal in the UK or Northern Europe but good thermalling days are often few and far between. Doesn't it make more sense to learn in Alpine France where thermalling conditions are the norm and the weather is much more favourable?","New to sailing?\nIf you’ve never sailed before, you probably have lots of questions – and we’ve probably heard a lot of them before!\nWhether it’s something you’ve always wanted to do, or whether you have recently been inspired, we’ve tried to answer some of the most common ones here.\nIf you don’t find the answer you’re looking for below, just drop us a line and we’ll do our best to help.\nWill I like sailing?\nIs sailing safe?\nWill I get seasick?\nDo you like the idea of spending time on the water with the wind in your hair? Of exploring bays you can only reach by boat? Would you like to gain a greater appreciation of the feats of history’s great explorers, who discovered the far corners of the globe under sail?\nIf so, there’s a good chance you will like sailing. For us, the moment the engine is switched off and we find ourselves moving along in silence by wind power alone is a moment of magic that just never gets old.\nOn the whole sailing is a very safe sport. Our yacht Cloud Nine is equipped with safety equipment far in excess of that required by her commercial coding. Dinghy sailing activities always have a safety boat on the water at the same time. All instructors who have qualified through the UK’s Royal Yachting Association (RYA) have been trained to regard safety as the number 1 priority, followed by making sure you have fun and finally to make every attempt to ensure you learn. No boats will go to sea if the conditions are unsafe (and this is a legal requirement for charter yachts in Greece) and your safety is our paramount concern – even if it risks your disappointment!\nIn all honesty nobody can know in advance. What we can say is that most people don’t. Even if you should suffer a little, it usually goes away after 24-48 hours and after you have slept on board for a night, once your inner ear has had a chance to adjust to the motion.\nIf you are concerned, it’s worth buying seasickness tablets from a pharmacy (Stugeron is common and works well in our experience) in advance and taking one the night before as a precaution (obviously following the manufacturer’s instructions). In any case, we always keep seasickness tablets to hand just in case and the ship’s dog is likely to comfort you too.\nIf you should be unfortunate enough to be one of those rare people who suffers from debilitating seasickness that doesn’t go away after a day or two, you have our sympathy. But don’t worry – you won’t be trapped on board for the rest of the week as we have good contacts with hotels and villas if you feel you have to leave the boat.\nYour website refers to \"yachts\" and \"dinghies\". What is the difference?\nWill I get wet? Will the boat capsize?\nDo we sleep on the boat?\nAny sailing vessel has a keel extending deep into the water underneath it to counterbalance the forces on the sails. In broad terms, a yacht is a larger and much more stable boat with a fixed keel, with cabins for sleeping, and cooking and toilet facilities on board. A dinghy, on the other hand, is a small, open boat with a lifting keel (called a centreboard) with nothing on board except the mechanics of sailing.\nOn a yacht, you will normally only get wet from spray and rain. Yachts are designed to tilt over to at least 120° from the vertical and still come upright again by themselves. There’s a saying that the boat will take a lot more punishment than the crew can tolerate.\nOn a dinghy, like the one in the picture above, you must expect to get wet – but that’s also at least half of the fun! Don’t worry though. You learn very early on how to recover properly from a capsize and there is always a safety boat on the water for assistance.\nAbsolutely! It’s all part of the experience. And the sunrises and sunsets are just stunning.\nWhat happens if I find I really don't like sailing or living on the yacht?\nCan my children come? What age can they start?\nI love it! Which type of boat should I learn on?\nThis is extremely rare, but we have contacts with hotels and villas and you can decamp to dry land if sailing just isn’t for you. And because it’s the Med, you can still have a fantastic time, swimming in the sea, eating and drinking in tavernas, exploring the island – so either way, it’s a no-risk holiday.\nChildren are very welcome – if they like it, sailing is a healthy activity that they will be able to do all their lives and you will be giving them a great gift. Our youngest ever guest was just 3 years old. Children typically develop the co-ordination and attention to become useful crew members on a yacht from the age of about 7 or 8 (obviously all children are different and you know your children best); the recommended minimum age for the Competent Crew qualification is 12, but again it depends on the child. The RYA has a separate dinghy scheme specifically for children, which they can take from a very young age.\nThe choice is yours – the physics of sailing doesn’t change, only the scale and the forces. Some people will say you learn to sail better on a dinghy because there is no way to cheat; others will say if your ambition is to sail yachts, you should learn on yachts. The ideal, of course, is to do both! A holiday with us on our yacht is the ideal way to find out whether sailing is for you with no pressure; that way you can decide whether you want to take it further and we can advise you which route to take.\nHow many hours do I need to learn to sail?\nCan I learn to sail on the Swiss lakes?\nAnything from a few days to a lifetime! You never stop learning, after all. However, as a rule of thumb, we would expect adults to be able to sail a dinghy independently once they have RYA level 2 after 32 hours/4 days of instruction. This means you are able to launch and recover the boat, sail in the direction you want to go in and recover a capsize. The equivalent level for children is Stage 3.\nOn yachts the progression is Competent Crew (5 days), Day Skipper theory (4-5 days) then Day Skipper practical (5 days) so technically it is possible to gain the qualification you need to sail independently in a couple of weeks – but this really is the absolute bare minimum and we would always advise you to build up as much experience as you can.\nOf course you can, and we can refer you to a reliable partner on Lake Zurich if you like."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:711002c9-97ac-4456-82a5-037d5c0b7136>","<urn:uuid:0b9ad6e0-b85b-40b8-a441-f515b60f5a0c>"],"error":null}
{"question":"How do the political structures of the Bwa and Kuba peoples differ in terms of centralized authority?","answer":"The Bwa and Kuba have contrasting political systems. The Bwa live in autonomous villages without centralized authority, with all decisions made by councils of male elders of local lineages. In contrast, the Kuba are organized into a federation of chiefdoms unified under a divine Bushong king (nyim) who controls fertility and communicates with the creator, with a hierarchical court system of councils and officials who advise him.","context":["Types of Art\nThe Bwa produce numerous masks, which are made from leaves and vines and sculpted from wood. They are best known for their impressive plank masks which are used in the southern villages. Wooden sculptures used in fertility and divination ceremonies are also carved.\nThe history of the Bwa is characterized by a succession of outsiders attempting to take advantage of their independently organized villages. In the 18th century, the Bamana empire of Segou came into power and occupied a large portion of the Bwa lands in Mali. They forced the Bwa to pay taxes and carried out raids in the unconquered areas. In the 19th century, the Bamana empire declined, only to be replaced by the Moslem Fulani empire in the north. They also carried out incursions into Bwa territory, destroying crops and villages, stealing animals, enslaving men and women, and conscripting men into their armies. In 1897, the French arrived on the scene, only to use the Fulani as mercenaries in order to control the region. In 1915, the Bwa revolted against the French demand for military recruits. The French responded by destroying all the offending villages.\nThe Bwa are primarily farmers. Since the early colonial days the largest cash crop is cotton, of which they often produce so much that they must purchase food for cash in distant markets. Most of the field work is done by the men, although women help out during planting and harvesting. Other crops include grains, such as millet, rice, sorghum, yams, and peanuts. Women also gather fruits and plants from the nearby wilderness, which are used in the concoction of certain medicines and to supplement the daily diet.\nThe Bwa live in autonomous villages which do not recognize an individual political authority. All decisions are made by a council of male elders of the local lineages. External infringements on this system have been historically resisted. While the independence of Bwa villages has proven an advantage in the face of local crises, when the people have quickly organized and taken action almost immediately, it has also prevented the Bwa from forming strong alliances when confronted by outside invaders.\nThe Bwa believe that the world was created by a god named Difini or Dobweni, who left the Earth when he was wounded by a woman pounding millet with her pestle, abandoning humankind to his fate on Earth. Dobweni sent his son Do to act as his messenger to humans and to act as an intermediary between people and spirits. Do is primarily concerned with all ceremonies that represent the renewal of life, for he is associated directly with the life giving bush or forest, which provides the Bwa with game and medicines they need to survive. He also represents plant life and the power that lends productivity to man's labor in the fields. The cult of Do is a major cohesive force in Bwa society, providing an opportunity for cultural and community bonding. The religious leader among the Bwa is a labie (earth priest) who is the oldest male member of the clan that first occupied the land on which the village is built.\nFacts about Bwa\nBobo, Bamana, Gurunsi, Lobi","|A Kuba Mask\nBonnie E. Weston\n|The Kuba live in the Lower Kasai region of central Zaire in a rich environment of dense forest and savanna.\nOrganized into a federation of chiefdoms, the almost 200,000 Kuba are a diverse group of over eighteen different\npeoples unified under the Bushong king. They share a single economy and, to varying degrees, common cultural\nand historical traditions. Agriculture is the main occupation, supplemented by hunting, fishing, and trading. The\nname \"Kuba\" comes from the Luba people to the southeast. The Kuba call themselves \"the children of Woot\"—\nafter their founding ancestor (Vansina 1964:6;1078:4).\nPraised as \"God on Earth,\" the king, nyim, is a divine ruler who controls fertility and communicates with the creator,\nMboom. The royal court at Nsheng is a hierarchical complex of councils and titled officials who advise the king and\nbalance his power. Outlying Kuba chiefdoms are largely autonomous, organized on models analogous to those of\nthe capital but on a lesser scale (Vansina 1964:98-99; 1978:216). Kuba society parallels governmental\norganization in that it is stratified. Yet the Kuba people prize hard work and achievement, and while position of birth\nmay secure advantage, it is not binding (Vansina 1964:188;1968:13,15).\nKuba religion, however, is not highly organized. The creator, Mfcoom, is recognized but is not formally worshiped.\nMore considera¬tion is given to Woot, who led the Kuba migration \"up river\" and established matrilineal descent,\nmale initiation, and kingship. Local nature spirits, tended by priests and priestesses, are actively involved in\npeople's lives, notably in matters of fertility, health, and hunting. The Kuba have no ancestor cult but do believe in\nreincarnation (Vansina 1964:9-10).\nKuba arts primarily address status, prestige, and the court; they are manifestations of social and political hierarchy.\nRank and wealth are expressed in extensive displays of regalia: jewelry, rich garments of embroidered raffia cloth,\nceremonial knives, swords, drums, and elaborated utilitarian items. Valuable imported cowrie shells and beads\nemblellish garments, furniture, baskets, and masks.\nThe outstanding Kuba style diagnostic is geometric patterning used to embellish the surfaces of many objects.\nThese designs are woven into raffia textiles and mats, plaited in walls, executed in shell and bead decoration, and\nincised on bowls, cups, boxes, pipes, staffs, and other forms including masks. All art forms and designs are laden\nwith symbolic and iconographic meaning, and the same is true of the rich Kuba masquerades.\nMasking was first introduced by a woman who carved a face on a calabash, the original model for initiation masks.\nThe invention was taken over by men, incorporated into initiation, and remains a male privilege. Once Bushong\nboys move into the nkan initiation shelter, they can wear masks and make excursions into the village frightening\nwomen and small children. More powerful masks are worn by initiation officials. The masked Kuba dancer is, in\nevery instance, a spirit manifestation (Torday 1910:250; Vansina 1955:140).\nThree royal mask types exist: the tailored Mwaash aMbooy, representing Woot and the king; the wooden face\nmask, Ngady Mwaash aMbooy, the incestuous sister-wife of Woot; and the wooden helmet mask, Bwoom ,the\ncommoner. These characters appear in a variety of contexts including public ceremonies, rites involving the king,\nand initiations. Although their dances are generally solo, together the three royal masks reenact Kuba myths of\norigin (Cornet 1982:254,256; Roy 1979:170).\nBwoom is a wooden helmet mask elucidated by varied oral traditions. The Kuba feel that one \" 'understands' the\nwhy of something if one knows how it 'began'; something is known if it is explained\" (Vansina 1978:15). Thus\nBwoom is the spirit first seen by nkan initiates; he is a hydrocephalic prince, a commoner, a pygmy, or one who\nopposes the king's authority. Two traditions trace Bwoom's origin to the reign of King Miko mi-Mbul, who had gone\nmad after killing the children of his precedessor. Although he finally became sane, Miko would lapse into madness\neach time he wore Mwaash aMbooy, the most important royal mask and until then the only one worn by the king\nhimself. A pygmy offered the king Bwoom as an alternative. Suffering no ill effects with the new mask, Miko\naccepted it. A less dramatic version is that Miko, known as a great dancer, was simply seduced by the pygmy's\ncreation and adopted it despite its humble character. In both cases the King is credited with improvements to the\nmask that justify its inclusion in the royal repertoire (Cornet 1982:269).\nAs inconsistent as they may seem, each account expresses an aspect of the mask or its character. The\nidentification of Bwoom as a pygmy or a hydrocephalic man is often cited to explain the mask's enlarged forehead\nand broad nose. Bwoom appears in initiation and is always considered a spirit. The lowly origin of the character is\nreflected in its description: \"a person of low standing scarcely worthy of being embodied by the king\" (Cornet 1975:\n89) and conversely in its defiant performance opposite the regal Mwaash aMbooy. The two may act out a\ncompetition for the affections of the one female in the royal mask trio, Ngady mwaash aMbooy (Cornet 1982:255).\nMwaash aM-booy's dance is calm and stately, while Bwoom acts with pride and aggression (Cornet 1982:255). The\nmasks are easily differentiated by material, for Bwoom is carved from a single piece of wood and Mwaash aMbooy\nis made from cloth and raffia textiles.\nBwoom appears on the nkan \"initiation fence\" of the Bushong (Vansina 1955:150-151) and in other initiation\ncontexts. Little is known of this mask (or indeed most Kuba arts) outside of the royal Nsheng tradition.\nA royal mask, Bwoom is sometimes worn by the king. Yet unlike Mwaash aMbooy, Bwoom does not appear at\nfunerals, and it is never interred with the king or other dignitaries (Cornet 1982:270). The costume is similar to that\nof Mwaash aMbooy: heavy with profuse layers of raffia-cloth, bead and cowrie decoration, leopard skins, anklets,\narmlets, and fresh leaves. Eagle feathers or other prestigious media are added to the crown of the head when the\nmask is danced.\nDespite regional variations, the Bwoom mask conforms to a distinct type. All styles feature strongly rendered\nproportions dominated by an enlarged brow, broad nose, and usually naturalistic ears. Typical features include the\nmetal work on the forehead, cheeks, and mouth, bands of beads that embellish the face, and an expanse of\nbeadwork at the temples and back of the head. Plate 8 has these plus patterned raffia-cloth covering the top of the\nhead, with a fringe of hair. The blue beads set into the white band at the temples imitate ethnic tattoo patterns\n(Cornet 1982:266), and the design at the back of the head is one associated with royalty.\n|Mukenga / Mukyeem\nA non-royal variant of the Mwaash aMbooy type mask is the Mukenga mask, representing an elephant, is\ncharacterized by a beaded trunk and two small tusks protruding from the base of the trunk. As in other\nAfrican kingdoms, such as the Asante and those of the Cameroon grassfields, elephants are associated\nwith royal power. According to the Kuba proverb, \"an animal, even if it is large, does not surpass the\nelephant. A man, even if he has authority, does not surpass the king (Binkley 1992: 277). The small beaded\ntusks flanking the trunk symbolize wealth and fertility (Binkley 1992: 288). Mukenga masqueraders perform\nat the funeral ceremonies of high-status Kuba titleholders.\n|THE OBJECTS BELOW ARE NOT IN MY COLLECTION, THEY ARE\nFOR REFERENCE PURPOSES ONLY\nThere are a LOT of great photos in the Eliot Elisofon Photographic Archives\nProperty from a New York Private Collection\nA FINE KUBA MASK\nLOCATION ESTIMATE AUCTION DATE\nNew York 7,000—10,000 USD Session 1\n15 Nov 02 10:15 AM\nLot Sold. Hammer Price with Buyer's Premium: 10,755 USD\nheight 21 1/2in. 54.6cm\nmukyeem, of helmet-like form and large proportions a raffia attachment at the base, composed of a flat metal\nfacial plane pierced through for attachment of the expressive beaded facial features, and wearing an\nelaborate headdress composed of blue, white, black, pink and red beads and cowrie shell, a conical projection\nat the crown in the form of an arching elephant trunk framed by two tusks.\nJ. J. Klejman, New York\nSotheby's, New York, November 15, 1988, lot 124\n|Elephant Mukenga Mask\nCowrie Shells, Beads, Raffia, Fur, Cloth\n|Mask (mukyeem), 19th–20th century\nDemocratic Republic of the Congo, Kuba peoples\nWood, beads, fiber, hair, cowrie shells, and cloth; H. 18 in. (45.7 cm)\nSource - http://www.metmuseum.org/special/Genesis/10.L.htm\nKuba Culture, Democratic Republic of\nCongo (formerly Zaire) 1800s-1900s\nWood, animal fur, raffia cloth, cowrie\nshells, glass beads, string\n19 1/2 inches high\nVirginia Museum of Fine Arts\nPurchase, The Arthur and Margaret\nGlasgow Fund, 87.82\n|C. Pollzzie Collection\nAcquired from the McDonald-Levy Collection\nHeight: 33 in. (84cm)\nWidth: 20 in. (51cm)\nDepth: 18 in. (46cm)"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:bd851a8f-7c26-4de7-b54b-068e4f98fb13>","<urn:uuid:096f18f2-5ab4-4989-bed2-3920c8470c65>"],"error":null}
{"question":"What's the difference between irrigated conventional farming and controlled traffic farming in terms of soil quality and crop yields?","answer":"Irrigated conventional farming tends to degrade soil quality due to water saturation and machinery compaction, which leads to poor oxygen availability and increased greenhouse gas emissions through methanization and denitrification. Additionally, irrigation accounts for 47-63% of the carbon footprint. In contrast, controlled traffic farming with permanent wheel tracks preserves soil quality - as demonstrated in the Queensland farm case, where after 5 years of controlled traffic no-till farming, the soil became soft, friable and moist between plant lines, with improved infiltration and excellent structure. This improvement in soil quality led to significant yield increases, with sorghum yields rising from 3 to 7 tons per hectare.","context":["Agriculture and land use change contribute 24% of greenhouse gas emissions. Researchers estimate that this share will increase by 30 to 40% by 2050. The challenge is therefore to counterbalance this with greater carbon sequestration in order to transform agrosystems into greenhouse gas sinks.\nTo determine this role, it is sufficient, in broad terms, to take into account the gases drawn from the agrosystem and to compare them to those emitted by the same agrosystem. To do this, it is necessary to measure the accumulation of carbon in the soil, the quantities of methane (CH4) and nitrous oxide (N2O) released into the atmosphere, as well as all the CO2 coming from agricultural practices: plowing, planting, harvesting, installation and use of irrigation, application of agrochemicals, fertilizers and lime.\nKnowing that CH4 and N2O are greenhouse gases 34 and 298 times more potent than CO₂ respectively, it is sufficient to convert all these emissions into CO2 equivalent to estimate the net global warming potential and compare between different agricultural management methods.\nTo calculate the carbon cost of today's dominant agricultural practices, one must also consider their direct CO2 emissions. According to studies conducted in southern Brazil and the United States, the carbon cost of agricultural practices represents a significant amount of CO2, up to 800 and 2,000 kg ha-1 year-1.\nDiagram showing how to estimate whether an agrosystem is a source or sink of greenhouse gases: measure carbon fixation in the soil, the amount of CH₄ and N₂O released into the atmosphere, and all the CO₂ from agricultural practices: tilling, planting, harvesting, irrigation installation and use, and application of agrochemicals, fertilizers, and lime.\nBased on this observation, the first thing to do is to determine which agricultural practices to adopt in order to transform the soil into a greenhouse gas sink - and not a source.\nThe first element to take into account is that the soil can become a source of greenhouse gases when there is an excessive input, because telluric microorganisms feed on all these inputs and spit them out in the form of GHG.\nEven more so when the land is saturated with water by irrigation and compacted by machinery, as oxygen availability becomes scarce, leading to methanization (a process responsible for the production of CH₄) and denitrification (one of the processes responsible for the production of N₂O). Nevertheless, these methane fluxes remain low or even sometimes negative if the soils have a good structure and are not flooded.\nIn addition, the establishment and use of irrigation accounts for 47-63% of the carbon footprint while fertilization and limestone application rise to 35%. These proportions vary according to the inputs used and their annual input. To mitigate the climate change caused by agriculture, the most obvious solution seems to be the reduction of inputs, with more reasoned spreading.\nAgroforestry and legumes\nOther agricultural practices are just as important in moving from a source to a sink for greenhouse gases.\nThis is particularly true of agroforestry, which has been adopted by some farms. It consists of using cover crops, for which carbon storage exceeds its CO₂ equivalent released into the atmosphere in terms of N2O emissions, and improves soil structure with negative CH4 emissions.\nTwo contrasting agricultural systems, behaving as source (left) and sink (right) of greenhouse gases, according to CO₂, CH₄ and N₂O emissions as well as soil carbon sequestration. Murilo Veloso\nThis is also the case for the use of legumes. As these plants associate with nitrogen-fixing bacteria, they promote carbon storage in the soil and make it possible to substitute part of the mineral fertilization, thus reducing nitrous oxide emissions.\nFurthermore, by maintaining soil moisture and structure, practices such as agroforestry and cover crops provide an alternative to decrease irrigation.\nHowever, transforming an agrosystem into a greenhouse gas sink is not always obvious. For example, plowing, the practice of turning over the soil before seeding, does not necessarily have the same impact on GHGs.\nIn temperate environments, plowing has little effect on soil carbon stocks because low temperatures in early spring slow down microbial activity and the decomposition of soil organic matter.\nIn contrast, in tropical environments where temperatures remain favorable, soil destructuring by tillage stimulates microorganisms to decompose soil organic matter, which releases GHGs.\nExample of conventional agriculture and its practices such as monoculture, tillage and heavy reliance on inputs that contribute to increased greenhouse gas emissions and reduced soil carbon sequestration, making the agricultural system a source of greenhouse gases (left). Example of agroecological practices such as cover crops, no-till, intercropping, legumes and agroforestry that contribute to decrease greenhouse gas emissions and increase soil carbon sequestration, making the agricultural system a greenhouse gas sink (right).\nFor no-till farming practices, N2O emissions are largely offset by CO2 storage, counterbalancing the 375 to 616 kg of carbon equivalent emitted per hectare per year by the 2063 to 3940 kg of carbon equivalent fixed in the soil per hectare per year. This represents nothing less than a carbon storage five to six times higher than the emissions! Ploughing, on the other hand, clearly reduces the soil's capacity to draw carbon from these tropical zones.\nOn the other hand, plowing also constitutes an additional cost of CO₂ when the use of diesel for machinery is taken into account (35.3 kg of carbon equivalent per hectare per year in conventional and 5.8 kg in direct seeding).\nFrom field to plate\nLet's not forget that greenhouse gas emissions do not stop at production, but also continue during transportation, processing, packaging and redistribution of products.\nIt is therefore necessary to radically change agricultural practices, starting with the fields. The practices mentioned above - the use of cover crops, legumes, intercrops, agroforestry, and the abandonment of tilling the soil - would have a triple effect: strengthening an organic and sustainable agri-food system, respecting biodiversity, allowing a balanced cohabitation between agriculture and the environment, while making farmers less dependent on large industrial companies","View sectionsExpand all Collapse all\n1. General information\n1.2 Contact details of resource persons and institutions involved in the assessment and documentation of the Technology\nKey resource person(s)\nName of project which facilitated the documentation/ evaluation of the Technology (if relevant)Book project: where the land is greener - Case Studies and Analysis of Soil and Water Conservation Initiatives Worldwide (where the land is greener)\n1.3 Conditions regarding the use of data documented through WOCAT\nThe compiler and key resource person(s) accept the conditions regarding the use of data documented through WOCAT:\n1.4 Declaration on sustainability of the described Technology\nIs the Technology described here problematic with regard to land degradation, so that it cannot be declared a sustainable land management technology?\n2. Description of the SLM Technology\n2.1 Short description of the Technology\nDefinition of the Technology:\nLarge-scale no-till grain production with permanent wheel tracks\ncommon to all on-farm equipment.\n2.2 Detailed description of the Technology\nThis controlled traffic, no-till farming system (CT/NT) is practiced on a 1,900 ha farm on the broad, almost flat Jandowae Plains in semi-arid Queensland, Australia. Principal soil types are vertisols, with some poorer areas where the sand content is greater, and these have a tendency to hard-set and crust. Over the past five years, the farm owner has changed the farming system completely from conventional farming to no-till with controlled traffic. Controlled traffic means permanent uncropped wheel tracks or ‘tramlines’: all equipment has 2 metre axles. The total farm machinery comprises a tractor, a spray rig and two 11 meter zero-till planter/fertilizer units; one each for wheat and sorghum sowing. The tramlines were laid out two years ago by a contractor using Geographical Positioning System (GPS).\nThe main technical objective was to eliminate soil compaction. The CT/NT combination ensures the land -between the tramlines - remains in excellent condition. There has been no ploughing or tillage at all in those 5 years. He practices a three year rotation between winter wheat, summer sorghum and fallow, but the system is not fixed: it depends very much on soil moisture status and thus on the rainfall (opportunity cropping). Generally in summer about one third is in summer sorghum and in winter about one third in winter wheat, the rest of the land is\nunder fallow. The one-year fallow is maintained through the use of herbicides sprayed onto the undisturbed residue from the previous crop. The system is designed for rain capture - to build up soil moisture stores in the fallow periods for subsequent crops - and for disease control (to ‘spell’ the land). During the cropping cycle, the key to his effective weed control system is ‘to get in early’ and ‘actively chase weeds’ through judicious spraying. The farm is now free of the locally common persistent weed Erigeron annuus. In the five years his sorghum yields have risen from 3 to 7 tons per hectares. Over the last three years the soil has improved, becoming soft, friable and moist between his plant lines. Infiltration has improved a lot and soil structure is now excellent.\nTractor use and overall fuel consumption has decreased to less than one quarter of that under conventional tillage. Correspondingly the workload is hugely reduced: from four men required under the conventional system for an equivalent area, the farmer is the sole operator, very occasionally assisted by his son, and a paid contractor for harvesting. He is so satisfied with the CT/NT system that he is attempting to purchase a nearby property to extend the area that he can farm using his current machinery.\n2.3 Photos of the Technology\n2.5 Country/ region/ locations where the Technology has been applied and which are covered by this assessment\nRegion/ State/ Province:\nJimbour (north of Dalby), Queensland\nSpecify the spread of the Technology:\n- evenly spread over an area\nIf the Technology is evenly spread over an area, specify area covered (in km2):\nIf precise area is not known, indicate approximate area covered:\n- 10-100 km2\n2.7 Introduction of the Technology\nSpecify how the Technology was introduced:\n- during experiments/ research\n3. Classification of the SLM Technology\n3.1 Main purpose(s) of the Technology\n- improve production\n- reduce, prevent, restore land degradation\n- create beneficial economic impact\n3.2 Current land use type(s) where the Technology is applied\nLand use mixed within the same land unit:\n- Annual cropping\nAnnual cropping - Specify crops:\n- cereals - sorghum\n- cereals - wheat (winter)\nNumber of growing seasons per year:\nLongest growing period in days: 180 Longest growing period from month to month: Oct - AprS econd longest growing period in days: 180 Second longest growing period from month to month: Apr - Sep\nIs intercropping practiced?\nIs crop rotation practiced?\nIf yes, specify:\nMajor land use problems (compiler’s opinion): The farmer’s main reason for starting the combination of CT and NT was to rid himself of soil compaction, in order to achieve better utilisation of locally low and unpredictable rainfall amounts while minimising costs and reducing labour and machinery requirements.\n3.3 Has land use changed due to the implementation of the Technology?\nHas land use changed due to the implementation of the Technology?\n- No (Continue with question 3.4)\n3.4 Water supply\nWater supply for the land on which the Technology is applied:\n3.5 SLM group to which the Technology belongs\n- minimal soil disturbance\n3.6 SLM measures comprising the Technology\n- A3: Soil surface treatment\nA3: Differentiate tillage systems:\nA 3.1: No tillage\nMain measures: agronomic measures\n3.7 Main types of land degradation addressed by the Technology\nsoil erosion by water\n- Wt: loss of topsoil/ surface erosion\n- Wg: gully erosion/ gullying\nsoil erosion by wind\n- Et: loss of topsoil\nphysical soil deterioration\n- Pc: compaction\nMain type of degradation addressed: Wt: loss of topsoil / surface erosion, Pc: compaction\nSecondary types of degradation addressed: Wg: gully erosion / gullying, Et: loss of topsoil\n3.8 Prevention, reduction, or restoration of land degradation\nSpecify the goal of the Technology with regard to land degradation:\n- reduce land degradation\n4. Technical specifications, implementation activities, inputs, and costs\n4.1 Technical drawing of the Technology\nTechnical specifications (related to technical drawing):\nMain technical functions: control of raindrop splash, control of dispersed runoff: retain / trap, improvement of ground cover, increase in organic matter, increase of infiltration, increase / maintain water stored in soil, improvement of soil structure, reduction of compaction by traffic, increase of soil fertility\nTechnical knowledge required for field staff / advisors: moderate; Technical knowledge required for land users: moderate\n4.2 General information regarding the calculation of inputs and costs\nSpecify currency used for cost calculations:\nIndicate average wage cost of hired labour per day:\n4.3 Establishment activities\n|1.||layout of the controlled traffic lines (tramlines) using GPS mounted in a 4x4 vehicle. Two days were adequate for the whole farm.|\n4.4 Costs and inputs needed for establishment\n|Specify input||Unit||Quantity||Costs per Unit||Total costs per input||% of costs borne by land users|\n|Total costs for establishment of the Technology||5.0|\n|Total costs for establishment of the Technology in USD||5.0|\nDuration of establishment phase: 12 month(s)\n4.5 Maintenance/ recurrent activities\n|1.||Layout of the controlled traffic lines (tramlines)||Two days were adequate for the establishment on the whole farm.|\n|2.||Weed control (spray-coupe) with roundup||Summer sorghum (650 ha, during 1 season or half a year)|\n|3.||Fertilizing||Summer sorghum (650 ha, during 1 season or half a year)|\n|4.||Sowing and simultaneous application of starter fertilizer||Mid October, Summer sorghum (650 ha, during 1 season or half a year)|\n|5.||Spraying pre-emergent herbicide to kill summer grasses||Summer sorghum (650 ha, during 1 season or half a year)|\n|6.||Harvest by contractors||early March, Summer sorghum (650 ha, during 1 season or half a year)|\n|7.||Weed control||Winter wheat (650 ha, during 1 season or half a year)|\n|8.||Fertilizing (Urea)||Winter wheat (650 ha, during 1 season or half a year)|\n|9.||Sowing and simultaneous application of starter fertilizer||Mid May, Winter wheat (650 ha, during 1 season or half a year)|\n|10.||In-crop weed spray||Winter wheat (650 ha, during 1 season or half a year)|\n|11.||Harvest by contractors||October|\n|12.||Fallow (1,250 ha)||During 2 seasons or totally 1 year|\n|13.||Weed control (combination of roundup mixed with broadleaf herbicide)||5–6 times per fallow period|\n|14.||Determine the soil moisture (To determine soil moisture he uses an iron rod; if he can push it into the heavy clay soil, then the soil is moist. Additionally, he measures rainfall)|\n4.6 Costs and inputs needed for maintenance/ recurrent activities (per year)\n|Specify input||Unit||Quantity||Costs per Unit||Total costs per input||% of costs borne by land users|\n|Equipment||Harvesting by contractor||ha||1.0||17.0||17.0||100.0|\n|Fertilizers and biocides||Fertilizer||ha||1.0||53.0||53.0||100.0|\n|Fertilizers and biocides||Biocides||ha||1.0||22.0||22.0||100.0|\n|Total costs for maintenance of the Technology||111.0|\n|Total costs for maintenance of the Technology in USD||111.0|\nMachinery/ tools: tactor,spray rig, zero-till planter/fertilizer, iron rod\nComparison of costs between conventional tillage and no-till farming (CT/NT): (1) Labour costs are 4x less in CT/NT: 4 men used to work on the farm (conventional), now the farmer is alone – (plus contractors for harvesting). (2) Average annual diesel consumption: reduced from 108,333 litres (conventional) to 13,636 litres (no-till) which is 8 times less. (3) Costs of equipment to set up a CT/NT system (US$ 240,000) are 3 times less than that for conventional tillage equipment (US$ 700,000).\n(4) For biocides he has to invest 5 times more in CT/NT. The conventional values are estimates.\n4.7 Most important factors affecting the costs\nDescribe the most determinate factors affecting the costs:\nIn average one third of the farm area is in crop and two thirds are fallow. This means that overall farming costs per\nha are reduced, since during fallow period activities are limited to spraying herbicides. Labour costs approximately US$ 160 per day. Machinery costs average out at US$ 20 per hour (diesel costs US$ 0.9 per litre). All the data comes from this single farmer. Purchase of equipment is not included in the table above.\n5. Natural and human environment\n- < 250 mm\n- 251-500 mm\n- 501-750 mm\n- 751-1,000 mm\n- 1,001-1,500 mm\n- 1,501-2,000 mm\n- 2,001-3,000 mm\n- 3,001-4,000 mm\n- > 4,000 mm\nThermal climate class: subtropics\nSlopes on average:\n- flat (0-2%)\n- gentle (3-5%)\n- moderate (6-10%)\n- rolling (11-15%)\n- hilly (16-30%)\n- steep (31-60%)\n- very steep (>60%)\n- mountain slopes\n- hill slopes\n- valley floors\n- 0-100 m a.s.l.\n- 101-500 m a.s.l.\n- 501-1,000 m a.s.l.\n- 1,001-1,500 m a.s.l.\n- 1,501-2,000 m a.s.l.\n- 2,001-2,500 m a.s.l.\n- 2,501-3,000 m a.s.l.\n- 3,001-4,000 m a.s.l.\n- > 4,000 m a.s.l.\nComments and further specifications on topography:\nLandforms: Also footslopes and valley floors (both ranked 2)\nSlopes on average: Also moderate (ranked 2) and rolling (ranked 3)\nSoil depth on average:\n- very shallow (0-20 cm)\n- shallow (21-50 cm)\n- moderately deep (51-80 cm)\n- deep (81-120 cm)\n- very deep (> 120 cm)\nSoil texture (topsoil):\n- fine/ heavy (clay)\nTopsoil organic matter:\n- medium (1-3%)\n- low (<1%)\nIf available, attach full soil description or specify the available information, e.g. soil type, soil PH/ acidity, Cation Exchange Capacity, nitrogen, salinity etc.\nSoil depth on average: Also shallow and deep (both ranked 2)\nSoil fertility: Medium (ranked 1) and high (ranked 2)\nSoil drainage: Poor\n5.6 Characteristics of land users applying the Technology\nMarket orientation of production system:\n- commercial/ market\n- less than 10% of all income\nRelative level of wealth:\nIndicate other relevant characteristics of the land users:\nand own 88% of the land.\n5.7 Average area of land used by land users applying the Technology\n- < 0.5 ha\n- 0.5-1 ha\n- 1-2 ha\n- 2-5 ha\n- 5-15 ha\n- 15-50 ha\n- 50-100 ha\n- 100-500 ha\n- 500-1,000 ha\n- 1,000-10,000 ha\n- > 10,000 ha\n5.8 Land ownership, land use rights, and water use rights\n- individual, titled\nLand use rights:\n6. Impacts and concluding statements\n6.1 On-site impacts the Technology has shown\nIncome and costs\nSLM/ land degradation knowledge\nWater cycle/ runoff\nexcess water drainage\nsoil organic matter/ below ground C\nBiodiversity: vegetation, animals\nOther ecological impacts\n6.2 Off-site impacts the Technology has shown\nreliable and stable stream flows in dry season\ngroundwater/ river pollution\n6.4 Cost-benefit analysis\nHow do the benefits compare with the establishment costs (from land users’ perspective)?\nHow do the benefits compare with the maintenance/ recurrent costs (from land users' perspective)?\n6.5 Adoption of the Technology\nIf available, quantify (no. of households and/ or area covered):\n200 land user families have adopted the Technology without any external material support\nThere is no trend towards spontaneous adoption of the Technology\nComments on adoption trend: There isn’t a strong trend now towards growing spontaneous adoption: uptake has slowed dramatically as many conservative farmers prefer to continue their traditional tillage practices.\n6.7 Strengths/ advantages/ opportunities of the Technology\n|Strengths/ advantages/ opportunities in the compiler’s or other key resource person’s view|\nLand that previously was un-farmable is now under crops. Site inspection shows initially poor land to be now in good condition (after only 5 years). The value of the land has increased\nHow can they be sustained / enhanced? Farmers practising CT/NT can and are buying/leasing more land, which will improve the overall state of the land in Queensland.\nFarmers can manage much larger growing areas with less personnel and equipment. A single operator is well able to run a large arable farm on his own\nHow can they be sustained / enhanced? Ditto.\nCereal farming is now less prone to yield losses (and crop failure) in drought years – as there is better rainwater infiltration and water use efficiency with CT/NT\nHow can they be sustained / enhanced? Continue with the system.\n|He has all weeds under control (without need for tillage).|\n6.8 Weaknesses/ disadvantages/ risks of the Technology and ways of overcoming them\n|Weaknesses/ disadvantages/ risks in the compiler’s or other key resource person’s view||How can they be overcome?|\n|The contract harvester runs on 3 m wide axles, so the wheels run on the beds. However, there has only been one wet harvest in 5 years so the incidence of soil compaction from harvesting is negligible||This is not really seen as a problem. One solution would be to build a dedicated harvester (too expensive) or find a contractor with equipment that fitted the system.|\n|A conservative mentality towards conservation agriculture is constraining the adoption of the system by other farmers||Continue demonstrating and disseminating knowledge about benefits.|\n7. References and links\n7.1 Methods/ sources of information\n7.2 References to available publications\nTitle, author, year, ISBN:\nBlackwell P (1998) Customised controlled traffic farming systems, instead of standard recommendations or ‘tramlines ain’t tramlines’.In Second national controlled farming conference, pp. 23–26. Eds JN Tullberg and DF Yule.\nAvailable from where? Costs?\nGatton College: University of Queensland\nTitle, author, year, ISBN:\nHulme PJ, McKenzie DC, MacLeod DA and Anthony DTW (1996) An evaluation of controlled traffic with reduced tillage for irrigated cotton on a Vertisol.\nSoil and Tillage Research 38:217–237\nTitle, author, year, ISBN:\nMcGarry D, Bridge BJ and Radford BJ (2000). Contrasting soil physical properties after zero and traditional tillage of an alluvial soil in the semi-arid tropics. Soil and Tillage Research 53:105–115"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"temporal_focus","category_name":"atemporal"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:af9dd96c-4d30-4a93-9431-853dd63dbf04>","<urn:uuid:3b7d88af-256a-4201-a206-a132bb775170>"],"error":null}
{"question":"What's the link between climate extremes impact on buildings and metal contamination in honey - are they both affected by urban development?","answer":"Yes, urban development affects both issues, but in different ways. For buildings, urbanization contributes to climate change which leads to more extreme weather conditions, affecting building energy performance and requiring new robust design approaches to handle both typical and extreme conditions. For honey production, urbanization and industrialization create environmental problems through emissions, dust, and ash that introduce heavy metals into the environment. These metals are then picked up by bees during their foraging activities and accumulate in honey products. The metals come from various urban sources including industrial emissions, traffic, and agricultural practices near residential areas.","context":["Climate robust buildings: towards buildings with a robust energy performance under climate change\nMetadataShow full item record\nBuilding performance simulation (BPS) is a powerful tool allowing building designers to estimate the behavior of buildings and assess the impacts of their design decisions on their performance. BPS requires large number of input variables, of which some can be predicted during design phase with reasonable certainty such as thermal properties of materials and building dimensions, and some are difficult to be predicted, such as climate and occupancy. Climate as an input variable in BPS is the main theme of this PhD work. Climate conditions are key input variables for BPS, but traditionally and for simplification, a typical climate condition is used to represent the most likely condition that a building will experience. Such approach results for the final designs to be sensitive to variation of climate conditions and even fail to provide expected performance when the conditions are beyond typical ranges. Such sensitivity of buildings to atypical climate conditions is becoming more critical considering that due to climate change the frequency and intensity of extreme climate conditions is increasing. This thesis provides an overview of the risks induced by climate change on the performance of buildings and provide a method for protection against future climate uncertainty. The first step towards protection against climate uncertainty is to identify the climate conditions that a building might face during its life span. The work identifies a prospect of climate conditions for built environment as: climate normals or typical climate conditions and climate extremes. Climate extremes are distinguished into two: foreseeable extreme conditions and unforeseeable extreme events. It further discusses to which extent these conditions can be considered during the design phase of buildings. After identifying the possible climate conditions, a work was set to create a framework that conceptualise protection for buildings against all these conditions. After reviewing the concepts and definitions provided in the literature, the two concepts of «robustness» and «resilience» were found appropriate for the aimed framework. According to the defined framework, the concept of robustness is the most proper to deal with typical and foreseeable extreme climate conditions, where in this concept the main focus is on reducing the sensitivity of performance under presence of source of uncertainty. The discussion on protection against unforeseeable extreme events falls into the concept of resilience, where withstanding and recovery mechanisms should be considered and was out of scope of this thesis. Based on the framework a climate robust building is “a building that, while in operation, can provide its performance requirements with a minimum variation under typical and foreseeable extreme climate conditions“ In the second step, a total of 74 representative weather files are synthesized for city of Geneva to account for future foreseeable extreme conditions together with typical climate conditions. The aim is to investigate the impacts of these conditions on the energy performance of single buildings and their combination to create a virtual neighborhood. The results showed, depending on the type of building, the relative change of peak load for cooling demand under near future can be up to 28.5% higher for extreme conditions compared to typical conditions. Furthermore, the results for the neighborhood demonstrate the critical situation that an energy network may face due to increased peak load under extreme climatic conditions. It is concluded that only those weather files that take into consideration both typical and extreme conditions are the most reliable for providing representative boundary conditions to test the energy robustness of buildings under future climate uncertainties. In the final step, a method is proposed in this work, in which three future weather files including typical, extreme warm and extreme cold conditions are used in a simulation-based optimization process. The method allows architects and engineers to effectively consider future climate uncertainties during the design phase and achieve solutions with robust energy performance against these uncertainties. Using only three weather files make the process feasible and computationally inexpensive. To test the effectiveness of the method, the primary energy use of an obtained optimum solution is calculated for the 74 weather files. According to the results, the performance of the optimum solution not only has 81.5% lower variation (less sensitivity to climate uncertainty) but at the same time 14.4% lower mean value of energy use in comparison to a solution that is compliant with a recent construction standard (ASHRAE 90.1-2016). Less sensitivity to climate uncertainty means better robustness against climate change and simultaneously keeping a high performance. The simplicity and the low computational demand of the process ascertain the feasibility and applicability of this method. The approach can be used at any stage of design process and can help architects and engineers to improve robustness of their design against future climate uncertainties.\nHas partsPaper 1: Moazami, Amin; Carlucci, Salvatore; Causone, Francesco; Pagliano, Lorenzo. Energy retrofit of a day care center for current and future weather scenarios. Procedia Engineering 2016 ; Volum 145. s. 1330-1337\nPaper 2: Pagliano, Lorenzo; Carlucci, Salvatore; Causone, Francesco; Moazami, Amin; Cattarin, Giulio. Energy retrofit for a climate resilient child care centre. Energy and Buildings 2016 ; Volum 127. s. 1117-1132\nPaper 3: Moazami, Amin; Carlucci, Salvatore; Geving, Stig. Critical Analysis of Software Tools Aimed at Generating Future Weather Files with a view to their use in Building Performance Simulation. Energy Procedia 2017 ; Volum 132C. s. 640-645\nPaper 4: Moazami, Amin; Nik, Vahid; Carlucci, Salvatore; Geving, Stig. Impacts of the future weather data type on the energy simulation of buildings – Investigating long-term patterns of climate change and extreme weather conditions. Applied Energy 2019 ;Volum 238. s. 696-720\nPaper 5: Moazami, Amin; Carlucci, Salvatore; Geving, Stig. Robust and resilient buildings: A framework for defining the protection against climate uncertainty. Submitted to IAQVEC 2019 conference in Bari, Italy. Is not included due to copyright restrictions.\nPaper 6: Moazami, Amin; Carlucci, Salvatore; Nik, Vahid; Geving, Stig. Towards climate robust buildings: an innovative method for designing buildings with robust energy performance under climate change. Energy and Buildings 2019 ; Volum 202. s. – © 2019. This manuscript version is made available under the CC-BY-NC-ND 4.0 license http://creativecommons.org/licenses/by-nc-nd/4.0/","Honey is commonly produced by bees using nectar extracted from flowers. It is a widely known sweetener that has been used across the world since ancient times. In addition to being a natural sweetener, it has also been used as a remedial agent [1, 2].\nWhile there is a wealth of data available on the properties of honey from regions such as North America, Europe, Australia, India, and South Africa, information on Libyan honey is scarce. To address this gap, our paper outlines our initial findings from analyzing honey samples collected from sixteen locations in the east, two locations in the west, and two additional locations in the southwest regions of Libya.\nBeekeeping is often undertaken in locations situated in or near residential and industrial areas.\nHowever, if bee colonies are placed in unsuitable or inadequate apiaries, or if incorrect production methods are employed, this can adversely affect the quality and natural characteristics of bee products. In addition, environmental problems that result from population growth, urbanization, industrialization, and changing consumption patterns are becoming more prevalent.\nFor instance, plants can accumulate heavy metals from dust and ash emissions released into the air from various sources .\nBees come into contact with metal pollutants during their flights and while collecting water, pollen, and nectar as food resources. These metals accumulate in the bodies of bees and in the hive products they produce, which can have negative effects on their survival, physiology, and behavior .\nThe primary sources of heavy metals in agricultural soil are inorganic and organic fertilizers, which are substances added to the soil to improve plant growth and yield, along with sources such as liming, sewage sludge, irrigation waters, and pesticides .\nHeavy metal toxicity is a cause for environmental worries in regions where mining, industry, and agriculture processes are present. This is because, when present in high concentrations, heavy metals can be fatal to honey bees.\nHowever, it remains unclear how sublethal doses of heavy metal contamination may affect bees or if bees will consume food that is contaminated .\nMaterilas and Methods\nThe samples were collected from different areas in Libya (Tables 1 and 2). East regions (Elqwarsha, Ras Elhelal, Sousa, Wadi Alkoof, Jurds, Elhemida, Taknis, Deryana, Elabiar, Benqerdan, Elmari, and Ejdabia) samples 2-16; west regions (Qasr Elshrief, Masallata, and Mesrata) samples 1, 17, and 18; southeast region (Tazerbo) samples 19 and 20; and southwest region (Aobari).\nAbout 1 g of the representative sample was measured by using a sensitive analytical balance and transferred to a 25 mL volumetric flask, heated in a water bath to decrease the viscosity 0.25 mL nitric acid and 2.5 mL concentrated hydrogen peroxide were added, followed by 0.1 mL of ammonium dihydrogen phosphate to those samples being analyzed tree elements (Ni, Cd, and Pb). Then samples were diluted with 25 mL of deionized water and were sonicated for 5 minutes with continuous stirring. Finally, the samples were analyzed using the graphite furnace micro atomic absorption spectrometry . In Micro Analytical Center, Faculty of Science, Cairo University.\nTable 1. Name of Location where honey samples were collected and surrounding nature of hives\nTable 2. The Location and type or name of honey samples\nResults and Discussion\nThe results of this work are summarized in the following: The mineral content of honeys can be influenced by various factors, including temperature, humidity, soil, floral type, and other parameters . Therefore, it is not possible to make definitive conclusions about the mineral content of honey.\nThis discussion will focus on nickel, cadmium, and lead, which are trace elements that have toxic properties . If recommended amounts are exceeded significantly, other elements can also cause harmful effects .\nOne of the elements that has been measured in honey samples is nickel. The concentration of nickel in the samples ranges from 0.20-0.75 mg/kg with an average of 0.436 mg/kg (as presented in the table). These findings are consistent with Romanian honey samples, which have a concentration range of 0.9 to 2.5 mg/kg .\nOur results show lower ranges as compared to the honey samples obtained from Siena (Italy), where the range varies from 0.017 to 0.049 mg/kg .\nThe second component in our investigation is cadmium (Cd) which is a weighty metal that is toxic  and not necessary for human health . Cadmium concentration in the honey sample ranges (0.25-1.75) mg/kg with a mean of 1.0538 mg/kg, as listed in Table 3. Therefore when we comprise our results with the Polish standard permits of Cadmium in honey which are (0.1 mg/kg)  and the maximum residues limits (MRL), proposed for the ER also (0.1 mg/kg) , we see all our results are higher than these limits.\nWe observed that all the Libyan honey samples analyzed in our study were found to be contaminated with a hazardous element.\nTable 3. The concentration of elements (Ni, Pb, Cd) in different locations samples\nAs we previously mentioned, the source of this metal could potentially be from the steel or galvanized containers utilized during processing, shipment, or storage . Industry, miming automobile exhaust gases may cause Cadmium contamination in honey [17,18].\nLead (Pb) is one of the three most significant toxic heavy metals .\nThe concentration of lead and cadmium in honey samples ranges from 0.25-51.00 mg / kg, with an average of 9.400 mg / kg, as provided in Table 3. All results indicate that each sample contains a certain amount of lead, and most of these samples have very high concentrations of this element. This high concentration implies that the honey samples have been exposed to lead pollution due to one or more of the reasons mentioned earlier. When we compare our findings with the approved limit of lead in honey according to the Polish standards, which is 0.4 mg/kg . Furthermore, the EU has proposed a maximum residue limit (MRL) of 1.0 mg/kg .\nAll of our results exceed the specified limits, except for samples with numbers 4, 6, 15, and 19. However, the Czech bylaw 298/1997 permits a tolerable amount of lead up to 8.0 mg/kg. In comparison, the Romanian honey samples had a lead concentration ranging from 1.0 × 10-4 to 0.2 mg/kg .\nThe range for honey produced in England is between 0.002 to 0.2 mg/kg . Honey in Siena (Italy) with a range from 0.0032 to 0.186 mg/kg , honey from Burgos (Spain) with range from 0.004 to 0.127 mg/kg .\nChilean honey, which ranges from 0.01 to 0.11 mg/kg , and Middle Anatolia honey (Turkey) which ranges from 0.0176 to 0.032 mg/kg , was much lower than our results.\nAll honey samples contain varying levels of certain elements, making it difficult to draw definitive conclusions about their origins. This is because honey, being a product of bees, can provide evidence of environmental pollution within an area of approximately 7 km2. Therefore, we collected some information from beekeepers about each sample under study to set some probabilities of the presence of these elements (Table 1). The levels of trace elements nickel, cadmium, and lead (Ni, Cd, and Pb) were measured and unfortunately, it was discovered that different levels of these elements are present in all honey samples analyzed. In other words, the honey has been contaminated with these trace elements, and we have outlined the likelihood of their presence. The level of nickel concentration in the sample was relatively low, and fortunately, it falls within the acceptable limits of nickel in food. However, it is believed that the main source of nickel presence is due to the use of steel or galvanized containers in different stages of processing, shipping, or storage. Another possible factor could be water supply used by the honeybees in their colonies, which may have been transported in galvanized containers. The elevated average lead concentration found in Libyan honey samples suggests that these samples have been exposed to lead pollution. However, the reliable interpretation of these results might be hindered due to those variables that are currently unknown. There is a possibility that some of the honey samples contain high levels of lead, possibly due to various factors such as insecticides, proximity to high traffic roads, human activity, or even the use of paint containing lead in the beehives.\nNo potential conflict of interest was reported by the authors.\nThis research did not receive any specific grant from funding agencies in the public, commercial, or not-for-profit sectors.\nAll authors contributed to data analysis, drafting, and revising of the paper and agreed to be responsible for all the aspects of this work.\nNajwa H Ansir\nHow to cite this manuscript: Najwa H Ansir*, khalid M darwish, Abdalslam Azzouz, Nuha El- Naas, Mohammed Y Gargoghil. Study and Estimation of Some Trace Elements (Ni, Cd, Pb) Content in Libyan Honey. Asian Journal of Green Chemistry, 7(4) 2023, 250-257. DOI: 10.22034/ajgc.2023.397344.1391"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"comparison"}],"document_ids":["<urn:uuid:f35f7e2f-4c40-4d59-b039-a1641260786f>","<urn:uuid:046eaaa9-a1d8-4863-853c-8049fa09122d>"],"error":null}
{"question":"What are the key differences in treatment approaches between Little League Elbow and Tennis Elbow, particularly regarding rest periods and rehabilitation exercises?","answer":"Both conditions share some similar treatment approaches but have distinct protocols. For Little League Elbow, the primary treatment is complete cessation of throwing while the growth plate is inflamed, along with ice packs for 20-30 minutes every 3-4 hours for 2-3 days. Specific rehabilitation exercises are prescribed, including wrist range of motion, forearm range of motion, and elbow range of motion exercises. For Tennis Elbow, treatment follows the R.I.C.E. method, with ice application for about 15 minutes several times daily. Additional treatments include braces and splints to support the forearm and physical therapy. While Little League Elbow requires careful monitoring of throwing activities for return to sport, Tennis Elbow may require surgery if symptoms persist after 6-12 months of conservative treatment.","context":["Little League Elbow\nWhat Is Little League Elbow? Little League Elbow (aka medial apophysitis) is pain on the side of the elbow that is closest to the body. The elbow joint is made up of the bones in the upper arm (humerus) and one of the bones in the lower arm (ulna). The bony bumps at the end of the humerus are called epicondyles. The bump closest to the body is called the medial epicondyle, and the bump on the outer side of the elbow is called the lateral epicondyle. The muscles that work to bend the wrist attach at the medial epiconyle, and the muscle that work to straighten the wrist attach at the lateral epicondyle. Too much bending of the wrist will irritate the muscles that attach to the medical epicondyle. In a child, the bones grow from areas called growth plates at the medial apophysis. There is a growth plate at the medial epicondyle called the medial apophysis. In Little League elbow this growth plate is irritated or inflamed.\nHow Does It Occur? Little League elbow is caused by too much throwing. Too much throwing puts stress on the muscles that bend the wrist where they attach to the inner side of the elbow. The growth plate becomes inflamed. In severe cases, the growth plate may actually break way from the upper arm.\nWhat Are The Symptoms Of Little League Elbow? Little League Elbow causes pain at the inner side of the elbow. There may be swelling and tenderness\nHow Is Little League Elbow Diagnosed? It is advisable to see a doctor who will examine your child's arm and elbow. Usually there will will be tenderness along the medial epicondyle. It is common for a child to feel pain when he or she throws a ball for the doctor. X-rays may show irritation or a break in the growth plate.\nHow Is Little League Elbow Treated? The most important treatment for Little League elbow is to not throw if the growth plate is inflamed. Ice packs should be placed on the elbow for 20 to 30 minutes every 3 to 4 hours for 2 to 3 days or until the pain goes away. An elastic elbow wrap may be placed on the inflamed elbow to give it more support. The doctor may give your child an anti-inflammatory medication. Your child will be given rehabilitation exercises to help encourage the healing process. In severe cases of Little League elbow where there is a break in the bone, surgery may be needed.\nWhen Can My Child Return To His Or Her Sport Or Activity? The goal of rehabilitation is to return your child to his or her sport or activity as soon as is safely possible. If your child returns too soon the injury may be worsened, which could lead to permanent damage. Everyone recovers from an injury at a different rate. Return to your child's sport or activity will be determined by how soon the elbow recovers, not by how many days or weeks it has been since your child's injury occurred. In general, the longer your child has symptoms before starting treatment, the longer it takes to get better. Your child may begin throwing when there is no swelling around the injured elbow and it has regained its normal strength compared to the uninjured elbow. Your child must have full range of motion of the elbow. Throwing should be gradually increased but stopped if the elbow becomes painful. A quality elbow support can be helpful in relieving discomfort when necessary.\nHow Can Little League Elbow Be Prevented: The best way to prevent Little League elbow is to limit the amount of throwing a child does. Since this problem occurs the most in pitchers, there are guidelines for how many pitches or innings a child can throw in a week. In general, a child ages 9 through 12 years old should pitch a maximum of 6 innings per week (and no more than 250 pitches). A youngster ages 13 through 15 should pitch a maximum of 9 innings per week (and no more than 350 pitches).\nLittle League Elbow Exercises: You may do stretching exercises 1 through 3 right away. You may do strengthening exercises 4 through 6 when stretching is painless.\n- Wrist range of motion: Bend your wrist forward and backward as far as you can. Repeat 10 times. Do 3 sets.\n- Forearm range of motion: With your elbow at your side and bent 90 degrees, bring your palm facing up and hold for 5 seconds then slowly turn your palm facing down and hold for 5 seconds. Repeat 10 times. Do 3 sets. Make sure you keep your elbow bent at 90 degrees throughout this exercise.\n- Elbow range of motion: Gently bring your palm up toward your shoulder and bend your elbow as far as you can. Then straighten your elbow out as far as you can. Repeat 10 times. Do 3 sets.\n- Wrist strengthening: A) Wrist flexion: Holding a soup can or hammer handle with your palm up, slowly bend your wrist up. Slowly lower the weight and return to the starting position. Repeat 10 times. Do 3 sets. Gradually increase the weight of the can you are holding. B) Wrist extension: Holding a soup can or hammer handle with your palm down, gently bend your wrist up. Slowly lower the weight and return to the starting position. Repeat 10 times. Do 3 sets. Gradually increase the weight of the can you are holding. C) Wrist radial deviation strengthening: Put your wrist in the sideways position with your thumb up. Holding a can of soup or hammer handle, gently bend your wrist up with your thumb reaching towards the ceiling. Slowly lower to the starting position. Do not move your forearm throughout this exercise. Repeat 10 times. Do 3 sets.\n- Pronation and supination strengthening: Hold a soup can or hammer handle in your hand and bend your elbow 90 degrees. Slowly rotate your hand with palm upward and then palm down. Repeat 10 ties. Do 3 sets.\n- Elbow flexion and extension: Hold a can of soup with your palm face up. Slowly bend your elbow so that your hand is approaching your shoulder. Then lower it slowly so your elbow is completely straight. Repeat 10 times. Do 3 sets. Slowly increase the weight you are using.\nAll material provided is designed for information purposes only and should not be used to replace the care of a health care professional. Do not rely on any of the information for diagnosis or treatment. It is recommended that you visit a qualified health care professional for individual and personal attention.\nShow more Show less","TENNIS ELBOW (LATERAL EPICONDYLITIS)\nTennis elbow, or lateral epicondylitis, is a type of tendinitis that causes pain in the elbow and arm, and is the most common reason that people see a physician for elbow pain. Tennis elbow is an overuse injury that causes inflammation to the tendon that joins the forearm muscles on the outside of the elbow. Despite its name, you do not have to be an athlete, or play tennis, to develop tennis elbow. Any repetitive gripping activities, especially movements using the thumb and first two fingers, can contribute to tennis elbow.\nTennis elbow affects the tendons attached to the muscles on the outer (lateral) side of the elbow, which work to extend the wrist backwards and straighten the fingers. In contrast, golfer’s elbow affects the tendons attached to the muscles on the inner (medial) side of the elbow, which work to flex the wrist and contract the fingers when you grip something.\nCOMMON CAUSES OF TENNIS ELBOW\nTennis elbow usually develops slowly over time due to repetitive stress placed on the tendons on the outside of the elbow. Continuous stress can eventually cause microscopic tears in the tendons that connect your forearm muscles to the bones in your elbow, resulting in inflammation and discomfort.Activities such as tennis, weight lifting, gardening, throwing, and swimming can all cause damage to the tendons in the elbow. People with jobs or hobbies that require repetitive arm movements or gripping that require turning the wrist can also develop tennis elbow over time. This would include hair stylists, carpenters, plumbers, knitting, painting, and more.\nCOMMON SYMPTOMS OF TENNIS ELBOW\nSymptoms of tennis elbow include pain and tenderness in the bony knob on the outside of your elbow. The injured tendon connects to the bone where this knob is located. Pain from tennis elbow can radiate into the upper and lower arm as well. Even though the damaged tendon is located in the elbow, painful symptoms are likely to occur when doing things with your hands. Patients often experience painful symptoms when:\n- Lifting objects\n- Gripping an object, such as a tennis racket\n- Opening a door or shaking hands\n- Raising your hand or straightening your wrist\nTo diagnose tennis elbow, your physician will first conduct a physical exam to assess symptoms such as swelling and tenderness in the elbow. The physician will also perform a series of movements to check your arm, wrist, and elbow to try and replicate any painful symptoms. X-rays help determine the condition of the elbow and can help rule out other potential problems. An MRI may also be needed in order to see of soft tissues (muscles, ligaments, tendons) within the elbow.\nTennis elbow, or lateral epicondylitis, is usually treated effectively with rest. The R.I.C.E. method is a simple self-care technique that helps reduce swelling, ease pain, and speed the healing process.\n- Rest: when you begin experiencing pain and discomfort in the elbow to help reduce inflammation and give the tendon time to heal\n- Ice and Cold Packs: can help reduce pain and swelling. Ice should be applied for about 15 minutes several times a day\n- Over-the-counter anti-inflammatory medication: such as Ibuprofen (Advil, Motrin) and naproxen (Aleve) can ease mild to moderate pain and reduce inflammation\n- Braces and Splints: supportive bracing on the forearm can help take pressure off the tendons in the elbow. A wrist splint worn at night can help rest the muscles and tendons in the lower extremities\nYour physician my also recommend a corticosteroid injection to treat painful symptoms and reduce inflammation in the elbow. Physical therapy can also help reduce pain, speed the recovery process, and reduce the risk of reinjuring the elbow.\nConservative treatments usually work for tennis elbow. However, if painful symptoms remain after six to twelve months of conservative treatment, you may need surgery. The surgical procedure for tennis elbow involves removing any damaged muscle and reattaching healthy muscle back to the bone. Physical therapy will be an important part of the recovery process. Full recovery time may take three to six months."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:351bf85f-53ff-499f-b8c7-6d4b39ecb959>","<urn:uuid:b98af60b-cde5-4947-bb6d-83e8698af43c>"],"error":null}
{"question":"How have historical developments in decarboxylation influenced modern cannabis storage practices, and what scientific principles connect these two aspects of cannabis preparation?","answer":"Decarboxylation's historical development since the late 19th century, when chemists discovered that certain organic compounds transform when heated, has influenced modern cannabis storage practices. This scientific understanding shows that both processes involve careful control of environmental factors. In storage, elements like humidity, temperature, airflow, and light must be regulated to preserve cannabinoids and terpenes. Similarly, decarboxylation requires precise control of factors like temperature, time, environment, and moisture content. The connection between these aspects is particularly evident in how both processes aim to manage the transformation of cannabis compounds - storage focuses on preventing unwanted changes, while decarboxylation intentionally triggers beneficial chemical reactions. Modern innovations in both areas emphasize precision and control, whether through humidity packs for storage or advanced decarboxylation devices with precise temperature controls.","context":["- Humidity, light, temperature and oxygen affect the taste, smell and potency potential of cannabis.\n- Keep cannabis in a cool, dry spot, away from direct sunlight.\n- Tools such as hygrometers, humidity packs and humidors can help maintain freshness.\nAlthough packaged dried cannabis does not generally include an expiry date, there are ways to keep it fresh and prolong each strain’s unique flavours, aromas and colours, as well as its maximum potency potential. Read on to learn how to properly preserve and store your cannabis after purchase.\nKeep tabs on humidity, temperature, airflow and light – which can cause adverse effects if left unchecked.\nWhen storing your cannabis, take the following into consideration:\nHumidity: Ideally, cannabis should be stored at a relative humidity (RH) of 59% to 63%. Too much moisture, and mould and bacteria will grow, producing unpleasant flavours and odours. At the same time, too little humidity in your storage container, and the trichomes that contain the terpenes and cannabinoids will break down, and the essential oils will dry out.\nTemperature: The temperature at which you store your cannabis affects its overall freshness— warm air holds more moisture than cold air, so it’s best to keep cannabis below 25°C to reduce the opportunity for mould to grow.\nAirflow: Oxygen is a tricky element to regulate but having an excess of it in your storage container will increase the speed of degradation, while having not enough can affect the humidity, especially if the cannabis is not quite dry to begin with.\nLight: Above all, limiting exposure to light plays the largest role in preserving dried cannabis. Simply storing cannabis products out of direct sunlight will prevent them from breaking down too quickly.\nTo shop storage solutions, click here.\nSo how can I manage all of these factors and keep my cannabis fresh?\nMuch like wine, cannabis is best kept in a cool, dry location, such as a low shelf or basement (just ensure it’s in a secure container and stored away and out of the reach of children and pets – we recommend using lockable containers). Avoid plastic, which can have a static charge that will attract the trichomes.\nDo not store dried flower in the fridge, which has fluctuating temperatures and moisture that can promote mould. Freezing is out, too, as the low temps can cause trichomes to become brittle and break easily when handled.\nOther cannabis products, such as oils or capsules, can be stored at either room temperature or in the refrigerator but be sure to always follow the manufacturer’s directions before doing so. Remember to clearly mark any products that you store in a refrigerator.\nThere are a lot of accessories available to help you keep track of elements, such as moisture, humidity and oxygen, when storing your cannabis.\nAvoid using tobacco humidors to store your cannabis, since they are often made of cedar and can add oils to your product. However, if you choose to use a humidor made of cedar, you can avoid direct contact between the wood and the dried flower by using additional products such as a glass storage jar. Shop for cannabis humidors, here.\nWhen storing your cannabis, there are a lot of factors to consider so do your research. But above all, rely on your senses to determine whether the quality has degraded — if the cannabis has no aroma or smells “off”, it’s best not to use it.","Decarboxylation might sound like a term straight out of a scientist’s playbook, but in reality, it’s a simple concept that has significant implications for various industries and even in our everyday lives. In short, it refers to a chemical reaction that removes a carboxyl group from a molecule, releasing carbon dioxide in the process. Imagine it as a transformation phase where certain compounds “shed” a specific part of themselves to become something more active or useful.\nNow, you might be wondering: why does this matter to me? Whether you’re a fan of cannabis products, an aficionado of culinary arts, or just someone curious about the chemical changes in substances around us, understanding decarboxylation can unlock a world of insights. For enthusiasts, it’s the magic that makes THC and CBD — the main psychoactive and medicinal compounds — accessible to the human body. For cooks and chefs, it’s a process that can influence flavors and textures. And that’s just the tip of the iceberg. As we delve deeper into this topic, we’ll uncover the science, history, and practical applications of this intriguing chemical reaction.\nDecarboxylation might sound complex, but its historical roots trace back to the late 19th century. Early chemists observed that under specific conditions, certain organic compounds would transform when heated, releasing a gas. This gas, identified as carbon dioxide, led to the coining of the term ‘decarboxylation’ – a process describing the removal of a ‘carboxyl’ group.\nAs the years progressed, the significance of decarboxylation became apparent in tangible applications. By the early 20th century, it was instrumental in the development of synthetic dyes and various chemicals. This period marked the beginning of decarboxylation’s real-world impact, beyond laboratory confines.\nPharmaceuticals and the Cannabis Renaissance\nAs the 20th century advanced, decarboxylation’s role expanded into areas like pharmaceuticals and the emerging cannabis industry. For cannabis, it was a game-changer, turning the non-intoxicating raw plant into a sought-after source of relaxation and medicinal relief.\nBut decarboxylation wasn’t limited to labs or big industries. It has also found its way into our kitchens. Cooking processes that harness this chemical reaction can enhance flavors or offer unique textures, demonstrating its versatile application in everyday life.\nFrom its early days as a curious observation to its pervasive influence today, decarboxylation’s journey is a reflection of the interplay between science and practical application. As we move forward, we’ll further explore the intricacies of this process and its modern-day relevance.\nThe Science Behind Decarboxylation\nDecarboxylation is, at its heart, a chemical reaction. To really grasp its significance, let’s break down the basics:\n- Carboxyl Group: It’s a specific chemical group present in some organic molecules, and it looks something like this: -COOH. The “COO” part represents the carboxylate, and the “H” is a hydrogen atom.\n- The Process: When decarboxylation occurs, the molecule loses this -COOH group, releasing it as carbon dioxide (CO2). What’s left behind is a transformed molecule with new properties.\nFactors Influencing Decarboxylation\nSeveral elements can affect the rate and outcome of the decarboxylation process:\n- Temperature: One of the primary drivers of decarboxylation. Different compounds may require varying heat levels to effectively decarboxylate.\n- Time: Duration plays a pivotal role. Some compounds might decarboxylate quickly, while others may require extended periods.\n- Environment: The presence of air or certain catalysts can either hasten or inhibit the reaction.\n- Moisture: Some substances might need to be dried before effective decarboxylation can take place.\nThe Cascade Effect\nOne interesting facet about decarboxylation is that it often doesn’t occur in isolation. When one molecule undergoes this transformation, it can trigger other reactions within a substance, leading to a cascade of changes. This is particularly noticeable in complex mixtures like plant materials.\nUnderstanding decarboxylation isn’t just academic. For instance:\n- In the cannabis world, without decarboxylation, THC (the compound responsible for the “high”) remains in its non-psychoactive form, THCA. Only through decarboxylation does it become the potent THC many are familiar with.\n- In the realm of culinary arts, the process can have profound impacts on taste, aroma, and even texture.\nIn essence, decarboxylation serves as a pivotal gateway, converting potential into reality across various fields.\nApplications of Decarboxylation\nDecarboxylation isn’t a one-size-fits-all process. Depending on the industry or application, the methods and outcomes can vary widely. Let’s unveil its broad spectrum:\n- Activation of Compounds: Decarboxylation is critical for unlocking the potential of cannabinoids. Raw cannabis contains compounds like THCA and CBDA. It’s only through decarboxylation that these transform into THC and CBD, respectively.\n- Consumption Methods: From edibles to tinctures, almost all forms of cannabis consumption rely on decarboxylation to ensure effectiveness. For instance, when making cannabis-infused brownies, decarboxylating the weed before mixing ensures that the consumer gets the desired effect.\n- Safety and Consistency: Proper decarboxylation ensures users consume a consistent and safe product. Knowing how much active THC or CBD is in a product can aid in dosing and avoid overconsumption.\n- Flavor Profiles: It can change the taste and aroma of certain ingredients, offering chefs a tool to fine-tune dishes. For example, certain herbs may develop richer, more robust flavors upon decarboxylation.\n- Texture Transformations: Some ingredients, when decarboxylated, might change in texture, offering a novel culinary experience.\n- Pharmaceuticals: Beyond cannabis, it is vital in drug synthesis. By transforming molecules, new therapeutic agents or more efficient versions of existing drugs can be created.\n- Biofuel Production: Decarboxylation can be an integral step in transforming organic matter into usable fuels. By removing the carboxyl group from fatty acids, biofuels can be produced.\nWhile the applications span industries and disciplines, the universal thread is transformation. Decarboxylation, in essence, allows industries to tap into the latent potential of substances, whether for therapeutic, recreational, or functional purposes.\nCommon Methods of Decarboxylation\nWhile the concept of decarboxylation is universal, the ways it’s achieved can vary. Here, we delve into some of the most common methods, highlighting the pros and cons of each.\n- Process: Place the material on a baking sheet and bake at a controlled temperature, often between 220-250°F (104-121°C), for approximately 30 to 45 minutes. However, it’s important to note that the exact time can vary depending on the material’s moisture content, the desired level of decarboxylation, and individual oven variances.\n- Accessible for most people; ovens are common household appliances.\n- Relatively easy to do with minimal equipment.\n- Risk of uneven decarboxylation if not monitored closely.\n- Temperature fluctuations can lead to less efficient conversion.\n- Process: Using a microwave to heat the material in short bursts, usually not more than a few minutes in total.\n- Quick and convenient.\n- Suitable for small batches.\n- Higher risk of overheating and destroying valuable compounds.\n- Not as consistent or uniform as other methods.\n- Process: Sealing the material in a vacuum bag and submerging it in a water bath with a precise temperature control for extended periods.\n- Highly accurate temperature control.\n- Lower risk of destroying compounds due to overheating.\n- Requires specialized equipment.\n- Longer duration compared to other methods.\nMaking the Choice\nThe ideal method often depends on the specific goals, available equipment, and the material being decarboxylated. For instance, a home chef or casual cannabis user might prefer the oven method for its simplicity, while a professional might invest in a sous-vide setup for precision. Understanding the intricacies of each technique empowers individuals to make informed decisions tailored to their needs.\nThe Importance of Precision\nDecarboxylation, while a transformative process, is delicate. Achieving the desired outcome often hinges on maintaining precision throughout the procedure. Let’s delve into why accuracy is paramount and the potential pitfalls if overlooked.\n- Fine Line: Many compounds, especially in the cannabis world, have a narrow window of optimal decarboxylation temperatures. A deviation, even if slight, can compromise the integrity of these compounds.\n- Overheating Risks: Excessive heat can not only prevent proper decarboxylation but also degrade or destroy valuable compounds, leading to reduced potency or altered effects.\n- Underheating Dilemmas: Insufficient heat might result in partial decarboxylation, leading to an inconsistent or subpar end product.\n- Duration’s Dual Edge: Just as with temperature, the duration can influence the end product. Too long can lead to degradation, while too short might not activate the compounds fully.\n- Consistent Monitoring: Keeping a close eye on the process, and possibly adjusting based on observations, ensures optimal results.\n- Air Exposure: Extended exposure to air, especially during decarboxylation, can oxidize some compounds, altering their properties or effectiveness.\n- Moisture Intricacies: While some methods require a dry material, others might utilize moisture as part of the process. Understanding the role of humidity is crucial for each specific method.\nNavigating with Knowledge\nPrecision in decarboxylation isn’t just about following a recipe to the letter. It’s about understanding the nuances of the material, the desired outcome, and the tools at hand. By grasping the importance of each variable, you can navigate this journey with confidence and finesse, ensuring the best possible results.\nRecent Advances & Future Outlook\nAs with many scientific and industrial domains, innovation drives evolution. Let’s explore the groundbreaking strides made in recent times and glimpse into what the future might hold.\n- Precision Equipment: The market is seeing the emergence of advanced devices with precise temperature controls and even heating mechanisms. Among these, the Ardent FX stands out as a dedicated machine for home users, specifically designed for the decarboxylation of cannabis. Such tools promise better consistency, optimal conversion, and preservation of valuable compounds.\n- Automated Systems: With the rise of AI and automation, there are now systems that monitor and adjust the decarboxylation process in real-time, reducing the margin for error.\n- Scaled Processes: For industrial applications, advancements in large-scale decarboxylation setups allow for mass production without compromising quality.\n- New Compounds: Ongoing research has identified other compounds, beyond THC and CBD in cannabis, that can benefit from decarboxylation, broadening its application.\n- Optimized Protocols: Studies are continually refining the “sweet spots” for decarboxylation, ensuring maximum yield and potency.\nSustainability and Efficiency\n- Eco-friendly Methods: As sustainability becomes a global focus, new decarboxylation techniques are being developed that reduce energy consumption or utilize renewable energy sources.\n- Waste Reduction: Advancements aim to minimize waste, ensuring that as much of the original material is utilized effectively in the decarboxylation process.\nCharting the Horizon While we’ve come a long way in understanding and harnessing decarboxylation, the journey is far from over. The fusion of technology, research, and a growing emphasis on sustainability promises a future where decarboxylation is even more precise, efficient, and eco-friendly. Whether for medical, recreational, or industrial purposes, the potential expansions of this process are boundless.\nDecarboxylation, from its humble scientific origins to its expansive applications today, stands as a testament to the marvels of chemical transformation. As we’ve journeyed through its history, mechanisms, applications, and future prospects, a few key themes emerge:\n- Unlocked Potential: At its core, decarboxylation is about transformation—turning raw materials into something more potent or accessible, be it the active compounds in cannabis or the refined flavors in culinary arts.\n- Precision’s Power: As we’ve underscored, the magic of decarboxylation hinges on precision. From temperature to time, and from equipment to environment, each variable plays a pivotal role in determining the success of the process.\n- Evolving Landscape: The realm of decarboxylation isn’t static. With each passing year, technological advancements and research breakthroughs are pushing the boundaries of what’s possible.\n- Universality & Specificity: While the principle of decarboxylation is universal, its applications are varied. Whether in pharmaceuticals, biofuels, food, or cannabis, the process is tailored to meet specific needs, showcasing its versatility.\nA Journey, Not a Destination\nAs we wrap up our exploration, it’s essential to recognize that our understanding of decarboxylation, like many scientific endeavors, is a journey, not a final destination. The future promises more discoveries, more innovations, and inevitably, more transformations. For the curious mind, the world of decarboxylation offers a rich tapestry of insights, waiting to be unravelled and appreciated.\nReferences and Further Reading\n- Smith, J. T., & Jones, R. S. (2019). Decarboxylation kinetics of cannabinoid acids. Journal of Cannabis Research, 1(1), 5.\n- “Decarboxylation Study of Acidic Cannabinoids: A Novel Approach Using Ultra-High-Performance Supercritical Fluid Chromatography/Photodiode Array-Mass Spectrometry”. Cannabis and Cannabinoid Research, University of Mississippi.\n- Russo, E. B. (2011). Taming THC: potential cannabis synergy and phytocannabinoid-terpenoid entourage effects. British Journal of Pharmacology, 163(7), 1344-1364."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:8948c86f-1cc2-4344-90e4-bc7d045c631f>","<urn:uuid:ee94064b-f610-4fba-a3f2-be542e017716>"],"error":null}
{"question":"What are the recycling sorting requirements for colored glass versus cardboard?","answer":"Colored glass and cardboard have different sorting requirements for recycling. For colored glass (blue, green, brown), it must be separated from clear glass during recycling since mixing different colors can diminish the quality and saleability of recycled glass. Many curbside programs require sorting colored glass from clear glass. For cardboard, it can typically be collected together with paper to maximize recycling opportunities while minimizing space. Cardboard must be kept clean and dry, though small amounts of contamination like grease are acceptable, and boxes should always be flattened before being placed in recycling containers.","context":["Cardboard, also referred to as old corrugated cardboard (OCC), is a readily recyclable material with well-established local markets for processing and manufacturing. Make sure cardboard is kept clean and dry as it is collected in your facility. Cardboard with a small amount of contamination, such as liquid or grease, can be recycled. Waxed cardboard should not be collected for recycling, but may be accepted by some commercial composting operations.\nCardboard boxes should always be flattened before being placed in a recycling container; the RecyclingWorks cardboard recycling graphic is available in six languages and can be used as a training tool and visual reminder for your staff: [English] [Spanish] [Portuguese] [Cape Verdean] [Simplified Chinese] [Haitian Creole]\nWhy should you recycle cardboard?\nIn Massachusetts, all recyclable paper, cardboard, and paperboard products are banned from disposal by the Massachusetts Waste Bans. According to the Massachusetts Department of Environmental Protection (MassDEP), cardboard in commercial loads of trash is one of the most common causes of a “failed load.”\nIn today’s economy, businesses and institutions recycle items like cardboard because it often saves them money on waste disposal costs. Recycling is also good for the planet and local communities because it helps conserve valuable resources, reduces pollution from production of new materials, and creates jobs. Some large generators of cardboard can bale or compact it, and market it directly to recyclers to receive revenue for this material.\nTo help businesses comply with Massachusetts Department of Environmental Protection Waste Ban for cardboard and other materials, RecyclingWorks developed the following sector-specific tip sheets, available in both English and Spanish. Tip sheets for additional business sectors will be posted below as they become available. If you are interested in having any of these materials translated into another language, please contact RecyclingWorks at (888) 254-5525 or firstname.lastname@example.org.\nHow does it get recycled?\nBusinesses in Massachusetts can work directly with their hauler to establish cardboard recycling services. Many haulers will collect paper and cardboard together, enabling you to maximize your recycling opportunities while minimizing the space you need for recycling. Please check with your hauler to confirm what types of paper should be collected together in your program.\nOnce picked up from the business or institution, this material is hauled to a facility where it is sorted and baled. The baled cardboard is then ready to be shipped to paper mills domestically and internationally for recycling into new paper products. There are local markets in Massachusetts where the entire process takes place. Trucks deliver loads of old corrugated cardboard, the material is inspected, pulped, rolled into sheets, corrugated, glued into new sheets, and cut into shape ready for market.\nWhat happens after it is recycled?\nRecycled cardboard is a high-quality material that can be used as packaging materials and boxes, and cardboard can be recycled many times without losing its strength. Corrugated cardboard containers that get used for shipping have a high percentage of post-consumer recycled content.\nWhat about pizza boxes?\nEmpty pizza boxes can typically be recycled, even if they contain grease. Remove all food, pizza savers (pizza tables), and liners. Liners and pizza savers should go in the trash, and any remaining food scraps should be composted or put in the trash.\nWhat about waxed cardboard?\nWaxed cardboard is commonly used in supermarkets, restaurants, and other food service businesses for products like ice-packed produce and meat, because the wax protects the cardboard from becoming soggy and breaking down. Unfortunately, this helpful feature also makes waxed cardboard unacceptable for recycling. Depending on the material characteristics and quantity, waxed cardboard can be composted or made into other products.\nCardboard Recycling Case Study: Wyman’s Liquors\nAfter receiving a failed load letter for excessive amounts of cardboard in the trash, Wyman’s Liquors made simple changes to their recycling program. Learn how Wyman’s came back in compliance with Massachusetts waste ban regulations and diverts 90% of the materials generated on-site.\nWyman’s Liquor Store Case Study: Learn more about how Wyman’s recycles cardboard, bottles, and cans throughout their retail space and offices. See the previous Wyman’s Liquors Case Study (2012) to learn more about program implementation.\nLearn about recycling other materials\nFor more information on other commonly recycled materials visit these pages:\n- Bottles & Cans\n- Construction Materials\n- Fluorescent Lamps/Light Bulbs\n- Food Waste\n- Single Stream\n- Find out how to start or improve your own recycling program.\n- Search our Recycler Database to find a hauler or processor for recyclable materials in your area.\n- Proper waste bin signage provides clear guidance on how to properly sort material, and can help improve the quality of materials collected for recycling or composting. Click here for an example of RecyclingWorks signage for cardboard.\n- To find out how you can purchase recycled products, check out our Buying Recycled Products\n- Learn about Massachusetts Waste Bans.\n- Use Recycle Smart MA for guidance on what materials are typically accepted for recycling in Massachusetts.","Recycling Colored Glass\nAn Overview on Recycling Blue, Green, Brown, & Clear Glass\nPretty blue glass bottles and fun green glass bottles add interest to our experience of glass, but recycling colored glass with clear glass can be an economic hazard. That’s because mixing different colors of glass in the recycling process can diminish the quality and saleability of recycled glass. Find out why separating colored glass from clear glass is important and how to go about doing it.\nHow to recycle blue, green, brown, and clear glass\nThough the basic glass recipe is similar across all types of glass, various types of glass are made with additional ingredients to impart various qualities, such as color, reflectivity, and so on. But because of these variable ingredients, certain types of glass have to be recycled separately from conventional glass. Colored glass is one such type of glass that requires special handling. Here’s why:\n- Recycling blue glass: Made with naturally-occurring iron impurities in sand, blue glass is used for food and beverage containers as well as glass for home design (tiles, flooring, stained glass, etc).\n- Recycling brown glass: The brown color found in this glass type is a result of things like carbon, nickel, and sulphur which is added to molten glass. Brown glass is used to make many food containers to protect what’s inside from direct exposure to sunlight. This preserves flavor and freshness, so is often used for things like beer and food that would easily oxidize in the presence of sunlight.\n- Recycling clear glass: Made with the basics of glass - sand, limestone, and so on - clear glass can be used for a wide variety of products, including food and beverage containers, electronics, home design products, and more.\n- Recycling green glass: Like brown glass, green glass is created by adding ingredients to the molten glass, including copper, iron, and chromium. It also protects its contents from exposure to sunlight and extremes of temperature and so green glass is often used for food and drink preservation.\nSo what’s involved in recycling colored glass?\n- Separation: Curbside recycling programs often require that you sort colored glass from clear glass. Check with your local recycling program office to find out whether you need to separate your colored glass from clear glass and then follow their recommendations.\n- Look for drop off centers: Whether your curbside program excludes colored glass or not, you may want to look for glass recycling drop-off programs. In many cases, by taking your used beer, soda, and wine bottles to these drop-off centers, you’ll be able to collect a deposit, which makes your recycling efforts somewhat profitable. You’ll find glass recyclers in our recycling database.\n- Find colored glass recyclers: If your curbside program does not accept colored glass for recycling, look for another provider willing to accept blue, brown, and green glass for recycling. Our recycling database has resources for how to find colored glass recyclers in your area.\n- Reuse colored glass: If there’s no company in your area that recycles your colored glass, first be sure to minimize your consumption of colored glass, and then find ways to reuse it. For instance, you could make your own wine and bottle it in blue glass. Or create crafts using colored glass containers. Use old colored jars to can fresh produce, and more!\nThings you should not include with your clear glass recycling\nThough there are many types of glass that can be recycled - both colored and clear - some glass types cannot be recycled with your regular curbside glass recycling. When “contaminants” are mixed in with glass to be recycled, it can decrease the value of the recovered glass, increase costs, slow production, reduce quality, and damage recycling equipment. As a result, you should not only remove metal and plastic lids and neck rings from your glass containers, but also be sure to keep the following types of glass out of your regular recycling bin:\n- Ceramic dishes and coffee cups\n- Clay gardening pots\n- Drinking glasses, including crystal and opaque glasses\n- Heat resistant glass cookware such as Pyrex or Visionware\n- Laboratory glass\n- Light bulbs (incandescent and compact fluorescents)\n- Window glass and mirrors"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:a9ce2765-d1a8-4833-94a6-c3c6574f4e77>","<urn:uuid:e41b805a-f708-46fb-90d3-85399c0108a8>"],"error":null}
{"question":"What were the historical African relationships with the Atlantic world, and how does this connect to modern anti-slavery advocacy in Africa? For example, are there any specific trade or cultural connections that still influence today's activism?","answer":"Historically, West Africa had significant engagement with the Atlantic world through trans-Atlantic slave trade and commerce, with cultural and economic links particularly strong between Brazil and Africa from the 16th to 19th centuries. This historical context connects to modern African anti-slavery advocacy through various forms, including national and international NGOs, political parties, grassroots movements, and religious associations. Today's African anti-slavery movements face distinct challenges and operate differently from African diaspora movements in Europe and the Americas. The activism addresses both historical legacies of slavery and contemporary forms of exploitation, with organizations working at both local and international levels to combat ongoing discrimination and human trafficking.","context":["Dr Toby Green\nSenior Lecturer in Lusophone African History and Culture\n+44 (0)20 7848 1741 Email firstname.lastname@example.org Address\nDepartment of History and Department of Spanish, Portuguese and Latin American Studies\nKing’s College London\nVirginia Woolf Building 5.28\nLondon WC2R 2LS\nResearch interests and PhD supervision\nAfter studying Philosophy, Toby Green worked as a writer and editor, publishing various books that have been translated into 12 languages. He then studied for his PhD at the Centre of West African Studies at Birmingham University, working with the Brazilian specialist on Timbuktu and Songhay Paulo de Moraes Farias and completing in 2007, before coming to King's in 2010.\nAfter holding fellowships from the British Academy and the Leverhulme Trust, in 2015 he was recipient of a British Academy Rising Star Engagement Award, for which he organised an interdisciplinary workshop with the musicologist Lucy Duran of SOAS, bringing musicians and historians from West Africa into dialogue.\nHe is currently the PI of an AHRC Leadership Fellowship Award, \"Money, Slavery and Political Change in Precolonial West Africa\" (May 2016 - August 2017). He has given seminars and contributed to symposia at various institutions in Brazil, France, Portugal, Senegal, The Gambia, The Netherlands, the UK and the USA.\nI aim to cross historiographical and geographical frontiers and to reconstruct the historical experiences of people who were born without the privileges of power, and who have been systematically written out of conventional historical narratives. I am primarily a historian of West Africa, and my work seeks to contribute towards a refocussing of the understanding of modern history by grasping the active roles of West Africans in shaping both global histories as well as local West African ones.\nI want to include these stories in the historical narratives of the early modern period and nineteenth century, when indigenous peoples around the world confronted European colonialism. Working in the \"Global North\", I seek also to work actively to reorient the privileges of academic power through collaborating with colleagues in the \"Global South\". I am currently active in collaborative projects with colleagues in Brazil, Guinea-Bissau, Mozambique, and The Gambia.\nMy research interests are broadly structured around West African engagement with the early Atlantic world through a number of themes. My monograph on the early trans-Atlantic slave trade was published by Cambridge University Press in 2012, as well as an edited volume on the precolonial history of Western Africa published by Oxford University Press for the British Academy, also in 2012, and an edited book with the late Patrick Chabal on contemporary Guinea-Bissau. published in 2016 by Hurst and Oxford University Press in the US. I am currently writing a book on precolonial West Africa's relations with world history through the lens of exchanges of money and power.\nSpecific areas of interest include:\n- Trans-Saharan and Trans-Atlantic Diasporas\n- The history of race and slavery in the Atlantic\n- Connections between the precolonial, the colonial and the postcolonial state in Africa\n- African economic history and its intersection with world economic history\n- Cultural and economic links between Brazil and Africa, 16th-19th centuries\nCurrent PhD supervision:\n- Dorothee Boulanger: The Use of Fiction as Historical Source in Postcolonial Angola\n- Joseph da Costa: Empire and Environmental Thought: Portuguese Humanism and the Creation of Universal Categories in the 16th Century\n- Neele Janke: Ethnicity and Political Parties in Contemporary Guinea-Bissau\n- Vincent Nadeau: African Origins of the Cuban Revolution\nFor more details, please see his full research profile.\nExpertise and public engagement\nToby Green (2012) (ed.) Brokers of Change: Atlantic Commerce and Cultures in Pre-Colonial Western Africa Oxford University Press for the British Academy [Edited Book in Print]\nToby Green (2012) 'Policing the Empires: a Comparative Perspective on the Institutional Trajectory of the Inquisition in the Portuguese and Spanish Overseas Territories (Sixteenth and Seventeenth Centuries)' HISPANIC RESEARCH JOURNAL, 13 (1), pp. 7-25. [Article in print Journal]\nToby Green (2011) 'Beyond the Culture Wars: Reconnecting African and Jewish Diasporas in the Past and the Present', in African Athena: New Agendas pp. 139-155 [Chapter]\nToby Green (2011) 'Building Slavery in the Atlantic World: Atlantic Connections and the Changing Institution of Slavery in Cabo Verde, Fifteenth-Sixteenth Centuries' Slavery and abolition, 32 (2), pp. 227-245. [Article in print Journal]\nTobias Green (2011) The Rise of the Trans-Atlantic Slave Trade in Western Africa, 1300–1589 Cambridge University Press [Authored Book in print]\nFor a complete list of publications, please see Toby's full research profile.\nToby Green is the Lead Consutant for the new OCR A Level History Option\"African Kingdoms, 1400-1800\", having written the accompanying ebook, and is a member of the OCR Consultative Forum for History. He has written widely for the national press, and has reviewed for The Independent, The London Review of Books and the TLS.\nHe has participated in collaborative projects with institutions including the Anneaux de la Memoire (Nantes), the British Library, and the National Centre for Arts and Culture in The Gambia. He is the Honorary Treasurer of the African Studies Association of the UK (ASAUK).","10 – 12 April 2018\nCall for Contributions\nSummer School in Mauritius Between Slavery and Post-slavery Citizenship, Dependence, and Abolitionism in African and Indian Ocean Societies Problem statement\nIn October 2014, the international conference Slavery in Africa: Past, Legacies and Present (SLAFCO) was held at the Catholic University of Eastern Africa (CUEA) in Nairobi. This three-day conference brought together over sixty scholars from all over the world and representatives of African anti-slavery NGOs and civil society organizations. Building on this first experience of exchange between researchers and activists, ‘Between Slavery and Post-Slavery’ will focus on (1) the recent legacies of past slavery; (2) contemporary forms of exploitation akin to slavery; and (3) the political mobilisation of African grassroots activists and politicians in various countries in Africa and in Atlantic Ocean and Indian Ocean islands.\n(1) Legacies of past slavery: This workshop will explore the political and social marginalization of persons of slave descent in different African societies today. In some contexts, groups of slave descendants are classified, collectively, through labels that indicate slave origins in particular African languages. These labels have derogatory connotations and are often accompanied by ideas about the sociocultural and biogenetic inferiority of those classified as slave descendants. These groups suffer from specific vulnerabilities ranging from political exclusion and ‘second-class citizenship’, to economic exploitation and restricted opportunities for social mobility, to increased exposure to violence and exactions. Contributions focused on slave descent will study identity-based discrimination: what forms it takes and what responses it elicits in terms of resistance and grassroots activism.\n(2) Slavery today: A second strand of phenomena examined here is the resilience of actual slavery, as an institution that enables control tantamount to possession over those enslaved. In spite of worldwide legal abolition, slavery has not ended. In the African continent illegal enslavement takes different forms. It can be a consequence of discrimination based on slave descent in areas where erstwhile slave-owners retained power and slave descendants remained vulnerable to extreme forms of exploitation. But slavery does not affect only persons of slave descent. Like elsewhere in the world, in Africa too, there is a persistent demand for cheap and easily controllable labour and exploitable persons. Human trafficking, especially in women and children, is well documented in different African regions and between Africa and other countries. Furthermore, recent African wars resulted in abductions and violence directed against civilians, primarily women, leading to the prosecution of perpetrators for crimes of sexual slavery. Some political movements, such as Boko Haram in Northern Nigeria, openly advocate the legitimacy of slavery as an institution. Contributions focused on slavery will consider its manifestations, discourses about slavery’s (il)legitimacy, and the resistance of those enslaved or at risk of enslavement.\n(3) African anti-slavery movements and grassroots activism: A third axis for reflection and discussion will focus on African anti-slavery NGOs and forms of political mobilization against slavery and the discrimination targeted at slave descendants. Some researchers described African anti-slavery NGOs as phenomena of extraversion, aimed at accessing international funding through links with ‘Western’ anti-slavery organisations. But African abolitionist movements are diverse. Some engage more with national politics than with international donors, as in the case of the Zoam Marxist movement founded by Malagasy slave descendants in the 1970s. Undoubtedly some of the main African anti-slavery NGOs benefit from the support of international anti-slavery organisations. But this does not make their struggles any less ‘real’. Their membership and opposition are national and local. Hence the question is not only whether the agenda of African anti-slavery NGOs chimes with the goals of global anti-slavery organisations: it clearly does. More specifically, we invite contributions that explore the meanings and functions of abolitionism in Africa today; the challenges identified by the leaders and grassroots members of these organisations, their driving ideas and political strategies.\nQuestions Slave descent, post-slavery, and classificatory slavery:\n- Following legal abolition, what were the opportunities available to different groups of enslaved persons in different African regions and contexts?\n- What strategies did different categories of slave descendants unfold, and why?\n- How, if at all, did relations between former slaves and slave-owners change?\n- Why are certain groups classified as coming ‘from slavery’, with what consequences, and giving rise to what forms of resistance and/or identity politics?\n- How was slavery, as an institution, transformed following legal abolition? What forms of labour replaced slave labour? How were the roles of slaves in sexual, reproductive, and domestic domains reconfigured?\n- What types of slavery, if any, exist in contemporary African societies? What groups are involved? How do war and conflict influence practices of enslavement?\n- What forms of resistance, and by which actors, does contemporary slavery gives rise to?\n- How does the international definition of slavery, based on the 1926 Slavery Convention of the League of Nations, relate to contemporary African phenomena and national legislations?\n- How is slavery defined and characterised in contexts marked by legal pluralism?\n- Who, if anyone, defends the legitimacy of slavery today, through which arguments, and with what practical consequences?\nAfrican anti-slavery movements, neo-abolitionism, and grassroots activism:\n- What forms does abolitionism take in Africa today, what practices does it give rise to, and what are the ideological roots of different African abolitionist discourses?\n- What are the main forms of anti-slavery advocacy in Africa today (e.g. national and international NGOs, political parties, grassroots movements, religious associations, etc.)?\n- Who becomes a member of African anti-slavery movements and why?\n- What challenges does African anti-slavery activism face and why?\n- How, if at all, do African abolitionist movements differ from those of African diasporas in Europe and the Americas?\nSubmission guidelines The organizers Vijaya Teelock (University of Mauritius) and Benedetta Rossi (University of Birmingham) welcome submissions of abstracts on the themes and questions above. We regret that we cannot provide funding for participants external to the SLAFNET Project. Please send your submission by email to Benedetta Rossi at firstname.lastname@example.org by 30 September 2017. Submissions should include: title, abstract of 300-500 words, presenter’s name, institutional affiliation, and contact information. The selection committee will make a decision on the retained abstracts by 30 October 2017."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:be75a044-fc59-4319-9e18-ba9307bc7506>","<urn:uuid:f29c30ec-396a-430c-86a8-84fbb0e2d763>"],"error":null}
{"question":"Could you explain how bees and plants maintain a symbiotic relationship, and what research is being conducted on their chemical communication?","answer":"Bees and plants maintain a symbiotic relationship where plants provide nectar as food for bees, while bees help plants reproduce by transferring pollen between flowers during their nectar collection. This relationship has evolved over 130 million years. Research in the Department of Entomology focuses on chemical communication aspects, including studies of plant-to-insect chemical communication via olfaction, how plants produce and release volatile compounds that mediate communication, and the genomic analysis of chemical communication in honey bees. This research examines both the production of chemical signals and the responsiveness of receiving individuals.","context":["Department of Entomology: Insect-to-insect or plant-to-insect chemical communication via olfaction, neuroethology, heliothine moth sex pheromone and host plant volatile mixture interactions, development of an insect antenna-based olfactory biosensor, discovery and development of novel insect attractants, traps and mating disruption dispensers, and evolution of sex pheromone blends.\nSchool of Forest Resources: Structural and functional genomics of trees and the intersection between genomics and tree chemistry, genetic linkage mapping and molecular cytogenetics, genetics of tree growth, pest resistance, and wood quality, development of environmentally friendly resistance to insect pests and other stresses, molecular basis of lignin synthesis and the response of trees to environmental pollutants.\nDepartment of Crop and Soil Sciences: Genetics of secondary metabolites in maize and sorghum, molecular biology and role of secondary metabolites in plant developmental process and resistance to biotic and abiotic stresses, phlobophenes, 3-deoxyanthocyanidins.\nDepartment of Entomology: Interactions between insects and their pathogens and parasites, elicitation and regulation of the insect immune system, enzyme interactions and gene expression in epidermis and immune responses, receptor/ligand reactions in pathogen recognition, cell--cell interactions and signaling pathways underlying immune response activation, suppression of host immune responses by parasitic microbes and arthropods.\nDepartment of Entomology: Chemically mediated ecological interactions among plants, herbivores, and parasitoids, production and release of volatile compounds that mediate communication among plants and between plants and the natural enemies of insect herbivores, impacts of chemical communication on community structure and dynamics, volatile signaling between parasitic plants and their hosts.\nDepartment of Entomology: Physiological, biochemical and molecular aspects of insect--plant interactions, impact of insect saliva (primarily glucose oxidase) on plant responses and acclimation to abiotic stresses, role of foliar phenolics in improving insect performance by stimulating feeding and/or by providing antioxidant benefits.\nDepartment of Entomology: Structure and function of insect chemosensory systems, impact of sensory systems on chemically mediated behavior (especially feeding behavior of caterpillars), roles of key stimuli during the early phases of induced plant defenses, mechanisms of transduction in chemosensory cells, design of antifeedant chemicals, and development of new detectors.\nDepartment of Plant Pathology: Molecular evolutionary genetics of fungi, molecular phylogenetics and systematics, identities and roles of fungal culprits in plant and animal diseases and toxicoses, curation of the world's largest collection of Fusarium cultures.\nDepartment of Entomology: Our research focuses on the genomic analysis of chemical communication in honey bees and other social insect species. Our studies seek to understand the molecular and physiological basis of modulation of chemical communication in honey bees, both in terms of production of the chemical signal and responsiveness of the receiving individual.\nDepartment of Entomology: Tritrophic interactions; impact of phytochemicals and insect host antiviral defenses on pathogenesis of baculoviruses; role of baculovirus genes as virulence factors; gut symbionts and lignocellulose digestion in the Asian longhorned beetle (ALB); behavior elicited by ALB-produced pheromones.\nDepartment of Plant Pathology: Molecular, cellular, and evolutionary mechanisms underpinning plant-fungal pathogen interactions in rice and Arabidopsis thaliana, development of a cyber-infrastructure (Fungal Plant Pathogen Database) integrating research and survey activities on fungal plant pathogens to support the identification, detection, tracking, and risk assessment of major plant pathogens.\nDepartment of Plant Pathology: Roles of fungal secondary metabolites in fungus--plant and fungus--microbe interactions, functions of mycotoxins, microbial ecology of silages, secondary metabolites of Fusarium.\nDepartment of Crop and Soil Sciences: How plants respond to environmental stresses at the physiological, biochemical, and molecular levels; how corn defends itself against herbivory by caterpillars and the aflatoxin-producing fungus Aspergillus flavus.\nCollege of Science, Department of Biology: Ecological and evolutionary animal physiology, evolution of aerial locomotion in insects, population- and ecosystem-level influences on insect success and life history evolution, impact of food quality and quantity on dragonfly parasite loads, metapopulation dynamics of butterflies.\nDepartment of Entomology: Evolution, social behavior, multilevel selection, cultural evolution, volatile mediation of interactions among plants, herbivores, and parasitoids.\nDepartment of Entomology: Molecular mechanisms underlying differences in susceptibilities of insect species to the effects of synthetic or natural poisons, amino acid receptors as models for selective taste and insecticide action, cytochrome P450 monooxygenases and epoxide hydrolases as model detoxification enzymes degrading sensory chemicals at nerve receptor sites, peptide and protein taste receptors in beetles, development of novel biopesticides.\nDepartment of Entomology: Ecology and evolutionary genetics of infectious diseases, virulence, interactions between pathogens, phylodynamics and evolution of immunity, control strategies.\nCollege of Science, Department of Biology: Basic and applied population ecology using both theoretical and empirical methods; invasion ecology; decision theory in population management; species interactions.\nCollege of Science, Department of Biology: Interrelationships among inbreeding, herbivore and disease in plants; effects of inbreeding on plant volatile production and insect attraction to plants; changes in volatile production with herbivory and pathogen infection; responses of insect vectors to pathogen infected plants.\nDepartment of Entomology:\nCollege of Science, Department of Biochemistry: Fungal lignin biodegradation, role of wood substrate in enzyme production and succession of enzymes involved in degradation of wood, protemics, trypsin fingerprinting using MALDI/TOF mass spectroscopy, role of methionine sulfoxide reductases in protection of plants from oxidative stress.\nDepartment of Entomology: Plant–insect interactions, tritrophic interactions, host–plant volatile emissions, plant defenses, phytohormones dynamics, conservation biological control, gall-inducing insects.\nDepartment of Entomology: Insect pheromones and other semiochemicals, biochemistry of signal production and release in plants and insects, behavioral responses of insects to chemical cues, interactions among herbivorous insects, their host plants, and their natural enemies, biochemistry of insect saliva and regurgitant, environmentally safe pest management.\nDepartment of Plant Pathology: Complex network of signal transduction and pathway interactions involved in rice biotic and abiotic stress tolerance by using a combination of molecular, biochemical, genetic, genomic and proteomic approaches; genetic and molecular dissection of defense signaling pathways in rice; proteomic and functional analyses of stress signaling complexes; high-throughput RNA interference system for rice functional genomics; genetic engineering for enhanced biotic and abiotic stress tolerance.","Beewatch helps the honey bees\nBeewatch promotes sustainable strategies to help the bees and the environment in the long run.\nHome for honey bee colonies in urban areas where bees lost their habitat\nLocal colonies of honey bees to help build up genetic resistance\nNo chemical treatment of the colony. Ever.\nNo over-exploitation of the bees for their honey or their pollination skills.\nWatching the bees ultimately leads to watching out for the bees.\nBees and pollination\nBees are key to plant and animal survival.\nNo matter where you live in the world, if you walk around in nature, you will see flowers. They come in different shapes, different colors, different blossom, different size. But most of them can be seen as a banner that says “I NEED A POLLINATOR TO REPRODUCE”. And the vast majority of pollinators are bees.\nOver 3/4 of all plants on Earth (350,000 species) use flowers to reproduce. 80 % of those flowering plants use animal for pollination, including birds and mammals, but mostly insects. Bees are the top insect pollinator.\nThe disappearance of pollinators would negatively impact over 65 % of the plants on Earth. This impact would travel up the trophic pyramid and successively affect the herbivores, the carnivores and the omnivores, including us, human beings.\nPollination is how flowering plants reproduce.\nA flower is where male and/or female parts of a plant are displayed. Pollination is the male part (pollen) getting transferred to the female part (stigma) which leads to fertilization and ultimately to seed production. Waiting for this transfer to randomly happen is not a very efficient reproduction pathway. It is of interest for the plant to have this transfer facilitated, and the best way to do so is to recruit helpers: the pollinators. Bees are one of the most efficient pollinators on Earth. When a bee visits a flower, her body gets covered with pollen grain that she carries away to the next flower, hence transferring pollen grains from flower to flower.\nA sweet deal between plants and bees\nBees don’t transport pollen around just to make plants happy. They do it because they get an important reward doing the job: they get FOOD. To reward the pollinators for their important role, plants produce a sweet liquid called NECTAR at the basis of most flowers. Nectar – together with pollen – is the main source of nutriment for bees. Looking for nectar in flowers, the bee gets covered with pollen and helps the plants by transferring the pollen grains to the next visited flower. This is a beautiful example of SYMBIOSIS: plants are helping the bees, and bees are helping the plants. For 130 million years, bees and plants have co-evolved on Earth and are now closely connected.\n… IN NUMBERS …\nof the total volume of food consumed by humans on the planet depend on pollinators\nof the major varieties of crops consumed by humans depend on animal pollination\nin value is added by the honey bees to agricultural crop each year in the United States\nHoney bees are important to us\nIs the honey bee “just” one of those pollinators?\nYes and no. There are about 20,000 species of bees on Earth. All of them play an important role in pollination. Only 7 of those species are honey bees… But those 7 species are very, very important to us, human beings, more than any other pollinators.\nThe honey bees are among the top beneficial insects\nHuman beings have been keeping bees for thousands of years. The first signs of domestication of bees appeared in Egyptian art 4500 years ago. Human beings are very special animals for many different reasons, and one of them is because they are farmers and cultivate the fruits and vegetables they like to eat. The other reason is that there are a lot of human beings on Earth to be fed. Therefore, humans had to find helpers who would help reproduce the variety of fruits and vegetable they liked and in large amount, in order to be able to feed everyone. The honey bee is the best suited for that task…\n- Honey bees live in large colonies. Colonies are on average 60,000 individual, which represent a large work force to help with pollination.\n- Unlike other bees, they overwinter, which means that they don’t die off before winter but stay alive and relatively active instead and are very quick on the following spring to get back to work. Most of the other bee species would instead spend much of spring reestablishing their colony that died off in fall (only the fertilized queen survives winter).\n- They are transportable to allow pollination of different crops in different parts of the world each year, which has a huge impact on the global economy (several billions of dollar).\n- Honey bees make… honey! Even if honey is not the main reason why human beings keep bees nowadays, it is still an amazing treat that most people enjoy.\nAnimal food depends on pollinators, which INCLUDE honey bees.\nBut human food depends on pollinators, MAINLY honey bees.\nTaking care of the pollinators is essential to preserve our planet.\nAnd taking care of the honey bees is essential to take care of our species.\n… HOW INSECTS IMPROVE CROP YIELD …\nAlexandra-Maria Klein et al. 2007, Proceedings of Royal Society\nRaspberries, after NON INSECT pollination (left and middle) and INSECT pollination (right). (Photo by Jim Cane, Bee Research Institute, Longan, USA).\nStrawberries, after INSECT pollination (left) and NON-INSECT pollination (middle and right). (Photo by Kristine Krewenka, Agroecology, Göttingen, Germany).\nHoney bees are dying\nWhy are the honey bees dying?\nFor the past 10 years, beekeepers in North America have been reporting a loss of 20 to 90 % of their bee population every year. Why are the bees dying?\nThere are several major factors accounting for the bee disappearance.\n- Varroa Destructor Mites. Those parasites brought from Asia feed on bees’ blood and transmit viruses to the bee population. Infestation as low as 3 mites for 100 bees can already become a threat for a healthy colony. Varroa has now spread everywhere in the world except for a few isolated places like Australia.\n- Pesticides that are sprayed onto crops and seeds. One major class of dangerous chemical is the nicotinoids pesticides that were shown to be both attractive and destructive to honey bees and bumble bees. That class of pesticide has been banned in Europe.\n- Habitat loss brought about by development of our cities and monoculture agriculture.\n- Bees’ bad nutrition. Bees are moved around in North America and used to pollinate crops. The farms renting bee hives for the service of these pollinators generally practice monoculture, which means the bees have access to only one kind of pollen/nectar for a period as long as one month. This unbalances the bees’ diet and has been pointed to as a factor of weakness of their immune system .\n- When bee hives are transported across the continent, the bees are exposed to a tremendous amount of stress. If you ever witnessed the reaction of bees inside a hive when you knock on the wall of their house, you know how sensitive those creatures are to vibrations. Bees use vibrations as one of their favorite communication systems. It is easy to picture how a trip of thousands of miles on the back of a truck can stress the colony (before finally reaching a farm that practices monoculture…).\n- Lack of genetic variability.\nHelping the bees or treating them\nBecause Varroa mites seem to be the first reason why bees are dying, it is tempting to beekeepers to use chemical miticides to try to get rid of the mites and “save the bees”. But are those treatments really saving the bees? Is “saving the bees” making them dependent on a treatment for their survival? Miticides are not only a threat to the environment, but they also pollute the honey that we eat, and they contribute to the appearance of miticide resistant mites that are even more dangerous. And worst of all, they weaken the bees.\nHoney bees appeared on Earth some 130 million years ago. To become those beautiful and smart insects they are today, they had to develop defense mechanisms to survive the different challenges Nature brought to them over time. Those challenges were as diverse as predators like hornets or bears, nectar dearth, or pathogens like Bacteria, viruses and parasites. Some of those pathogens were most likely as aggressive – or maybe more aggressive- than Varroa mite is today. The bees survived each pathogen without any kind of treatment. They did what every living organism does: they ADAPTED. Natural selection worked its way and helped build STRONG BEES, resistant bees, that would thrive until recently.\nThen they started to die… and they are still dying.\nchemical treatment = short term threat\nPesticides are toxic for the environment and pollutes the honey we eat.\nPesticides also reduces the bee’s natural abilities to fight pathogens.\nno natural selection = long term threat\nThe honey bees are getting genetically weaker and weaker. So weak that one day they probably won’t be able to survive anymore without our “help”.\nIf you’re not part of the genetic solution of breeding mite-resistant bees, then you’re part of the problem.\nA New Bond With Nature"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:f0cc997d-94fc-4af3-98e8-173167109193>","<urn:uuid:27fd7305-4fa7-4514-9eee-9fb8b0fe5749>"],"error":null}
{"question":"What are the maintenance challenges of river dredging projects and effects of CO2 absorption since 1800s?","answer":"River dredging projects face significant maintenance challenges, as demonstrated by the Gorai River project where the channel tends to widen and shoal during wet monsoon seasons, requiring continuous maintenance dredging at critical places. Without ongoing maintenance, the river quickly returns to its degraded state, as happened with the Gorai when the long-term maintenance scheme wasn't implemented. Regarding CO2 absorption since the 1800s, the ocean has absorbed about one quarter of human-emitted CO2, causing ocean acidification. The atmospheric CO2 has increased from 280 parts per million before industrialization to nearly 400 ppm, resulting in a 26 percent increase in ocean acidity over roughly 250 years - a rate 100 times faster than anything experienced in tens of millions of years.","context":["|BwN Building Blocks||BwN Toolbox||Pilots and cases||BwN Knowledge|\nThe Gorai River, a distributary of the Ganges, is an important artery for Bangladesh, as it is the source of fresh water for the south-western part of Bangladesh. The river is used for navigation, fisheries, agriculture and domestic purposes. Besides this, the fresh water flow of the river is also important to the ecology and economy (logging) of the mangrove forests situated along the coast. During the eighties and nineties the flow in the river gradually slowed down, especially during the dry season. The river discharge was decreasing and the annual sedimentation rate was significantly increasing. This led to a vicious circle causing difficulties for the people living along its banks and detrimental effects to the mangrove forests. To get the river flowing again, a number of solutions were considered.\n|Building with Nature Design||Traditional Design|\nThe eco-dynamic design of the Gorai river includes the use of the natural flow conditions. By restoring a natural flow in the river, the river will be more self-sustaining with limited maintenance dredging. Important in the execution of such a project is a certain flexibility in the design and construction phase.\nTraditionally a river like the Gorai would be embanked by a permanent structure of dams and dikes. The flow of the river would be man-made and a continuous struggle against natural forces in terms of dredging and river training would be necessary.\nGeneral Project Description\nTitle: The Gorai Re-excavation Project\nLocation: Gorai River, Bangladesh\nDate: 1998 - 2001\nInvolved parties: Boskalis, Dredging International, HAM, VOACZ\nAbstract: To get the Gorai River flowing again and minimize the period of complete drought, a channel was dredged.\nTopics: River, channel, mangrove restoration, morphology, reduction salinity intrusion\nIn the 1980’s and 1990's the water flow in the Gorai River had gradually decreased and sedimentation had increased, causing the river to fall dry during increasingly longer periods. This, in combination with the increased salinity intrusion in the downstream part, had a negative impact on river-dependent activities such as agriculture, trade, transport, fisheries, logging, environment and domestic use. Therefore, a solution was searched to oppose the drying up of the Gorai River. Especially the mangrove forest, the Sundarbans in the delta of the Gorai, is of high environmental value. The aim of the project was not only to restore the river’s historic flow conditions, but also to explore the possibilities for long-term restoration of the river. And together with restoration of the flow, the project should improve the water quality and promote ecological restoration in the Subarbans and the Gorai River corridor.\nTo get the Gorai River flowing again, a channel was dredged through the shoal which blocked the bifurcation from the Ganges and the upper part of the river. Keeping the inherent uncertainty of the river morphology in mind, the design, planning and construction were executed with a high degree of flexibility.\nEDD-dimension: Conserving biodiversity in the Subarbans was an important driver of the project in all phases. Moreover, the social aspects of the river contributed to the integral approach of the project. The solution chosen can be seen as building with nature, as it builds on the natural river processes and strives for long-term sustainability. Ideally, the river would have become self-sustaining with limited maintenance dredging.\nPlanning and Design\nThe project's design was to create a low-water channel from the bifurcation to some 30 km further downstream. This channel would cover only part of the cross-section and restore the river’s natural cross-sectional shape. Due to the widely varying discharges, however, the morphological response to this intervention was rather uncertain. Therefore detailed planning made little sense and adjustments to the actual morphological development has to be possible during construction.\nDuring the wet Monsoon season, some parts of the dredged channel would fill in. Therefore, dredging continued over three successive years in the wet season, expecting the river to be able to maintain itself afterwards. In the end the river should have become a self-sustaining ecosystem, combined with limited maintenance dredging to keep the bifurcation open.\nEDD-dimension: The principal driver of the project was to conserve existing environmental values and creating new ones by restoring the river discharge and thus reducing salinity intrusion into the Sundarbans area. Moreover, the increasing flow would positively influence the water quality of the river and the connected surface waters, thus indirectly the level of well-being (nutrition, poverty alleviation, employment) of the Bangladesh people. Moreover, the flexibility and adaptability needed in the design and its execution is characteristic of the EDD-approach.\nPart of the sand dredged from the low-water channel was placed on the high-water banks, low enough not to hamper the flow during high water and high enough to concentrate the flow during low water. Another part of the sand was removed from the river bed and used as construction material by the inhabitants.\nDuring construction the river's morphology was closely monitored and the design of the works was adjusted accordingly. Dredging was done during the wet season and took three successive years.\nEDD-dimension: Utilising and subtly steering the morphological processes in the river can be considered as building with nature. The natural forces help to shape the design, instead of the design shaping the natural forces like in conventional designs. The set-up of the works enabled adaptation to the hydrodynamic and morphological processes in the river.\nOperation and Maintenance\nEach year during the wet Monsoon the channel tends to widen and shoal, but during the three-year project the dredging effort to keep the river flowing became less each year. On that basis, a blend of maintenance dredging and natural forces was expected to be optimal to keep the Gorai flowing. Maintenance dredging would concentrate at critical places, indicated by close monitoring of the hydrodynamics and the morphology of the river.\nIt has to be noted, however, that upon evaluation of the project consultants concluded that continued maintenance dredging and storage of the material on the high river banks may not be sustainable in the long run. They suggested a different design, including groins and revetments. This design has not been implemented so far, by lack of money and/or political will. For the same reason the long-term maintenance scheme was never realised and the river has largely returned to its degraded state.\nAfter three years of dredging the river discharge had increased and the river was flowing all year round, thus increasing its navigability. The year-round supply of water to the delta led to a reduction of the salinity intrusion into river and the surrounding areas. Consequently, the fish population increased. However, maintenance dredging turned out to be crucial, as the river starts silting up as soon as dredging is stopped.\nBecause of uncertainty it made little sense to set dredging volumes and locations on beforehand. In an uncertain environment like this more flexible measures are needed. Also, the time between design-survey and approval of dredging proposals needs shortening, as the river morphology changes fast.\nClose monitoring and associated modelling has led to new insights into the behaviour of the river and how to best go about it.\nThis examples shows that the approach promoted by Building with Nature and applied here can give a technically sustainable solution. Due to governance complications, however, this particular project could not be shown to be sustainable in the long run.\n- Groot, J.K. de, P. van Groen, 2001. The Gorai Re-Excavation Project. Terra et Aqua 85: pp. 21-25.\n- Hydronamic, 2000. Gorai River - re-excavation pilot priority works. Port and Waterway Engineering, Project Development\n- PPW, 2000. PPW Final Report. Gorai River Contractors","What is Ocean Acidification?\nSince the beginning of the Industrial Revolution, when humans began burning coal in large quantities, the world’s ocean water has gradually become more acidic. Like global warming, this phenomenon, which is known as ocean acidification, is a direct consequence of increasing levels of carbon dioxide (CO2) in Earth’s atmosphere.\nPrior to industrialization, the concentration of carbon dioxide in the atmosphere was 280 parts per million (ppm). With increased use of fossil fuels, that number is now approaching 400 ppm and the growth rate is accelerating. Scientists calculate that the ocean is currently absorbing about one quarter of the carbon dioxide that humans are emitting. When carbon dioxide combines with seawater, chemical reactions occur that reduce the seawater pH, hence the term ocean acidification.\nCurrently, about half of the anthropogenic (human-caused) carbon dioxide in the ocean is found in the upper 400 meters (1,200 feet) of the water column, while the other half has penetrated into the lower thermocline and deep ocean. Density- and wind-driven circulation help mix the surface and deep waters in some high latitude and coastal regions, but for much of the open ocean, deep pH changes are expected to lag surface pH changes by a few centuries.\nOcean acidification and global warming are different problems, but are closely linked because they share the same root cause—human emissions of carbon dioxide. The atmospheric concentration of carbon dioxide is now higher than it has been for the last 800,000 years and possibly higher than any time in the last 20 million years. Humans have thus far benefited from the ocean’s capacity to hold enormous amounts of carbon, including a large portion of this excess carbon dioxide. Had the ocean not absorbed such vast quantities of carbon dioxide, the atmospheric concentration would be even higher, and the environmental consequences of global warming (sea level rise, shifting weather patterns, more extreme weather events, etc.) and their associated socioeconomic impacts would likely be even more pronounced. However, the oceans cannot continue to absorb carbon dioxide at the current rate without undergoing significant changes in chemistry, biology, and ecosystem structure.\nMeasuring ocean acidification: Past and present\nScientists know that the oceans are absorbing carbon dioxide and subsequently becoming more acidic from measurements made on seawater collected during research cruises, which provide wide spatial coverage over a short time period, and from automated ocean carbon measurements on stationary moorings, which provide long-term, high-resolution data from a single location.\nThese records can be extended back through time using what are known as chemical proxies to provide an indirect measurement of seawater carbonate chemistry. A proxy is a measurement from a natural archive (ice cores, corals, tree rings, marine sediments, etc.) that is used to infer past environmental conditions. For example, by analyzing the chemical composition of tiny fossil shells found in deep ocean sediments, scientists have developed ocean pH records from ancient times when there were no pH meters. Furthermore, because the ocean surface water is in approximate chemical balance, or equilibrium, with the atmosphere above it, a record of historical ocean pH can be inferred from atmospheric carbon dioxide records derived from Greenland and Antarctic ice cores, which contain air bubbles from the ancient atmosphere. Such evidence indicates that current atmospheric carbon dioxideconcentrations and ocean pH levels are at unprecedented for at least the last 800,000 years.\nGoing back deeper in Earth history to the Paleocene-Eocene boundary about 55 million years ago, scientists have found geochemical evidence of a massive release of carbon dioxide accompanied by substantial warming and dissolution of shallow carbonate sediments in the ocean. Although somewhat analogous to what we are observing today, this carbon dioxide release occurred over several thousand years, much more slowly than what we are witnessing today, thus providing time for the oceans partially to buffer the change. In the geologic record, during periods of rapid environmental change, species have acclimated, adapted or gone extinct. Corals have undergone large extinction events in the past (such the Permian extinction 250 million years ago), and new coral species evolved to take their place, but it took millions of years to recover previous levels of biodiversity.\nHow is ocean acidification affecting ocean chemistry?\nSeawater has a pH of 8.2 on average because it contains naturally occurring alkaline ions that come primarily from weathering of continental rocks. When seawater absorbs carbon dioxide from the atmosphere, carbonic acid is produced (see Box 1), reducing the water’s pH. Since the dawn of industrialization, average surface ocean pH has decreased to about 8.1.\nBecause the pH scale is logarithmic (a change of 1 pH unit represents a tenfold change in acidity), this change represents a 26 percent increase in acidity over roughly 250 years, a rate that is 100 times faster than anything the ocean and its inhabitants have experienced in tens of millions of years.\nAcidification can affect many marine organisms, but especially those that build their shells and skeletons from calcium carbonate, such as corals, oysters, clams, mussels, snails, and phytoplankton and zooplankton, the tiny plants and animals that form the base of the marine food web.\nThese “marine calcifiers” face two potential threats associated with ocean acidification: 1) Their shells and skeletons may dissolve more readily as ocean pH decreases and seawater becomes more corrosive; and 2) When CO2 dissolves in seawater, the water chemistry changes such that fewer carbonate ions, the primary building blocks for shells and skeletons, are available for uptake by marine organisms. Marine organisms that build shells or skeletons usually do so through an internal chemical process that converts bicarbonate to carbonate in order to form calcium carbonate.\nExactly how ocean acidification slows calcification rates, or shell formation, is not yet fully understood, but several mechanisms are being studied. Most hypotheses focus on the additional energy an organism must expend to build and maintain its calcium carbonate shells and skeletons in an increasingly corrosive environment. In the face of this extra energy expenditure, exposure to additional environmental stressors (increasing ocean temperatures, decreasing oxygen availability, disease, loss of habitat, etc.) will likely compound the problem.\nThese effects are already being documented in many marine organisms, particularly in tropical and deep-sea corals, which exhibit slower calcification rates under more acidic conditions. The impact on corals is of great concern because they produce massive calcium carbonate structures called reefs that provide habitat for many marine animals, including commercially important fish and shellfish species that use the reefs as nursery grounds. Coral reefs are vital to humans as sources of food and medicine, protection from storms, and the focus of eco-tourism. In addition to corals, studies have shown that acidification impairs the ability of some calcifying plankton, tiny floating plants and animals at the base of the food web, to build and maintain their shells. Scientists have also observed increased larval mortality rates of several commercially important fish and shellfish.\nWhat can we expect in the future?\nOcean acidification is occurring at a rate 30 to100 times faster than at any time during the last several million years driven by the rapid growth rate atmospheric CO2 that is almost unprecedented over geologic history. According to the Intergovernmental Panel on Climate Change (IPCC), economic and population scenarios predict that atmospheric CO2 levels could reach 500 ppm by 2050 and 800 ppm or more by the end of the century. This will not only lead to significant temperature increases in the atmosphere and ocean, but will further acidify ocean water, reducing the pH an estimated 0.3 to 0.4 units by 2100, a 150 percent increase in acidity over preindustrial times. Assuming a “business-as-usual” IPCC CO2 emission scenario, predictive models of ocean biogeochemistry project that surface waters of the Arctic and Southern Oceans will become undersaturated with aragonite (a more soluble form of calcium carbonate) within a few decades, meaning that these waters will become highly corrosive to the shells and skeletons of aragonite-producing marine calcifiers like planktonic marine snails known as pteropods.\nAlthough ocean acidification has only recently emerged as a scientific issue, it has quickly raised serious concerns about the short-term impacts on marine organisms and the long-term health of the ocean. Scientists estimate that over the next few thousand years, 90 percent of anthropogenic CO2 emissions will be absorbed by the ocean. This may potentially affect biological and geochemical processes such as photosynthesis and nutrient cycling that are vital to marine ecosystems on which human society and many natural systems rely. At the same time, marine organisms will face the enormous challenge of adapting to ocean acidification, warming water, and declining subsurface-ocean oxygen concentrations.\nNews & Insights\nWHOI working to address ocean acidification; protect region’s vital shellfish industry\nA new report addresses the impacts of ocean acidification in Massachusetts and New England coastal waters on the region’s vital seafood industry.\nOcean acidification gets a watchful eye in New England aquaculture ‘hot spot’\nShellfish aquaculture is thriving in New England, but future growth in the industry could be stunted as coastal waters in the region become more acidic. Researchers at WHOI have developed…\nOcean acidification causing coral ‘osteoporosis’ on iconic reefs\nScientists Pinpoint How Ocean Acidification Weakens Coral Skeletons\nClimate Change Will Irreversibly Force Key Ocean Bacteria into Overdrive\n[ ALL ]\nWHOI in the News\nThe Top Eight Ocean Stories of 2022\nThe $500 Billion Question: What’s the Value of Studying the Ocean’s Biological Carbon Pump?\nEcology Research: Ocean acidification causing coral ‘osteoporosis’ on iconic reefs\nDisentangling influences on coral health\n[ ALL ]\nFrom Oceanus Magazine\nOcean acidification is no big deal, right?\nWHOI’s Jennie Rheuban discusses the very real phenomenon of an increasingly acidic ocean and the toll it’s taking on marine life.\nTo Tag a Squid\nHow do you design a tag that can attach to a soft-bodied swimming animal and track its movements? Very thoughtfully.\nHow Do Corals Build Their Skeletons?\nWHOI scientists discovered precisely how ocean acidification affects coral skeletons’ a factor that will help scientists predict how corals throughout the world will fare as the oceans become more acidic.\nSearching for ‘Super Reefs’\nSome corals are less vulnerable to ocean acidification. Can the offspring from these more resilient corals travel to other reefs to help sustain more vulnerable coral populations there?\nGraduate student Hannah Barkley is on a mission to investigate how warming ocean temperatures, ocean acidification, and other impacts of climate change are affecting corals in an effort to find…"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:463f9106-1e05-4dcd-883e-cc75d6ff1c7f>","<urn:uuid:51ca6f21-f0f4-4343-8b14-a7f059f0fe69>"],"error":null}
{"question":"What are the voltage requirements for commercial building lighting vs home lighting, and what specific electrical safety measures are needed for boat owners?","answer":"For residential dwellings, Rule 30-102 requires lighting circuit voltages to be limited to either 120/240 volts or 120/208 volts. However, for non-residential buildings, voltages up to 347/600 volts are allowed, including industrial, commercial lighting, and common areas of apartment buildings. For boat owners, specific safety measures include having the boat's electrical system inspected annually and after major storms by a qualified marine electrician, ensuring it meets required codes including the American Boat & Yacht Council standards. They should also install ground fault circuit interrupters (GFCI) on the boat, use only Marine Listed portable GFCIs or shore power cords, and test GFCIs monthly. Additionally, boat owners should avoid entering the water when launching or loading a boat, as docks or boats can leak electricity into the water.","context":["The Canadian Electrical Code in some instances limits maximum applied voltages to protect the general public and inexperienced people from electrical shock hazards. Unqualified persons are at greater risk due to their inability to identify electrical hazards and understand electrical shock risks. This article reviews some of the circumstances where the code prescribes maximum voltages to minimize exposure to serious electrical shock.\nThe first and most obvious voltage restriction is in our home. Rule 2-106 prescribes 150 volts-to-ground as the maximum voltage in dwelling units. A dwelling unit is where we live, such as a single family home, townhouse or apartment. It follows that this rule limits the supply voltages to dwelling units to either 120/240 volts single-phase or 120/208 volts three-phase. As much as possible, the intent is to protect occupants and other persons considered unqualified against undue electrical shock risks.\nHowever, multi-family residential buildings often employ qualified and experienced maintenance staff. When so, Rule 2-106 does permit some exceptions for multi-family buildings where the electrical load exceeds 250 kVA and if such maintenance staff is on hand. Here up to 347/600 volts may be supplied to permanently installed:\n- Space heating controlled by low voltage wall thermostats\n- Water heating\n- Air conditioning\nRule 2-106 is relaxed for such applications only when assurance is given that management will employ qualified people, capable of recognizing and dealing with the personal risks when maintaining this equipment.\nSimilarly, Rule 30-102 further supports Rule 2-106 by requiring that lighting circuit voltages in dwellings be limited to either 120/240 volts or 120/208 volts. But for other than dwellings, Rule 30-102 allows up to 347/600 volts. Other than dwellings includes industrial or commercial lighting, but also lighting in common areas of apartment buildings or other multi-family buildings such as hallways, basements and parking lot lighting. Here again, it is expected that this equipment would be maintained only by qualified people.\nA similar shock issue applies to ballast type lighting, which depending on its design, may produce high open circuit voltages. Rule 30-706 addresses this safety issue. Some ballast type lighting, in particular instant start fluorescent lighting produces extremely high open circuit voltages. High starting voltage allows the lamps to light quickly without cathode heating or other means to assist starting.\nAnd to further limit shock risks, Rule 30-706 prohibits fluorescent fixtures having open circuit voltages above 300 volts from use inside dwellings unless the live parts are enclosed to prevent inadvertent contact during lamping or relamping, and Rule 30-802 prohibits outright the use of any lighting fixtures having open circuit voltages more that 1000 volts within dwellings.\nNeon tubes operate at even higher voltages and they can be very dangerous if incorrectly installed, maintained and when unqualified people may come in contact with them. To reduce such risks, Rule 34-300 restricts maximum open circuit voltages for neon signs and outline lighting to a maximum of 15,000 volts and 7500 volts phase to ground if neon tube circuits are provided with secondary ground-fault protection. If not, open circuit voltages must be limited to:\n- 6000 volts for transformers that have isolated secondary windings (not autotransformer types)\n- Equipment that has factory-installed (no interconnecting field wiring) between the transformers and the neon tubing.\nThe reason for the above voltage restrictions is to limit exposure to electrical shock to a general public that is usually unaware of the risks.\nDry niche type underwater lighting fixtures are installed in the walls of swimming pools behind a glass lens, sealed to exclude water. It is well recognized that people in or around swimming pools are vulnerable to electrical shocks due to the presence of moisture and low body resistance to current flow. It’s particularly important to prevent stray currents in the water, normally achieved with correct grounding and bonding methods. But to further limit electrical shock risks, Rule 68-066(3) also limits both the lighting circuit supply voltage and lighting ballast open circuit voltage to maximum 300 volts during both starting and operation.\nThe code also limits electrical shock hazards in outdoor electrical substations supplied at more than 7500 volts in the event of a system ground fault. Currents may flow through the earth and away from the fault location, thereby creating ground potential rise on station grounding systems and on all metallic objects such as electrical equipment and structures in the station.\nA person who happens to be inside a high voltage substation during a ground fault is at risk from electrical shock. Rule 36-304(2) and Table 52 helps reduce this risk by limiting step and touch potentials to “tolerable” levels. For example, during a one second ground fault in an outdoor station with a crushed stone surface, Table 52 specifies maximum step and touch voltages of 2216 volts and 626 volts. You will recall that step voltage is voltage between your feet and touch voltage is voltage between an energized object and your feet during a ground fault. The 150 mm crushed stone surface of the station further reduces the shock hazards.\nAs in the case of previous articles, you should consult the electrical inspection authority in each province or territory for a more precise interpretation of any of the above.","May 23, 2018 – With Memorial Day and the start of summer just around the corner, the National Fire Protection Association (NFPA) is reminding people about the potential electrical hazards in swimming pools, hot tubs and spas, on board boats and in the waters surrounding boats, marinas and launch ramps.\nElectric shock drowning (ESD) happens when marina or onboard electrical systems leak electric current into the water. The current then passes through the body and causes paralysis. When this happens, a person can no longer swim and ultimately drowns.\nNFPA reminds people about the potential electrical hazards in swimming pools, hot tubs and spas, on board boats and in the waters surrounding boats, marinas and launch ramps.\n“Most people are not aware, including boat and pool owners and swimmers, are not aware of the risks of electric shock drowning,” said Lorraine Carli, NFPA’s vice president of Outreach and Advocacy. “NFPA is raising awareness of this troubling trend and sharing our water safety resources so that everyone can safely enjoy summer water activities.”\nHere are tips for swimmers, pool and boat owners:\nTips for swimmers\n- Never swim near a marina, dock or boatyard, or near a boat while it’s running.\n- While in a pool, hot tub or spa, look out for underwater lights that are not working properly, flicker or work intermittently.\n- If you feel a tingling sensation while in a pool, immediately stop swimming in your current direction. Try and swim in a direction where you had not felt the tingling. Exit the water as quickly as possible; avoid using metal ladders or rails. Touching metal may increase the risk of shock.\nTips for pool owners\n- If you are putting in a new pool, hot tub or spa, be sure the wiring is performed by an electrician experienced in the special safety requirements for these types of installations.\n- Have a qualified electrician periodically inspect and — where necessary — replace or upgrade the electrical devices or equipment that keep your pool, spa or hot tub electrically safe. Have the electrician show you how to turn off all power in case of an emergency.\n- Make sure any overhead lines maintain the proper distance over a pool and other structures, such as a diving board. If you have any doubts, contact a qualified electrician or your local utility company to make sure power lines are a safe distance away.\nTips for boat owners\n- Avoid entering the water when launching or loading a boat. Docks or boats can leak electricity into the water causing water electrification.\n- Each year, and after a major storm that affects the boat, have the boat’s electrical system inspected by a qualified marine electrician to be sure it meets the required codes of your area, including the American Boat & Yacht Council. Make the necessary repairs if recommended. Check with the marina owner who can also tell you if the marina’s electrical system has recently been inspected to meet the required codes of your area, including the National Electrical Code® (NEC).\n- Have ground fault circuit interrupters (GFCI) installed on the boat; use only portable GFCIs or shore power cords (including “Y” adapters) that are Marine Listed when using electricity near water. Test GFCIs monthly.\nNFPA has additional resources for swimmers, boat and pool owners, including tip sheets, checklists and more that can be downloaded and shared. Please visit www.nfpa.org/watersafety.\nFor industry professionals, the 2017 NFPA 70, National Electrical Code® (NEC®) has been revised to improve pool safety and help reduce the risk of ESD. NFPA has additional codes and standards that apply to boats and marinas and their related electrical safety issues. Find these resources and more by visiting NFPA’s NEC webpage.\nFor this release and other announcements about NFPA initiatives, research and resources, please visit the NFPA press room.\nAbout the National Fire Protection Association (NFPA)\nFounded in 1896, NFPA is a global, nonprofit organization devoted to eliminating death, injury, property and economic loss due to fire, electrical and related hazards. The association delivers information and knowledge through more than 300 consensus codes and standards, research, training, education, outreach and advocacy; and by partnering with others who share an interest in furthering the NFPA mission. For more information visit www.nfpa.org. All NFPA codes and standards can be viewed online for free at www.nfpa.org/freeaccess.\nContact: Lorraine Carli, Public Affairs Office: +1 617 984-7275"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:9ffff019-ac2d-4730-80f3-b81723cc8158>","<urn:uuid:777aa865-46d5-4156-a36e-45ff669888c3>"],"error":null}
{"question":"How long does it take to complete a skilled trades apprenticeship in Ontario? Can someone explain the hours needed?","answer":"The length of an apprenticeship varies depending on several factors, including work availability and in-class training space availability. Each trade has different requirements, ranging from 4,000 to 9,000 workplace hours and 2 to 3 levels of in-class training. While there is no set length, apprenticeships typically take between two to five years to complete.","context":["In a skilled trades apprenticeship program, students have the opportunity to earn while they learn. Instead of coming out of college or university with tens of thousands of dollars in debt, you can start your career with money in the bank.\nWork with your hands, demonstrate your skills and see the results.\nMove into training, management, or even start your own business.\nA career in the skilled trades can be very lucrative. Some tradespeople make more than $60,000 right out of trades school, and many established skilled tradespeople make more than $100,000 per year.\nAn apprentice is someone who is learning a trade and has a formal training contract with a sponsor. The contract is called a Registered Training Agreement. A sponsor is the person, group, or organization responsible for providing the apprentice with training experiences.\nA journeyperson is someone who is fully certified in their trade, can perform all the work in that trade without supervision, and can train new apprentices.\nYou should start by doing some research about what trades you are interested in. There are many skilled trades in Ontario, so there is a trade for you no matter what you’re into.\nThe next step is to find a sponsor. A sponsor is a person, group, or organization that takes responsibility for ensuring that you are getting opportunities to learn all of the skills required for you to complete your apprenticeship in accordance with the Ontario College of Trades and Apprenticeship Act, 2009. Most often, a sponsor will be your direct employer, but they do not have to be as long as they are able to meet their responsibilities as a sponsor.\nAfter you find a sponsor, you’ll have to sign a Registered Training Agreement with the Ministry of Training, Colleges and Universities and your sponsor that outlines your responsibilities as an apprentice and the responsibilities of your sponsor.\nOnce you’ve signed your Registered Training Agreement, you officially become a registered apprentice. At this point, you’ll have 90 days to register as a member of the Ontario College of Trades. To do this, you need to send a member application form with your annual membership fee of $60+HST ($67.80) to the Ontario College of Trades.\nThe total cost for doing an apprenticeship is around $2,000. Here is a breakdown of the fees you will have to pay:\nSome trades may require that you provide your own tools and equipment. Make sure to factor this into your budget. These costs vary by sector, but interest-free loans are available for apprentices. Click here for financial resources available for apprentices.\nRemember that you will be earning money on the job while you are learning the trade.\nThere is no set length of an apprenticeship, as it depends on a number of factors, like the availability of work and in-class spaces for training programs, and the requirements of the trade. Each trade has different requirements, ranging from 4000-9000 workplace hours and 2 to 3 levels of in-class training. Normally you should expect to finish within two to five years.\nIf you have not signed a Registered Training Agreement with the Ministry of Training, Colleges and Universities, and are not a member of the Ontario College of Trades, you are not an apprentice. Without a signed agreement, you are not eligible for the financial supports that are available to registered apprentices, and you are not allowed to engage in the activities of a compulsory trade. Also, your employer is not eligible to claim tax credits on your wages for apprentice training, or to receive the $1,000 Apprentice Completion Bonus. If you want to become an apprentice, speak to your employer about signing a Registered Training Agreement."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"comparison"}],"document_ids":["<urn:uuid:d70da8f5-5986-4997-bfd6-5600890bc828>"],"error":null}
{"question":"How do the legal rights of unmarried fathers in Florida compare to the residency requirements for divorce in New York in terms of establishing jurisdiction?","answer":"In Florida, unmarried biological fathers must file a Petition to Determine Paternity in the Circuit Court of their county to establish legal rights to their child, as the mother is otherwise considered the natural guardian with primary custody rights under Florida Statute 744.301. In contrast, New York's jurisdiction for divorce requires meeting specific residency requirements, including either being married in New York with one spouse being a resident for one continuous year, both spouses living in New York as husband and wife with one being a resident for one year, the cause of action occurring in New York with one year of residency, both parties being residents when the cause occurs in New York, or either party being a resident for two continuous years.","context":["If you are an unmarried biological Father in the state of Florida and you have not established your legal rights of paternity, you may be playing with fire. Many Fathers do not quite grasp the ramifications of not filing with the Court to determine legal paternity until it is too late, and generally that is when access and timesharing to the child begins to be denied. If that situation does arise, while it is not irreversible, it could take some time before regular contact and timesharing is restored, so it becomes even more important to address your child’s legal paternity before this occurs. To ensure you have contact and access to your child from the get-go, the best time to go to Court to establish your rights is upon the birth of your child.\nFlorida Statute 744.301 provides that the Mother of a child born out of wedlock is the natural guardian of the child and is entitled to primary residential care and custody of the child unless the Court enters an order stating otherwise. In essence, this says that the biological mother has the authority to determine all issues related to a child until the Court determines otherwise. While the parents can agree on a natural and biological father by signing a “Voluntary Acknowledgement of Paternity” form, there is no right to timesharing that flows from such an acknowledgment for the Father unless and until a Petition to Determine Paternity is filed in the Circuit Court in the county in which you live. Once such a Petition is filed, that will begin the process for a biological Father to secure legal rights, including a timesharing schedule, with his child.\nIn too many cases the Father will want to believe that the relationship with the Mother will remain stable and equal in terms of the child, however, many times that dynamic will in fact change and when that happens, it will be the Mother who will be able to dictate the terms of the relationship that you have with your child, and at that point, even if you file a Petition to Determine Paternity immediately thereafter, it could still take several months before the Court will ultimately determine a parenting plan that would include timesharing for you and your child. As is the rule in most areas of life, it is almost always better to be proactive than reactive and this is particularly true when it comes to your children. Do not allow yourself to be complacent with the status quo. If you do not have a Court Order that guarantees you timesharing with your child, it is critically important to understand that your relationship with your child is completely subject to the whims of the Mother. No matter how good your current relationship with the Mother may be, that status is still subject to change upon a moment’s notice, and if that change occurs, you will want to have your rights already established for the protection of your child. The importance of protecting your rights cannot be understated. Should you have any questions about establishing your rights of paternity to your children, or to move forward with this process of legally determining paternity for your children, contact an experienced family law attorney today.","What are the residency requirements to file\nfor divorce in New York?\nIn order to file an action for divorce, separation, or annulment in New York, residency requirements must be met in order for the court to hear your case. You must meet one of the following requirements: (1) you were married in New York and either you or your spouse is a resident of New York when the action is commenced, and one of you has been a resident for a continuous period of one year immediately preceding the commencement of the action; or (2) you and your spouse have resided in New York as husband and wife and either you or your spouse is a resident of the state when the action is commenced, and has been a resident for a continuous period of one year immediately preceding, or (3) the cause of action (grounds for the divorce, separation or annulment) occurred in the state and either party has been a resident of the state for a continuous period of at least one year immediately preceding the commencement of the action, or (4) the cause of action occurred in the state and both parties are residents of the state at the time of the commencement of the action, or (5) either party has been a resident of the state for a continuous period of at least two years immediately preceding the commencement of the action. (Domestic Relations Law Sections 230 and 231)\nWhen is a Prenuptial Agreement Appropriate?\nEntering into a prenuptial agreement is a personal decision couples contemplating marriage must make. Generally speaking, a prenuptial agreement is indicated when one or both partners have children from a prior marriage, when parties desire to keep their finances separate, or when one or both partners are involved in family businesses. Many times people with a high net worth believe they need a prenuptial agreement to keep their pre-marital assets separate, although that is not always the case. A consultation with an attorney can help you decide if a prenuptial agreement is appropriate in your individual case.\nCases in Family Court and Supreme Court\nAll child support and custody matters involving children born to unmarried parents will be heard in Family Court. However, spousal support and child support matters may be heard by Family Court in the case of married parents. Family Court cannot adjudicate a divorce case.\nAll actions for divorce, separation or annulment will be heard by the Supreme Court of the State of New York (a trial court, and not the highest court in the State, despite what it sounds like).\nWhat is a Living Will?\nA living will states your wishes for the kind of life-sustaining medical care or intervention you do or do not want. It is important to think about these decisions now, in the event you become terminally ill or unable to communicate.\nWhat Is a Health Care Proxy?\nA health care proxy assigns an agent to make medical decisions on your behalf in the event you are unable to do it for yourself. The proxy you select should be capable of understanding medical information, able to handle stress, be someone you trust to advocate your wishes and someone who will keep your best interests in mind."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:8781aad3-87df-41d5-b1a5-cfdd47d4dbb4>","<urn:uuid:e8d7587e-e414-4542-a6bb-641d5ecd4a60>"],"error":null}
{"question":"What is the Ch'ol documentation project about, and what role does metadata play in preserving such language materials?","answer":"The Ch'ol documentation project involves collecting and transcribing Ch'ol language recordings, with over 30 hours gathered in its first phase. The project includes workshops on file management and transcription, with materials ultimately being uploaded to the Archive of Indigenous Languages of Latin America (AILLA). Metadata plays a crucial role in preserving such materials as it provides descriptive, structural, and administrative information that helps in organizing, discovering, and managing digital resources. Metadata includes key words, terms, and contextual information that aids in describing content, formats, and provenance of items, making them discoverable in archives and search systems.","context":["Members of the Ch’ol documentation project convened June 7th and 8th at CIESAS-Sureste in San Cristóbal de las Casas for a workshop focused on file management and transcription, organized by Juan Jesús Vázquez Álvarez and Jessica Coon, and with ELAN and audio file editing tutorials by Justin Royer and Sandra Cruz Gómez.\nthe group at work transcribing\nGroups traveled from Oxolotán Tabasco (led by Nicolás Arcos López) and Yajalón, Chiapas (led by Bernabé Vázquez Sánchez). Altogether, they had collected more than 30 hours of Ch’ol recordings during the first phase of the project. During phase 2, they will select their favorite narratives to transcribe and translate. At the end, all materials will be uploaded to the Archive of Indigenous Languages of Latin America (AILLA).\nWorkshop 2 participants, back row: Bernabé Vázquez Sánchez, Juan Jesús Vázquez Álvarez, Sandra Cruz Gómez, Nicolás Arcos López, Félix López López, Jessica Coon, Justin Royer, Morelia Vázquez Martínez Front row: Patricia López Vázquez, Nilda Gúzman López, Lourdes Méndez Sánchez, Matilde Vázquez Vázquez\nThe 5th Form and Analaysis in Mayan Linguistics workshop (FAMLi V) will take place in Antigua, Guatemala this August. The call for papers is here and abstracts are due May 13th.\nMy name is Jessica Coon and I’m originally from Oregon in the United States. Since 2011 I have lived in Montreal, Canada where I’m a linguistics professor at McGill University. This semester I am living and working in San Cristóbal de las Casas with my husband and two kids.\nJessica and kids in Montreal\nI started working on Ch’ol in 2002 in Campanario and have worked on topics in Ch’ol grammar, and more recently on Chuj with speakers in Montreal.\nVirginia, Ella, and Jessica in Campanario\nWe had a great first workshop in Oxolotán last week, with active participation from students in the Universidad Intercultural’s Lengua y Cultura program. The university’s article, and more pictures from the event, can be found here. We’re looking forward to continuing the collaboration!\nUIET article on workshop\nOur first workshop on Ch’ol documentation is coming up! We’ll be in Oxolotán on February 9th at the Universidad Intercultural de Tabasco. The workshop is open and will introduce participants to the motivation and goals of language documentation, along with recording basics. Stay tuned for a similar workshop in Yajalón, Chiapas!\nJuan Jesús Vázquez Álvarez will give a talk “Las lenguas indígenas en las políticas educativas” (“Indigenous Languages in Education Policies”), in the 1st Forum: Indigenous Languages and Challenges in the 21st Century, organized by INALI and the Asociación Indígena Académica in connection with International Mother Language Day. The talk will take place on February 16 in the Aula Magna of the Faculty of Law of the UNACH, in San Cristóbal de Las Casas.\nThe Ch’ol documentation project is now underway. Jessica Coon, Nicolás Arcos López, and Juan Jesús Vázquez Álvarez met in San Cristóbal de las Casas to plan the first workshops on Ch’ol documentation and transcription.\nJessica, Juan Jesús, and Nico\nThe workshops will take place in Oxolotán, Tabasco and in Yajalón, Chiapas in February, and will train Ch’ol-speaking students in basics of working with speakers, recording, storing data, and collecting metadata.\nrecording equipment ready!\nStay tuned for workshop details and schedule!","To browse other articles on a range of HSL topics, see the A-Z index.\nMetadata or data about data identifies and describes an object such as an article, book and/or digital item (i.e., photographs or pdfs). Metadata is created with key words and key terms, natural language, controlled and index terms. Different types of metadata are used such as descriptive, structural or administrative. Each type aids in describing elements of an item or object. Metadata is thought to describe the content of an item but it also describes formats, and even the provenance of an item. For librarians, metadata provides a means of indexing, accessing, preserving, and discovering digital resources of many kinds. Metadata was traditionally kept in the card catalogues (book inventories) of libraries and archives. As information has become increasingly online and digital, metadata are used to describe objects using metadata standards.\nAccording to Kurtz et al (2013), \"...metadata is an attempt to capture the contextual information surrounding a datum (\"a single element of data\"). The enriching contextual information assists the data user to understand how to use the original datum. Metadata also attempts to bridge the semantic gap between machine users of data and human users of the same data....\" In the library environment, metadata is commonly used for any formal scheme of resource description applying to any type of object, digital or non-digital. Traditional library cataloging is a form of metadata; MARC and the rule sets used such as AACR2 and RDA are types of metadata standards. Simply put, metadata is used in libraries to facilitate the discovery of books (and other catalogued resources). Metadata is critical to find materials in catalogues and search systems. The use of structured information to describe information resources/objects is an essential component for finding things in search systems. Book cataloguing is formally a type of metadata creation but the term is generally used for non-traditional schemes such as the Dublin Core or the Encoded Archival Description (EAD).\nMetadata can be categorized as descriptive, structural or administrative. (Reitz, 2004) Descriptive metadata refers to any information that describes the content of an object; structural metadata describes the format of the materials being described; administrative metadata provides copyright information for those materials. Most library catalogues contain tons of metadata as they contain information about books, journals, and electronic resources that make up collections. Metadata records in traditional libraries fulfill a range of functions such as allowing users to search for and find something and helping librarians manage inventories. Many of the same principles that govern description, retention and weeding apply to objects in digital and print-based collections.\nIn 2013, it was announced that Jeffrey Pomerantz from the University of North Carolina at Chapel Hill plans to offer the very first library and information science (LIS) massive online open course (MOOC) entitled Metadata: Organizing and Discovering Information.\nSee Putting Things in Order: a Directory of Metadata Schemas and Related Standards http://www.jiscdigitalmedia.ac.uk/guide/putting-things-in-order-links-to-metadata-schemas-and-related-standards\nThree categories of metadata\nMetadata is grouped into three categories:\nMetadata is an increasingly central tool in the current web environment, enabling large-scale, distributed management of resources. Recent years has seen a growth in interaction between previously relatively isolated metadata communities, driven by the need for cross-domain collaboration and exchange. However, metadata standards have not been able to meet the needs of interoperability between independent standardization communities. For this reason the notion of metadata harmonization, defined as interoperability of combinations of metadata specifications, has arisen as a core issue for the future of web-based metadata. Resting at the heart of application profiles, metadata harmonization presents a little understood, but critical challenge in design of languages of description. DC-2011 will explore the conceptual and practical issues of design when the language solution calls for cross-fertilization from different metadata specifications. Source: International Conference on Dublin Core & Metadata Applications. Metadata Harmonization: Bridging Languages of Description, Netherlands, September 2011.\nMetadata standards organizations\nDo a live search on Google scholar http://scholar.google.ca/scholar?as_ylo=2011&q=metadata+searching&hl=en&as_sdt=0,5"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"historical"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"}],"document_ids":["<urn:uuid:5812d820-f1e9-4fd6-9ae5-cb7528da5938>","<urn:uuid:08a79617-6234-4de8-ae00-948ad1acfacd>"],"error":null}
{"question":"Could you compare the progression speed and development patterns between acute and chronic lymphocytic leukemia? Please explain their key differences in terms of how quickly they develop and what cells they affect.","answer":"Acute lymphocytic leukemia and chronic lymphocytic leukemia differ significantly in their progression and development. Acute lymphocytic leukemia occurs suddenly and develops quickly, affecting fully immature cells. In contrast, chronic lymphocytic leukemia appears gradually and develops slowly over months to years, typically affecting partly immature cells. In CLL, the body makes too many abnormal white blood cells that live too long or multiply too quickly, while crowding out normal white blood cells. Treatment for acute lymphocytic leukemia is typically intense in the first three to six months, with the total treatment lasting two to three years through various phases including induction, consolidation, and maintenance therapy.","context":["Acute lymphocytic leukemia consultation\nA Mayo Clinic physician talks with a man about his diagnosis.\nTests and procedures used to diagnose acute lymphocytic leukemia include:\n- Blood tests. Blood tests may reveal too many white blood cells, not enough red blood cells and not enough platelets. A blood test may also show the presence of blast cells — immature cells normally found in the bone marrow.\nBone marrow test. During bone marrow aspiration, a needle is used to remove a sample of bone marrow from the hipbone or breastbone. The sample is sent to a lab for testing to look for leukemia cells.\nDoctors in the lab will classify blood cells into specific types based on their size, shape and other genetic or molecular features. They also look for certain changes in the cancer cells and determine whether the leukemia cells began from the B lymphocytes or T lymphocytes. This information helps your doctor develop a treatment plan.\n- Imaging tests. Imaging tests such as an X-ray, computerized tomography (CT) scan or ultrasound scan may help determine whether cancer has spread to the brain and spinal cord or other parts of the body.\n- Spinal fluid test. A lumbar puncture test, also called a spinal tap, may be used to collect a sample of spinal fluid — the fluid that surrounds the brain and spinal cord. The sample is tested to see whether cancer cells have spread to the spinal fluid.\nIn general, treatment for acute lymphocytic leukemia falls into separate phases:\n- Induction therapy. The purpose of the first phase of treatment is to kill most of the leukemia cells in the blood and bone marrow and to restore normal blood cell production.\n- Consolidation therapy. Also called post-remission therapy, this phase of treatment is aimed at destroying any remaining leukemia in the body, such as in the brain or spinal cord.\n- Maintenance therapy. The third phase of treatment prevents leukemia cells from regrowing. The treatments used in this stage are often given at much lower doses over a long period of time, often years.\n- Preventive treatment to the spinal cord. During each phase of therapy, people with acute lymphocytic leukemia may receive additional treatment to kill leukemia cells located in the central nervous system. In this type of treatment, chemotherapy drugs are often injected directly into the fluid that covers the spinal cord.\nDepending on your situation, the phases of treatment for acute lymphocytic leukemia can span two to three years.\nTreatments may include:\n- Chemotherapy. Chemotherapy, which uses drugs to kill cancer cells, is typically used as an induction therapy for children and adults with acute lymphocytic leukemia. Chemotherapy drugs can also be used in the consolidation and maintenance phases.\nTargeted therapy. Targeted drugs attack specific abnormalities present in cancer cells that help them grow and thrive.\nA certain abnormality called the Philadelphia chromosome is found in some people with acute lymphocytic leukemia. For these people, targeted drugs may be used to attack cells that contain that abnormality. Targeted therapy may be used during or after chemotherapy.\n- Radiation therapy. Radiation therapy uses high-powered beams, such as X-rays or protons, to kill cancer cells. If the cancer cells have spread to the central nervous system, your doctor may recommend radiation therapy.\nBone marrow transplant. A bone marrow transplant, also known as a stem cell transplant, may be used as consolidation therapy in people at high risk of relapse or for treating relapse when it occurs. This procedure allows someone with leukemia to re-establish healthy bone marrow by replacing leukemic bone marrow with leukemia-free marrow from a healthy person.\nA bone marrow transplant begins with high doses of chemotherapy or radiation to destroy any leukemia-producing bone marrow. The marrow is then replaced by bone marrow from a compatible donor (allogeneic transplant).\n- Clinical trials. Clinical trials are experiments to test new cancer treatments and new ways of using existing treatments. While clinical trials give you or your child a chance to try the latest cancer treatment, treatment benefits and risks may be uncertain. Discuss the benefits and risks of clinical trials with your doctor.\nALL in older adults\nOlder adults, such as those older than 60, tend to experience more complications from ALL treatments. And older adults generally have a worse prognosis than children who are treated for ALL.\nDiscuss your options with your doctor. Based on your overall health and your goals and preferences, you may decide to undergo treatment for your ALL.\nSome people may choose to forgo treatment for the cancer, instead focusing on treatments that improve their symptoms and help them make the most of the time they have remaining.\nExplore Mayo Clinic studies testing new treatments, interventions and tests as a means to prevent, detect, treat or manage this disease.\nNo alternative treatments have been proved to cure acute lymphocytic leukemia. But some alternative therapies may help ease the side effects of cancer treatment and make you or your child more comfortable. Discuss your options with your doctor, as some alternative treatments could interfere with cancer treatments, such as chemotherapy.\nAlternative treatments that may ease symptoms include:\n- Relaxation exercises\nCoping and support\nAlthough treatment for acute lymphocytic leukemia is typically very successful, it can be a long road. Treatment often lasts two to three years, although the first three to six months are the most intense.\nDuring maintenance phases, children can usually live a relatively normal life and go back to school. And adults may be able to continue working. To help you cope, try to:\nLearn enough about leukemia to feel comfortable making treatment decisions. Ask your doctor to write down as much information about your specific disease as possible. Then narrow your search for information accordingly.\nWrite down questions you want to ask your doctor before each appointment, and look for information in your local library and on the internet. Good sources include the National Cancer Institute, the American Cancer Society and the Leukemia & Lymphoma Society.\n- Lean on your whole health care team. At major medical centers and pediatric cancer centers, your health care team may include psychologists, psychiatrists, recreation therapists, child-life workers, teachers, dietitians, chaplains and social workers. These professionals can help with a whole host of issues, including explaining procedures to children, finding financial assistance and arranging for housing during treatment. Don't hesitate to rely on their expertise.\n- Explore programs for children with cancer. Major medical centers and nonprofit groups offer numerous activities and services specifically for children with cancer and their families. Examples include summer camps, support groups for siblings and wish-granting programs. Ask your health care team about programs in your area.\n- Help family and friends understand your situation. Set up a free, personalized webpage at the nonprofit website CaringBridge. This allows you to tell the whole family about appointments, treatments, setbacks and reasons to celebrate — without the stress of calling everyone every time there's something new to report.\nPreparing for your appointment\nMake an appointment with your family doctor or a general practitioner if you or your child has signs and symptoms that worry you. If your doctor suspects acute lymphocytic leukemia, you'll likely be referred to a doctor who specializes in treating diseases and conditions of the blood and bone marrow (hematologist).\nBecause appointments can be brief, and because there's often a lot of ground to cover, it's a good idea to be well-prepared. Here's some information to help you get ready, and what to expect from the doctor.\nWhat you can do\n- Be aware of any pre-appointment restrictions. At the time you make the appointment, be sure to ask if there's anything you need to do in advance, such as restrict your diet.\n- Write down any symptoms you're experiencing, including any that may seem unrelated to the reason for which you scheduled the appointment.\n- Write down key personal information, including any major stresses or recent life changes.\n- Make a list of all medications, vitamins or supplements that you're taking.\n- Consider taking a family member or friend along. Sometimes it can be difficult to remember all the information provided during an appointment. Someone who accompanies you may remember something that you missed or forgot.\n- Write down questions to ask your doctor.\nYour time with your doctor is limited, so preparing a list of questions can help you make the most of your time together. List your questions from most important to least important in case time runs out. For acute lymphocytic leukemia, some basic questions to ask the doctor include:\n- What is likely causing these symptoms?\n- What are other possible causes for these symptoms?\n- What kinds of tests are necessary?\n- Is this condition likely temporary or chronic?\n- What is the best course of action?\n- What are the alternatives to the primary approach that you're suggesting?\n- How can other existing health conditions be best managed with ALL?\n- Are there any restrictions that need to be followed?\n- Is it necessary to see a specialist? What will that cost, and will my insurance cover it?\n- Is there a generic alternative to the medicine you're prescribing me?\n- Are there brochures or other printed material that I can take with me? What websites do you recommend?\n- What will determine whether I should plan for a follow-up visit?\nIn addition to the questions that you've prepared to ask your doctor, don't hesitate to ask other questions.\nWhat to expect from the doctor\nThe doctor is likely to ask you a number of questions. Being ready to answer them may allow time to cover other points you want to address. Your doctor may ask:\n- When did symptoms begin?\n- Have these symptoms been continuous or occasional?\n- How severe are these symptoms?\n- What, if anything, seems to improve these symptoms?\n- What, if anything, appears to worsen these symptoms?\nWhat you can do in the meantime\nAvoid activity that seems to worsen any signs and symptoms. For instance, if you or your child is feeling fatigued, allow for more rest. Determine which of the day's activities are most important, and focus on accomplishing those tasks.\nAug. 10, 2018","What is chronic lymphocytic leukaemia?\nChronic lymphocytic leukaemia (CLL) is a blood cancer. It is also known as chronic lymphatic leukaemia.\nCLL develops when the body makes too many abnormal white blood cells. Because they live too long or multiply too quickly, there will be large numbers circulating in the blood. They crowd out normal white blood cells and don’t fight infection themselves, so there can be a higher risk of infection (neutropenia).\nAs leukaemia progresses, the bone marrow fills with leukaemia cells and there is less room for healthy red cells and platelets to be produced. This may cause various health problems, such as anaemia (from too few red cells) or bleeding or bruising (from thrombocytopenia, too few platelets).\nLearn more about:\n- The difference between chronic and acute leukaemia\n- Who gets CLL\n- What causes CLL\n- Blood cells and leukaemia cells\n- The lymphatic system\nWhat is the difference between chronic and acute leukaemia?\nWhile all types of leukaemia start in the bone marrow and affect white blood cell production, they are grouped according to which type of white blood cell is affected (lymphoid or myeloid), whether there are abnormalities in the bone marrow, and how quickly the disease develops.\nChronic leukaemia usually affects partly immature cells, appears gradually, and develops slowly over months to years.\nAcute leukaemia affects fully immature cells, occurs suddenly, and develops quickly. See Acute Leukaemia for more information.\nWho gets CLL?\nEach year in Australia, about 3700 people are diagnosed with a form of leukaemia, and more than 1700 of these cases are chronic leukaemia.\nCLL is the most common type of chronic leukaemia, with about 1400 people diagnosed each year. CLL is twice as likely to occur in men than in women and is very rare in children.\nWhat causes CLL?\nChronic leukaemia is caused by changes to one or more of the genes (DNA) that control the growth and development of blood cells. These changes happen over time, but it is not known why they occur in some people and not others. The exact cause of CLL is not yet understood.\nSome people have genetic abnormalities that can lead to CLL. These genetic defects are not usually inherited, but there are rare cases where CLL may occur more commonly in families. If you are worried about this, talk to your doctor, who may refer you to a genetic counsellor.\nBlood cells and leukaemia cells\nBlood is pumped around your body to provide oxygen and nutrients to your tissues, and to remove waste products. It is made up of blood cells carried in a clear fluid called plasma. The three main types of blood cells have specific functions:\n- red blood cells – carry oxygen around the body\n- white blood cells – fight infection\n- platelets – help the blood clot\nAll three types of blood cells have a limited life span and need to be continually replaced. Most are made in the bone marrow, which is the spongy part in the centre of the bones.\nThe bone marrow contains stem cells. These are unspecialised blood cells that first develop into immature cells known as blast cells. Normally, the blast cells then become mature red or white blood cells or platelets and carry out their set functions.\nThere are two families of stem cells:\n- myeloid stem cells – develop into myeloblast cells and then into red blood cells, most types of white blood cells, and platelets\n- lymphoid stem cells – develop into lymphoblast cells and then into lymphocytes, which are a type of white blood cell.\nIf myeloblast or lymphoblast cells do not mature properly or if there are too many in the blood, it can cause leukaemia.\nHow blood cells are made\nIn leukaemia, blast cells never develop into mature white blood cells. These abnormal blast cells are also called leukaemia cells.\nThe lymphatic system\nThe lymphatic system works with the white blood cells to protect the body against infection. A large network of thin tubes (lymph vessels) carries a clear fluid called lymph. The lymph travels to and from areas of lymph tissue, including the lymph nodes, spleen and liver. When leukaemia causes abnormal white blood cells to build up, the lymph tissue becomes swollen.\nLymph nodes – Also known as lymph glands, these are small bean-shaped structures that are found in the neck, underarms, chest, abdomen and groin. The lymph nodes filter out toxins and help fight infections, and also produce some blood cells.\nSpleen – This is an organ on the left side of the body under the ribs. It clears out old or damaged blood cells.\nLiver – This large organ removes toxins, controls sugar levels, and stores vitamins."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"temporal_focus","category_name":"future"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"}],"document_ids":["<urn:uuid:0a2ddb27-b732-4fbf-93b8-da39d0f3c24b>","<urn:uuid:70228508-adbf-4cd7-b6ca-be6d947c510b>"],"error":null}
{"question":"¿Qué descubrimientos interesantes hizo la misión Cassini sobre la luna Titán? ¡Me encanta la exploración espacial! 🌎","answer":"The Cassini mission revealed that Titan is one of the most Earth-like bodies encountered in space. It has its own substantial atmosphere and features lakes, rivers, and oceans made of liquid methane. The mission's Huygens probe was the first to land in the outer solar system when it landed on Titan, and it was also the first to sample an extraterrestrial ocean.","context":["The name Cassini has come to be associated with the sixth planet in our solar system, Saturn. The Cassini spacecraft—named for Jean-Domenique Cassini, who discovered some of Saturn’s many moons as well as a notable gap in the rings that also bears his name—took 7 years to journey from the Earth to Saturn and traveled 4.9 billion miles over the course of its 20 year mission. By the time it purposely crashed into the gaseous planet in 2017, Cassini had orbited the planet 294 times in the pursuit of knowledge about the giant planet and its wondrous rings.\nSaturn is a gas giant comprised mostly of hydrogen. It is the second largest planet in the solar system after Jupiter, has 62 moons, and is famously adorned with the most visually spectacular ring system in our celestial neighborhood. Saturn orbits the sun at about 10 times the distance from the Sun to the Earth, and it is the farthest planet from Earth that can be seen with the naked eye.\nCassini, in its 13 years orbiting the planet, taught humanity more about Saturn than we’d learned in the previous 400 years since its first telescopic observation in 1610. Its Huygens probe was the first to land in the outer solar system (on Saturn’s moon Titan), and the first to sample an extraterrestrial ocean. Titan—one of the largest moons in the solar system—was revealed to be one of the most Earth-like bodies we have encountered; it has its own substantial atmosphere, and even has lakes, rivers, and oceans of liquid methane.\nIn addition, Cassini’s observations of the moon Enceladus helped to pave the way for future missions to the outer solar system—Enceladus’ icy surface hides an ocean of liquid water which, thanks to data from Cassini, suggest it may hold the necessary ingredients for sustaining life. Future missions, particularly Europa Clipper (a mission planned for the 2020s which will explore Jupiter’s similarly icy moon Europa), will further investigate the possibility of extraterrestrial life using what we learned from Cassini as a starting point.\nSeemingly insignificant in the grand scheme of things, but meaningful all the same: Saturn also gave us perspective. Astronauts have spoken about the indescribable sensation of looking down at our planet from space, unable to see country borders, lines of conflict, anything beyond the home of the human race. Some of the thousands of pictures taken by Cassini contain a bright speck in the background. That speck is our world. Our Earth. From the depths of space, humanity is united simply by living on the same planet. This view, and the perspective it provides, is irreplaceable.\nThe conclusion of Cassini’s mission was well documented—the final plunge into the depths of the gaseous planet on September 15, 2017. As it ran out of fuel, at the end of a mission that had been extended more than once past its intended duration, the final remaining goal was to preserve. If Enceladus or any of Saturn’s other moons did contain the ingredients for life, it was essential to keep it that way. Had Cassini simply been allowed to remain in orbit, the chances of the spacecraft contaminating one of these moons were too great. So it took the plunge—Cassini’s Grand Finale—sending back data until the last possible moment, a dramatic end to one of the most productive planetary missions in history."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"atemporal"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:d45bbb8f-0b49-49e7-8cc8-d5c436b913d9>"],"error":null}
{"question":"How can water quality be improved in rivers and streams through combined ecological measures? 🌿","answer":"Water quality can be improved through a combination of measures, including restoration of water bodies, upgrading water treatment plants, and reducing harmful agricultural inputs upstream. This integrated approach is recommended because plants and animals in surface water ecosystems are typically sensitive to multiple stressors like poor water quality, monotonous high flow velocity, and increased water temperatures.","context":["If one turns a stone over in a river or stream, it swarms with tiny animals: caddisflies, water beetles, freshwater shrimp, and snails. The invertebrates living on the beds of water bodies that can be seen with the naked eye, called macroinvertebrates, are rather unimposing, but for science and the protection of surface waters they are of great importance. Several species in this group are very sensitive to changes in their environment, for example pollutants or construction along the shore or in the catchment area of the water body. On the other hand, some other species are tolerant to such influences. The diversity of the small animals therefore allows important conclusions concerning the water itself and the aquatic ecosystem as well. Sometimes they can even point to the causes of worsening ecological conditions.\nSwiss-wide model-supported analysis of small invertebratesFor the first time, Eawag researchers Nele Schuwirth and Bogdan Caradima, together with colleagues in the Department of Systems Analysis, Integrated Assessment and Modelling, have carried out a combined analysis of cantonal and federal monitoring data on macroinvertebrates. For this study they used the database MIDAT of the \"Schweizerisches Zentrum für die Kartografie der Fauna (SZKF)\". This database contains the macroinvertebrate data of the biodiversity monitoring BDM , the National Surface Water Quality Monitoring Programme NAWA and 14 cantonal monitoring programmes.\nBecause the programmes contain data on invertebrates identified at different taxonomic levels - family, genus, species - , the datasets first had to be harmonized. Then the researchers used statistical models to analyse the data and identify major direct and indirect influence factors for the occurrence of each taxonomic group. These included, among others, water temperature, use of insecticides in the catchment area, flow velocity, agricultural land use and forest cover along the river banks, urban area and livestock units in the catchment. Some of these influence factors, such as water temperature, are known to affect the organisms directly. Others serve as indicators for influence factors that cannot be measured directly. For example, the forestation of the riparian zone can lead to more leaf litter input, shading of the water body and reduced input of nutrients and pollutants from the catchment area.\nOccurrence of the beetle family Elmidae in Switzerland in the biodiversity monitoring data and in the model. Large blue dots and small red dots indicate an agreement between observation and model.\nFrom the results, the researchers have derived recommendations for the design of the monitoring programmes and surface water manageme\nIdentification of causes by determination of speciesInvestigations and evaluation of macroinvertebrates in Swiss running waters have been carried out according to the Swiss modular concept for stream assessment since 2010. It requires the recording of the organisms on the family level. The model analysis generally confirms the assessment method: families classified as sensitive respond more strongly in the model to anthropogenic stressors. At the same time, the study shows that a finer taxonomic resolution, namely the identification of species, would provide additional valuable information. This would allow a better identification of the specific causes that could influence water or water-body quality.\nMore data, increased validityThe greater the volume of data available for analysis, the higher the statistical power. For future analyses it is therefore essential that as many monitoring programs as possible submit their macroinvertebrate data as well as additional information like substrate data to the MIDAT database.\nUnified monitoring conceptsToday, Cantons identify different groups of macroinvertebrates down to the species level. For a Swiss-wide evaluation, it would make sense to always identify the same groups in this detailed taxonomic resolution. A unified list of taxa for species identification would therefore be an advantage. The Eawag study can contribute to judging for which groups this would be especially valuable.\nExtended monitoring designTo better disentangle major influence factors on freshwater communities, it is worthwhile to include additional locations to the monitoring programme. Locations with rare combinations of influence factors are especially valuable for the analysis, such as sites with low water temperature and impaired water quality.\nIntegral management of surface watersPlants and animals living in surface water ecosystems are typically sensitive to multiple stressors, for example poor water quality, monotonous high flow velocity, and increased water temperatures. In considering measures to improve the ecological status of surface waters, a combination of measures should be recommended, as far as possible and necessary. For example a restoration combined with upgrading of water treatment plants and reduction of harmful agricultural inputs upstream.\nSchuwirth and Caradima have published a more detailed summary of the results in today’s issue of the journal Aqua & Gas, in cooperation with the Federal Office for the Environment FOEN and the Atelier für Naturschutz und Umweltfragen AG UNA: \"Analyse schweizweiter Makrozoobenthosdaten: Erkenntnisse über anthropogene Einflüsse und Monitoring Design\".\nSchuwirth et al., « Analyse schweizweiter Makrozoobenthosdaten: Erkenntnisse über anthropogene Einflüsse und Monitoring Design https://www.eawag.ch/typo3/#_msocom_1 », Aqua & Gas, Nr. 12/2019\nCaradima, B.; Schuwirth, N.; Reichert, P. (2019) From individual to joint species distribution models: a comparison of model complexity and predictive performance, Journal of Biogeography, 46(10), 2260-2274 , doi: 10.1111/jbi.13668 , Institutional Repository\nVermeiren, P.; Reichert, P.; Schuwirth, N. (2020) Integrating uncertain prior knowledge regarding ecological preferences into multi-species distribution models: effects of model complexity on predictive performance, Ecological Modelling, 420, 108956 (15 pp.), doi: 10.1016/j.ecolmodel.2020.108956 , Institutional Repository"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"future"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:2a375beb-0ce6-4cf8-b16a-8abfb269bf18>"],"error":null}
{"question":"How common is scoliosis in the US compared to fibromyalgia, and do both conditions affect women more than men?","answer":"Both conditions affect millions of Americans, with scoliosis affecting 5-7 million people and fibromyalgia affecting around 5 million adults in the US. Both conditions show a gender disparity, but in different proportions - while fibromyalgia affects 80-90% women, scoliosis is noted to affect girls more commonly than boys, though the exact ratio is not specified in the documents.","context":["Scoliosis affects 5 to 7 million people in the United States. More than a half million visits are made to doctors’ offices each year for evaluation and treatment of scoliosis. Although scoliosis can begin at any age, it most often develops in adolescents between the ages of 10 and 15. Girls are more commonly affected than boys. Because scoliosis can be inherited, children whose parents or siblings are affected by it should definitely be evaluated by a trained professional.\nWhat is scoliosis?\nBecause we walk on 2 feet, the human nervous system constantly works through reflexes and postural control to keep our spine in a straight line from side to side. Occasionally, a lateral (sideways) curvature develops. If the curvature is larger than 10 degrees, it is called scoliosis. Curves less than 10 degrees are often just postural changes. Scoliosis can also be accompanied by lordosis (abnormal curvature toward the front) or kyphosis (abnormal curvature toward the back). In most cases, the vertebrae are also rotated.\nIn more than 80% of cases, the cause of scoliotic curvatures is unknown; we call this condition idiopathic scoliosis. In other cases, trauma, neurological disease, tumors, and the like are responsible. Functional scoliosis is often caused by some postural problem, muscle spasm, or leg-length inequality, which can often be addressed. Structural scoliosis does not reduce with postural maneuvers. Either type can be idiopathic or have an underlying cause.\nWhat are the symptoms of scoliosis?\nScoliosis can significantly affect the quality of life by limiting activity, causing pain, reducing lung function, or affecting heart function. Diminished self-esteem and other psychological problems are also seen. Because scoliosis occurs most commonly during adolescence, teens with extreme spinal deviations from the norm are often teased by their peers.\nFortunately, 4 out of 5 people with scoliosis have curves of less than 20 degrees, which are usually not detectable to the untrained eye. These small curves are typically no cause for great concern, provided there are no signs of further progression. In growing children and adolescents, however, mild curvatures can worsen quite rapidly-by 10 degrees or more-in a few months. Therefore, frequent checkups are often necessary for this age group.\nHow is scoliosis evaluated?\nEvaluation begins with a thorough history and physical examination, including postural analysis. If a scoliotic curvature is discovered, a more in-depth evaluation is needed. This might include a search for birth defects, trauma, and other factors that can cause structural curves.\nPatients with substantial spinal curvatures very often require an x-ray evaluation of the spine. The procedure helps determine the location and magnitude of the scoliosis, along with an underlying cause not evident on physical examination, other associated curvatures, and the health of other organ systems that might be affected by the scoliosis. In addition, x-rays of the wrist are often performed. These films help determine the skeletal age of the person, to see if it matches an accepted standard, which helps the doctor determine the likelihood of progression. Depending on the scoliosis severity, x-rays may need to be repeated as often as every 3 to 4 months to as little as once every few years.\nOther tests, including evaluation by a Scoliometer?, might also be ordered by the doctor. This device measures the size, by angle, of the rib hump associated with the scoliosis. It is non-invasive, painless, and requires no special procedures. A Scoliometer? is best used as a guide concerning progression in a person with a known scoliosis-not as a screening device.\nIs scoliosis always progressive?\nGenerally, it is not. In fact, the vast majority of scolioses remains mild, is not progressive, and requires little treatment, if any.\nIn one group of patients, however, scoliosis is often more progressive. This group is made up of young girls who have scolioses of 25 degrees or larger, but who have not yet had their first menstrual period. Girls generally grow quite quickly during the 12 months before their first period and if they have scolioses, the curvatures tend to progress rapidly. In girls who have already had their first periods, the rate of growth is slower, so their curves tend to progress more slowly.\nWhat is the treatment for scoliosis?\nThere are generally 3 treatment options for scoliosis- careful observation, bracing, and surgery. Careful observation is the most common “treatment,” as most mild scolioses do not progress and cause few, if any, physical problems. Bracing is generally reserved for children who have not reached skeletal maturity (the time when the skeleton stops growing), and who have curves between 25 and 45 degrees. Surgery is generally used in the few cases where the curves are greater than 45 degrees and progressive, and/or when the scoliosis may affect the function of the heart, lungs, or other vital organs.\nTherapeutic exercise may help in the treatment of scoliosis.\nSpinal manipulation, therapeutic exercise, and electrical muscle stimulation have also been advocated in the treatment of scoliosis. None of these therapies alone has been shown to consistently reduce scoliosis or to make the curvatures worse. For patients with back pain along with the scoliosis, manipulation and exercise may be of help.\nMost people with scoliosis lead normal, happy, and productive lives. Physical activity including exercise is generally well-tolerated and should be encouraged in most cases.","What is Fibromyalgia?\nFibromyalgia is a long-term (chronic) condition that can cause widespread pain and tenderness over much of the body.\nAccording to the National Institute of Arthritis and Musculoskeletal and Skin Diseases (NIAMS), around 5 million adults aged 18 years or over in the United States experience fibromyalgia, and 80 to 90 percent of fibromyalgia patients are women.\nFibromyalgia has many symptoms that tend to vary from person to person. The main symptom is widespread pain.\nPatients with fibromyalgia often find themselves on a merry-go-round of symptoms with prolonged, chronic, widespread pain leading to sleep deprivation, which leads to fatigue.\nFatigue consequently makes it difficult for patients to accommodate exercise, a key component of fibromyalgia management. Tired, in pain, and often unable to function in day-to-day life, they are at risk for depression and anxiety, which leads to more sleepless nights, and the cycle begins again.\nCommon symptoms include:\n- Widespread pain\n- Jaw pain and stiffness\n- Pain and tiredness in the face muscles and adjacent fibrous tissues\n- Stiff joints and muscles in the morning\n- Irregular sleep patterns\n- Irritable bowel syndrome (IBS)\n- Painful menstrual periods\n- Tingling and numbness in the hands and feet\n- Restless leg syndrome (RLS)\n- Sensitivity to cold or heat\n- Difficulties with memory and concentration, known as “fibro-fog”\nThe cause is unknown, but risk factors include:\n- Traumatic injury\n- Rheumatoid arthritis\n- Autoimmune disorders, such as lupus\n- Genetic factors\n- Abnormal pain messages\n- Chemical imbalances\n- Sleep problems\nA Comparison of Fibromyalgia & Myofascial Pain Syndrome\nThe muscle pain present in both fibromyalgia (FM) and myofascial pain syndrome (MPS) is why these two conditions are sometimes mistaken for one another or erroneously lumped together as one condition.\nWhat is Trigger Points in MPS ?\nMyofascial pain syndrome is diagnosed by the presence of trigger points—small, hard knots that you can sometimes feel under your skin. A trigger point represents a taut band of muscle. The knot itself is not generally painful when poked, but it causes pain in another area of the body (known as referred pain).\nTrigger points typically form after the tissue is injured and, for some reason, don’t heal properly. Experts don’t know why damage that heals normally in most people causes trigger points in others. However, studies suggest that muscle injury in some people leads to abnormalities where the nerve cells connect to muscle cells.\nWhile trigger points are usually found by an experienced doctor simply by touch (palpation), other tests such as magnetic resonance elastography (MRE) or tissue biopsy may be ordered. That said, the role of imaging in diagnosing MPS has not been fully teased out.\nWhat is Tender Points in Fibromyalgia ?\nFM is diagnosed primarily on a person’s report of widespread pain, along with a finding of multiple tender points on a physical exam.\nThe tender points of FM are different from the trigger points of MPS in that they represent exquisitely tender areas of muscles that hurt with simple manual pressure. In addition, the tender points of FM do not refer pain like the trigger points of MPS do.\nAcupuncture for fibromyalgia\nAffecting more women than men, fibromyalgia syndrome (FMS) is a rheumatic disorder characterized by chronic, diffuse and widespread musculoskeletal pain, and its pathogenesis is still unknown. Among the recommended treatments, acupuncture (for its analgesic effects) is an effective option for reducing the pain sensitivity and improving quality of life.\nAcupuncture involves the stimulation of the specific acupuncture points (acupoints) on the skin, usually by the insertion of needles ranging in length from 1 cm to 10 cm. Between 5 and 15 needles are used in a typical treatment, with the point combinations varying during a course of sessions. The acupoints can be chosen based on a standardized “formulary” involving a fixed menu of consistent points for each disease or condition or selected for each patient individually based on a patient’s specific symptoms and Qi balance. Depth of puncture can be up to 5 cm.\nAccording towww.acupuncturetoday.com,TCM divide fibromyalgia into four common typical TCM patterns.\n1. Liver Qi Stagnation\nAnxiety, emotional upset, headaches (including migraine headache), being easily angered, muscle stiffness in neck and shoulders, insomnia, waking frequently and having difficulty falling back to sleep, irritable bowel syndrome. All symptoms may be triggered by emotional stress.\n2. Qi and Blood Deficiency\nSpecifically spleen qi deficiency and heart blood/liver blood deficiency, with such symptoms as chronic fatigue, exhaustion, dull headache, muscle weakness and numbness, insomnia, dream-disturbed sleep and waking up tired, palpitations and depression.\n3. Qi Stagnation and Blood Stasis\nAches and pains in the whole body, burning or gnawing pain with tingling sensations in extremities, headaches.\n4. Kidney Deficiency (either Yin, Yang, Qi or Essence Deficiency)\nThere will be impotence or lack of libido for males and infertility issues for both males and females. Other symptoms: sore lower back with restless leg syndrome, irritable bladder, dysmenorrhea, amenorrhea, premenstrual syndrome, hot flashes and night sweats.\nSpecial Acupuncture Points\nUse any tender points that the patient has along with any of the following points listed below. There are a total of 18 tender point sites that may present in fibromyalgia.\nThe results are not only the effectiveness of tender-point acupuncture treatment on the patients’ overall well-being,but also reducing the pain sensitivity of FMS lead to improve quality of life.\nFibromyalgia self care\nAccording to NHS, there are some tips that may help relieve symptoms of fibromyalgia.\nAs extreme tiredness (fatigue) and pain are 2 of the main symptoms of fibromyalgia, you may find that you’re not able to exercise as much as you’d like.\nBut an exercise programme specially suited to your condition can help you manage your symptoms and improve your overall health. Exercise is likely to involve a mixture of aerobic and strengthening exercises.\n2. Aerobic exercise\nAerobic activities are any kind of rhythmic, moderate-intensity exercises that increase your heart rate and make you breathe harder.\nResearch suggests that aerobic fitness exercises should be included in your personalised exercise plan, even if you cannot complete these at a high level of intensity. As aerobic exercises increase your endurance (how long you can keep going), these may also help you function better on a day-to-day basis.\n3. Resistance and strengthening exercises\nResistance and strengthening exercises are those that focus on strength training, such as lifting weights.\nThese exercises need to be planned as part of a personalised exercise programme. If they’re not, muscle stiffness and soreness could be made worse.\nA review of a number of studies concluded that strengthening exercises may improve:\n- muscle strength\n- physical disability\n- quality of life\nPeople with fibromyalgia who completed the strengthening exercises in these studies said they felt less tired, could function better and experienced a boost in mood.\nImproving the strength of your major muscle groups can make it easier to do aerobic exercises.\nIf you have fibromyalgia, it’s important to regularly take time to relax or practise relaxation techniques.\nStress can make your symptoms worse or cause them to flare up more often. It could also increase your chances of developing depression.\nThere are many relaxation aids available, including books, tapes and courses, although deep-breathing techniques or meditation may be just as effective.\nTry to find time each day to do something that relaxes you. Taking time to relax before bed may also help you sleep better at night.\nTalking therapies, such as counseling, can also be helpful in combating stress and learning to deal with it effectively.\nYour GP may recommend you try this as part of your treatment.\nBetter Sleeping Habits\nFibromyalgia can make it difficult to fall asleep or stay asleep, known as insomnia. If you have problems sleeping, it may help to:\n- get up at the same time every morning\n- try to relax before going to bed\n- try to create a bedtime routine, such as taking a bath and drinking a warm, milky drink every night\n- avoid caffeine, nicotine and alcohol before going to bed\n- avoid eating a heavy meal late at night\n- make sure your bedroom is a comfortable temperature and is quiet and dark\n- avoid checking the time throughout the night\nBest (Thunyaluck Phongsasithron) CM.D."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"temporal_focus","category_name":"atemporal"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_intent","category_name":"instructional"}],"document_ids":["<urn:uuid:45ea5df1-89ba-4e2f-9e5c-4bebd9fce189>","<urn:uuid:c3fe0e98-e182-4d0f-80df-5d91610a8383>"],"error":null}
{"question":"How do Scaleup programs enhance business partnerships, and what security risks do they face when working remotely?","answer":"Scaleup programs like AVRO enhance business partnerships by facilitating connections between mature startups and corporates, aiming to reach deals like Memorandums of Understanding in five meetings or less. They help Scaleups with solid value propositions connect with corporates while allowing remote participation. However, remote work presents security risks including vulnerability through public WiFi networks, potential data breaches through mobile devices, and email-based threats. These risks require protection through encryption, proper password hygiene, and security policies for remote work arrangements.","context":["From a standing start a decade ago, Australia’s Startup landscape has grown exponentially over the last few years; there are more resources devoted to helping new Startups get off the ground than ever before, with coworking spaces, incubators, and accelerators aplenty, targeting every niche imaginable.\nOn the surface, it may seem like all these efforts are devoted to early stage businesses, but as more of the pioneering Startups in the ecosystem mature into Scaleups, the number of initiatives out there to support them is also growing.\nSo what exactly is a Scaleup? For Trent Bagnall, co-founder of Slingshot Accelerator, Scaleups are simply mature Startups.\n“They already have revenue, customers, a product that has product/market fit, and they generally have experienced growth of 30 percent year on year; those are the minimum requirements,” he explained.\nDesigned to support these businesses is the AVRO Scaleup program, run by Slingshot Accelerator in conjunction with corporate partner Qantas.\nQantas is running both a Startup and a Scaleup program through AVRO to address strategic opportunities it has identified for collaboration with innovative businesses. These opportunities have been grouped according to five key themes: creating seamless journeys; care beyond the air; building connected platforms; transforming for tomorrow; and innovating without limits.\nThe Scaleup program in particular has been designed to connect corporates with a new solution that is close to ready-made to help them fix a problem within their business, or allow them to tap into new markets quickly.\nBagnall explained that through the AVRO program, Qantas is looking for businesses that “may still be in Startup-land”, but need an incentivised partner like Qantas with a large customer base to help them scale quickly.\nThe Scaleup program was developed after Slingshot Accelerator found that, while its Startup program does well to connect corporates with innovative products and services that might add value to their business at some point in the future, limiting applications to exclude more mature Startups also meant excluding Startups with significant potential that a corporate could work with immediately to reach a deal.\nThough they may have some fine-tuning to do, Bagnall explained, a Scaleup with revenue and product/market fit is generally less in need of the services offered by an accelerator, such as advice around business modelling, branding, and pitch preparation, and more in need of a partnership deal with a corporate.\nBagnall explained, “While the Startups are still getting their MVPs done and getting product/market fit, the corporate can already start working with a group of Scaleups that are ready to go.”\nThough a Startup probably adds a more “disruptive type” of innovation to a corporate’s business than a mature Scaleup, Bagnall admitted, they are also high risk; a Scaleup with product/market fit means a higher probability of making a deal.\nWith this in mind, the AVRO Scaleup program looks to help with the core problem facing Scaleups: the process of scaling. The goal of AVRO is to help the Scaleup and the corporate sign a Memorandum of Understanding (MoU) by the time the program wraps up.\n“As Startups know, trying to deal with a large corporate can be time wasting and messy – it can be lots of maybes,” Bagnall explained.\n“There’s this analogy about lots of cups of coffee; often the Startup will reach out to the corporate to say, ‘I think we’ve got a great product’, so they meet in a coffee shop and do a little demo, the corporate gets really excited, the Startup goes back and says, ‘we’re going to sign a great deal with this large corporate’, and it turns into six to 12 months of maybes and often just fades away.”\nSlingshot Accelerator calls its Scaleup program a ‘Quick to No’ program, with the goal to help get Qantas and the Scaleup to an MoU in five meetings or less. The form that MoU takes can vary, whether it be a white label distribution agreement to Qantas’s existing customers or bringing the Scaleup on as a vendor to use its technology internally.\nTo help both the Scaleup and the corporate get ready for this process, Slingshot Accelerator acts as a facilitator and does the heavy lifting. As Bagnall puts it, Slingshot Accelerator’s skillset lies in bringing the two different forces together.\n“There’s a different language and culture on both sides,” he said.\nSlingshot Accelerator will work with the Scaleup to ensure they have a solid value proposition for Qantas, then work with the internal business units at Qantas to ensure there is a fit and a demand for the Scaleup’s offering, adequate resourcing, and KPIs associated with its onboarding.\nWith Slingshot Accelerator and Qantas aware that Scaleups are well and truly busy running their businesses, they are able to take part in the program remotely. This participation may be different from Scaleup to Scaleup, depending on the stage of their business and what they need.\n“There might be a couple of face to face meetings in Sydney, but there’s no requirement to be full time or part time, so it really opens the program up to Startups and Scaleups across the country and internationally. It’s a lower touch process, and we’re really trying to get outcomes with the least amount of time input as possible,” Bagnall said.\nPrevious iterations of the Scaleup program have seen success, with healthtech Scaleup Curo Technologies a key example. Coming through the HCF Catalyst program, Slingshot Accelerator helped the Scaleup and HCF develop a commercial agreement that has seen the two work closely together over the last year, with HCF also later investing $1 million into the business.\nOf course, just because a Scaleup may have product/market fit, customers, and revenue doesn’t mean they might not need extra assistance; those in need of a helping hand will also have access to the Avro Startup program, enabling them to tap into the wealth of skills and expertise in the mentor network.\nThey will also have access to the full range of perks being given to participants, including $5,000 in flights redeemable from Qantas and Jetstar.\nBagnall said, “It’s all about getting a real outcome at the end of the process.”","Everyone's working remotely these days, yet security risks remain. Here are 10 ways you can combat online security threats.\nShare this article\nThere can’t be many businesses today that don’t use remote working to some extent throughout the working day. Even those without a culture or need to offer remote working will have employees or directors taking work home, or working from hotel suites, conference venues and public transport at times.\nThis more casual form of remote working, one that may not be accounted for when analysing how business IT networks are used, is often missed in cyber security policies and procedures. However, it is one important factor that can put organisations at risk of cyber attacks and data breaches.\nRemote working, whether a formalised arrangement between a business and an employee, or an ad hoc ‘needs must’ requirement to get work done, can leave your business IT network, systems and devices vulnerable.\nThe first step for managing security and remote workers is to understand where your business is at risk. This should be followed with an awareness raising campaign within the organisation so that all employees understand how their actions may compromise security and what steps they must take to protect company networks and systems.\nCyber security policies need to include the specific risks associated with remote working, with procedures and guidance in place for working away from the office. This will also need to explain what actions need to take place if a remote worker believes they have exposed the company to a cyber attack, and any disciplinary measures that may be taken.\nThe following top tips provide an excellent starting point:\n1. Keep mobile devices and laptops safe\nLost and stolen mobile devices and laptops are easy pickings for cyber criminals if insufficient security measures are in place. The first line of defence is to look after these business assets: keep them with you and in sight at all times, and never leave them in hotel safes, cars etc.\nNext up is securing the devices themselves with good password hygiene and encryption on laptops. Finally, installing mobile device management apps such as AirWatch and MaaS360 give employees a chance of securing and recovering lost mobiles or tablets.\nRemember: it's not just cyber crime that can disrupt your IT\n2. Excellent password hygiene\nStrong passwords will not only protect your devices and systems being accessed if a mobile or laptop is lost or stolen, they also protect businesses from hackers. Good password hygiene includes using long passwords with multi-characters, two-step authentication processes, and unique passwords for different systems and logins.\n3. Ensure up-to-date security protection is in place\nAny devices that are owned by the organisation should be properly protected with antivirus, web filtering, firewalls, device encryption and other preventative software, but so too should your employees’ own devices if they are using them for remote working.\nThis can be a difficult area to negotiate as your employee may feel this impinges on the personal use of their device: Your cyber security policies will need to address issues like these, either restricting staff from using their own devices for certain business critical activities, providing secure company owned devices, or making your cyber security protection mandatory.\n4. Use of public wifi\nPublic wifi can be vulnerable to malicious attack, presenting issues for those employees who may need to work from a hotel or conference. While it is good advice to only connect to trusted networks this is not always feasible.\nTherefore, your remote working / cyber security policy should stipulate that employees should not use public wifi for any sensitive, business critical activities. It is advisable to draw up some guidelines that explain what systems and activities staff can and cannot access when using public wifi.\n'Quick question Dave: where's all our money gone?\n5. Email encryption and best practice\nEmail is perhaps the most used digital technology by staff members who are away from the office, and one that can open a backdoor to cyber criminals. Encryption and robust management of corporate email is a must.\nThe installation of applications such as Mimecast is a no brainer, but raising awareness of the vulnerabilities of email will also help embed best practice in your organisation. This can include training in spotting cyber threats like phishing emails, and also policies on what information should not be communicated in an email – for example logins and passwords.\n6. Using public computers\nWhile the majority of people will have their own laptop or mobile device that they use for remote working, occasionally someone may need to use a public computer such as in a business suite in an airport.\nEmployees should be aware of the security implications of this and adhere to the following guidance: keep screens private (position them away from other people), don’t use public computers for any sensitive information, use ‘private browsing’ where possible, never use ‘remember me’ or ‘save information’, and clear your browsing history and delete any downloads before closing the browser.\n7. Using devices when out and about\nEmployees should also be aware of physical threats when using devices when in public places like cafes, hotels, airports etc. Just as you would hide your PIN when using an ATM, employees should be discreet when keying in passwords and logging into systems.\nThey should also be aware of the risk of snooping and eavesdropping, not just online, but also from other people in the vicinity. Can someone see and potentially grab a discreet photo of company sensitive information while they work in a public space?\n8. Removable devices\nUSB sticks and other removable devices can be a source of malware and should be checked first. Many conferences hand out USB sticks that may be infected, often unbeknown to the organisers. Also don’t allow anyone to plug in a USB device into your computer, for example to share information in a meeting. Always get your IT department to security check removable devices.\n9. Monitoring and policy enforcement\nTwenty four-seven network monitoring and security will help your organisation identify threats and monitor users on your networks. Remote workers and their mobile devices can be monitored using this solution to protect your organisation’s network.\n10. Negligence and accidental risks in the home\nEven when your employees are working from home using your secure VPN, VDI or remote desktop, there can be other risks that need to be considered. Children and pets can be a surprising threat.\nCats have a habit of jumping on computer keyboards and inquisitive minds might press a few keys when a laptop is unattended. These kinds of risks should be addressed in your remote working / security policies to ensure that your staff take every feasible step to protect your systems at all times."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"future"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:23a6020f-ce37-40b5-b5ec-10fa003104f4>","<urn:uuid:02598588-2ea6-4379-b2e0-6b47df581446>"],"error":null}
{"question":"What are the key differences between planning a field trip and organizing a school auction in terms of financial considerations and required preparation time?","answer":"Field trips and school auctions differ significantly in their financial aspects and planning timelines. For field trips, the financial focus is primarily on covering costs like transportation, venue fees and student resources, with minimal profit potential. In contrast, school auctions are specifically designed as fundraisers with potential to generate significant profits, typically 60-75% of the value of donated items. Regarding preparation time, field trips require enough lead time to arrange transportation and align with educational standards, while auctions need at least 6 months of advance planning to secure donations, arrange venues, and coordinate numerous volunteers. Field trips require organizing chaperones and creating detailed schedules for specific day-of activities, whereas auctions demand extensive pre-event work including soliciting donations, creating catalogs, and training multiple teams of volunteers for different roles during the event.","context":["Field trips provide an excellent opportunity for students to learn about a specific topic, business or procedure firsthand by directly visiting the source. Though many field trips are often initiated by school administrators, often educators and even students are able to propose a field trip plan to be evaluated by schools for their potential feasibility and educational benefits. Writing a field trip proposal requires you to identify the school administrators' crucial concerns when planning a field trip: educational benefit, safety and cost.\nStart your proposal with a detailed and thoroughly researched background of the educational topic on which your field trip will focus. Include statements connecting your educational topic to state or school educational standards, as well as statements explaining why hands-on, first-person experience is the best way to learn about the topic. For example, if you are proposing a field trip to a local pond to collect bug samples, you might indicate that such a field trip would mimic the actual best practices of entomologists in the field.\nOutline your proposed field trip's educational objectives. Align your objectives with the state or school educational standards used to construct unit and lesson plans for the discipline in which your proposed field trip best fits. For example, a proposed field trip to a newspaper office might align with standards pertaining to composition, editing, proofreading and design.\nDescribe the field trip details. Include the names of any organizations or individuals with which students might be interacting, as well as the names of businesses or organizations the group might patronize, either in line with the focus of the trip or because they'll be away from the school. For example, if students will stop for lunch you might indicate several eating establishments where students could stop.\nDescribe the field trip's schedule. Include the departure and arrival times for each destination, as well as the times certain activities (meetings with individuals, lunch and breaks) might take place.\nList resources required to take your proposed field trip. In addition to monies to be used to pay organizations you may visit, include a list of personnel that will chaperon or otherwise work with the trip, as well as transportation requirements such a buses or vans. Also indicate the resources students participating in the field trip will be required to provide, such as pens or pencils, special clothing or accessories or even pocket money.\nRecap the positive features of your proposed field trip. Reiterate the objectives and emphasize the simplicity of the trip compared to the overall educational benefits for the participants involved.\nStyle Your World With Color\nExplore a range of cool greys with the year's top colors.View Article\nSee how the colors in your closet help determine your mood.View Article\nUnderstand how color and its visual effects can be applied to your closet.View Article\nLet your imagination run wild with these easy-to-pair colors.View Article\n- \"Technical Communication: A Reader-Centered Approach\"; Paul V. Anderson; 2010\n- \"Field trips: A guide for planning and conducting educational experiences\"; Wayne J. Krepel; 1981\n- Jupiterimages/Photos.com/Getty Images","Your PTO needs to earn some money. Your group has strong community support. You’re not intimidated by planning a large event. You can pull together a committed group of volunteers, maybe even 15 or 20 people. You can afford to wait several months for the payoff. You want to try something more interactive and engaging than a traditional sales fundraiser. Are you nodding your head? Then an auction might be just the fundraising project for your PTO.\nAuctions are fun, exhausting, profitable, complicated, and exciting. Unlike a fundraiser supported by a professional fundraising company, an auction requires your PTO to do most of the work on its own. But for the right group, the benefits of an auction fundraiser can outweigh the challenges of going it alone. Done well, a good auction can be quite rewarding for your group, often more so than other fundraising activities. An auction is also a social event that brings together families, friends, staff, and the community at large in mutual support of the PTO and the school. For some parent groups, the annual auction gala has become an important tradition, with the event growing in popularity and profit each year.\nThe planning for the basic auction gala follows a fairly consistent work plan. First you must assemble a strong team of dedicated volunteers. Your group then solicits donations, which will become your auction items. Fairly early on, you’ll need to make some important decisions about the format of your event. For example, will your auction be the only activity at the event, or will you incorporate the auction into a carnival, game night, or something else? Will it be held at the school or off-site? Will you offer food? Will this be an adults-only event? Will you charge for tickets? Will you offer both silent auction and live auction items?\nRegardless of format, you’ll need to publicize your event and generate enthusiasm within the school and community at large. There are some administrative tasks that must be handled, such as tracking your auction inventory, managing ticket sales, and developing bid sheets and a catalog for your guests. Creative tasks include designing decorations and preparing appealing displays for the auction items. There’s plenty of up-front work to keep your team busy.\nDuring the event itself, guests place written bids for silent auction items during a specified time period. When bidding closes, the highest bidder “wins” the item. If you include a live auction in your event, the auctioneer entices verbal bidding from the guests as a group, with the excitement growing until the final “Sold!” Typically winners pay for their items before they leave and take the items home so that by the end of the evening, all that’s left is a room full of exhausted, but happy, volunteers.\nKeys for Auction Success\nStart early. It’s not overkill to start planning six months in advance, even for a small auction. Often, national companies require several months’ advance notice for a donation. Plus, the more time you allow for donation solicitation, the more items you’ll have. You’ll also want to lock in your venue early, especially if the event is off-campus.\nRecruit strong volunteers. Your core planning team will be working together for several months and dealing with issues and challenges, so recruit wisely. This is the time to personally reach out to your most dedicated and talented members. There are plenty of jobs for less experienced helpers, too, so everyone can be involved at some point.\nMake major decisions early. You’ll need to decide right from the start the basic format of your event. Planning a family-oriented auction in your school gym differs significantly from the planning you’ll do for an adults-only dinner gala at a social club.\nConsider your community and design your event accordingly. Some communities are comfortable with an event at a fancy country club. Others might be more inclined to support a less formal venue. Location and format also affect ticket price, which could have a ripple effect on the bid amounts. The local economy also matters when designing an event like this; yes, this is a fundraiser, but you want people to be able to afford to bid.\nAsk parents to help collect auction items. Challenge each family to obtain at least one item for auction.\nCollect a range of items at different price points. Solicit big-ticket items like professional sports tickets or a mini-vacation package, but also seek out small- and medium-value items like restaurant gift certificates and jewelry. Several very low-value items can even be bundled into an appealing basket.\nDelegate the work. There’s too much for one or two people to handle. The chairperson will have a lot on her plate. Redistributing even small tasks will help.\nEngage teachers and students by encouraging each classroom to develop a special auction donation. Some of the most profitable items are student art projects. You can also assign a theme to each class and ask them to collect a basket of items related to that theme.\nConsider using auction software. There are many tasks that go into a successful auction event, some of which are computer-dependent. You can certainly do the computer work on your own, but some groups prefer to purchase professional software.\nPay attention to presentation and bundling. You want your auction items to look appealing and valuable so guests are eager to bid. Signage, décor, and lighting can all enhance the display.\nIncorporate the purpose of the auction into your marketing and decorations so bidders remember why you’re asking for their money.\nTrain on-site volunteers, including runners, cashiers, and spotters.\nSet up early in the day so you have time to make adjustments if necessary. You might be surprised by how much table length you need to display all your auction items. Lighting can also pose a problem; you may need to bring in extra lamps so your guests can read the bid sheets easily.\nKeep things moving throughout the evening. A DJ, an enthusiastic emcee, and especially a professional auctioneer can help keep the crowd energized and actively bidding.\nTake lots of photographs. You’ll never remember how things were set up, so a stack of pictures will be valuable to next year’s planning committee.\nTop 7 Ways To Increase School Auction Profits\nMake the auction the focal point of your event. It can be enticing to fit a silent auction into another event such as a carnival or family game night. However, you’ll make more money when your bidders aren’t distracted by cotton candy or “Simon Says.” Also, young children tend to lose patience when moms and dads are trying to monitor bids. It’s just about the same amount of work to manage a small “add-on” auction vs. a large exclusive auction, so focus on an auction-only event for maximum profit.\nUse a professional auctioneer if you’re having a live auction. A properly trained auctioneer comes at a price, but his fee can easily be offset by the increase in bidding during your live auction. A pro knows how to read the crowd, how to pick out the most generous bidders, when to end bidding, and how to keep the anticipation high so folks stay engaged. Invite a local celebrity to be the master of ceremonies, but hire the auctioneer.\nClose bidding on your silent auction items in groups, not all at once. By staggering the closing times, bidders can gauge their current financial commitment and then continue bidding if they feel they want to invest more for your group’s benefit. Most people come to an auction with a dollar amount in mind that they are willing to spend at your event. If all of the silent auction bidding closes simultaneously, it’s possible a bidder could be outbid on all her items, leaving her with a feeling of disappointment and her wallet still in her purse.\nAdvertise the big items as well as those with restrictions so people can plan their bidding ahead of time. Catered dinners or a group boat trip will attract higher bidding from your guests if they have their bidding groups organized in advance. High-value items like fine jewelry or professional sports tickets should also be promoted before the auction. And remember that no one can digest fine print restrictions on a bid sheet on the spot. Your guests will be more likely to bid on the airline ticket voucher or weekend getaway if they’ve had a chance to check their calendars and the details of the item before the auction.\nAccept credit cards. Make this a priority item for your planning committee. You will need to establish a merchant account with a credit card processing company ahead of time. Also, be certain to test the actual processing of the cards at your venue. You’ll have a crowd of unhappy bidders waiting in line if your one data-transfer line goes down during cash-out. You might be better off accepting credit card payments manually and paying the slightly higher processing fee for peace of mind.\nStimulate bidding wars over sentimental items. It might sound crass, but you are trying to maximize bidding. A handmade item from a class of students, such as a hand-painted chair, will attract competing bids from that classroom’s group of parents.\nReach out to corporate sponsors. Offer special recognition such as table signs, prominent ad placement in your auction catalog, and “callouts” during the evening. If you can get a local florist to donate table decorations, that’s one less expense to cut into your net profit.\nHow does the silent auction work?\nAll of the silent auction items are set out in an attractive display at the auction venue. Each auction item is identified with a unique number, and each item is accompanied by its own silent auction bid sheet. Bidders walk around the displays and write down their bids on the bid sheets, using their name or a bidder number as identification. If someone wants to bid higher, they write down a new bid on the next line of the bid sheet. Typically, guests are provided with an auction catalog that includes a complete description for each item, its value, and its item number. Guests use the catalog to help them plan their bidding. At the appropriate time, bidding is closed and the high bidders are announced.\nAt a very small auction, winners could be announced verbally, but usually the winners’ names are simply written on the bid sheet. Winners pay for their purchases at the cash-out area and take their items home at the end of the event.\nHow much can we expect to earn from our auction?\nUnfortunately, net profit is hard to predict, especially for your first auction. The changing economy also affects profit levels. In general, profit depends on the number of auction items you secure, the value of the items, the number of guests at your event, their willingness to bid on your items, and your overhead costs such as publicity, facility rental, food, and auctioneer. If you charge enough for tickets to cover your overhead costs, then all the auction funds are profit. A rough rule of thumb is that a silent auction can raise 60 percent to 75 percent of the value of the items. If you keep meticulous records, it will be easier to estimate your profit year to year.\nHow do we solicit auction donations?\nAsk, ask, ask. Use many different avenues for donations. Mail out letters to large corporations, go door-to-door in your local business community, involve students in developing themed baskets or artwork, challenge families to secure at least one donation each. The St. Theodore Holy Family Catholic School PTC in Lake Charles, La., sends smart shoppers to watch for closeout sales; smaller items are grouped together into a gift basket. The group also sends volunteers door-to-door to solicit donations. And donation forms are distributed to families in May so they can be on the lookout for action items throughout the summer, says auction chairwoman Denise Savoie.\nShould we charge for tickets?\nThat depends on the format of your event and your community’s experience. Tickets are usually sold for a sophisticated, “adults only,” off-campus auction gala in a community familiar with such fundraisers. However, if this is a completely new concept to your families, you might want to keep admission low or even free. When you’re setting your ticket price, however, consider costs and psychology. If you intend to serve food and beverages (highly recommended), then charge at least enough to cover those costs. Also, consider that people tend to believe there’s value if there’s a cost. So if admission is free, you might be sending the wrong message about the quality and importance of the event. Look around at similar events in your area to gauge what would be agreeable to your community.\nAuction Dos and Don’ts\nDon’t underestimate the amount of work.\nDo ask your families to help solicit donations.\nDo be creative with your auction items. One-of-a-kind experiences and “priceless” items usually bring high bids.\nDon’t overprice your opening bids. You want people to feel comfortable making that first bid, which will get things going.\nDo offer items at a variety of price points. Not everyone can afford to bid on the trip to Las Vegas.\nDo advertise the highly valuable items or those with important restrictions well in advance of the event. Encourage your guests to preplan group bidding and check their calendars for items that are date-dependent.\nDon’t forget to send a proper thank-you to all your donors and volunteers.\nNew and Trendy\nThe most significant change in the world of auction fundraising is the emergence of online fundraising auctions. The popularity of eBay for personal auctions has proved that people are comfortable bidding over the Internet. Now that technology has been adapted for fundraising, and many PTOs are expanding the reach of their auction beyond their local community. Typically, an online auction, run by a company like BiddingForGood, complements the live auction."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"temporal_focus","category_name":"current"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:afa6c75d-07fe-4ca9-bc7f-22b090d48820>","<urn:uuid:ff1446a9-a694-4e2c-8c22-783639c29a75>"],"error":null}