{"question":"How did post-WWII Soviet influence affect the architecture of Sillamäe versus Tallinn?","answer":"Sillamäe and Tallinn experienced Soviet influence differently. Sillamäe became a prime example of a utopian Stalinist city, built according to an all-Union standardized project to embody Communist happiness. It was also a closed city due to uranium mining. In contrast, Tallinn's Soviet architecture was more moderate - described as 'middle-class' compared to other socialist republics, making it popular for filming 'western life.' Tallinn's Soviet period included both Socialist Classicism (1940s-1950s) and Soviet Modernism (1950s-1980s), but maintained some of its pre-war character and even incorporated influences from Northern Europe, especially Finland.","context":["Ida-Virumaa ülesehitamisest pärast sõda kirjanduses ja filmikunstis / On the Reconstruction of the Ida-Virumaa Region in Post-War Literature and Film\nArtiklis on vaadeldud Narva ja Sillamäe linnast inspireeritud kirjandust ja üht mängufilmi, mis tegelevad lähemalt maastikuloomega ning kohamälu tekitamisega pärast II maailmasõda. Sõjajärgse Kirde-Eesti ülesehitamine tööstuspiirkonnana on peegeldunud memuaristikas, tagasivaatelistes omaeluloolistes tekstides ning oma kaasajas ehitust kajastavates allikates. Vaadeldud näited avavad seda, kuidas on kirjeldatud nõukogude perioodi tööstuslinna, alustades sõjajärgsest taastamistööst ning lõpetades Andrei Hvostovi tagasivaatega nõukogudeaegsele lapsepõlvelinnale. Tekstide analüüs võimaldab märgata sõjaeelse maastiku transformeerumist tööstusmaastikuks, selle kajastuste vastuolulisust ning sõltuvust kirjutamisajast.\nThe article observes literary depictions of two towns in North-East Estonia, Narva and Sillamäe, both of which were reconstructed as industrial towns after World War II, in fiction, life writing and a film script, as well as in a feature film made on the basis of the latter. The texts are simultaneously engaged in the making of landscape and creation of local memory after the region’s dramatic change caused by the war.\nIda-Virumaa became an industrial region in the second half of the nineteenth century; the Kreenholm Textile factory was one of the world’s largest by the end of the century. In 1916, industrial mining for oil shale was started in North-East Estonia. Oil shale was a strategic resource in World War II as well. In 1944, with the second occupation of Estonia by the Soviet Union, uranium mining was started as a secret object of interest for the military industry.\nThe historical town of Narva was almost completely destroyed in World War II. Few buildings were restored, while the city was filled with blocks of flats typical of the Soviet period and the historical street network was transformed significantly. Still, Narva did not become a utopian Stalinist city – in Estonia, the only example of the latter is Sillamäe, a closed city built according to an all-Union standardised project, that attempted to embody an image of Communist happiness.\nPostwar literary depictions of Narva have often proceeded from the baroque city centre that has become a separate symbolic site of memory. In the more recent past, different genres have started to complement one another, different periods have been compared and, as a result, representations of various spaces have received a more analytic artistic treatment that connects the pre-war period with the post-war one.\nThe first set of texts discussed here consists of POW memoirs of the immediate post-war reconstruction works, set down some decades later. After that, contemporary reflections of the reconstruction in Soviet Estonia in the 1950s-1960s are considered. Finally, attention is paid to texts that comment on the reconstruction era from a larger temporal distance: a backward look at Soviet-time Sillamäe from 2011 (expanded edition 2014) by Andrei Hvostov, a journalist with a degree in history, who spent his childhood in the town. Hvostov’s memoirs and his short stories on similar topics that were published earlier serve as attempts at parallel interpretations of several possible local memories. A work that in a way unites all three periods is Vladimir Beekman’s novel The Narva Waterfall (1986). Its protagonist Stiina was born and grew up in Narva, left the war-ravaged city and criticises harshly the changes that have taken place in the city.\nThe examples of memoirs, retrospective autobiographical texts and sources reflecting their contemporary period also reveal how industrial cities of the Soviet era have been depicted in different periods. An analysis of the texts discloses the transformation of the prewar landscape into an industrial one, the contradictory nature of its descriptions, as well as dependence of the latter on the time of writing. Examples are given of the possibilities of representing large-scale industrial constructions that significantly also involve not just the creation of new values but also the way of doing this – reflecting the work of the udarniki of the Young Communist League. According to Katerina Clark’s typology of Stalinist novels, one of the texts observed, the film script concerning the shock workers’ building of the Balti Thermal Power Plant to which the youth from the Young Communist League contributed, can be categorised as the most widespread and ritualised type of Soviet fiction, the so-called production novel.\nThe selection of texts discussed in the article is by no means exhaustive and the Ida-Virumaa region may offer fruitful material for future studies using the categories of space and memory, both as regards ways of describing a real region in literature as well as analysing the stories clustered around a site of memory. The notion of a literary city emerging in the texts is broad, as areas and objects with different functions form part of it. The observed texts display an interesting conflict in spatial memory: a deliberate loss of memory induced during a certain period and the creating of something new as if into a void can be emphasised as can be using rhetorical devices to bring forth a new spatial representation, a site of memory in its own right.","The many faces of architecture in Tallinn\nAdd to Favourites\nTallinn is a compact seaside town of contrasts and its medieval old town, defence structures and wooden suburbs are its most valuable architectural pearls.\nSome people say that Tallinn is similar to Helsinki, while it reminds others of Prague. In the 19th century, our capital was called the Naples of Scandinavia, but Tallinn is, indeed, still Tallinn.\nOld churches, buildings and fortifications have been magnificently preserved in the Old Town. Just step outside the Old Town and cross the street where you will find yourself in the ultramodern Rotermann Quarter with the old suburb of Kalamaja located opposite. The area mostly consists of wooden buildings that once accommodated fishermen. At present, it is one of the most well-known residential areas for hipsters in Europe. In Kadriorg, a baroque palace and modern art museum Kumu stand alongside each other. These two are adjoined by the picturesque quarter that even today exhibits a 19th century provincial atmosphere. In the centre of town, the pre-war strict and integrated architecture representative of the Republic of Estonia is mixed with Soviet buildings. Below you can read about the various architectural styles represented in Tallinn. Each description of a style will also include examples that can be admired throughout the town.\nThe districts of Tallinn with distinguishing architecture\nThere was a fortified stronghold on the slope of Toompea in the 11th century and there were also a settlement and fenced-in market place in the vicinity of the present Town Hall Square. There were two market yards nearby – the Scandinavian and the Russian market.\nWhen the crusaders arrived in 1219, a castle and dome church were erected in Toompea. The building of the first battlements around Toompea was started in 1229. In the lower town, the first battlement was erected in 1265 at the behest of Queen Margaret. The battlement that remains today dates back to the 14th century. A town consisting of two separate parts was formed at that time – the capital of the Estonian Duchy – Toompea (Domberg or upper town) – and the lower town of the Hanseatic Town Reval.\nThe most important period in the architectural development of Tallinn was 13-16th century. Tallinn’s gothic architecture was influenced by the architecture of the island of Gotland, Lower Rhine and Westfalen and subsequently by the architecture of the Hanseatic Towns and the German Order. Local construction material – limestone – added character to the architecture.\nBy the 14th century, the castle in Tallinn had become one of the most powerful fortresses of the Livonian Order. The layout of the castle, its architectural austerity and its simplicity served as a model for other fortifications in the area. Only the western and northern outer walls, along with its three towers – amongst them one of Estonia’s symbols, Tall Herman – were spared later reconstruction.\nIn the 15th century (Late Gothic era), a town hall, guild building, convent buildings and residential houses were built in the town. These are characterised by the high dormers on the high-stretched facades. Of the different layouts, the prevalent type of house was that with two rooms, a diele and a dornse. A diele is a spacious room that extends to the height of two storeys with a fireplace at the back wall; this type of building was primarily used as an office or workshop. And behind it was the dornse – a living room with hot-air heating. The upstairs, cellars and attics were used as storage rooms.\nSuch buildings were first erected on Pikk street (The Three Sisters, 71 Pikk street), Lai street (The Three Brothers, 38, 40, 42 Lai street) and at the Old market (Father and Son, 1 Kuninga street).\nTallinn Old Town has been entered in the UNESCO World Heritage List as a well-preserved medieval town. It is a unique town within the Baltic Sea region and in the context of Europe.\nExamples of Gothic architecture in Tallinn:\n1. Town Hall (15th century), 1 Raekoja street.\n2. Dome Church (15th century), 6 Toom-Kooli street.\n3. St. Nicholas’ Church or Niguliste Museum (1420), 3 Niguliste street.\n4. St. Olaf’s Church or Oleviste Church (15th century), 65 Pikk street / 50 Lai street.\n5. Church of the Holy Ghost (15th century), 2 Pühavaimu street.\n6. Great Guild Hall (1417), 17 Pikk street.\n7. St Olaf’s Guild Hall (1422), 24 Pikk street.\n8. St. Catherine’s Dominican Monastery Hall (14-15th century), 12/14 Vene street.\n9. New alms-house (16th century) 7/9 Rüütli street.\n10. Horse mill (14-18th century), 47 Lai street\n11. The ravelins of St. Bridget’s Convent (1417), 18 Merivälja road.\nThere are a few buildings left that date to the Renaissance era. One example is the House of the Blackheads (1597) located at 26 Pikk street. In Tallinn, Renaissance-style architecture manifested itself most frequently in the ornaments of houses, especially in carved details and decorative paintings.\nIn the beginning of the 17th century, a new style reached Tallinn. This was baroque, or to be more precise protestant Scandinavian Baroque. It is an extremely restrained style that manifests itself in functionality and simplicity.\nIn the 18th century, we can mostly see Baroque architecture in reconstructions – from the reign of Peter the Great to the middle of the 18th century, the construction of stone buildings was prohibited throuhgout the whole of the Russian empire, excluding St. Petersburg.\nThe pearl of Baroque architecture in Tallinn is the von Rosen Palace (1670s, 28 Pikk street). The most magnificent Baroque building is Kadriorg Palace, which was designed in Italian Baroque style by architect Niccolò Michetti (1718, 37 A. Weizenbergi street). Another example of baroque architecture is the residence of the Governor of Estonia and the house of the Provincial government in Rococo style with some elements of classicism (1773, architect Johann Schulz, 1 Lossi square). Stenbock House (1686, 17 Lai street), which at one point was owned by A.D. Menshikov, represents Dutch Baroque.\nThe facade of the northern porch of St. Nicholas’ (Niguliste) Church was decorated with sculptures in the 17th century, but quite the tower spire was rebuilt in baroque style at the end of the century (3 Niguliste street).\nIn the era of classicism (from the end of the 18th century to the beginning of the 19th century) many buildings were erected in the upper town, whereas buildings were being rebuilt in the lower town. In the course of rebuilding, many of the medieval facades were given a modern classicist exterior. The Gothic style often prevailed inside the yards.\nThe best examples of classicist architecture in Tallinn are: the seat of the government (1790, 3 Rahukohtu street), von Rosen House (1830, 5 Lai street), Benckendorff House (1814, 8 Kohtu street), the first dome building – St. Nicholas Church (1827, 24 Vene street).\nIn the middle of 19th century historicism and eclecticism came into vogue. The first manifestations of this style in Tallinn were St. Canute’s Guild Hall (1864, 20 Pikk street), which was initially built in the Tudor-Gothic style, and the Estonian Knighthood House (1848, 1 Kiriku square). Alexander Nevsky Cathedral (1900, 10 Lossi plats) is an example of the Pseudo-Russian style. The Reichmann house (1909, 21/23 Pikk street) is the most interesting example of Neo-Mannerism.\nThe historic centre of Tallinn changes rapidly from the second half of the century onwards. The area between Viru Square and Tõnismägi is actively developed and the old town and the new parts begin to gradually merge.\nDue to the unique construction material, the industrial architecture of the new era greatly resembles that of the Old Town – with the Rotermann warehouses and factories (8 Rotermanni street) and Rosen’s Distillery (6 Mere avenue) as examples.\nIn the 20th century, Tallinn welcomes an architectural style that was widespread in Europe – Art Nouveau, in particular Scandinavian Art Nouveau, which emerged due to the influence of Finnish architecture.\nThis is the era when well-known Finnish architects Armas Lindgren, Herman Gezelius and Eliel Saarinen were working in Tallinn. The latter drafted the town’s first general plan in 1913 that prescribed the shift of trading outside the boundaries of the Old Town.\nExamples of Scandinavian Art Nouveau:\n1. Estonian National Opera (1913), 4 Estonia boulevard.\n2. Estonian Drama Theatre (1910), 5 Pärnu road.\n3. Saarinen House (1912), 10 Pärnu road.\n4. The Luther Factory workers' house (1905), 37 Vana-Lõuna street.\nThe other sub-style of Art Nouveau that spread in Tallinn was the eclectic-decorative style, known as Riga Art Nouveau. It is more flamboyant and stands out with a great number of masks and ornaments. An excellent example of this sub-style is J. Rosenbaum’s Draakoni Gallery (1910, 18 Pikk street).\nThe pre-war architecture of the Republic of Estonia\nThis is the time when the town shifts outside its historical heart. A new Tallinn is formed – the capital of the Republic of Estonia.\nThe architecture of 1930s Tallinn is a mixture of traditionalism, functionalism, Art Déco and Scandinavian classicism. It is clearly recognisable and respectable, primarily due to its rectangular shapes and the popular brown or greyish colour anthracite grout popular at the time. At the end of the 1930s, it became popular to cover the facades with dolomite panels or broken limestone.\nIt is indeed the functionalism of the 20th century that gave the present heart of Tallinn its truly national exterior.\nThe pre-war architecture of the Republic of Estonia can be seen at Tõnismägi and by Pärnu road, as well as Raua street and in the area around Police Park.\nExamples of functionalism include:\n1. Tallinn Art Hall (1934), 6 Vabaduse square.\n2. Tallinn City Government building (1935), 7 Vabaduse square.\n3. Tallinn “Chile House” (Chilehaus) (1936), 23 Roosikrantsi street / 36 Pärnu road\n4. The House of Parliament / Riigikogu (1922), 1a Lossi square.\n5. Fire station (1939), 2 Raua street.\n6. Chapel at Metsakalmistu (Forest Cemetery) (1937), 36 Kloostrimetsa road.\n7. Chapel at Liiva cemetery (1935), 34a Kalmistu road.\nThis period added two new original styles to architecture in Tallinn – the Socialist Classicism of the 1940s-1950s and the Soviet Modernism of the 1950s-1980s. The peculiarity of Soviet architecture in Tallinn lies in the fact that it is middle-class in comparison to other socialist republics – this is also why Tallinn was such a popular place for film-makers who came here to film the so-called western life.\nArchitecture in 1945-1961\nThe architects who stayed on in Estonia after the war designed buildings in the pre-war style. There are signs of German influences there – high stone roofs, the grey or brown grout characteristic of the 1930s.\n1. The building of the Estonian Academy of Sciences (1958), 7 Estonia boulevard.\n2. Sõprus Cinema (1955), 8 Vana-Posti street.\n3. The Radio Building (1958), 14 Kreutzwaldi street.\nIn the beginning of the 1950s, international Socialist Classicism gathered ground.\nAt the time, architects from Leningrad (modern-day St. Petersburg) were sent off to work or go on a traineeship to Tallinn. They added the Soviet style to the exterior of the town; the new style made the town ideologically more restrained and helped to express the Stalinist ideas better; however, these were still type projects.\n1. Tower building (1954), 24 Tartu road.\n2. Naval Officers’ House (1954), 5 Mere boulevard.\nThe examples of Soviet architecture that are of particular interest are the developments in Mustamäe, Pirita and Nõmme from the 1950s to the 1960s, which show no similarities in any way to the building style employed in other republics of the Soviet Union.\nArchitecture in 1960-1980\nArchitects began to try out different styles in Tallinn at the beginning of the Khrushchev Thaw in the 1960s. The erected buildings become symbols of both the town and the whole republic. Despite the iron curtain, new modern trends from Northern Europe, especially Finland, became apparent in Estonian architecture. What makes modernism special is its international character.\n1. Building of the Ministry of Foreign Affairs (1968), 1 Islandi square.\n2. The Library of the Tallinn University (1964), 10 Rävala boulevard.\n3. Flower Pavillion and restaurant Tuljak (1964/1970), 26 Pirita tee road, 26e Pirita road.\n4. The stage of the Song Festival Grounds (1960), 95 Narva road.\n5. Viru Hotel (1972), 4 Viru square.\n6. The Writers’ House (1963), 1 Harju street.\n7. Maarjamäe Memorial Complex (1960/1975), 74 Pirita road.\nIn 1980s, the style of brutalism is used in construction in Tallinn – the majority of buildings were completed for the Olympic Regatta held in Tallinn during the 1980 Olympic Games. At this the time, Pirita road is built together with the seaside promenade that joins the centre of town with Pirita and the Olympic Yachting Centre.\n1. Tallinn Olympic Yachting Centre (1980), 1 Regati boulevard.\n2. Hotel Olümpia (1980), 33 Liivalaia street.\n3. Linnahall/City Hall (1980), 20 Mere boulevard.\n4. The building of the National Library of Estonia (1992), 2 Tõnismägi street.\nContemporary Estonian architecture\nAfter the era of panel houses characteristic of the 1970s and Soviet modernism of 1990s, Estonian architecture – which was considered progressive at the time – made a giant leap forward by the end of the 1990s.\nThe most recent projects have changed the town's exterior remarkably. Those interested in modern architecture will have plenty to see in Tallinn. The buildings here now exhibit trends that are typical of Northern Europe. The characteristic features are: functionality, the use of modern (including natural) materials (especially timber/wood)) and energy-efficient technologies.\nA good example is the art museum Кumu (2006, 1 Valge street). In striving to fit into the stony landscape, it literary rises up from inside the ground and delicately shifts the boundaries of this historic quarter.\nSeveral religious buildings can be seen in the background of modern houses – the new St. Bridget’s Convent (2001, 18 Merivälja road) melts perfectly in its surroundings and follows the de facto the traditions of the old convent, built in the 15th century and now in ruins. Tallinn Synagogue (2007, 16 Karu street) is an interesting solution where the relatively modest building on the outside is decorated by an amazing interior.\nAlongside new projects, people are now actively involved in the renovation of old buildings. In many such buildings, as much of the old is preserved as possible.\nThe former Rotermann industrial quarter (8 Rotermanni street) now houses a new, conceptual building complex – the old factories are complemented by modern houses; as a result, the quarter is slowly claiming a central role in the town's architectural ensemble.\nEnergy Discovery Centre and the Tallinn Creative Hub were opened in the building of a former power plant (27a Põhja boulevard).\nOne of the recent projects is also the Maritime Museum, which is housed in the former hydroplane hangars (1917). The latter constitutes an excellent and rare example of the use of concrete domes both in Estonia and elsewhere in the world (6 Vesilennuki street)."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:756b73df-0d73-4f1b-b132-f7bb5c068c94>","<urn:uuid:cb94d8ec-645c-439b-8696-5f764243f1b4>"],"error":null}
{"question":"What impact have greenhouses had on food sustainability in Ladakh's remote villages?","answer":"Greenhouses have had a significant impact on food sustainability in Ladakh's remote villages. In one particularly isolated community, a small greenhouse has enabled the village to grow enough food year-round for the entire population. In another area, a larger greenhouse is producing surplus vegetables that are sold at market, with profits being reinvested in potato planting and greenhouse maintenance.","context":["Meet: Tamara Cannon, charity worker\nPhoto - T. Cannon\nGreenhouses are producing life-saving vegetables in the high-altitude desert villages of Ladakh, thanks to the Australian charity Lille Fro. Robin Powell spoke to its founder Tamara Cannon.\nTell us a bit about Lille Fro.\nIt’s a charity I started in 2008. We work with families and communities in the remotest places on earth, in Ladakh in northern India. We fund education for kids through child sponsorship, and we have a skills development program for mums and dads teaching them to grow vegetables at high altitude.\nWhy is that necessary?\nOur focus is in reaching families living in extreme poverty and helping them become sustainable. These villages are not only poor, they are isolated, with winters of -30 degrees for 6-8 months. What vegetables they can grow through summer don’t last through winter. Malnutrition is high; many of the children suffer from disabilities.\nThe sustainability solution you’ve been implementing is greenhouses. How is that going?\nIt has had an amazing effect on health and wellbeing. One community is so isolated it can’t reach a market at all through the winter, and with a small greenhouse it has become sustainable and is able to grow enough food for the whole village all year. In another area a larger greenhouse has started producing an excess, which is being sold at market. The profit is being invested in planting potatoes and in mending the greenhouses.\nVillage women building a greenhouse. Photo - T. Cannon\nHow many communities are you working in?\nWe have six programs in various stages of development at the moment. The whole process takes about 24 months because you can only access the village for such a brief period of time.\nHow do you get to these isolated places?\nIt’s not hard to get to Ladakh itself. The capital Leh is an hour-and-a-half flight from Delhi. It’s a tourist mecca, one of the most beautiful landscapes you’ve ever seen, like Shangri-la. Then it’s a two-day jeep ride over some fairly harsh terrain to a village where we can base ourselves and get our bearings for a few days. Then it’s a trek. One village is 13-hour trek over a pass that is 5,5000ft above sea level.\nA great harvest. Photo - T. Cannon\nHow did it come about that you are doing this work in Ladakh?\nIt happened by accident. I was a corporative lawyer until 2008 when I put my law degree into the bottom drawer. I found myself in Hong Kong with some time on my hands, so just closed my eyes and pointed to a spot on the map. My finger landed on Mt Everest. I had never trekked or climbed a mountain before, and I saw that as I challenge. So I bought a pair of hiking boots and up I went. I just fell in love with the Himalayas. I was just in awe. It inspired me to start climbing mountains. Nepal was shut for down for the monsoon season, so I made my way to India and Ladakh where there are some relatively easy peaks to climb.\nMy guide, Dawa, came from a poor background, and had been sponsored as a child, which had enabled him to go to school. He felt this love and gratitude towards his sponsor that really moved me. I sponsored a little girl, and enrolled her in school. It was so easy, I started to think how it could be to share that with other children. I found it difficult to turn my back on that thought. And so I started Lille Fro."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:b96f6a2c-cd98-44c9-a283-64054cb51888>"],"error":null}
{"question":"What factors affect how long a wooden carving will last and how can we preserve it for multiple generations? 哪些因素会影响木雕的寿命，我们如何才能让它保存多代？","answer":"Wood carvings can last from a few decades to several lifetimes depending on how they're maintained. The main destructive agents are moisture, bad weather, and insects. To ensure longevity, two key preservation methods are essential: 1) Store the carving indoors away from direct sunlight - if outdoor display is necessary, use UV-approved marine varnish and recoat periodically. 2) Apply proper wood sealer - for initial treatment, apply several coats with daily intervals, then reapply regularly during the first year and once yearly after that. Softer woods need thicker sealer while harder woods require thinner application.","context":["When it comes to The best way of finishing a wood carving project there are many things you should first consider before you even come to the finishing products or techniques to apply. The essential things to put into considerations are for example the type and the characteristics of the wood, the type of carving, and the final look you want your carving to appear. That is why we prepared this article to help you out.\nPurpose of finishing wood carving\nFinishing your wood carving ensures there’s an additional layer that is purposefully there to protect the wood beneath. It’s however important to note that some finish may conceal the wood beneath. If you desire to show the wood as part of the artistic appeal make sure you use oil-based finishes. Such types of finishes can penetrate the grain, therefore, offering both protection and ‘reveal’. A personal favorite is Linsheen it’s pretty easy to use and does a good job of both protection and giving the grain a good popping color.\nFactors to consider before finishing wood carving\n- Considering the type and characteristics of wood, it is important to know which type of wood the carving has been made from since some finishing may not go well with a certain type of wood. Extremely porous and softwoods, like basswood for example, that are notorious for not staining/dyeing evenly can be somewhat evened out with a sealer first\n- On the final appearance of your carving, it will solely depend on you. Others may opt to go for a gloss finish while others may like it satin-finished\nSo what is the best way of finishing your wood carving? Here is a guide that answers all your Queries on the finishing of wood carvings.\nThe best way of finishing a wood carving project\nYour piece should be protected from UV light, it is, therefore, a good idea to store your wood-carved pieces indoors. If the piece has to be outdoor make sure you coat it with a UV-approved coat like marine varnish. This varnish will go to great lengths to protect your outdoor wooden sculpture from UV and even moisture.\nIt is, however, worth noting that the solar and moisture are strong agents and wear out coats with time therefore make sure to recoat from time to time.\n1. Applying wood sealer.\nSealing a wood carving helps preserve it for as long as possible.\nUseful tips on application of wood sealer\n- When applying a sealer ensure that the carving is smooth and clean. If you prefer sanding it, make sure it’s way up to at least 220 grit sandpaper.\n- After that, remove all the sanding dust using a soft brush or short bursts of canned air.\n- Then apply your preferred sealer to your carving.\n- Apply several coats of the sealer with daily intervals between each layer.\n- Reapply the sealer regularly during the first year, only once per year after the initial twelve months.\nIt is important to note that softer woods will absorb the sealer easily thus require a thicker sealer, whereas harder wood will need you to thin the sealer more.\n2. Applying Beeswax wood finishes.\nBeeswax wood finishes are natural and easy to apply. Beeswax finishes penetrate directly into the wood and get rid of dry, dull, moisture, and sun-damaged surfaces leaving a great warm and shiny glow. It leaves a kind of shine that every home decorator wishes for.\nHow to apply Beeswax wood:\n- All you require is a soft cloth or rag.\n- Then, scoop a small amount (begin with a size of a dime) of the finish into the cloth and just rub it on the wood carving.\n- Allow the finish to dry for 10 to 20 minutes to get it ready to handle.\n- When it has dried, you can apply a smooth and shiny gloss, making your art look great and allowing the wood grain to reveal its natural colors. Apart from the great natural looks, the beeswax finish will leave your sculpture feeling silky-smooth when touched.\nThe advantages of using beeswax are they are natural, safe to use in household carvings, and are inexpensive.\nThe only disadvantage of beeswax finishes is that they are not heat resistant. If the piece of art is exposed to direct sun or kept in a warm place the beeswax will get soft and tacky.\nTherefore, when you choose to use beeswax store the wood carving in a cool place away from direct sun and there won’t be any problems.\n3. Applying Tung oil finishes.\nAnother great option for caring for your wood carving is applying a Tung oil finish.\nTung oil is extracted from the nuts of the Tung tree, native to the Southern parts of China.\nHow to apply Tung oil:\n- Using a soft brush or cloth, apply as much as you need to cover the wood.\n- Allow the oil to dry for like an hour and apply another coat.\n- Do this severally until the oil penetrates the wood fully.\n- To get the desired outcome, the oil will just sit on the wood rather than sink in it.\nThey are also safe for use. Unlike other oils, Tung oil will naturally harden and create a protective layer on the wood.\nTung oil finishes penetrate deeply into the wood and the surface cures hard over time becoming scratch and water-resistant. In addition to that, as the finish ages, it will yellow slightly creating a warmer look on the sculpture.\nHowever, their only disadvantage is they take between 3 to 7 days to completely dry and it is advisable you add 3 to 5 layers to get a good protective layer.\n4. Applying Danish oil wood finishes.\nApart from Tung oil, you can also use Danish oil which offers a great protective layer and dries faster than Tung oil.\nDanish oil can be made from Tung oil or polymerized linseed oil, which is then mixed with solvents.\nTo apply Danish oil wood:\n- All you are required to do is to apply a thin layer to the wood and allow it to sit for 5 minutes.\n- After that, rub the oil into the wood with a soft cloth until the surface is dry.\n- Allow it to dry for 4 to 8 hours.\nMost kinds of Danish oil are all-natural and once dry they create a non-toxic finish.\nDanish oil easily penetrates the wood and hardens to provide a non-peeling protective layer that is resistant to moisture and chipping.\nMoreover, it is important to note that Danish oil doesn’t have any specific ingredients. Therefore, ensure that you read on the ingredients on the oil by a certain manufacturer to ensure that it suits the wood you want to use it on.\nnote better: Make sure you are Storing the wood caving away from direct sunlight.\nStoring the wood carving in a place away from direct sun protects it from excessive sunlight.\nLight can make the carving appear dull especially if it is dyed or colored.\nTherefore, store the carving in a place with low amounts of natural light. If possible, I would recommend you set up room or display lights to be on only when the piece is being viewed or when there are people in the room.\nWhich wood is good for carving?\nWhen you are working on your first wooden project, it’s important to use a type of wood that will be easy for you to work with.\nTo begin with, for all your wood carving projects you can never go wrong with lime wood. However, many other suitable timber species are depending on the characteristics you want your wood carving to have.\nWorkability is one of the key qualities to check when looking for timber for wood carving. This is because different species have different qualities that affect how they respond to carving tools.\nA good wood for carving, especially for intricate work, needs to have a close grain. The tight-knit structure hinders wood splitting when it is being worked on. Therefore, you should also consider the type of design you want to crave, either delicate and small or large furniture.\nMoreover, the type of wood you choose for wood carving will be influenced by your level of skill. Some timbers can require more refined carving skills.\nAlso, it is crucial you also consider your budget and aesthetics.\nEasiest Woods to Carve\nLimewood is also referred to as basswood. It is the most common type of wood used in wood carving. This kind of wood is a good choice for both a newbie and knowbie of woodcarving.\nLimewood is ideal for intricate carving because it is extremely soft and crisp. They also work well with hand tools. This high workability is due to the wood’s very close grain structure.\nIn addition to that, lime is pleasing to the eye because of its amazing light cream color. They are also budget-friendly.\nThis is another white wood that is quite common in woodworks.\nThere is a variety of aspen found in the world, but the most popular is the quaking aspen which grows prolifically throughout North America but specifically in the Great Lake Basin.\nIt is stronger than basswood but very soft. Therefore, it is easy to use in wood cravings.\nMoreover, it is readily available and affordable.\nThis type of wood is commonly used by those searching for something light to medium-light in weight and straight-grained.\nThis is one of the best softwoods that can be used in wood carving.\nJust like basswood, butternut is completely easy to work with, does well with stains and the smell level is low.\nRaw butternut can be very budget-friendly and has a natural pink finish, with coarse wood grains.\nIn addition, it is a favorite pick for professionals due to its visible grains that add beauty to the art.\nAlso, it is a great choice for beginners because of its high workability.\nMost species of oak like the American Oak are easy on carving tools.\nOak has a tougher grain than lime wood, which makes them more suitable for larger pieces rather than highly delicate ones.\nHowever, with its strength, rigidness, and good workability, oak is an amazing choice for bigger projects like exterior and interior furniture.\nThey create a beautiful and versatile hardwood carving.\n5. Black walnut.\nBlack walnut is known for its beautiful, rich dark chocolate-brown color and its prominent grain and pattern.\nMoreover, this wood takes in carving tools and detail well.\nHowever, they are more expensive but they would win you a chance to achieve a certain display of splendor and wealth in your wood carving.\nDifference between carving and sculpture.\nWood carving is the act of removing material from wood to get a shape. Therefore, a carving is something made from the art of wood carving.\nIn contrast, to sculpt is to add material to something to get a shape, hence sculpture is something made from sculpting.\nHow long does wood carving last?\nThere are many destructive wood agents, like moisture, bad weather, and insects. Wood carving is an art that is not easy to master, so you might wonder how long your wood carvings will last, given the difficulty of learning wood carving.\nWorry not for wood carvings can stay from a few decades to several lifetimes or more.\nIt is easy for wood carving to last several decades outside if it is kept away from direct sunlight and is frequently treated and sealed. In contrast, they will last almost indefinitely if they are indoors and are sealed.\nHow to care for your wood carving to ensure it lasts\nIt is easy to take care of your wood carving if you want it to last. The most ideal way to ensure that your wood carving is protected is by storing them in the right conditions away from direct sunlight and applying a wood finish to seal the wood from elements and add a protective layer that guards the wood against direct damage.\nConclusion on the best way to finish carvings.\nTo sum up, wood is always evolving, whether in life or death, as well as wood carvings too. Therefore, to ensure that your wood carving lasts you some decades, ensure that you choose the best kind of wood and follow the preservation measures above."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:64e31574-97f9-4bb6-9be8-d89872aa1bc0>"],"error":null}
{"question":"In what ways have recent Supreme Court decisions affected both administrative and judicial oversight of patents, and how do these changes reflect evolving views of patent rights?","answer":"Recent Supreme Court decisions have fundamentally reshaped patent oversight through both administrative and judicial channels. The Oil States decision characterized patents as 'public franchises' subject to administrative review, affirming the Patent Trial and Appeal Board's authority to conduct inter partes review as a way to ensure patents stay within their legitimate scope. Simultaneously, TC Heartland and subsequent cases like In re Cray significantly restricted judicial venues for patent litigation, requiring cases to be filed either in a corporation's state of incorporation or where they have an established physical business presence with alleged infringement. These changes reflect a shift toward viewing patents as regulated public rights rather than absolute private property, while also limiting patent holders' ability to strategically choose favorable court venues.","context":["By a majority of 7-2, the Supreme Court has ruled that inter partes review is a valid exercise of statutory authority vested in the Patent Trial and Appeal Board. Oil States Energy Services, LLC v. Greene’s Energy Group, LLC, 16-712 (Apr. 24, 2018). In an anxiously awaited decision upholding this widely utilized venue for challenging patent validity before the Patent Office, the Court rejected the patentee’s argument that inter partes review violates Article III and the Seventh Amendment right to a jury trial. The majority held that, unlike the adjudication of private rights, “[i]nter partes review . . . involves reconsideration of the Government’s decision to grant a public franchise” and that “Congress has permissibly reserved the PTO’s authority to conduct that reconsideration.” Slip Op. at 6. Justice Gorsuch, joined by Chief Justice Roberts, dissented on grounds that patentees can only be divested of patent rights by independent, Article III, judges.\nAs many stakeholders anticipated, Oil States touches on the nature of modern patent rights. The majority concludes that patents are “public franchises” that are created and granted by the Government, observing that patents are a “creature of statute law.” Slip. Op. at 7. In the majority’s view, the modern patent is analogous to a government-issued grant to operate a toll bridge, build a railroad, or install a telegraph line: it is a revocable public franchise. “As a public franchise, a patent can confer only the rights that the statute prescribes . . . [T]he patentee’s rights are derived . . . from statutes, are to be regulated and measured by those laws, and cannot go beyond them . . . One such regulation is inter partes review.” Slip Op. at 10 (quotations omitted). In terms of the historical backdrop against which the Constitution is interpreted, the majority noted that patent cancellation proceedings existed at the time of the nation’s founding.\nWhile the majority emphasizes “the narrowness of our holding,” its conclusion that patents are revocable public franchises will have broader implications in terms of galvanizing efforts to calibrate the patent system through legislation and administrative policy. Slip Op. at 16. The majority notes that “our decision should not be misconstrued as suggesting that patents are not property for purposes of the Due Process Clause or the Takings Clause,” but rather the express endorsement of inter partes review as a way to “protect the public’s paramount interest in seeing that patent monopolies are kept within their legitimate scope.” The Court thus speaks broadly to the significant gate-keeping role that Congress and the Patent Office continue to play even after a patent is granted. Slip Op. 9 (quoting Cuozzo Speed Technologies, LLC v. Lee).\nThe outcome in Oil States maintains the status quo in terms of keeping inter partes review on the table, both as a strategic option for petitioners as well as an administrative tool for policy-makers to regulate patent quality. Nevertheless, the Supreme Court’s exposition on the nature of patent rights and the post-grant review process may influence other outstanding controversies.\nFor more information, please contact:\nPauline M. Pelletier, Associate, email@example.com\nJon E. Wright, Director & Co-chair, Appellate Practice, firstname.lastname@example.org\nMichael D. Specht, Director & Co-chair, Patent Office Litigation Practice, email@example.com","Two key recent cases have shifted the balance of negotiation leverage in patent disputes between patent owners and accused infringers. The cases restrict the venues where patent cases against corporations can be brought. This change will tilt the balance away from patent owners and more in favor of accused infringers.\nThe decisions limit venue forum shopping as to a corporate defendant to\n- The defendant’s state of incorporation; or\n- A district where the defendant has a physical location, a regular and established place of business which is operated by the defendant, and where an alleged act of infringement must have occurred.\nCompanies facing threats of patent litigation from trolls and others should be aware that such litigation just got harder for those asserting infringement. The choice of possible venues has now been considerably narrowed, and for many companies, those districts which meet the new criteria are often both more friendly and more convenient.\nA major issue in many patent litigations is venue: where the case will be heard. For many patent trolls, a favorite has been the Eastern District of Texas, considered a favorable forum for patent plaintiffs. Defendants naturally prefer districts closer to home, especially those considered more defendant friendly. The mere threat of litigating in a distant and unfriendly forum is often used as leverage in settlement negotiations. But two recent key decisions have significantly limited such forum shopping.\nIn May, the Supreme Court decided TC Heartland LLC v. Kraft Foods Group Brands LLC, overturning 20 years of Federal Circuit precedent. The patent venue statute allows infringement claims to be brought “where the defendant resides.” The Court limited that to a corporation’s state of incorporation.\nPatent owners then turned to the second part of the patent venue statute, that allows infringement claims to be brought “where the defendant has committed acts of infringement and has a regular and established place of business.” In September, the Federal Circuit construed that provision in In re Cray. According to Cray, the statute requires:\n- A physical location in the district – a physical, geographic location where the defendant conducts business in the district.\n- The presence must be regular and established – meaning there is some steady, permanent business presence in the district.\n- The place must be that of the defendant – not merely employee homes, or independent contractors (or as one later case held, wholly owned subsidiaries).\n- Patent infringement must have allegedly taken place there.\nThis test was not met where a company had two salesmen in the district who were allowed to work remotely from their home offices. Later cases further hold that it is not met by a website accessible in the district, nor by shipping infringing goods into the district, nor by the presence of a retailer subsidiary corporation.\nSome issues remain open. The Supreme Court noted that its decision does not apply to foreign corporations. And, it is not clear what happens when the “state of incorporation” contains multiple districts, as some large states (California, Texas, New York) do. Can a California corporation based in San Jose, for example, be sued for patent infringement anywhere in California? These issues have yet to be worked out by the federal courts."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:a796b93f-4a3e-4f09-b598-8563a95e923a>","<urn:uuid:6c913cd6-2e4a-4e1c-b17b-7107629911f0>"],"error":null}
{"question":"How do firms achieve Nash Equilibrium in a duopoly market? Can you explain the process using the WesCo and RifCo example?","answer":"In a duopoly market, firms reach Nash Equilibrium through a process where no participant has an incentive to change their strategy while others maintain theirs. Using the WesCo and RifCo example, the process works as follows: Initially, both companies might start with low prices (WesCo earning 50, RifCo earning 70). WesCo then increases prices to improve profits from 50 to 300. RifCo follows by increasing prices, raising their profit from 70 to 350. Although the highest combined profits (800) occur when both charge high prices, RifCo would be motivated to lower prices to increase its profit from 300 to 350, causing WesCo's profit to fall from 500 to 300. The final Nash Equilibrium position has WesCo at high price with 300 profit and RifCo at low price with 350 profit, as neither firm has incentive to change strategy.","context":["An oligopoly market has few sellers of a product and many buyers. These sellers are large players in their industry who determine the prices or quantities. For example, credit card companies such as Visa, MasterCard, and Amex.\nIf firms collude, the total market demand is divided among the individual participants. The firms act like a cartel and decide how to divide the demand, and what price to set for the products in order to maximize profit.\nIf firms do not collude, each firm faces an individual demand curve and a market demand curve. There are several models that try to explain pricing in oligopoly markets:\nPricing Interdependence – Kink Demand Curve\nAccording to this theory, a competitor will not follow a price increase, but will cut prices in response to a price decrease.\nExample: Let us assume a town has two cola suppliers: Coke and Pepsi. This type of oligopoly is called a duopoly. Now, assume the initial equilibrium price of 1 liter Coke bottle is 100 and the quantity is 5000.\nEffect of price increase: If Coke increases its price from 100 to 105, what will Pepsi do? According to the interdependence theory, Pepsi will not increase the price and consumers will switch from Coke to Pepsi. The quantity demanded of Coke will decrease (see the elastic portion of the demand curve).\nEffect of price decrease: Instead, if Coke decreases the price to 95, then Pepsi will also decrease the price to 95. The quantity demanded of Coke will increase when the price decreases, but not by much because there is no substitution effect. Consumers do not switch from Pepsi to Coke as both are selling at the same price. To the right of the kink, the demand curve is inelastic.\nSome important points:\nFirms compete simultaneously to determine a profit-maximizing output, based on the assumption that the other firms’ output will not change. In the long run, change in price or quantity will NOT increase profits. As the number of firms in an oligopoly increase, the equilibrium point moves closer to perfect competition.\nAssume there are two firms with the output levels q1 and q2 respectively. Firm 1 chooses its output as q1 to maximize profit based on the assumption that firm 2’s output level q2 is constant in the future. Similarly, firm 2 chooses its output as q2 to maximize profits by assuming that firm 1’s output level is constant. Firms choose q1 and q2 simultaneously. Let us now look at the price and quantity numbers associated with the Cournot assumption.\nThe Nash Equilibrium in a Duopoly Market\nUnlike perfect competition, in oligopoly there is a lot of strategic interdependence between firms. Since the number of firms are few, the actions one takes affects the others.\nNash Equilibrium: A set of choices/strategies among two or more participants is called a Nash equilibrium if, holding the strategies of all other participants constant, no participant has an incentive to choose a different strategy. In an oligopoly, firms arrive at an equilibrium strategy after considering the actions of other firms (interdependence). Once they arrive at equilibrium, no firm wants to change its strategy.\nAssumptions made in Nash equilibrium:\nExample: WesCo and RifCo sell a similar product. Each company can employ a high-price strategy or a low-price strategy. The profit for each strategy is shown. What is the Nash equilibrium?\nThe four possible strategies are shown in the four boxes. For example, box 1 on the top-left corner has WesCo adopting a low price strategy and RifCo adopting a low price strategy as well. The profit for WesCo is 50 and that for RifCo it is 70. At any point in time, the companies can be in only one box. It is not possible for WesCo to adopt a low price strategy with profit of 50 (box 1) and RifCo to adopt a high price strategy with profit of 0 (box 2).\nNo matter where the companies start, they will end up in box 4 (lower left box).\nLet’s start with box 1. The total profit of WesCo and RifCo is 120. They are both selling the products at a lower price. It is in WesCo’s best interest to increase prices, and their profits jump from 50 to 300 in box 4. It is in RifCo’s best interest as well if WesCo increases the price, as RifCo can also increase the price. RifCo’s profit jumps from 70 to 350. The combined profit of box 4 now is 650.\nThe combined profits are the highest in box 3, which is 800. Both the companies are charging high prices. Box 3 is in WesCo’s best interest as it earns its maximum profit of 500, but it’s possible only if RifCo also charges the high price. But RifCo is not happy here and would lower the prices to increase its profit from 300 (box 3) to 350 (box 4).\nWhen RifCo lowers its price to make a profit of 350 in box 4, WesCo’s profit falls from 500 to 300. The Nash equilibrium position in box 4 is what they arrive at finally.\nCan both companies be better if they collude? Yes, if both the companies agree to collude and charge high prices. If WesCo and RifCo agree to split the maximum profit of 800 equally, then each company makes a profit of 400, which is better than the Nash equilibrium profit of 300 and 350 profit respectively. Companies are said to form a cartel when they engage in collusive agreements openly.\nFactors that affect the chances of successful collusion:\nThere is one dominant large firm and many small firms. The large firm sets the price and has the first mover advantage.\nIn the Stackelberg model, the decision-making happens sequentially (recall it happens simultaneously in the Cournot assumption). The leader firm chooses the output first and then the follower firm chooses its output.\nThe curriculum discusses the supply analysis for only one type of oligopoly – the dominant firm oligopoly.\nExample: Say we have an oligopoly market where one firm has a significantly lower cost of production than its competitors and has a 40% market share. A dominant or leader firm is a firm with at least 40 % market share, greater capacity, lower cost structure, and is price maker. A follower firm is a small firm that is a price taker – i.e. it accepts the price set by the leader firm. Let us say there are five such firms in this market.\nThe graph below shows the quantity that will be supplied and the price charged by the market leader, as well as by the other firms.\nInterpretation of the graph:\nThere is no single optimum price and output model that works for all oligopoly market situations because of different strategies and pricing methods. The process for determining the optimal price for a few methods is listed below:\nLong-run economic profits are possible, but empirical evidence suggests that over time the market share of the dominant firm declines."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:fbed8c28-867f-448d-8b2e-be5b04c4d2e0>"],"error":null}
{"question":"What are the similarities in panning guidelines for vocals and bass between mixing software and live stage setups?","answer":"In both mixing software and live stage setups, vocals and bass should be positioned in the center. For live sound, monitors for vocals and bass are placed up front facing the audience so fans can experience the vocals and bass groove clearly. Similarly, in mixing guidelines, both the bass line and lead vocals should be 'dead center' (panning value of 0), as this helps maintain clarity in the mix and prevents low frequencies from competing in different locations of the stereo image.","context":["The core controls is a term I use for the attributes that every track and every piece of audio have, and that in the end play the most important role in making the song sound the way you want.\nThe members of this core group are: volume, panning, timing, tempo (& metronome) and automation. While not really in the same category, I will I also mention some things about record and monitor enabled. But that is all for the next chapter, let’s first go over the two most important ones: volume and panning.\nVolume (or gain)\nEvery track has a big vertical slider (or button) for volume. This is by far the most important button, as you probably don’t want all instruments (or any instrument at all) at the same volume. The fact that it’s impossible to record every instrument at the exact same level of loudness, and that you only want a few instruments to take the lead in your mix, make volume adjusting a very necessary tool.\nBecause of that, changing volume can usually be done in lots of places in the software (or audio interface itself, but I recommend only changing stuff in the software). And all you have to do is pull a slider down to make the sound softer, and push it up to crank up the volume.\nDAWs have an at first sight unusual way of representing the volume: in negative dB. When you record a something, the track is set to a volume level of 0 dB. This means the standard operating volume of the system you’re working on. You can see that the volume slider in software is usually about (1/3) down the slider by default, with a 0 next to it. This means that there is a small amount of dB you can increase your track, but I will never allow you to do that!\nInstead, if you want something to be more prominent, you should lower other instruments that overwhelm it. That’s the reason that most tracks are set to a negative decibel level, which only means that it is a certain amount softer than the standard volume, and not that it creates some sort of anti-sound or whatever.\nWhy should we lower other instruments if we want one to be heard more? Well, because increasing volume if you want something louder in the mix is a never-ending process. You might think ‘hmm, let me increase the volume on the guitar a bit’, and then think ‘well, now I cannot hear the piano anymore, lets increase that one too’, and so it goes on and on. When you can’t hear something, it is usually not because it isn’t loud enough, but because there are other instruments fighting for their spot which should be tamed.\nA last general volume guideline: if you can hear the bass, it’s probably too loud.\nPanning is the control making the difference between mono and stereo sound. With mono sound, every instrument is panned to the same spot: center. With stereo sound, you get the possibility to place certain instruments or tracks more to the right and/or more to the left.\nUsually, this can be done moving a horizontal slider to the left or right, and notation for panning level is L or R, followed by the amount of panning (higher is further to the side).\nHere are some general panning guidelines:\n- The base drum and snare should be dead center. All other parts of the drum kit can be spread out a bit to the right and a bit to the left, just like a real-life drum kit.\n- The bass line and lead vocals should also be dead center.\n- The rest of the instruments and audio can be distributed left and right, although it is preferred to have them in a logical position. For example, if you have one track that plays low piano notes and one that plays the high ones, it is somehow more pleasant to have them distributed left and right respectively, because that is also their place on a real piano.\n- Balance is key here. Your left and right sides should be balanced, preferably by using the same amount of instruments. If that is somehow not possible, you can pan all instruments on one side more away from the center than on the other side to compensate.","Panning is how the instruments are arranged within the stereo image. By properly using this mixing feature, you can create a very realistic mix. Mixing engineer should mix tracks with a live sound stage/concert stage perspective. A vocal is always in the center because the band lead singer is the star of the show. At the back of the vocals is the bass player. Typically at the back of the bass player is the drummer. The band’s guitarists are on the left and the right. Bear in mind that different panning arrangement are possible for additional instruments (such a band with piano or others). But this concept illustrates the basic things on how to do panning in audio mixing to create a very realistic stereo image such as the diagram shown below:\nLive sound monitors for vocals and bass are placed up front facing the audience, so that fans can get a great feel of the vocals and the bass groove. On the left and right loud sound monitors are the guitars.\nIn the commercial audio production and using a recording software, panning can be controlled between -100 to +100. Where mostly -100 is the leftmost part of the stage and +100 is the rightmost part of the stage. Mixing from the real live stage perspective, a mixer can set:\na. Vocals to panning= 0 (center)\nb. Kick drums = 0 (center)\nc. Bass guitar= 0 (center)\nd. 1st guitarist=75 (hard right)\ne. 2nd guitarist= -75 (hard left)\nf. Whole drum set (crash cymbals to ride cymbals)= -12.5 to 12.5 (this is the correct one)\nUsing ratio and proportion, typical sound stage width is about 40 feet wide. Using recording software, this whole panning width is 200 panning units. (Length of -100 to +100).\nTherefore the ratio of panning units to feet is:\n200 panning units/ 40 feet = 5 panning units/feet (For a 40 feet sound stage)\nTo check how realistic is this conversion, we will use the width of the real drum set.\nReal drum set needs 5 feet width space when fully set-up. Converting 5 feet to panning units in recording software is about :\n5 feet x 5 panning units/feet = 25 panning units, so our panning specifications are correct.\nThis means that for a 40 feet sound stage, to create a real stereo image of drums, it should be panned between -12.5 to 12.5 (this is the correct specification).\nGuitarist are placed +75 to -75 respectively. This means they are both located :\n1st guitarist: -75 panning units/ 5 panning units= 15 feet from the left of the vocals.\n2nd guitarist: +75 panning units/5 panning units= 15 feet from the right of the vocals.\nOne important thing to take note on panning is the energy level with respect to panning distance. Rule of thumb is that, the lowest frequencies should be pan on the center except for the vocals. And the higher the frequencies, the farther you can place them away from the center. It is because, low frequencies such as bass occupies massive energies and needs to placed at the center for maximum volume.\nThe following are advantages of proper panning in mixing :\na. Create a real stereo image of an actual live sound stage.\nb. Avoid battling the same frequencies in the same location of the stereo image.\nBy placing the vocals in the center of the mix, means not in conflict in low frequencies and those guitars that occupy the same frequencies as the vocals are placed away from the center. Thus panning improves the clarity of the mix.\nFor details about panning settings for different musical instruments, you can refer to the following tutorials:"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:747505f0-40d9-4c5f-bb26-6533d9f70216>","<urn:uuid:b2eac978-3889-4f7b-a4fc-5164463872ad>"],"error":null}
{"question":"What are the differences between weed evolution through crop-wild hybridization versus herbicide resistance development?","answer":"Weed evolution through crop-wild hybridization occurs when domesticated crops crossbreed with their wild relatives, potentially creating more invasive plants with enhanced reproduction capabilities and adaptive traits. In contrast, herbicide resistance development is seen in weeds like Palmer amaranth and kochia that have developed resistance to specific herbicide modes of action (MOA) like ALS-inhibitors and glyphosate, requiring farmers to use multiple MOAs for effective control. This is why current recommendations include using at least two different modes of action that are both effective for controlling target weed species to reduce the possibility of resistant weeds surviving future herbicide applications.","context":["Crops gone wild: evolution of weeds and invasives from domesticated ancestors\nArticle first published online: 14 JUL 2010\n© 2010 Blackwell Publishing Ltd\nSpecial Issue: Evolution in Agro-Ecosystems\nVolume 3, Issue 5-6, pages 494–504, September 2010\nHow to Cite\nEllstrand, N. C., Heredia, S. M., Leak-Garcia, J. A., Heraty, J. M., Burger, J. C., Yao, L., Nohzadeh-Malakshah, S. and Ridley, C. E. (2010), Crops gone wild: evolution of weeds and invasives from domesticated ancestors. Evolutionary Applications, 3: 494–504. doi: 10.1111/j.1752-4571.2010.00140.x\n- Issue published online: 27 AUG 2010\n- Article first published online: 14 JUL 2010\n- Received: 16 May 2010 Accepted: 21 May 2010 First published online: 14 July 2010\n- 2010. Gene Flow between Crops and Their Wild Relatives. Johns Hopkins University Press, Baltimore, MD. , and .\n- 2006. Evolution through Genetic Exchange. Oxford University Press, Oxford, UK.\n- 2005. Wheat domestication and de-domestication – What are the odds? In J.Gressel, ed. Crop Ferality and Volunteerism, pp. 167–173. CRC Press, Boca Raton, FL. , and .\n- 2010. Genetic diversity of feral alfalfa (Medicago sativa L.) populations occurring in Manitoba, Canada and comparison with alfalfa cultivars: an analysis using SSR markers and phenotypic traits. Euphytica 173:419–432. , , , , and .\n- 1974. The evolution of weeds. Annual Review of Ecology 5:1–24.\n- 1965. The Genetics of Colonizing Species. Academic Press, New York, NY. , and .\n- 2008. Nonnative species and bioenergy: are we cultivating the next invader? BioScience 58:64–70. , and .\n- 1983. Crop mimicry in weeds. Economic Botany 37:255–282.\n- 2008. Effective fennel (Foeniculum vulgare) control with herbicides in natural habitats in California. Invasive Plant Science and Management 1:66–72. , , and .\n- 2005. Risks of gene flow between sunflower and other Helianthus species. In J.Gressel, ed. Crop Ferality and Volunteerism, pp. 209–230. CRC Press, Boca Raton, FL. , , , and .\n- 1995. Evolution of increased competitive ability in invasive nonindigenous plants: a hypothesis. Journal of Ecology 83:887–889. , and .\n- 2005. Phenotypic and genetic differentiation between native and introduced plant populations. Oecologia 144:1–11. , , , , , and .\n- 2008. Genetic variation in photosynthetic characteristics among invasive and native populations of reed canarygrass (Phalaris arundinacea). Biological Invasions 10:1317–1325. , , and .\n- 2005. Feral rye – evolutionary origins of a weed. In J.Gressel, ed. Crop Ferality and Volunteerism, pp. 175–192. CRC Press, Boca Raton, FL. , and .\n- 2006. Origin and genetic structure of feral rye in the western United States. Molecular Ecology 15:2527–2539. , , and .\n- 2007. Rapid phenotypic divergence of feral rye from domesticated cereal rye. Weed Science 55:204–271. , , and .\n- 2009. Can feral weeds evolve from cultivated radish (Raphanus sativus, Brassicaceae)? American Journal of Botany 96:498–506. , and .\n- 2006. Weed evolution after crop gene introgression: greater survival and fecundity of hybrids in a new environment. Ecology Letters 11:1198–1209. , , and .\n- 2006. Genetic diversity and origin of weedy rice (Oryza sativa f. spontanea) populations found in North-eastern China revealed by simple sequence repeat (SSR) markers. Annals of Botany 98:1241–1252. , , , , , , and .\n- 2009. Common garden comparisons of native and introduced plant populations: latitudinal clines can obscure evolutionary inferences. Evolutionary Applications 2:187–199. , , and .\n- 2009. The role of intraspecific hybridization in the evolution of invasiveness: a case study of the ornamental pear tree Pyrus calleryana. Biological Invasions 11:1107–1120. , and .\n- 2005. Incestuous relations of foxtail millet (Setaria italica) with its parents and cousins. In J.Gressel, ed. Crop Ferality and Volunteerism, pp. 81–96. CRC Press, Boca Raton, FL.\n- 1859. On the Origin of Species by Means of Natural Selection. John Murray, London, UK.\n- 1868. The Variation of Animals and Plants under Domestication. John Murray, London, UK.\n- 2004. Gene exchange between wild and crop in Beta vulgaris: how easy is hybridization and what will happen in later generations? In H. C. M.Den Nijs, D.Bartsch, and J.Sweet, eds. Introgression from Genetically Modified Plants into Wild Relatives, pp. 53–61. CABI Publishing, Wallingford, UK.\n- 2008a. Founding events in species invasions: genetic variation, adaptive evolution, and the role of multiple introductions. Molecular Ecology 17:431–449. , and .\n- 2008b. Invading populations of an ornamental shrub show rapid life history evolution despite genetic bottlenecks. Ecology Letters 11:701–709. , and .\n- 1995. Teosinte branched1 and the origin of maize: evidence for epistasis and the evolution of dominance. Genetics 141:333–346. , , and .\n- 1950. Classification of the forms of Japanese barnyard millet. Proceedings of the Crop Science Society of Japan 20:245–246. , and .\n- 2005. Sorghum and its weedy hybrids. In J.Gressel, ed. Crop Ferality and Volunteerism, pp. 123–136. CRC Press, Boca Raton, FL. , and .\n- 2000. Hybridization as a stimulus for the evolution of invasiveness in plants? Proceedings of the National Academy of Sciences USA 97:7043–7050. , and .\n- 1923. Heterosis and dominance of size factors in Raphanus. Genetics 8:116–153.\n- 2005. Gene movement between rice (Oryza sativa) and weedy rice (Oryza sativa) – a U.S. temperate rice perspective. In J.Gressel, ed. Crop Ferality and Volunteerism, pp. 323–354. CRC Press, Boca Raton, FL.\n- 2004. Crop domestication as a long-term selection experiment. Plant Breeding Reviews 24:1–44.\n- 2005a. Introduction – the challenges of ferality. In J.Gressel, ed. Crop Ferality and Volunteerism, pp. 1–7. CRC Press, Boca Raton, FL.\n- 2005b. Crop Ferality and Volunteerism. CRC Press, Boca Raton, FL.\n- 2006. The evolution of California’s wild radish has resulted in the extinction of its progenitors. Evolution 60:1187–1197. , , , and .\n- 2005. A biogeographical approach to plant invasions: the importance of studying exotics in their introduced and native range. Journal of Ecology 93:5–15. , , and .\n- 1978. Flavonoid patterns and systematics in Eleusine. Biochemical Systematics and Ecology 6:247–249. , , and .\n- 1977. The World’s Worst Weeds: Distribution and Biology. University Press of Hawaii, Honolulu. , , , and .\n- 1997. World Weeds: Natural Histories and Distribution. John Wiley & Sons, New York, NY. , , , , and .\n- 2005. Origin of weedy rice grown in Bhutan and the force of genetic diversity. Genetic Resources and Crop Evolution 52:395–403. , , , , , , et al.\n- 2009. Brewing trouble: coffee invasion in relation to edges and forest structure in tropical rainforest fragments of the Western Ghats, India. Biological Invasions 11:2387–2400. , , and .\n- 1992. Taming the wilderness myth. BioScience 42:271–279. , and .\n- 2009. Adaptation and colonization history affect the evolution of clines in two introduced species. New Phytologist 183:678–690. , , , , and .\n- 2005. Urban ornamentals escaped from cultivation. In J.Gressel, ed. Crop Ferality and Volunteerism, pp. 97–121. CRC Press, Boca Raton, FL.\n- 2004. Reed canary grass (Phalaris arundinacea) as a biological model in the study of plant invasions. Critical Reviews in Plant Sciences 23:415–429. , and .\n- 2009. Genetic origins and the evolution of invasiveness of Cynara cardunculus in California. PhD dissertation in Genetics, Genomics, and Bioinformatics. University of California, Riverside, California, USA.\n- 1978. The origin of isolating mechanisms in flowering plants. Evolutionary Biology 11:185–317.\n- 2007. Origins and population genetics of weedy red rice in the USA. Molecular Ecology 16:4523–4535. , and .\n- 2000. 100 of the World’s Worst Invasive Alien Species: A Selection from the Global Invasive Species Database. The Invasive Species Specialist Group (ISSG) a specialist group of the Species Survival Commission (SSC) of the World Conservation Union (IUCN). , , , and .\n- 2009. Rethinking the common garden in invasion research. Perspectives in Plant Ecology, Evolution and Systematics 11:311–320. , , , , and .\n- 2005. Crop-to-weed introgression has impacted allelic composition of johnsongrass populations with and without recent exposure to cultivated sorghum. Molecular Ecology 14:2143–2154. , , , , , and .\n- 2000. Characterization of weed beet in Germany and Italy. Journal of Sugar Beet Research 37:19–38. , , , , and .\n- National Research Council. 1989. Field Testing Genetically Modified Organisms: Framework for Decisions. National Academy Press, Washington.\n- 2007. The role of evolution in the invasion process. Proceedings of the National Academy of Sciences USA 104:3671–3672.\n- 1967. The origin of variation in “wild”Raphanus sativus (Cruciferae) in California. Genetica 38:243–274. , and .\n- 2002. What has QTL mapping taught us about plant domestication? New Phytologist 154:591–608.\n- 1995. The weediness of wild plants: molecular analysis of genes influencing dispersal and persistence of johnsongrass, Sorghum halepense (L.) Pers. Proceedings of the National Academy of Sciences USA 92:6127–6131. , , , , and .\n- 2008. Adaptive evolution in invasive species. Trends in Plant Sciences 13:288–294. , , , , and .\n- 2000. Inference of population structure using multilocus genotypic data. Genetics 155:945–959. , , and .\n- 2009. The nature of selection under plant domestication. Nature 457:843–848. , and .\n- 2009. Evolution of enhanced reproduction in the hybrid-derived invasive, California wild radish (Raphanus sativus). Biological Invasions 11:2251–2264. , and .\n- 2008. Bidirectional history of hybridization in California wild radish, Raphanus sativus (Brassicaceae), as revealed by chloroplast DNA. American Journal of Botany 95:1437–1442. , , and .\n- 2007. Plant domestication, a unique opportunity to identify the genetic basis of adaptation. Proceedings of the National Academy of Sciences USA 104:8641–8648. , , and .\n- 2009. Hybridization and the evolution of invasiveness in plants and other organisms. Biological Invasions 11:1093–1105. , and .\n- 2005. Lantana invasion: an overview. Weed Biology and Management 5:157–165. , , and .\n- 1995. Evolution of Crop Plants, 2nd edn. Longman, Harlow, UK. , and .\n- 2005. Can feral radishes become weeds? In J.Gressel, ed. Crop Ferality and Volunteerism, pp. 193–208. CRC Press, Boca Raton, FL. , and .\n- 1999. The value of genomic in situ hybridization (GISH) in plant taxonomic and evolutionary studies. In P. M.Hollingsworth, R. M.Bateman, and R. J.Gornall, eds. Molecular Systematics and Plant Evolution, pp. 199–210. Taylor & Francis, London, UK. , and .\n- 1998. Genetic relationships and diversity among Tibetan wheat, common wheat and European spelt wheat revealed by RAPD markers. Euphytica 99:205–211. , , , , and .\n- 1969. A dynamic population of weedy rye. Crop Science 9:121–124. , , and .\n- 2005. The damage by weedy rice – can feral rice remain undetected? In J.Gressel, ed. Crop Ferality and Volunteerism, pp. 279–294. CRC Press, Boca Raton, FL.\n- 2005. Asian rice and weedy rice – evolutionary perspectives. In J.Gressel, ed. Crop Ferality and Volunteerism, pp. 257–277. CRC Press, Boca Raton, FL. , , , , and .\n- 2007. Bet hedging in a guild of desert annuals. Ecology 88:1086–1090.\n- 1995. Finger millet. In J.Smartt, and N. W.Simmonds, eds. Evolution of Crop Plants, 2nd edn, pp. 137–140. Longman, Harlow, UK.\n- 1975. Weeds and domesticates: evolution in the man-made habitat. Economic Botany 29:99–107. , and .\n- 1984. Systematics and evolution of Eleusine coracana (gramineae). American Journal of Botany 71:550–557. , , , and .\n- 2006. Weeds of the West. Western Society of Weed Science, Newark, CA.\n- 2010. Phenotypic divergence during the invasion of Phyla canescens in Australia and France: evidence for selection-driven evolution. Ecology Letters 13:32–44. , , , , , , and .\n- 2002. Population genetics of duplicated disease defense genes, hm1 and hm2, in maize (Zea mays ssp. mays L.) and its wild ancestor (Zea mays ssp. parviglumis). Genetics 162:851–860. , , , and .","Herbicides for Corn, Dry Bean Rotation in Nebraska\nHerbicide options in dry beans are limited compared to other common row crops in Nebraska (NE), such as corn or soybean. With the increasing prevalence of Acetolactate synthase (ALS)-inhibitor- and Glyphosate-resistant Palmer amaranth and kochia in NE dry bean acres, dry bean growers have few herbicide options for controlling weeds within dry bean crops. Consequently, corn and other rotational crops, with more diverse herbicide options available, are key tools for controlling difficult weeds prior to rotating to dry bean.\nCorn is the most common rotational crop planted the year before dry bean in western NE. However, herbicide programs must be chosen with foresight as many corn herbicides can injure dry beans the next season due to crop rotation restrictions. Table 1 lists labeled corn herbicides for use the year before planting dry beans. Due to the increase of herbicide-resistant weeds in western NE, Glyphosate and ALS-inhibiting herbicides should always be applied along with another effective mode of action (MOA). Using multiple modes of action at each application, using PRE followed by POST herbicide programs, and using residual herbicides at each application can help manage and reduce the probability of future herbicide-resistant weeds.\n|Mode of Action||Herbicide||Kochia (ALS-Glyphosate-Resistant) Control (%)||Palmer Amaranth (ALS-Glyphosate-Resistant) Control (%)||Rate per Acre||Cost per Acre (US$)|\n|PRE Activity Only|\n|14||Sharpen®||80-84||80-84||2.0 fl oz||12.25|\n|14+15||Verdict®||80-84||85-90||10.0-12.0 fl oz||18.00-21.60|\n|Residual Activity Only|\n|15||Zidua®||80-84||80-84||1.5-2.75 oz or 2.5-4.5 fl oz||12.75-23.25|\n|Dual II Magnum®||<60||85-90||1.0 pt||18|\n|Outlook®||<60||85-90||10.0-13.0 fl oz||11.00-14.30|\n|POST Activity Only|\n|4||2,4-D||60-69||80-84||8.0-16.0 fl oz||1.50-2.75|\n|Dicamba||85-90||85-90||9.0-16.0 fl oz||3.50-8.50|\n|Starane Ultra®||90-95||< 60||0.4 pt||15|\n|4+19||Status®||85-90||85-90||5.0 fl oz||18|\n|10||Liberty/Scout® 1||80-84||80-84||32.0-36.0 fl oz||15.75-20.75|\n|POST and Residual Activity|\n|4+27||Diflexx Duo® 2||85-90||90-95||24.0-40.0 fl oz||4.50-8.25|\n|14+15||Anthem Maxx® 3||70-79||85-90||2.5-3.0 fl oz||12.50-15.00|\n|15+5+27||Acuron® 4||96-100||90-95||2.0 qt||40|\n|15+27||Acuron Flexxi® 4||96-100||90-95||2.0 qt||40|\n|27||Armezon® *||70-79||80-84||< 0.5 fl oz||9|\n|Impact® *||70-79||80-84||< 0.75 fl oz||13.5|\n*Do not exceed rates described\n1 LibertyLink® Hybrid required\n2 Wait 18 months after its application to plant red kidney beans.\n3 Anthem Maxx®: do not use flood irrigation to activate or incorporate it.\n4 Can only be rotated to dry bean the next year if corn and dry beans are grown under center pivot irrigation.\nSource: 2020 Guide for Weed, Disease, and Insect Management in Nebraska (EC130)\nDiverse Herbicide Programs\nA common and effective herbicide program in the Panhandle of NE in corn is glyphosate tank mixed with dicamba. However, such a program may not be a sustainable solution to the problem of herbicide-resistance as dicamba-resistant kochia exists in southwestern NE, and dicamba-resistant Palmer amaranth has been confirmed outside of NE. Palmer amaranth is also resistant to both group 27 and group 14 herbicides outside of the Panhandle of NE. The arrival of new resistant biotypes of kochia or Palmer amaranth into the Panhandle of NE is a question of when it arrives, not if it arrives.\nTo adequately manage both current and future resistant biotypes, at least two modes of action should be used that are both effective for controlling a target weed species, so that the possibility of a resistant weed surviving future herbicide application can be reduced. We recommend using the Herbicide Resistance Risk Calculator (HRRC) as a tool to select your herbicide program. Instructions on how to use the HRRC can be found in this article. Once herbicides and a weed species with or without resistant biotypes are selected, the model will calculate an herbicide resistance risk score for each herbicide selected. Risk scores are values from 0 to 4, and the goal when selecting herbicides is to keep the risk score below 1.0. Some herbicide programs are described below to provide examples of diverse herbicide programs that are compatible with crop rotations including dry bean in Western NE.\n- Managing herbicide-resistant weeds in corn prior to rotating to dry bean is one of the most important tools to manage weeds in western Nebraska. Many effective herbicide options exist for corn, while dry beans and specialty crops in the region lack diverse herbicide options.\n- Many corn herbicides cannot be used the year before dry bean is planted due to the risk of injury from herbicide carryover. Be sure to consult herbicide labels prior to applying any herbicide.\n- Use a two-pass PRE/POST weed control program when possible, and include residual herbicides and multiple modes of action for both PRE and POST applications. Two-pass systems increase the likelihood of season-long weed control and reduce the risks of new herbicide-resistant biotypes.\n- Consider using the Herbicide Resistance Risk Calculator to aid in planning your weed management program.\nKnezevic SZ, Klein R, Ogg C, Creech C, Kruger GR, Lawrence N, Jhala AJ, Proctor C, Jackson-Ziems T, Harveson R, Wegulo S, Bartles M, Timmerman A, Sivits S, Broderick K, Wright R, Ohnesorg W, McMechan J (2020) 2020 Guide For Weed, Disease, and Insect Management in Nebraska (EC130). University of Nebraska-Lincoln. 356 p."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:d9b6f3b3-5dd0-49ef-a21d-b1e65584cbd4>","<urn:uuid:9a6ee76d-ac13-4afc-b71d-42018bb20857>"],"error":null}
{"question":"What are the key differences in medical observation approaches between head injuries and ACL injuries in young athletes?","answer":"For head injuries, doctors recommend an observation period in the emergency department before deciding to perform CT scans, particularly for medium-risk cases where symptoms may take time to develop. This observation approach helps avoid unnecessary radiation exposure while still catching serious brain injuries, which occur in less than 1% of cases. In contrast, for ACL injuries, observation focuses on prevention through specific training exercises and immediate response to symptoms. The documents emphasize that unlike head injuries where waiting is sometimes beneficial, ACL injuries should never be played through - persistent pain requires prompt medical attention as untreated injuries can lead to lifelong problems.","context":["Doctors Suggest Waiting To Scan Kids For Brain Injury\nAccording to a new study published in Pediatrics, observing kids after a head injury may help doctors determine if they need a head x-ray.\nResearchers are still unsure whether too many of those x-rays, called computed topography, or CT scans, might trigger cancer later on in life.\nDr. Lise Nigrovic of Children’s Hospital Boston, who worked on the study, said CT scans are a good strategy for kids who have some risk of a serious brain injury, but have not started showing symptoms.\n“CT isn’t bad if you really need, but you don’t want to use it in children who are at low risk for having a significant injury,” Dr Nigrovic, who led the study, said in a statement.\n“For parents, this means spending a couple of extra hours in the emergency department in exchange for not getting a CT. It’s the children in the middle risk groups ““ those who don’t appear totally normal, but whose injury isn’t obviously severe ““ for whom observation can really help.”\nShe told Reuters that if a kid shows up at the ER soon after a head injury, “you may just not have had enough time for symptoms to develop. Or, a kid “may have some symptoms that make you a little concerned, but you just want some time” before making a decision about doing an x-ray.\n“We all want to make sure that we use CT scanning in the cases where it’s likely to be positive and that we save children from the radiation for those that we know are very unlikely to be positive,” Dr. Martin Osmond, of the Children’s Hospital of Eastern Ontario, told Reuters Health.\n“This study adds important new information about who to observe” before making that decision, added Osmond, who has no ties to the new study.\nThe researchers reviewed data on over 40,000 kids with a head injury who were taken to one of 25 different emergency rooms.\nThe Pediatric Emergency Care Applied Research Network collected the original data. Doctors treating the kids made a note in their records about whether each kid was kept in the hospital and observed by doctors and nurses before they decide whether or not to perform a CT scan.\nThe researchers studied about 5,400 kids. About 31 percent of them had the head x-ray, versus 35 percent of kids when doctors made that decision right away.\nLess than 1 of every hundred kids in both groups had a serious brain injury.\nTwenty-six kids went home without a CT scan and came back later for an x-ray, while 1 of them ended up having a brain injury diagnosed by the x-ray.\nCo-author Dr Nathan Kuppermann, chair of the Department of Emergency Medicine at UC Davis, told the Telegraph: “There is a clear need to develop appropriate and safe guidelines for decreasing the number of inappropriate head CT scans that we do on children.”\n“The results of this analysis demonstrate that a period of observation before deciding to use head CT scans on many injured children can spare children from inappropriate radiation when it is not called for, while not increasing the risk of missing important brain injuries.”\nOn the Net:","LOS ANGELES–(BUSINESS WIRE)–#ACLinjury–With spring upon us and summer not too far behind, April has been\nproclaimed Youth Sports Month – a time to encourage youngsters to get\nout and play while also providing important guidance on how to avoid\ninjury and stay in the game.\nOne injury of particular concern is the number of anterior cruciate\nligament (ACL) tears found among today’s youths. The ACL is one of the\nmajor ligaments that provides stability to the knee joint; and although\ncommonly talked about in professional sports, this injury is even more\noften found in athletes under the age of 25. In fact, the number of ACL\ninjuries, particularly among high school students, has risen\ndramatically over the past 20 years. Researchers have found the overall\nincidence of ACL tears among 6- to 18-year-old patients has increased by\n2.3 percent per year, and the rate of ACL tears surgically reconstructed\nhas increased by 3 percent per year over the study period.\n“ACL injuries have become a youth sports epidemic and are the No. 1\nsports injury we operate on at our outpatient surgical center,” said\nJennifer Beck, M.D., associate director of the Center for Sports\nMedicine at the Orthopaedic Institute for Children. “The injury\nis most common in sports that involve sudden changes of direction – such\nas football and soccer – but fortunately there are some basic things\nathletes can do to lessen the chance of injury.”\nAccording to Dr. Beck, most ACL injuries are not the result of contact\nwith another player but rather occur during sudden twisting motions\n(such as when the feet are planted one way and the knees are turned\nanother way) or when landing from a jump. Factors that can contribute to\nACL injuries include biomechanical factors such as muscle strength and\nleg alignment as well as sport technique and preparation.\nDr. Beck says that athletes can reduce their risk of ACL injuries by\nperforming training drills that require balance, jumping, power and\nagility. “Drills such as these also help improve neuromuscular\nconditioning and muscular reactions and have shown to ultimately\ndecrease the risk of ACL injury.” Other suggested exercise includes a\nvariety of focused stretches (calf, hamstring, quadriceps, etc.) leg\nraises, leg lifts, prone hip extensions and sidesteps with a Theraband\nresistance band. A complete list and more information on ACL sprains and\ntears can be found at http://ortho-institute.org/education/patient-library/anterior-cruciate-ligament-sprain.\nWhile ACL injuries are on the rise, it is not the only potential hazard\nfor youth who are gearing up for another season of sports … and many of\nthe basic tips provided to all young athletes apply to ACL injury\nprevention as well. The OIC Center for Sports Medicine advises parents\nand coaches to work together with young athletes to ensure that players:\nDon’t skip the warm-ups. It is important to warm up properly,\nincluding stretching and jogging. Preparing the muscles for more\nstrenuous exercise can help prevent strains and sprains (including ACL\ninjury) while improving performance.\nDrink enough fluids. Dehydration can make muscles more\nsusceptible to damage. Players should drink water before, during, and\nafter practice and games.\nUse proper equipment. There have been many advances through the\nyears in sports equipment that not only help performance but lessen\nthe risk of injury. Make sure that athletes have the right shoes, pads\nand helmets before they take to the field.\nNever play through pain. It is never okay for young athletes to\nplay through pain or fatigue. Persistent pain should not be ignored.\nLeft untreated simple injuries can become complicated conditions.\n“We want children to have fun, but it is also important to have a common\nsense approach to playing and to not ignore injury,” says Dr. Beck.\n“While rest, ice and ibuprofen can help reduce basic soreness, if pain\npersists parents should contact a physician. Failure to address a sports\ninjury properly and promptly can lead to lifelong problems.”\nThe Orthopaedic Institute for Children is home to Los Angeles’ premier\nCenter for Sports Medicine for children. Its state-of-the-art facility\nis staffed by a specially trained team of sports medicine physicians,\npediatric orthopaedic surgeons, nurse practitioners, medical assistants,\nathletic trainers and physical therapists all focused on helping each\nchild return to his or her sport activities as quickly and safely as\npossible with the shortest possible recovery time.\nAbout Orthopaedic Institute for Children\nOrthopaedic Institute for Children (OIC) was founded in 1911 as Los\nAngeles Orthopaedic Hospital. Focused solely on musculoskeletal\nconditions in children, OIC receives 60,000 patient visits each year. In\nalliance with UCLA Health and with the support of the OIC Foundation, we\nadvance pediatric orthopaedics worldwide through outstanding patient\ncare, medical education and research. Our locations in downtown Los\nAngeles, Santa Monica, Westwood and Calexico treat the full spectrum of\npediatric orthopaedic disorders and injuries. For more information,\nvisit us at ortho-institute.org.\nOrthopaedic Institute for Children\nCamille Strickland, 213-742-1501"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:5eb92937-00c2-4a42-811c-cf21a0ad8abf>","<urn:uuid:2256f0be-08f4-4fc2-b2c1-de5f91ca9e23>"],"error":null}
{"question":"How do the compositional approaches of modern theatre music and John Williams' film scores differ in terms of timing and structure? Could you explain their distinct characteristics when it comes to synchronizing music with the action?","answer":"Theatre music and John Williams' film scoring represent different approaches to timing and structure. In theatre, the music needs flexibility since scenes may vary in timing between performances, requiring composers to create modular musical cues that can be triggered by specific dialogue lines - similar to video game music that morphs based on action. In contrast, Williams' film scoring follows the classical Hollywood style where music has a locked timeline synchronized precisely with the film's action, using techniques like leitmotifs and 'Mickey-Mousing' to complement specific moments. His scores for films like Star Wars demonstrate this tight integration through recurring musical themes for characters and careful orchestration timed to the visuals.","context":["You have worked in feature film, documentaries and written for the theatre, what would you say are the main differences if any between the three mediums?\nMusically there isn’t necessarily a big difference. The direction of the music is determined by the vision of the director in collaboration with the composer, in both film and theatre productions. But the working methods are different. In a theatre performance, you don’t have a “locked” timeline like in a movie, so you don’t normally use the same amount of macro-timing like you might do when scoring a complex film sequence with a lot of different cue points. Since theatre is a living and breathing medium, the timing of the actors also might vary a bit from performance to performance. So the structure of the music needs to be a bit more “flexible” since the scenes might play out a bit different from day to day. That said, for theatre productions I often like to work around this, by splitting the musical cues into different parts that can indeed be triggered by certain dialogue lines or other cue points – so that you get a seamless effect of a wholly composed thing that just magically fits together! It’s a semi-interactive approach to the music, a bit like in modern video games when the music continues to play in the background, morphing to a different part of the music when something specific happens in the action.\nWhat is clearly also different in the theatre, is that the actors are often already working with the music while they are rehearsing the play. So there might be more cases of the music actively influencing the stage direction and the rhythm of certain sequences. That rarely happens with music for film, unless you are filming musical numbers which of course requires that music to be ready before filming. But in general the composer comes in a little bit later in the filmmaking process, often after filming has wrapped. So in films, the rhythm and structure of the music cues are more often determined by the editing, than vice versa.\nThere is approx. 30 mins of music in Mio, min Mio, when you have written the score is the music played live with the performance or is it recorded and played when the performance is on stage?\nOn both “Mio, min Mio” and “Ingenting” (both directed by the amazing Hilde Brinchmann) the music was pre-recorded and played back by the stage sound engineer through a piece of software called QLab. This way the musical cues can be split into different parts like I mentioned before, and glued together on-stage during the final weeks of rehearsals, fine-tuning the whole performance and the structure of the music on location. It is a very creative and fun process between director, composer and sound engineer.\nHowever, on another recent project, a modern adaptation of Henrik Ibsen’s “Peer Gynt” which was staged the last three summer seasons as an outdoor play in Oslo, we needed to do the same kinds of seamless live transitions between cues, but with a 40 piece live orchestra (actually the Staff Band of the Norwegian Armed Forces) instead of pre-recorded files. Which means that the conductor (the magnificent Bjarte Engeset) had to keep track of a very long list of micro-cues throughout, carefully listening to every line of dialogue by the actors, at the same time as conducting the orchestra, being prepared to skip a certain amount of bars or even skipping to a different piece of music at any point in time! At certain points we had different players in the orchestra purposely playing two different pieces of music simultaneously, to create optimal “crossfading” effects! Total madness, but when you work with amazing people, it can be done!\nWhat is your principal instrument when you are writing a score for a play or film?\nThe piano is my composing tool, for getting the ideas down (although the drums are what I regard as my main instrument). I never get my best ideas when I am in the studio, surrounded by all the software synths and sounds with their limitless possibilities, like they are almost a distraction from the ideas themselves. I find that an acoustic piano delivers another kind of feedback, it’s almost like it’s talking back to you instead of just making the sounds. So I might have working days when I purposely stay away from the studio, to have more peace for just getting the ideas down first, recording rough piano sketches into my phone or iPad. Or just taking a walk in the forest while having the phone ready to record me singing, when an idea appears. I think I read somewhere that the brain is more efficient at producing new ideas when you’re walking than when you’re sitting still – it certainly seems that way to me! As soon as I have the idea for a track, I more or less know where I want to go with it, in terms of instrumentation and arrangement. That’s when I go back to my studio and get to work.\nWhat percentage of the instrumentation was symphonic on Mio, min Mio?\nI would say 1%! The only live element are some of the drums (which I played myself). The rest is all sample libraries, played on keyboards and edited and mixed in my sequencer. The budget is really what determines what you can do. For good and bad, sample libraries are sounding better and better, and are making it easier than ever to produce decent sounding results in quite a short amount of time – but they can’t in any way replace the real thing, and they shouldn’t. It’s a difficult balance, because I always want to use as many live musicians as possible, and I also want to support and give jobs to all the great musicians around! But the way things are now, only the big budget films in Norway makes it possible to hire a full orchestra. And the way you might utilize a blend of real players and sample libraries are also determined by what kind of sound you are attempting to create. On my first two feature films “Rafiki” (2009) and “The Tough Guys” (2013) I used studio musicians to cover up the shortcomings of the symphonic sample libraries and to make it breathe. On later projects I have sometimes opted for more of a chamber music sound rather than a full symphonic one, like in “The Brothers Lionheart” (2014) which is largely based on a string quintet with added percussion and keyboards, and “Los Bando” (2018) which is more of an indie pop score with strings and woodwinds, drums and keyboards. Going the “chamber” route gives you the privilege of basing the whole thing on a group of 5 or 6 real musicians and not just use them to “cover up” the samples. “Mio” was a more minimalistic production with a tighter schedule, but still needed this big symphonic kind of sound, which led me to just embracing the sample libraries fully this time – but I would love to rework some of the music for a symphonic suite or something at a later date. On “Ingenting” this was a much easier creative choice since the music isn’t even supposed to sound symphonic – it’s all based on retro synth sounds, inspired by the likes of Wendy Carlos. And “Secret of the Catacomb” is sort of a blend between the symphonic and synthetic aesthetics and had to be composed and produced in a very short time, so that’s all sample based too.\nYou have not released your latest three scores on CD, will they get a compact disc release do you think?\nIn Norway, music streaming has completely taken over the market. CDs are given away for free by the bucket loads, people just want to get rid of them here. Not me though – I love CDs! Ideally, I would like to release every album on CD, so it’s really just a question of time and money. But I have noted that the soundtrack fan community seems to still hold the CD in high regard, like I do. That’s awesome! And I think there’s a fair chance we will see a CD version of “Mio” sometime in 2020.\nWhat would you say are your musical influences, or which composers and artists have inspired you?\nThat’s a big one! Everything I have ever listened to and loved, I guess! When I was young, I listened to a lot of Genesis, Phil Collins and Peter Gabriel (still do), and in my teenage years I loved Norwegian alternative 90s rock bands Motorpsycho and Seigmen. I played a lot of computer games and totally absorbed the music of all those classic Lucas-Arts games of the 90s, with composers like Michael Z. Land, Peter McConnell and Clint Bajakian. I also discovered John Williams, listening to those Star Wars Special Edition double CD albums and reading the analytic liner notes with great care. That was a big eye-opener into the world of film music, I guess I was 14 when those albums came out. Today, Williams’ more modern work with those beautiful and more experimental scores like “A.I. Artificial Intelligence” has a special place in my heart. I also identify greatly with Danny Elfman in terms of his journey from rock musician to reluctant film composer and have a soft spot for some of his more mature and minimalist work like “The Unknown Known”. In the pop/rock realm I am a big fan of Ben Folds, every one of his albums and all of his crazy ideas. Other piano-oriented songwriters like Tori Amos and Fiona Apple and genre-defining, ground-breaking artists like Björk and Radiohead were also a big part of my musical coming-of-age period. Last but not least: My three all-time favourite classical composers are probably Edvard Grieg, Antonin Dvorak and Maurice Ravel. I go absolutely nuts over Grieg – and that’s not just because I am a Norwegian! His catalogue is simply an endless treasure trove of beautiful music (not just the “hits!).\nSECRET OF THE CATACOMB I think is a very atmospheric score, the music is very expressive and dark, how much time did you have to write the music for this radio production, and at what stage of production do you become involved and is it harder to write for a radio production as opposed to a feature film?\nGlad you enjoyed it! I think I used just over six weeks of composing and sequencing/recording and mixing simultaneously. Working with radio dramas is a lot of fun, and another quite different process from both film and theatre! Since you don’t have pictures, both the sound design and the music can get quite “descriptive”. That’s why you tend to go for those gut instinct things like dark Gregorian drones, to make the listener immediately aware that we are inside a dark cavern, and a scary monk-type creature is staring at us!\nThe series consists of eight episodes, each clocking at around 30 minutes. Obviously, scoring four hours of content in six weeks is… not recommended, to say the least. So this again is a creative process between me, director Guri Skeie and sound designer Hilde Rolfsnes. The first step is reading the script and partaking in an early script reading with the cast and crew. Then Guri and Hilde will give me a “wishlist” of different themes and cues that they need for placing around the episodes – they have such a detailed vision for the project and know exactly what they are after. So my job then is to compose the desired “package” of music cues, and record and produce it all in parallel with them recording the episodes with the actors. After that it’s largely sound designer Hilde’s job to glue all the music cues together with the episodes, at the same time as she’s creating all the sound design and mixing everything. There’s not much time for second-guessing or delivering something that doesn’t work, for any of us. It’s quite fast paced! But I don’t think it’s harder than working on a feature film. It’s different, since you’re not so much scoring scene for scene, but doing a more flexible package of cues that can work well for different scenes and situations. It’s a fun challenge!\nWhat musical education did you receive, and was writing music for film and theatre something you had always wanted to do?\nIn my teenage years I did spend a lot of time scoring the amateur short films and computer games me and my friends were having fun creating at the time. So, I think I knew deep down that I this was what I was going to be doing.\nI later studied musicology and music technology. There was no film music related course here back in the early 2000s and studying abroad was not even an option for me – I’m way too homesick. The national composition studies I knew of felt geared towards a certain type of contemporary classical music that I have never been that interested in. In that period, I spent most of my time playing in bands anyway, primarily as a drummer. In an act of desperation (or sudden inspiration?) I packed all my things and moved to the big city (Oslo) while I was supposed to be finishing my master’s degree in another town 500 kilometres away (Trondheim). Half a year later I got my first gig at the Norwegian Broadcasting Company with a children’s TV series. This was 2006, and I’ve been at it since then! I was a bit of a lousy student, to be honest. What I liked about musicology was the more playful aspects of it; like the subjects in composition and improvisation. I made some lifelong friendships, and my mind was opened to music history and learning more about certain composers and periods of music, of which I am grateful. But I didn’t speak the academic language. My mind was solely on making music, not analysing it.\nWhat are your earliest memories of any kind of music?\nMy dad has always been a big music fan. LPs by the likes of Frank Zappa were always in heavy rotation in our home – and as you may know, Zappa represents pretty much every music genre there is! I also enjoyed stuff like Santana’s debut album and The Beatles’ “Sgt. Pepper’s Lonely-Hearts Club Band” (I have since grown to be a huge Beatles fanatic). I vaguely remember the sound of a-ha coming out of the kitchen radio. I was three when they had their big breakthrough with “Take On Me” in 1985. But I was probably drumming on kitchen utensils and singing improvised nonsense lyrics before that.\nDo you orchestrate all of your music for film and theatre and do you think that orchestration is an extension of the composing process?\nI always do the arrangements myself, and indeed see them as an inseparable part of the composition. I have sometimes hired an orchestrator when working with larger ensembles, if I want some kind of proof-reading or even creative input on how to make the arrangements sound their best. As my university drop-out tactic might suggest, music notation is not exactly my strongest side – I enjoy doing it, but it’s not what I do best. So, it’s sometimes good to have a second opinion when dealing with the dirty details like harp pedalling or how often the tuba player needs to breathe. As a general rule, I only write down the parts that are actually going to be played by real musicians. If I am only going to use sample libraries, I skip the written score entirely, and only work directly in the sequencer. But on most of my projects, it’s a mix of the two. When you’re dealing with smaller ensembles and soloists, it’s always great to just talk to the musicians directly and communicate how you want the parts to be played. But of course, the closer the notation is to already be conveying those intentions in easily readable form, the more of a head-start you have in the recording session.\nMany Thanks to Eirik for taking the time to answer my questions.","John Williams & American Film Music\nHaving written over 100 film scores, as well as other symphonic and chamber works, John Williams is among the most prolific and celebrated composers of our time. His film scores, particularly those involving large-scale, orchestral forms, have earned him 51 Academy Award nomination and countless other honors. In addition, he has greatly influenced American symphonic repertoire and practices, as his work as both composer and conductor has helped bridge the gap between popular culture and classical music.\n- Music has been part of film since the beginning of cinema in the 1890s. Silent films were accompanied by live performance, and synchronized sound in film emerged in the 1920s. By the 1930s, music was an important part of the Hollywood film industry, with classical Hollywood film music involving large, orchestral scores, typically in the style of 19th century Romanticism.\n- By the time John Williams began working in TV and film in the late 1950s, film music had branched out to include all styles of popular music and modernism.\nWilliams quickly demonstrated versatility as a composer; his first Academy Award nomination was in 1967, and his first win was for his musical adaptation of Fiddler on the Roof (1971). His second Oscar came for Jaws (1975), directed by Steven Spielberg, with whom Williams has collaborated ever since. A departure from trends of the time, Jaws was scored for large orchestra with music structured around the now-iconic, two-note theme that represents the shark.\n- Williams became known for such narrative, large-scale, orchestral film scores that reference the classical Hollywood style. This can be heard in Star Wars (1977) and other films in the series. Often called a “space opera,” the Star Wars films feature recurring musical themes for characters and ideas (leitmotifs), musical effects to complement the action (called “Mickey-Mousing”), and vivid orchestration.\n- He has written several other heroic, orchestral scores (e.g., Superman, Raiders of the Lost Ark, E.T.), yet has a remarkable capacity to adapt his music to different types of films and stories. One such notable achievement is Schindler’s List (1993), for which he won his fifth Oscar and features poignant, Hebraic melodies and violin solos performed by Itzhak Perlman. Also noteworthy are the first three Harry Potter films (2001, 2002, and 2004), which musically transport the audience to a magical and mystical world.\n- Even though some criticize Williams’ music for being rooted in 19th century idioms, a particular hallmark of his film music is how well it can stand on its own as concert music. His compositions as well as work as a conductor (Boston Pops) have brought symphonic music into popular American culture, and also advanced and revitalized symphonic repertoire.\n- What are some of the musical devices that Williams uses to create musical narratives in films?\n- How does Williams adapt his musical style to different types of films and narratives? For example, what are some of the stylistic differences between Star Wars and Schindler’s List?\n- In what ways do the musical themes in the Star Wars movies represent the characters and ideas? How does Williams interweave these themes throughout each film, and across films? How does he do this in other films, such as Jaws or Harry Potter?\n- Even though Williams’ orchestral style is based on 19th century musical idioms, why does his music resonate so well with audiences today?\n- What are some other trends in contemporary film music? Who might follow in Williams’ footsteps?\nMore to Explore\n- Biography of John Williams Click here\nBooks for Further Reading & Listening\n- Audissino, Emilio. John Williams's Film Music: 'Jaws,' 'Star Wars,' 'Raiders of the Lost\nArk,' and the Return of the Classical Hollywood Music Style. University of Wisconsin Press, 2014. 346 pages. While there are many popular articles about John Williams and his music, this is the first (and currently only) scholarly book in English. Audissino provides an overview of film music, particularly the classical Hollywood style of the 1930s-40s, and discusses Williams’s tremendous contribution to film music from that perspective. He provides insight on Williams as a composer with in-depth discussion of some of his most successful film scores, and examines his music’s wide reaching influence.\nClick here to order\n- Kalinak, Kathryn. Film Music: A Very Short Introduction. Oxford University\nPress, 2010. 143 pages. As the title suggest, this is a brief overview of film music – it’s history from cinema’s beginning, how music functions in film, and different musical approaches and styles across the world of film. While not specifically detailing John Williams’s music, Kalinak’s general discussion puts his music into this larger perspective.\nClick here to order"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:d0173b9e-46fc-402d-b1be-d2149ca9a663>","<urn:uuid:bbed682e-50ce-49c8-85a5-a8508e1e4439>"],"error":null}
{"question":"How do the visual design philosophies differ between She Remembered Caterpillars and All Of You in terms of background elements and their impact on gameplay clarity?","answer":"She Remembered Caterpillars approaches background design with a careful balance between immersion and legibility, specifically avoiding overly simple backgrounds that didn't feel immersive enough, while ensuring the puzzle elements remain visible through contrast and careful color selection. The backgrounds tend to be darker and less saturated than the main puzzle elements, representing a trade-off between creating a sense of place and maintaining gameplay clarity. In contrast, All Of You takes a more straightforward approach to visual clarity, offering 'No Busy Backgrounds' as a specific feature where backgrounds can be made static or blank to avoid distracting from the action. The game also emphasizes visual clarity through large game elements and the ability to outline interactive elements for better visibility.","context":["She Remembered Caterpillars is a puzzle game where a set of coloured characters needs to be navigated through a maze of coloured obstacles. Each character can only cross certain obstacles while others obstruct its way.\nWhen I started working on this project, I was not yet aware of one of its major visual hurdles. At first I went the obvious way: bridges look like bridges, and walls look like walls. Character design could be anything but it would have to fit the world, of course. The results seemed promising. I could have stopped there. But I would not be writing this if I had.\nBut shortly thereafter, I came across an article about includification (a term coined by ablegamers) and how a game ideally should have options for those with colour-deficiencies. That made me think. Especially since there was a very early preview of our game on PCgamesN that started with the line,’this game is not for the colour-blind.’ After a bit of research, I realised that many games where the core mechanic uses a wide range of colours simply skip this part. But why? I wondered if it was that much more work.\nCould I redesign the characters and obstacles in such a way that even someone with a strong deficiency would be able to play the game? It was obvious to me from the start that including a colour shift option in the game would not work because the game features a spectrum of eight colours. This left one other solution: combine each colour with a specific symbol.\nWhile not a big challenge at first, it quickly dawned on me that not only did the symbols need to appear on the characters but also on each obstacle. What made all this even more difficult was the fact that in this game, players have the ability to merge two characters into a new colour which, in turn, meant that the symbols would have to explain this as well. And obviously it needed to be legible.\nOne might think that there is a wealth of information on this topic, given that 10% of humanity have a colour-deficiency of one form or another. However, apart from a few design articles I could not find anything that seemed helpful. Fortunately, I remembered some of my art education—specifically Wassily Kandinsky—and borrowed his way of associating basic shapes with primary colours. From there, I developed a set of matching merged symbols for the secondary colours. Consequently, black needed to be the combination of all of the symbols while white, the absence of colour (in this game), had to be a shape that was something else entirely.\nHowever, creating a game in such a way that a colourblind or colour-deficient person can play it without a lot of trouble is not solved by simply associating shapes and colours. Afterall it was always supposed to be a game with coloured backgrounds. Every detail, every colour, every movement creates an additional piece of information that needs to be processed and understood. For She Remembered Caterpillars this meant making sure that the essential elements needed to remain readable regardless of who was looking at them. This is the main reason why I tried to make sure that on all characters and obstacles there is always a visible contrast between the colour, the associated symbol, and the backgrounds. To achieve this I made extensive use of a colour-blindess simulation tool called Color Oracle. Below is composite of screenshots showing the differences.\nThe approach resulted in backgrounds that tend to be relatively dark and mostly not as saturated as the main puzzle elements. One of the biggest challenges for me was balancing the amount of detail. I tried for simpler backgrounds in an early version but they did not feel immersive enough for me. The result sometimes is (hopefully) a working trade-off somewhere between legibility and a good sense of place.\nand a final side by side comparison\nShe Remembered Caterpillars (caterpillar.solutions) is a fungipunk fantasy about love, loss, and holding on, told in the format of a colour-based puzzle game. A tale as the bond between parent and child, this lush and bewildering title will have players testing their wits against a variety of challenges, some devious, and others outright nefarious, but all beautiful and very, very strange.\nThe game is available on Steam, itch.io, and Humble Store.","All Of You Accessibility Report\nWe've documented 24 accessibility features for All Of You in the Controls, Getting Started, Reading, Navigation, Visual and Audio areas to aid enjoyment of the game for different players. This report is created with input from accessibility experts and the player community to help people find games that have the accessibility features they require. Once you have found potential games on the database, there are excellent specialist accessibility sites that offer in-depth reviews to guide your purchasing decisions.All of You is a platform game where you can pause time and control the levels rather than the character. By rearranging the timing, order and orientation of the world you play in you can help the mother hen get her chicks back.\nThe game pauses until you are ready to move to the next frame. You can't adjust the difficulty, although levels start easier and get harder through the game.\nWe've documented 4 accessibility features for Controls in All Of You which deal with how you control the game, different options for alternative inputs and whether you can remap these settings to suit your needs.\n1 Button & Single Stick: Can play with button and stick.\nAdditional gestures may be required for games played with a screenreader like VoiceOver.\nOne Motion Targeted: Can play with touchscreen, tap and swipe or hold gesture.\nSpecific button operation required to play\nHolding Down Buttons Optional: Holding down buttons for prolonged periods (a second or more) is not required or can be switched to toggling the action on and off. This is in addition to the movement stick/button which is not considered a hold for this purpose.\nRapid Repeated Pressing Optional: Quick, repeated button pressing (more than 2 times a second) is not required, can be skipped or switched to holding a button to trigger a repeated action.\nSimilar Games With More Accessibility Features for Controls\nIf you want to play All Of You, but it doesn't offer the Controls accessibility features you require, these similar games extend the Controls accessibility:\nWe haven’t documented any accessibility features for Difficulty in All Of You which deal with how you can adjust the challenge of play, and whether this is locked once chosen or can be adjusted as you play. The following games are similar to All Of You, and offer accessibility features for Difficulty:\nWe've documented 6 accessibility features for Getting Started in All Of You which deal with what support is offered to get started with the game. This includes customising the experience when you first open the game via any onboarding processes it provides as well as tutorials and other assistance when you first start playing.\nAssistance Getting Starting\nThese features aid your play of the game in terms of cognitive load on learning controls, dealing with pressure and coping with the environment and challenges.\nTutorials: There are helpful tutorials and instructions on how to play. Information is provided in a timely manner, with appropriate level of detail.\nPractice Area: You can practice freely without opponents or time pressures. This can be a specific practice option, or the ability to play levels with the easiest opponents to improve understanding and skill.\nReaction-Time Not Critical: Individual game actions don’t need quick reactions, or there are settings to lower the requirement for quick reactions. This means you don't need to quickly press a button in response to an on-screen prompt, target a fast-moving target or skillfully complete a scenario against the clock.\nLow Pressure: Game tasks aren't time-limited or there's a low-pressure mode. This avoids the pressure of being put on the clock for overarching missions, or failing tasks because you didn't reach a destination in time.\nAdjust Speed: Adjust the speed of the game at critical moments or throughout, or rewind play for a second attempt, to ease reaction times. By slowing the game, you have more time to interpret what is happening and then execute your actions. It also reduces the pressure on getting things right quickly or the first time you attempt them.\nAssistance For Progressing\nThese features aid your progress through the game offering different ways of maintaining your progression.\nSave Progress Anytime: The game automatically saves progress or you can save any time. This doesn’t mean you never lose progress, but it does mean you can stop whenever you want (without having to get to a save point) without losing progress.\nWe've documented 2 accessibility features for Reading in All Of You which deal with how much reading or listening comprehension is required, how well the game provides visual and audible access to the text and whether subtitles and captions are a good fit for purpose.\nHow much reading is required to play the game and how complex the language is. This doesn't include subtitles as required reading if they are fully voiced.\nNo Reading: No reading is required, other than simple menus. The game either has no text or can communicate textual content with visuals and interactions. If reading isn't required because the text is voiced the All Dialogue is Voiced feature indicates this.\nAll Speech Subtitled (Or No Speech In Game): All spoken content has subtitles, or there is no speech in the game. This means there is no requirement to hear spoken dialogue or narrative to play the game.\nSimilar Games With More Accessibility Features for Reading\nIf you want to play All Of You, but it doesn't offer the Reading accessibility features you require, these similar games extend the Reading accessibility:\nWe've documented 1 accessibility feature for Navigation in All Of You which deals with how the game provides guidance and assistance to navigate its worlds. These are only for games that have traversal and exploration in 2D and 3D spaces.\nAdjust Head-Up Display: Resize and adjust the content of the head-up display. This enables it to be made more visible. It can also enable the removal of too much information that can be distracting or confusing.\nSimilar Games With More Accessibility Features for Navigation\nIf you want to play All Of You, but it doesn't offer the Navigation accessibility features you require, these similar games extend the Navigation accessibility:\nWe've documented 8 accessibility features for Visual in All Of You which deal with how you can adjust the visuals to suit your needs, and offer additional information if you can't hear the game.\nMedium Contrast: Game uses generally well contrasting and bright visuals, or has a slider to make this the case.\nLarge Game Elements: Game characters and other elements are large and distinguishable. Enemies and player characters are at least 1/6 of the height of the screen. Or there is a zoom feature to make them larger.\nOutline Interactive Elements: Characters, platforms and enemies can be outlined or highlighted for visibility. This can be with a large border around the character or a special visual mode that adjust the colour to make characters more visible.\nNo Screen Shake: No screen shake effect or it is included but it can be disabled. This includes the absence of screen shake for dramatic effect as well as to indicate hits on a target.\nNo Busy Backgrounds: No distracting backgrounds or you can make them static or blank. This includes the absence of other movement elements in the background that might distract or confuse the action.\nAudio Cues for Visual Events\nAudio Cues for Visual Events: Audio is provided to indicate visual events. Game events or progress highlighted by visual icons, effects or animations are also accompanied by audio to signify that progress. This is useful for blind players.\nMotion Sickness Friendly\nMotion Sickness Friendly: Doesn't have 3D movement elements that may trigger motion sickness, like motion blur, depth of field and field-of-vision. Or includes the ability to disable motion blur, depth of field and field-of-vision effects.\nColour blind friendly: Game doesn’t rely on colour or can switch to colour blind friendly mode with double coding or similar way to avoid colour dependance.\nWe've documented 3 accessibility features for Audio in All Of You which deal with how you can adjust the audio of the game and whether audio cues compensate for aspects of the game that are hard to see.\nBalance Audio Levels: Set music and game sound effects separately. This enables you to select your preference as well as ensure critical game sounds aren't obscured by other audio.\nVisual Cues for Audio Events: Text or other visual indicators of audio events. This mirrors audio indicators of progress in the game with a corresponding visual indication.\nPlay Without Hearing\nPlay Without Hearing: No audio cues are necessary to play the game well.\nSimilar Games With More Accessibility Features for Audio\nIf you want to play All Of You, but it doesn't offer the Audio accessibility features you require, this similar game extends the Audio accessibility:\nSystem Accessibility Settings\nIn addition to the accessibility features provided in the game, you can also use system-wide accessibility settings:\niOS has a very extensive suite of accessibility settings including ways to navigate with voice and comprehensive screen reading, though most of the features don't work with games.\nRead more about system accessibility settings."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:30dfdc2d-e357-4995-baba-10dae462ab98>","<urn:uuid:9ff60870-46c2-44d5-9fd7-b7b25b0a056d>"],"error":null}
{"question":"How do sagging issues affect HogNet fence performance, and what troubleshooting steps are recommended for voltage problems?","answer":"The HogNet fence experiences sagging issues due to the 12-foot spacing between guide posts, which is too wide and requires additional posts for proper support. To troubleshoot voltage problems, users should check for broken wires, bad splice joints, loose connections, or excessive vegetation touching the fence. Voltage loss can be caused by broken underground cables, broken wire or insulators. Testing can be done using a blade of grass - by holding one end and touching the fence wire with the other end, you should feel a slight ping. The fence's effectiveness can be improved by using cold wires as extra earthing and connecting them throughout the fence from the main energizer earth stake.","context":["HogNet® 10/24/12 (also known as) HogBloc 10/24/12\nSpecifically designed (if properly energized) to keep feral hogs out of fields, gardens, lawns and yards. The large amount of strands in a 24\" fence increases visibility in brushy locations. Good for areas with high hog pressure. Can also contain domestic pigs.\nNet sets up as Pos/Neg for dry, rocky, sandy or winter soil conditions. This aids in overcoming poor soil conductivity.\nPos/Neg Fences are for dry, sandy or rocky conditions. Ideal for situations when there is too little moisture in the soil to properly ground the fence.\n- 10 horizontal white and black strands (9 electrified).\n- Horizontal spacings from bottom to top are: 4\" 2\", 2\", 2\", 2\", 2\", 2\", 4\", 4\".\n- Verticals are white plastic struts spaced 12\" apart.\n- Posts are 1/2\" diameter PVC with a bottom metal spike that goes into the ground.\n- Spikes are 6\" long and 1/4\" in diameter.\n- Posts are spaced every 12 ft.\n- Installed net is 24\" tall.\n- Net is supplied in 100' or 50' lengths.\n- 38 Ohms of resistance per 1000'\nEvery net is supplied with 1 warning sign and 1 repair kit.\nEach fence can be wired as a Pos/Neg fence (for dry soils) or Pos/Pos (soils damp enough to keep grass green).\n- #208066 - $1.11 per ft (100' roll with single spike posts)\n- #208065 - $1.56 per ft (50' roll with single spike posts)\nFor dry areas install as a Pos/Neg fence. Connect the energizer fence lead to the positive \"+\" net clip and energizer ground lead to the ground rod. Then connect a PowerLink from the negative \"-\" net clip to the ground rod.\nFor moist conditions connect both net clips together and attach energizer fence lead to net clips then attach energizer ground lead to ground rod.\nRemember...netting must always be properly electrified!\nNote: This is a pain barrier, not a physical barrier. If animals are scared or starved it is less likely to keep them out.\nUse only with a low or wide impedance intermittent pulse energizer. Warning! Do NOT use continuous output energizers with electric netting due to risk of fire. (Fi-Shock™ brand energizers which are sold as low impedance, continuous current output should NOT be used with electric netting.) All energizers sold on Premier's website use an intermittent pulse and are suitable for use with electric netting.\nDry conditions and wintertime usage may reduce the effectiveness of electric fencing.\nDry or frozen ground many cause the NetPost spikes to bend or break if inserted with force. Pilot holes may be needed.\nListed below are recommended optional components. Your particular situation may require alternative recommendations. Please call and talk to our fence consultants if there are any questions at 800-282-6631.\nFence Connectors and AccessoriesItem #201700 -\nA handy repair kit that includes all of the essentials to patch tears and holes in electric net fences.$2.00\nFence Connectors and AccessoriesItem #200700 -\nReplaces lost, misplaced or broken plastic caps (for posts 0.51\" in diameter) on netting posts. Holds top strand of net in place so there is less sagging.$0.16\nFence Connectors and AccessoriesItem #200800 -\nClip designed for the spikes on standard netting posts. Keeps bottom black strand from sliding up and creating a gap at the bottom of the net.$0.12\nWrite a Review\nYou must be logged in to leave a review. Please sign in.\nJeremy H from Wisconsin\nThese portable fences are awesome, it's a easy and fast way to partition off my pigs or expand on grazing area. I have 12 of these so far and all are great quality.\nDavid P from Ohio\nI purchased this product for typical backyard garden without traditional grass. I have my garden within an enclosed space that has wood mulch or river rocks under the fence. This prevents weeds from being in the garden and also prevents weeds from growing into the fence. However, neither rock or dry wood mulch are very good conductors, so animals standing on these during dryer times will not get much of a shock. I can prove this to myself by easily holding onto this fence when standing on the dry mulch or rocks (the single fence is connected to the Solar IntelliShock 60 Energizer Kit, which is supposed to be able to power three to five rolls of netting). Yes, there is a shock, but no, it would not discourage me from entering the garden.\nThat's where this specific fence design comes into play. By alternating hot and negative wires, animals typically have to hit two wires to get through (and definitely to get over) the fence. Because they are then hitting both the positive and ground, rather than the positive with a weak connection to the ground, they actually get a discouraging jolt.\nThis fence has worked well and my many tomatoes, bell peppers, lettuces, carrots, and watermelon have not been bothered. My yard regularly has squirrels, rabbits and raccoons near the fence, but I have never seen them inside.\nThe only thing that would make this fence more perfect is the spacing between the non-charged and non-negative bottom wire (it is nothing more than string). The current spacing is four inches before moving to 2 inch spacing above that. Squirrels and smaller animals can easily get under the bottom wire without touching it. To solve this, I simply buried my fence about 2 inches into the mulch and rocks. However, a fence designed similar to this without the 4 inch spacing before the first hot row would alleviate this problem. As long as you consider everything I've said, you should be able to keep any garden you have secure, no matter the ground surface it is on.\nOne other note- the spacing between guide posts is 12 feet. This is way too far and the fence will sag, no matter how tightly you pull it - you'll have to buy extra posts. I went with 30\" posts for this 24\" fence as they could be put in deeper for more support. They have held for several months now with no problems. The 24\" posts that come with this fence can not be put in deep enough, so they sag and even \"pop out\" when the ground is too wet.\nStephanie M from Arkansas\nThis fencing is working spectacularly well for us! We are pasturing our hogs and move them daily. Since they were already trained to white electric fence they knew what it was and showed great respect.\nOne pack of extra step in posts per 100 feet is more than adequate for saggy spots. If you pull the attached spike/post against the vertical wire as you install the fence, it diminishes sagging. I am 61 year old woman and can move 200 feet of this fencing and have it ready for hogs in 15 minutes.\nI am buying additional today and recommend it to other folks wanting to pasture their hogs...it sure cuts down on the feed bill.\nCathy P from Georgia\nI own several of these hog fences and love them! They are light weight, making them easy to carry and set up. They are also low to the ground, making them easy to step over. I use step in posts to keep them more upright and sturdy. The key feature is the black - cold - bottom wire. Grass does not have to be cut shorter than the first hot wire, making set up easier and avoiding the nuisance of a popping fence. I recommend them highly!\nChristina S from Illinois\nYes, it does sag between posts, but we have easily remedied this with cheap fiberglass step ins. Paired with a strong charger, this reliably keeps our pigs where we want them, plus it is easy to move. Am about to buy another one.","Quick Answer: What To Do When Solar Livestock Charger Shows Check Fence Indicator?\n- 1 Why is my fence charger not working?\n- 2 Why is my electric fence sparking?\n- 3 How long does a solar fence charger last?\n- 4 Do fence chargers wear out?\n- 5 How can I test my electric fence without a tester?\n- 6 Why is my electric fence not very strong?\n- 7 Why is my electric fence losing voltage?\n- 8 How can I boost my electric fence?\n- 9 Can you test an electric fence with grass?\nWhy is my fence charger not working?\nIn this case, it could be a broken wire, a bad splice joint, or anything that is not allowing voltage through. If the charger is clicking and there is low voltage, or if it turns on and won’t click, there is a problem with the charger. Livestock is going through the electric fence when there is adequate voltage.\nWhy is my electric fence sparking?\nAlmost all radio noise generated by electric fences is caused by a spark or arcing of the electrical current across fence hardware. Typical sources of arcing include bad splices in fence wire and gate hooks. Fence wire acts as an antenna to broadcast the arc. Vegetation can also cause arcing that is cyclic.\nHow long does a solar fence charger last?\nA solar fencer reaches every inch of your land. Days of Use Without the Sun – When fully charged, solar powered fence energizers store enough battery life to last up to two weeks without any sunlight exposure.\nDo fence chargers wear out?\nAn electric fence energizer doesn’t last forever, and you will need to have it quickly repaired or replaced when it inevitably breaks down or its malfunction can create problems. However, having the charger replaced is easier and more cost-effective than trying to repair it, which is also a time-consuming task.\nHow can I test my electric fence without a tester?\nHow To Test Your Electric Fence Without A Tester In 8 Steps\n- Step 1: Check Transmitter.\n- Step 2: Check for Broken Wires.\n- Step 3: Search for a Blade of Grass.\n- Step 4: Hold Blade of Grass Against Fence Wire.\n- Step 5: Move Blade Closer If Needed.\n- Step 6: Hold the Grass at the Sweet Spot.\n- Step 7: Consider Pulses.\nWhy is my electric fence not very strong?\nPoor grounding is one of the most common faults in electric fencing systems. If the ground is not completed correctly, the energizer cannot operate at is maximum potential. This could be accomplished by driving three ground rods that are each eight feet long into the ground at least 10 feet apart and attaching them.\nWhy is my electric fence losing voltage?\nThis can be caused by a broken underground cable, broken wire or insulator, a loose connection, or something touching the fence, such excessive vegetation. The Digital Voltmeter can help you locate the source of a short by measuring the voltage in the fence line.\nHow can I boost my electric fence?\nMake use of your fence’s cold wires (assuming you have some steel posts) as extra earthing to improve the voltage at the end of your electric fence. Connect them all the way throughout your fence starting from the main energizer earth stake. This means taking an earth wire and a live wire under every gate.\nCan you test an electric fence with grass?\nWhat you’ll need to get is a longer piece of green grass about 8 or so inches long. Squat down to a knee, pinch one end of the blade of grass between your thumb and index finger and lay the other end on the fence wire. You should feel a slight ping in the blade of grass."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:e0dc4d30-aaf7-48f5-a483-d7b7c12eb285>","<urn:uuid:7e7435b3-26d1-493b-a8a5-9854c272479d>"],"error":null}
{"question":"How do diabetes-related vs pain killer-induced kidney damage differ in early symptoms?","answer":"Pain killer-induced kidney damage, particularly from NSAIDs, directly damages kidney tubules and can lead to acute kidney injury and failure. Diabetes-related kidney damage (diabetic nephropathy) shows no symptoms in early stages, but can be detected through annual kidney function tests. Both conditions can lead to kidney failure if left untreated.","context":["Are you diabetic? Are you fond of taking pain-killers to ease your body pain? Do you take them frequently or everytime you feel any sort of pain? If yes… look for a kidney donor as probably you might be losing your own soon!!!\nPain-killers, especially the wrong ones, taken during diabetes lead to damage in kidneys, even kidney failure, say experts.\nDoctors say the use of pain-killers, particularly NSAIDS (Non-steroidal anti-inflammatory drugs) harms the tubules in the kidneys that often leads to kidney failure.\nNon-steroidal anti-inflammatory drugs are a class of drugs that provide analgesic (pain-killing), antipyretic (fever-reducing) effects, and anti-inflammatory effects in higher doses. Hence, these are not suitable for diabetes patients.\n“Most diabetics, especially those who have diabetes over a decade are more prone to kidney damage. Taking a pain killer especially NSAIDs (Non steroidal anti inflammatory drugs) increases your chances of acute kidney injury and failure” said Pradeep Gadge, consultant diabetologist, Gadge’s Diabetes Centre and Visiting Consultant at Breach Candy and Sevenhills Hospital.\nKidney Failure Symptoms\nThe worst part about kidney damage is that no symptoms are seen in the initial stages. With the progress in the kidney failure, the following symptoms may be evident:\n• Pain in the back, below the rib cage\n• Vomiting and nausea\n• Swelling of hands and feet\n• Anemia, dizziness\n• Loss of appetite\n• Weight loss\nEmphasizing on the fact that not all pain killers are harmful for diabetes patients, Gadge explained diabetes patients should use those pain killers which are safer from kidney perspective.\nPrateek Saikia, diabetologist of Safdarjung (Delhi, AIMS) says, “Pain killers cause damage of the tubules in the kidneys and leads to increase in creatinine”. “The problem is not always reversible. It may lead to acute renal failure patient may need dialysis and rarely even die” she further adds.\nAccording to the WHO factsheet, India is a home to 65 million diabetic patients and the number being second only to China. According to a recent analysis by the All India Institute of Medical Sciences, it was revealed that change in lifestyle with lack of sleep were among the top reasons behind the occurrence of the disease.\n• Urine tests – Carried out to check protein levels. An abnormally high level of protein in the urine is one of the first signs of kidney failure.\n• Blood pressure – Regular checks for increased blood pressure are essential. Raised blood pressure is caused by kidney failure and also contributes to its progression.\n• Blood tests – to check the degree of kidney function.\n• Biopsy – a small tag of tissue is removed from the kidney, through a slender needle and examined in a lab. This is usually performed when there is doubt about whether kidney damage is due to diabetes or due to another cause.\n• Kidney ultrasound – this enables the size of the kidneys to be imaged and allows the arteries to the kidneys to be checked for narrowing that can cause decreased kidney function.\nPrevention of Kidney Damage\n“Diabetes patients should avoid certain antibiotics such as amikacin, especially if they already have kidney problem. Also certain antibiotics like Gatifloxacin can cause severe fluctuations in blood sugar levels and can be dangerous” said Saikia.\nSince you may not be able to avoid taking medicines under certain conditions, here are a few ways in which you can reduce damage to your kidneys:\n• Avoid self-medication\n• Avoid taking over the counter pain killers.\n• Avoid habituating yourself to particular medicines such as sleeping pills or painkillers. Instead follow a healthy lifestyle.\n• Toxicity is often related to dosage and frequency. Make sure you are not overusing drugs\n• Long-term consumption of drugs should be only under supervision\n• Drink adequate fluids to flush out the toxins\n• Avoid drinking alcohol\n• Take ample of sleep.","Tests to check kidney function in people with Diabetes\nPeople with diabetes who don’t control their blood glucose levels, may develop a chronic complication called Diabetic Nephropathy that consists in irreversible kidney damage. This may culminate in Terminal Chronic Renal Failure and those affected will require dialysis or a kidney transplantation. Fortunately, these kidney damages can be stopped or reversed if detected early, so they won’t pose health problems that may affect your quality of life. As Nephropathy doesn’t show any signs or symptoms in its early stages, it’s important for every person with Diabetes to get a full examination of their kidney function at least once a year.\nSixty percent of people who need dialysis, are people with Diabetes, being Diabetic Nephropathy the leading cause of chronic renal failure. This doesn’t have to keep on happening, because, if people with Diabetes maintain optimal control of the blood glucose levels (glycemia) and Hemoglobin A1c, this will prevent Diabetic Nephropathy and other chronic complications.\nFurthermore, if people with Diabetes get checked every year to detect their kidney function, they’ll be able to detect any kidney damage in its initial stage, being able to easily reverse the problem and maintain a good health.\nWhen you check your renal function annually, you need to include at least the following tests, in order to rule out the presence of urine protein and albumin:\n- Microalbuminuria: is a test that tells if your kidneys are functioning properly. It can detect very small amounts (traces) of protein in the urine. Normal microalbuminuria values are of 30 micrograms per milligram (mcg/mg) or less. Values above this figure are not considered normal, and your kidneys may have started damaging. At this stage Diabetic Nephropathy could be reversed with the use of a new drug known as Angiotensin II antagonists.\n- Proteinuria: this is a urine test that detects if protein levels are high which may indicate irreversible kidney damage. Normal urine protein test values are 0 to 8 mg/dl. For the 24-hour test, the normal level should be less than 150 mg/dl. When people have proteinuria, progression of this damage can be delayed with the use of Angiotensin Converting Enzyme (ACE) Inhibitors.\n- Creatinine: Creatinine is the result of the decomposition of Creatine, which is an important muscle component. Creatinine is a blood test that allows us to know how our kidney function is and its normal levels lay between 0.8 and 1.4 mg/dl. In women, these values may vary, because they usually have lower levels than men. Creatinine values of 1.4 mg/dl or more, indicate failure in renal function due to one or more of the following conditions: Diabetic Nephropathy, Eclampsia, Preeclampsia, Pyelonephritis, Muscular Dystrophy, Glomerulonephritis, Acute Tubular Necrosis, Urinary Tract Obstruction, Rhabdomyolysis, Renal Failure and Dehydration.\n- Albumin is a blood test used to detect kidney damage. Normal blood albumin values are of 3.4 to 5.4 g/dl (34 to 54g/l). Any level below this range indicates possible kidney damage.\n- BUN: The BUN test or blood urea nitrogen, substance formed when protein breaks down, can tell us how our kidneys are functioning. Normal BUN values range between 6 to 20 mg/dl. Elevated levels may indicate kidney damage.\nIf your doctor observes that any of these tests is off normal values, he needs to refer you to a Nephrologist or kidney specialist, who will perform additional evaluations which may include:\n- Glomerular filtration rate: This is a test that measures the degree of creatinine filtration by the glomeruli found in the kidneys. When the kidneys aren’t functioning properly creatinine levels rise in the blood. This test helps us figure out what the filtration degree of the glomeruli is, allowing to predict any damage even before it happens, and if it already exists, it can determine the degree of progress. Normal results vary between 90 and 120 mL/min. Levels below 60 mL/min for three or more months are a sign of chronic kidney disease. GFR results below 15 mL/min immediately indicate chronic renal failure. Older people will have below normal GFR levels because these decrease with age.\n- 24-hour urine collection: this is a test used to measure the amount of urine and substances eliminated through it, over a 24-hour period. This test can help diagnose problems such as kidney damage and Diabetes insipidus, and involves a high fluid intake and the use of diuretic medications. Normal values range between 800 and 2000 milliliters per day (with a consumption of 2 liters of liquids per day).\n- Electrophoresis analysis of urine proteins: this is a urine test that determines the amount of certain proteins such as albumin and globulins which are expelled through urine. An electrophoresis analysis of urine proteins is performed to determine the cause and amount of these proteins expelled through urine. Normal urinary albumin values lie at 5 mg/dl or less. Urinary albumin values greater than 5 mg/dl may indicate the presence of Diabetic Nephropathy or renal failure, nephrotic syndrome, acute urinary tract infection, acute inflammation, multiple myeloma and amyloidosis.\n- Creatinine Clearance: Creatinine clearance is a test that compares blood and urine creatinine levels, and estimate the glomerular filtration rate (GFR). Given that the kidney’s filter tube secretes a small amount of creatinine, this test doesn’t accurately reflect the glomerular filtration rate. Normal test values for creatinine clearance lie between 97 and 137 ml/min in men and 89 to 128 ml/min in women. Values below normal indicate acute renal failure, chronic renal failure, congestive heart failure, acute tubular necrosis, bladder outlet obstruction, glomerulonephritis, renal ischemia, dehydration and shock, among others.\nOther important tests your nephrologist may prescribe are: Phosphorus, calcium, bicarbonate, PTH and potassium blood levels, Hemoglobin, Hematocrit, Renal arteriography, Renal scintigraphy and kidney biopsy.\nSome of the signs or symptoms that may indicate Diabetic Nephropathy or kidney damage are high blood pressure, leg swelling or edema, weight gain, loss of appetite, body itching, weakness, leg cramps, nausea and vomiting. Unfortunately, these signs and symptoms usually appear when kidney damage is already irreversible, so early renal function detection through screening and testing performed yearly will allow you to address the problem when the damage can be reversed without affecting your quality of life.\nOn Diabetes Up to Date, we are committed to provide you with all of the necessary knowledge to prevent the dreaded chronic complications associated with poorly controlled Diabetes so you can enjoy a healthy, productive and happy life."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:bb6a8956-e92b-4d6a-994c-98cbb71cda31>","<urn:uuid:9769305e-cd12-4a59-9913-f05f7172af42>"],"error":null}
{"question":"How do the career progression pathways compare between Building Control Surveyors and Building Services Engineers in terms of professional qualifications and educational requirements?","answer":"Building Services Engineers can progress through three levels regulated by the Engineering Council: engineering technician (requiring GCSEs/A levels/HNC), incorporated engineer (requiring BEng), and chartered engineer (requiring MEng or BEng plus masters). For Building Control Surveyors, the pathway typically involves completing a Level 6 apprenticeship leading to a BSc (Hons) in Building Control, with entry requirements of three A-Levels or Level 3 construction apprenticeship. Upon completion, Building Control Surveyors can apply for membership of the Chartered Institute of Building (CIOB) or Institute of Fire Engineers (IFE), while Building Services Engineers typically seek recognition through CIBSE or IET.","context":["Building services engineers: job role explained\nQuick links for this article\nBuilding services engineers see that a building has more than walls and a roof. They ensure that the lighting, power, ventilation, heating, cooling, fire prevention and water systems work – put simply, this covers anything from the air con to lifts and escalators. The job involves working with mechanical and electrical systems and processes, so building services engineers can also be called electrical engineers, mechanical engineers or ‘M&E engineers’.\nBuilding services engineers can work on any type of building: one building services apprentice that TARGETcareers spoke to worked on a train station, a football stadium and a further education college in the first two years of his apprenticeship.\nThe job of a building services engineer differs according to where you work:\n- If you work for a construction or engineering consultant – who designs and plans projects – you’ll work on the technical aspects of designs.\n- If you work for a construction or engineering contractor – who builds the project – you’ll make sure that the design is implemented properly.\n- If you work for a facilities or property management company, you’ll repair and maintain the systems in an already-operational building.\nYou can learn more about what consultants and contractors do – and how they work together – in our feature on how a construction project gets built.\nIt is a good choice if…\n- You want to be at the forefront of technological development – building services engineers work with the most up-to-date ‘building services intelligence’ technology.\n- You’d like to help stop climate change – building services engineers can design and implement greener systems.\n- You like getting into the nitty gritty of design work (for roles with consultancies).\n- You’d like to get out and about rather than be in an office (for roles with contractors or facilities/property management companies).\nAs with any form of engineering, there are routes in for school leavers and graduates alike. School leavers can join an apprenticeship or school leaver training scheme and graduates a graduate programme. Some building services roles are open to those who have studied a HNC (higher national certificate) or HND (higher national diploma) at college.\nMany of the apprenticeships available in building services engineering are ‘advanced apprenticeships’, which means that you can start them either after your GCSEs or A levels. Your apprenticeship could cover all of building services engineering or it could focus on one particular service, eg air conditioning, ductworks, or heating and ventilation.\nThere are some building services engineering degree courses around, but you can also get a graduate job in building services with an electrical or mechanical engineering degree. If you want to get on a degree course or a higher apprenticeship, you’ll need to take maths and, sometimes, physics at A level (or equivalent). Other useful subjects to take at GCSE and A level include further maths, computing, chemistry and DT.\nIt’s a good idea to ensure your degree is approved by the Chartered Institute of Building Services Engineers (CIBSE) and/or The Institution of Engineering & Technology (IET).\nIf you want to reach the top of your profession quickly, your best bet is to do either a four-year MEng degree or a three-year BEng degree plus a one-year masters degree. The Engineering Council regulates the profession and has three levels of engineer:\n- engineering technician – which you can work towards on the job if you have GCSEs, A levels, an HNC/HND or BTEC/NVQ level 3 (or equivalent)\n- incorporated engineer – which you can work towards on the job if you have a BEng degree\n- chartered engineer – which you can work towards on the job if you have an MEng or a BEng degree plus a masters.\nChartership is the most senior level, at which engineers are recognised as able to take the lead on projects and on developing solutions. They tend to receive the highest salaries.\nYou can start out as a technician and work your way up to incorporated and chartered status (either by gaining an appropriate level of in-the-workplace experience or by studying for a relevant academic qualification with your employer’s support). For this reason, an apprenticeship can lead to either technician or incorporated status. But the quickest way to climb the career ladder is to study for an MEng.","Providing an impartial, independent and accountable third party service to confirm that building work achieves compliance with minimum standards\nBuilding Control Surveyors provide an impartial, independent and accountable third party service certificating that building work achieves compliance with minimum standards, namely those set out in the Building Regulations. Building Control differs from other surveying roles in that Surveyors perform what is essentially an enforcement function, ensuring compliance through the Building Act 1984. In addition to construction technology, a Building Control Surveyor requires a full working knowledge of Building Regulations and associated legislation in force at the time work has been carried out in relation to areas such as structural, thermal, fire, acoustics, ventilation and inclusive design. Building Control Surveyors must be excellent communicators as this is a highly customer-facing role, requiring diplomacy and assertiveness, remaining impartial using the powers conferred on them to prosecute if necessary to protect the health and safety of people, and the wider environment.\nThe main duties and tasks of a Building Control Surveyor involve:\nBuilding Control Surveyors may also be known as: Building Control Officer; Building Control Inspector; Building Control Consultant; Building Control Assistant; Building Control Advisor.\nBuilding Control Surveyors may be contracted or employed by local authorities, private employers, and Approved Inspectors in the capacity of enforcing the Building Act and Regulations. Building Control Surveyors typically work as part of a team including technical support administrators and other surveyors of varying expertise and experience usually reporting to a building control manager. Teams can vary in size dependant on location and workload.\nA successful apprentice will have met the requirements in terms of knowledge and skills and all the behaviour requirements.\n|KNOWLEDGE||What is required - In the context of building control:|\n|1. Legislation||Demonstrate a robust knowledge of the requirements contained within the Building Act, Statutory Framework and other associated legislation related to Building Regulations.|\n|2. Data Management||In-depth knowledge of accurate application of Regulatory processes within the constraints of timescale, data management and confidentiality, in-line with data protection laws.|\n|3. Building regulations approval||Interpret the Building Regulations in relation to all types of building work covering areas such as structural design, means of escape, active and passive fire protection, ventilation, thermal efficiency and access provisions.|\n|4. Health and safety||Describe the principles and responsibilities imposed by Health and Safety law, codes of practice and other regulations in fulfilling the building control function.|\n|5. Sustainability and Accessibility||Understand how the Building Regulations places a requirement in relation to sustainability and accessibility to achieve environmental and social objectives.|\n|6. Construction Technology||Knowledge of building pathology and construction technology used in buildings including the performance criteria of materials.|\n|7. Finance||Knowledge of the Charges Regulations and its relevance to service delivery.|\n|8. Enforcement||Knowledge of the enforcement framework and powers within the Building Act to achieve compliance with the Building Regulations.|\n|9. Non-Statutory duties||Knowledge of non-statutory duties carried out by Local Authority Building Control teams as a delegated function of their Authority e.g. dangerous structures, demolitions.|\n|10. People management||Knowledge of the dynamics of the design team to be able to offer support and guidance where required.|\n|11. Specialist functions||Knowledge of specialist functions of building control e.g. Fire Engineering, Access Officer, Acoustic Engineer, Thermal Engineer.|\n|12. Consultation||Knowledge of why consultation is required with other local authority functions and external statutory bodies and organisations.|\n|13. Marketing||Awareness of how to promote the building control service through effective marketing.|\n|SKILLS||What is required - In the context of building control:|\n|1. Legislation||Apply the principles contained within the Building Act, Statutory Framework and other associated legislation related to Building Regulations.|\n|2. Data management||Undertake the administrative process of a Building Regulation application and use the data to ensure performance standards are met in compliance with relevant quality assurance standards.|\n|3. Building regulations approval||Utilise the Building Regulations to evaluate plans, drawings, specifications and other documents submitted for building regulation approval for all types of building work to ensure appropriate decisions are issued on applications.|\n|4. Health and safety||Identify and manage risks of health, safety and welfare in-line with legislation, hazards and safe systems of work.|\n|5. Sustainability and Accessibility||Advise on the Building Regulation requirement in relation to sustainability and accessibility to achieve environmental and social objectives.|\n|6. Construction technology||Utilise knowledge of construction technology to provide advice and guidance in connection with the design or construction of building projects.|\n|7. Finance||Calculate charges for the building control function.|\n|8. Information Technology Skills||Utilise proficient Information Technology (IT) skills and have a good knowledge of relevant technologies, including Building information modelling (BIM).|\n|9. Site Inspections||Inspect building work in progress as may be necessary to ensure compliance with the Building Regulations.|\n|10. Building Control Best Practice||Uphold high technical standards and best practice in building control in all aspects of building regulation compliance and its application to construction types and methods.|\n|11. Communication skills||Communicate effectively and appropriately - both verbally and in writing - with people at all levels to achieve a compliant outcome.|\n|12. Personal and Professional effectiveness||Manage own time and tasks, communicate and negotiate effectively within a commercial environment.|\n|13. Diplomacy||Applies diplomacy, tact and persuasive skills when dealing with difficult situations while remaining impartial.|\n|BEHAVIOURS||What is required - In the context of building control:|\n|1. Provide a high standard of service||Always ensure your client, or others to whom you have a professional responsibility, receive the best possible advice, support or performance of the terms of engagement you have agreed to and ensure you always give attention to detail.|\n|2. Act in a way that promotes trust in the profession||Demonstrate a personal commitment to professional and ethical standards, recognising one’s obligations to society and the profession.|\n|3. Act with integrity||\nAlways be trustworthy, open, transparent and challenge where necessary.\nRespect confidential information of your clients or potential clients and do not allow bias, conflict of interest or the undue influence of others to override your professional or business judgments or obligations.Always act consistently in the public interest when making decisions or providing advice.\n|4. Treat others with respect||Treat everyone with courtesy, politeness and respect.|\n|5. Take responsibility||Always act with skill, care and diligence and deal with any complaint in an appropriate professional manner.|\n|6. Adaptability and Resilience||Be open to the changing environment of the workplace and regulatory framework.|\nThe entry requirement for the apprenticeship will typically be a minimum of three A-Levels at Grade C or higher or a Level 3 apprenticeship in a construction or property related discipline, but the final decision is that of each employer.\nApprentices without level 2 English and maths will be required to achieve this prior to taking the end-point assessment. For those with an education, health and care plan or a legacy statement the apprenticeships English and Maths minimum requirement is Entry Level 3 and British Sign Language qualification are an alternative to English qualifications for whom this is their primary language.\nUpon completion of the apprenticeship, the apprentice will gain a BSc (Hons) degree in Building Control.\nSuccessful apprentices will be eligible to apply for membership of the Chartered Institute of Building (CIOB) and / or the Institute of Fire Engineers (IFE) having met the academic requirements for membership. Apprentices will also need to meet any additional requirements set out by the CIOB and / or the IFE as part of their membership application processes at the time.\nTypically 4 years.\nThis is a Level 6 apprenticeship standard.\nThe apprenticeship standard will be reviewed after three years\nCrown copyright © 2020. You may re-use this information (not including logos) free of charge in any format or medium, under the terms of the Open Government Licence. Visit www.nationalarchives.gov.uk/doc/open-government-licence\n|Version||Change detail||Earliest start date||Latest start date||Latest end date|\n|1.0||02/05/2019||Not set||Not set|"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:727797bf-f94c-4c20-9196-8f485e33d248>","<urn:uuid:608bbd96-53c9-4c41-82a5-272fee984a9e>"],"error":null}
{"question":"What are the nutritional values per 100g of Emmentaler AOP cheese?","answer":"Per 100g, Emmentaler AOP contains 36g of water, 29g of protein, 31g of fat, 4g of minerals, and provides 395 kcal (1640 kJ).","context":["Gentle lush alpine meadows, idyllic villages, farmhouses tucked in under vast sloping roofs, and sedate richly decorated farmyards characterise the delightful charm of the landscape that produces this great cheese. Each wheel is fashioned in keeping with the artisanal tradition observed in village cheese dairies for centuries. Its tradition, appearance and outstanding quality make Emmentaler AOP the undisputed ‘king of cheeses’ worldwide.\nEmmental (valley of the Emme river in the Canton of Bern)\nProtection of origin:\nAOP Appellation d’Origine Protégée (protected designation of origin) since 2006\nArea of production:\nCantons Aargau, Bern, Glarus, Lucerne, Schwyz, Solothurn, St. Gallen, Thurgau, Zug, Zurich, and parts of Canton Fribourg\nFresh unpasteurised milk from dairy cows left to graze naturally (no silage). The use of any form of additives or genetically modified ingredients is strictly forbidden.\nShape, size, weight:\nRound, flat to slightly convex wheel, 80–100 cm in diameter, 16–27 cm in height, 75–120 kg in weight (average: 95 kg)\nThe characteristic holes are formed as the cheese matures. The natural fermentation produces carbon dioxide which gathers in different places within the cheese and is unable to escape. For a hard cheese, the salt content at 0.5 g / 100 g is extremely low. Emmentaler AOP is lactose-free.\nMinimum 45% fat in dry matter, solid fat\nNaturally matured, firm, golden yellow, branded on one side with the red cheese dairy mark of Emmentaler Switzerland. As it ages the rind becomes dark brown to black in the case of cave-aged Emmentaler AOP, and acquires a patina.\nIvory to light yellow\nSmooth, easy to slice, then fine and crumbly with increasing maturity\nCherry-sized, mostly 2-4 cm in size\nCave-aged: at least 12 months*\n* of which at least 6 months in a natural stone or rock cellar\nAverage nutritional values per 100 g:\nWater 36 g\nProtein 29 g\nFat 31 g\nMinerals 4 g\nCalories 395 kcal\nJoules 1640 kJ\nThe dairyman needs around 1,200 litres of natural unpasteurised milk, rennet, bacteria cultures and plenty of expertise, devotion, and time to make a wheel of cheese weighing around 95 kg. Emmentaler AOP is absolutely free of any additives or genetically modified organisms. It owes its distinctive taste to the milk produced by dairy cows left to graze naturally, traditional processing methods, and the use of propionic bacteria cultures. After the brine bath the cheese is left to mature first in a warm maturation cellar, where the characteristic holes in Emmentaler cheese are formed. The maturation process then takes place in a cool storage cellar.\nThe patented dairy mark is applied to the side of the wheel already at the production stage, allowing this tamper-proof mark to blend permanently with the rind. Each wheel is branded with a radial Emmentaler AOP pattern, along with the operating number of the village cheese dairy. This comprehensive marking means that Emmentaler AOP is easily identified as an original, even when cut and pre-packed, and unambiguously differentiated from any counterfeit cheeses or imitations. Indeed, only Swiss Emmentaler AOP comes from controlled production and satisfies the stringent quality requirements of the trade organisation.\nEmmentaler AOP is tended to in the area in which it was produced for a period of at least four months. With its smooth even rind, its ivory consistency, its cherry-sized holes, and its distinctive nutty and tangy flavour, Emmentaler AOP is a genuine piece of Swiss nature and culture. It is highly prized by cheese connoisseurs as a delicacy capable of enhancing any cheese platter and complementing a full breakfast, but also as the perfect way to round off dinner. It’s also a tasty basic ingredient used in a variety of hot dishes.\nWith eight different varieties, Emmentaler AOP has something to tickle the taste buds of any cheese enthusiast. Depending on the type of maturation and the maturing time, the range covers the full spectrum of flavours, from nutty and mild to tangy and spicy.\nEmmentaler AOP retails as mild once it has aged for a minimum of four months, as mature after eight months, and as full-flavoured after twelve months. With the exception of the cave-aged Emmentaler, all Emmentaler AOP is stored and nurtured in dry cheese cellars. The cave-aged Emmentaler AOP is stored for a minimum of twelve months, six of which are inside a rock cellar. The longer an Emmentaler AOP is left to mature, the stronger its flavour and the darker its rind.\nEmmentaler AOP is highly prized by cheese connoisseurs as a delicacy capable of enhancing any cheese platter and complementing a full breakfast, but also as the perfect way to round off dinner. It’s also a tasty basic ingredient used in a variety of hot dishes."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:b991c830-68a4-45e7-8996-c5e7a1435bd0>"],"error":null}
{"question":"What are the key characteristics of Angelman syndrome from a clinical perspective, and what specific learning disabilities are commonly associated with it?","answer":"Angelman syndrome is characterized by severe learning difficulties, distinctive facial features, awkward gait, and jerky arm movements. From a clinical perspective, it involves mental retardation, absence of speech, seizures, and motor dysfunction. It is caused by various genetic mechanisms including maternal deletions of chromosome 15q11-q13, paternal uniparental disomy, imprinting defects, or UBE3A mutations. Regarding learning disabilities, these patients typically show impairments in multiple areas including auditory and visual perception, memory processing, language output, and motor skills. They may have difficulty with sequencing, organizing information, and both fine and gross motor coordination.","context":["This disorder is a rare genetic/neuro-developmental disorder, initially described by Angelman (1965), characterised by severe learning difficulty, particular facial appearance, and an awkward gait plus 'jerky' arm movements.\nASF's mission is to advance the awareness and treatment of Angelman Syndrome through education, information exchange and research.\nThe aim was to explore the comorbidity between Angelman syndrome and autism spectrum disorders (ASDs). Identification of autism in children with Angelman syndrome presents a diagnostic challenge. In the present study, 16 children with Angelman syndrome, all with a 15q11-13 deletion, were examined for ASDs. Thirteen children with Angelman syndrome received an ADOS-G algorithm classification of ASD; the remaining three were outside the autistic spectrum. Ten fulfilled the criteria for autism, and three for PDD-NOS. The 10 children with Angelman syndrome and comorbid autism were compared with eight children with only autism regarding their social and communicative skills. The results indicated that Angelman syndrome is better understood in terms of developmental delay, and autism in terms of developmental deviance. It is concluded that autism might have been overdiagnosed due to the extremely low mental age of the children with Angelman syndrome.\nChildren with comorbid autism and AS scored lower on measures of language, adaptive behavior, and cognition, and demonstrated a slower rate of improvement over the course of the study. Furthermore, they demonstrated deficits in communication and socialization that mirror those observed in children with idiopathic autism. The study highlights the phenotypic overlap between autism and AS and increases the probability that dysregulation of UBE3A may play a role in the causation of autism.\nWe describe here a 15q11–q13 genomic inversion in mothers of AS BP2/3-deleted patients and in 9% of subjects of the general population. Since BP2 and BP3 segmental duplications are usually in a tail-to-tail orientation (10,11), the inverted chromosomes are likely to arise by non-homologous recombination events between the high sequence identity of these segmental duplications.\nMaternal duplications of the imprinted 15q11-13 domain result in an estimated 1%ndash2% of autism-spectrum disorders, and linkage to autism has been identified within 15q12-13. UBE3A, the Angelman syndrome gene, has, to date, been the only maternally expressed, imprinted gene identified within this region, but mutations have not been found in autistic patients. Here we describe the characterization of ATP10C, a new human imprinted gene, which encodes a putative protein homologous to the mouse aminophospholipid-transporting ATPase Atp10c. ATP10C maps within 200 kb distal to UBE3A and, like UBE3A, also demonstrates imprinted, preferential maternal expression in human brain. The location and imprinted expression of ATP10C thus make it a candidate for chromosome 15ndashassociated autism and suggest that it may contribute to the Angelman syndrome phenotype.\nThe most common etiology for Prader-Willi syndrome and Angelman syndrome is de novo interstitial deletion of chromosome 15q11-q13. Deletions and other recurrent rearrangements of this region involve four common `hotspots' for breakage, termed breakpoints 1-4 (BP1-BP4). Construction of an ~4 Mb YAC contig of this region identified multiple sequence tagged sites (STSs) present at both BP2 and BP3, suggestive of a genomic duplication event. Interphase FISH studies demonstrated three to five copies on 15q11-q13, one copy on 16p11.1-p11.2 and one copy on 15q24 in normal controls, while analysis on two Class I deletion patients showed loss of approximately three signals at 15q11-q13 on one homolog. Multiple FISH signals were also observed at regions orthologous to both human chromosomes 15 and 16 in non-human primates, including Old World monkeys, suggesting that duplication of this region may have occurred ~20 million years ago. A BAC/PAC contig for the duplicated genomic segment (duplicon) demonstrated a size of ~400 kb. Surprisingly, the duplicon was found to contain at least seven different expressed sequence tags representing multiple genes/pseudogenes. Sequence comparison of STSs amplified from YAC clones uniquely mapped to BP2 or BP3 showed two different copies of the duplicon within BP3, while BP2 comprised a single copy. The orientation of BP2 and BP3 are inverted relative to each other, whereas the two copies within BP3 are in tandem. The presence of large duplicated segments on chromosome 15q11-q13 provides a mechanism for homologous unequal recombination events that may mediate the frequent rearrangements observed for this chromosome.\nRett syndrome (RTT) is a neurodevelopmental disorder caused by mutations in MECP2, encoding methyl-CpG-binding protein 2 (MeCP2). Brain samples from several related neurodevelopmental disorders, including autism, pervasive developmental disorder, Prader-Willi and Angelman syndromes showed significant differences in MeCP2 expression from age-matched controls by apparently different transcriptional and post-transcriptional mechanisms. These results suggest that multiple pathways regulate the complex developmental expression of MeCP2 and are defective in autism-spectrum disorders in addition to RTT.\nThe syndrome was first recognized in 1965, when English physician Harry Angelman described peculiar behavioral abnormalities in three patients and hypothesized that the cases were linked to a single but as-yet unnamed disease. The children with their flapping arms and laughter reminded Angelman of an oil painting by Gian Francesco Caroto, \"Boy With a Puppet.\"\nAngelman syndrome (AS) is characterized by mental retardation, absence of speech, seizures and motor dysfunction. AS is caused by maternal deletions for chromosome 15q11-q13, paternal uniparental disomy (UPD), imprinting defects or loss-of-function mutations in the UBE3A locus which encodes E6-AP ubiquitin-protein ligase. The UBE3A gene is imprinted with paternal silencing in human brain and similar silencing of the Ube3a locus in Purkinje cells and hippocampal neurons in the mouse. We have sequenced the major coding exons for UBE3A in 56 index patients with a clinical diagnosis of AS and a normal DNA methylation pattern. The analysis identified disease-causing mutations in 17 of 56 patients (30%) including 13 truncating mutations, two missense mutations, one single amino acid deletion and one stop codon mutation predicting an elongated protein. Mutations were identified in six of eight families (75%) with more than one affected case, and in 11 of 47 isolated cases (23%); no mutation was found in one family with two siblings, one with a typical and one with an atypical phenotype. Mutations were de novo in nine of the 11 isolated cases. An amino acid polymorphism of threonine substituted for alanine at codon 178 was identified, and a 3 bp length polymorphism was found in the intron upstream of exon 8. In all informative cases, phenotypic expression was consistent with imprinting with a normal phenotype when a mutation was on the paternal chromosome and an AS phenotype when a mutation was on the maternal chromosome. Laboratory diagnosis and genetic counseling for AS are complex, and mutation analysis is valuable in clinically typical AS patients with a normal methylation analysis.\nPrader-Willi syndrome (PWS) and Angelman syndrome (AS) are two distinct neurological disorders that map to human chromosome 15q11-q13 and involve perturbations of imprinted gene expression. PWS is caused by a deficiency of paternal gene expression and AS is caused by a deficiency of maternal gene expression. Experiments in the last year have focused on molecular analysis of the human chromosomal region as well as the homologous region on central mouse chromosome 7. New transcripts and exons have been identified and the epigenetic status of the PWS/AS region in mice and humans has been examined. The imprinting center that is hypothesized to control the switch between the maternal and paternal epigenotypes has also been characterized in greater detail and a mouse model that deletes the homologous element demonstrates a conservation in imprinting center function between mice and humans. In addition, analysis of non-deletion AS patients has revealed that UBE3A intragenic mutations are found in a significant number of cases. However, both human patients and mouse model systems indicate that other genes may also contribute to the AS phenotype. Thus, although much has been learned in the last year, considerable information is still required before these complex syndromes are fully understood.\nOpinions expressed by the authors of pages to which this site links do not necessarily reflect this site developer's opinions.\nIn other words: Sublime or ridiculous? You decide!\nCopyright © 2004-2008, Kathleen Seidel. All rights reserved.\nThis page was last updated on 5 November 2008, 3:48 pm\nHosted by TextDrive","Specific learning disability means a disorder in one or more of the basic psychological processes involved in understanding or in using language, spoken or written, which may manifest itself in an imperfect ability to listen, think, speak, read, write, spell, or to do mathematical calculations. The term includes such conditions as perceptual handicaps, brain injury, minimal brain dysfunction, dyslexia, and developmental aphasia. The term does not include children who have problems that are primarily the result of visual, hearing, or motor disabilities, or mental retardation, emotional disturbance, or of environmental, cultural, or economic disadvantage.\nThe types of LD are identified by the specific processing problem. They might relate to getting information into the brain (Input), making sense of this information (Organization), storing and later retrieving this information (Memory), or getting this information back out (Output). Thus, the specific types of processing problems that result in LD might be in one or more of these four areas.\nInformation is primarily brought into the brain through the eyes (visual perception) and ears (auditory perception). An individual might have difficulty in one or both areas.\nAuditory Perception. (Also called Receptive Language) The individual might have difficulty distinguishing subtle differences in sound (called phonemes) or might have difficulty distinguishing individual phonemes as quickly as normal. Either problem can result in difficulty processing and understanding what is said. Individuals might have difficulty with what is called auditory figure-ground. They have difficulty identifying what sound(s) to listen to when there is more than one sound.\nVisual Perception. One might have difficulty distinguishing subtle differences in shapes (called graphemes). They might rotate or reverse letters or numbers (d, b, p, q, 6, 9); thus misreading the symbol. Some might have a figure-ground problem, confusing what figure(s) to focus on from the page covered with many words and lines. They might skip words, skip lines, or read the same line twice. Others might have difficulty blending information from both eyes to have depth perception. They might misjudge depth or distance, bumping into things or having difficulty with tasks where this information is needed to tell the hands or body what to do. If there is difficulty with visual perception, there could be problems with tasks that require eye-hand coordination (visual motor skills) such as catching a ball, doing a puzzle, or picking up a glass.\nOnce information is recorded in the brain (input), three tasks must be carried out in order to make sense or integrate this information. First, the information must be placed in the right order or sequenced. Then, the information must be understood beyond the literal meaning, abstraction. Finally, each unit of information must be integrated into complete thoughts or concepts, organization.\nSequencing. The individual might have difficulty learning information in the proper sequence. Thus, he might get math sequences wrong, have difficulty remembering sequences such as the months of the year, the alphabet, or the times table. Or, she might write a report with all of the important facts but not in the proper order.\nAbstraction. A person might have difficulty inferring the meaning of individual words or concepts. Jokes, idioms, or puns are often not understood. He might have problems with words that might have different meanings depending on how they are used. For example, \"the dog\" refers to a pet. \"You dog\" is an insult.\nOrganization. An individual might have difficulty organizing materials, losing, forgetting, or misplacing papers, notebooks, or homework assignments. She might have difficulty organizing her environment, such as her bedroom. Some might have problems organizing time. They have difficulty with projects due at a certain time or with being on time. (Organization over time is referred to as Executive Function.)\nThree types of memory are important to learning. \"Working memory\" refers to the ability to hold on to pieces of information until the pieces blend into a full thought or concept. For example, reading each word until the end of a sentence or paragraph and then understanding the full content. \"Short-term memory\" is the active process of storing and retaining information for a limited period of time. The information is temporarily available but not yet stored for long-term retention. \"Long-term memory\" refers to information that has been stored and that is available over a long period of time. Individuals might have difficulty with auditory memory or visual memory.\nOne reads a sentence and hold on to it. Then the next and the next. By the end of the paragraph, he pulls together the meaning of the full paragraph. This is working memory. He continues to read the full chapter and study it. Information is retained long enough to take a test and do well. This is short-term memory. But, unless the information is reviewed and studied over a longer period of time, it is not retained. With more effort over time, the information might become part of a general body of knowledge. It is long-term memory.\nInformation is communicated by means of words (language output) or though muscle activity such as writing, drawing, gesturing (motor output). An individual might have a language disability (also called expressive language disability) or a motor disability.\nLanguage Disability. It is possible to think of language output as being spontaneous or on demand. Spontaneous means that the person initiates the conversation. Thoughts have been organized and words found before speaking. Demand language means that one is asked a question or asked to explain something. Now, she must organize his thoughts, find the right words, and speak at the same time. Most people with a language disability have little difficulty with spontaneous language. However, in a demand situation, the same person might struggle to organize her thoughts or to find the right words.\nMotor Disability. One might have difficulty coordinating teams of small muscles, called a fine motor disability. He might have problems with coloring, cutting, writing, buttoning, or tying shoes. Others might have difficulty coordinating teams of large muscles, called a gross motor disability. She is awkward when running or jumping.\nEach individual will have his or her unique pattern of LD. This pattern might cluster around specific common difficulties. For example, the pattern might primarily reflect a problem with language processing: auditory perception, auditory sequencing/abstraction/organization, auditory memory, and a language disability. Or the problem might be more in the visual input to motor output areas. Some people with LD will have a mixture of both.\nSymptoms of Learning Disabilities\nThe symptoms of learning disabilities are a diverse set of characteristics which affect development and achievement. Some of these symptoms can be found in all children at some time during their development. However, a person with learning disabilities has a cluster of these symptoms which do not disappear as s/he grows older.\nMost frequently displayed symptoms:\n- Short attention span\n- Poor memory\n- Difficulty following directions\n- Inability to discriminate between/among letters, numerals, or sounds\n- Poor reading and/or writing ability\n- Eye-hand coordination problems; poorly coordinated\n- Difficulties with sequencing\n- Disorganization and other sensory difficulties\nOther characteristics that may be present:\n- Performs differently from day to day\n- Responds inappropriately in many instances· Distractible, restless, impulsive\n- Says one thing, means another\n- Difficult to discipline\n- Doesn't adjust well to change\n- Difficulty listening and remembering\n- Difficulty telling time and knowing right from left\n- Difficulty sounding out words\n- Reverses letters\n- Places letters in incorrect sequence\n- Difficulty understanding words or concepts\n- Delayed speech development; immature speech"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:af5c9b8e-d5ba-4921-b18f-fa7479c8611a>","<urn:uuid:e1b7bc04-72bd-406b-9644-d678fa782a79>"],"error":null}
{"question":"How do the vitamin C requirements differ between a breastfeeding woman maintaining a strawberry garden and a regular adult male gardener?","answer":"A breastfeeding woman requires 120mg of vitamin C daily, while an adult male requires 90mg of vitamin C daily. Both could meet their requirements through strawberry consumption, as strawberries are high in Vitamin C and one cup of berries can supply a daily requirement. The difference in their needs (30mg) exists because breastfeeding increases vitamin C requirements.","context":["Strawberries are a great fruit choice for a home garden. They are easy to plant and care for, and a well-taken care of patch will continue to produce bright, red strawberries for years to come. Strawberries are very high in Vitamin C, and can supply a daily requirement of this vitamin with only one cup of berries. Strawberries can be eaten directly from the garden, or used in pies, ice cream, smoothies and many other yummy treats! If you have an excess of berries they can be frozen very easily for future use!\nSelecting your strawberry cultivar is very important. There are two main types of strawberries, early-season or June-bearing cultivars and ever-bearing cultivars. The early season plants will produce a crop in June while the ever-bearing varieties will begin production in late June and continue producing fruit through out the summer. The ever-bearing varieties will require more maintenance and probably irrigation during the summer. Ogallala and Ozark Beauty are two great choices in ever-bearing varieties. Ever-bearing varieties will yield better under cool periods throughout the season. Some good choices for early-season cultivars include Sunrise and Earliglow. Be sure to buy your plants from a reputable nursery and that they will guarantee they are virus-free.\nStrawberries should be planted in early spring, ideally in April. Plants should be set in the garden as soon as you purchase them. If you cannot plant the same day, you should place them in a dark room and pack moist packing material around the roots. You need to make sure that the roots will not dry out, as that will cause the plant to die.\nThe site you select for your strawberry patch is also important. Strawberries need dry conditions, so an area with a slight slope is ideal. The plants will bloom early in the spring, so you may want to choose an area that has an added frost protection. If the blooms freeze, the plants will not bear fruit. Do not plant strawberries on a south facing slope as the warm sun will trick the plants into thinking the weather is warmer and they will set out their blooms only to be attacked by frost.\nA sandy or loamy soil is best for strawberries. If strawberries are planted in a hard, clay like soil, the plants will suffer from fruit rot. Try to stay far away from trees and do not plant near tomatoes, potatoes or peppers. Those vegetables are attacked by the same bugs, so you will want to avoid placing them close together. Fertilize the soil with about 10 pounds of 10-10-10 fertilizer and work it into the top 6 inches of soil. Strawberries like a pH level between 6.5 and 7.5.\nThe first year you plant your strawberries you will want to pick all the blooms off so that the plant does not bear fruit. This allows the roots to grow and develop a strong root system. Cultivate the bed often to prevent weed growth and mulch the rows between the plants. After the first year, you can allow your plants to flower and bear fruit. It is very important to keep weeds under control by weeding the patch often.\nAfter the growing season is complete for the year you will want to trim or prune the plants. To do this you can mow off the plants to about one inch of height. This will prevent the patch from becoming overgrown and crowded out. The trimming should be done immediately after fruit production is complete. You don’t want to wait long because new leaves will grow up, and you want to allow them to grow.\nWinter mulching is very important to protect your strawberry plants. Low winter temperatures may kill the fruit buds as well as the roots and crowns of the plants. When the temperature drops to below 20 F you will want to cover the plants with a heavy layer of mulch. Straw and chopped cornstalks make excellent mulching materials. 4 inches of straw is needed to protect the plants adequately. Remove the mulch in the spring as soon as you see signs of growth. Remove the mulch little by little so that the plants do not suffer from the shock of the cooler temperatures. If there is a threat of frost, you can place the mulch back over the plants for a short amount of time.\nOnce you have planted the strawberries, you will need to maintain the patch year after year for optimum production. Rotating the crops and setting out new plants through out the patch will assure new growth and healthy roots. Try planting a small patch and see how delicious your berries are!","Vitamin C is an antioxidant present in many fruits and vegetables. Also known as L-ascorbic acid, vitamin C has a wide variety of uses in the body. It supports normal growth and development and helps the body repair damaged tissue.[2, 3] Vitamin C also assists in the production of collagen, a protein that’s necessary for healthy skin, cartilage, tendons, ligaments, and blood vessels.\nTo say that vitamin C is beneficial would be an understatement. It influences iron absorption and helps fight cell-damaging free radicals. A 16-year study found that regular vitamin C supplementation promoted heart health. Additionally, people who consume foods rich in vitamin C or other antioxidants may lower their risk of high blood pressure.[7, 8, 9]\nHigh Doses of Vitamin C\nIn the 1970s, chemist and Nobel Peace laureate, Linus Pauling, proposed that high doses of vitamin C could help prevent the common cold. Many people swear by Pauling's claim that vitamin C can boost the immune system naturally, but the research is still inconclusive.\nA number of studies have examined whether high-dose vitamin C can provide extraordinary therapeutic results. Results thus far are inconclusive. However, animal studies have found that vitamin C may make traditional therapies more effective.\nNatural Dietary Sources of Vitamin C\nMany types of food are fortified with vitamins and vitamin C is usually in the mix. However, like all vitamins, it’s best to get your daily intake from organic, natural sources and the best, natural sources of vitamin C are fruits and vegetables. Below are some of the best foods for vitamin C.\n|Sources of Vitamin C|\n|Food and Serving Size||Vitamin C (mg/serving)|\n|Red or Yellow Bell Pepper, Raw, 1/2 cup||95|\n|Orange Juice, 3/4 cup||93|\n|Orange, 1 medium||70|\n|Grapefruit Juice, 3/4 cup||70|\n|Kiwifruit, 1 medium||64|\n|Green Bell Pepper, raw, 1/2 cup||60|\n|Broccoli, cooked, 1/2 cup||51|\n|Strawberries, fresh, sliced 1/2 cup||49|\n|Brussels sprouts, cooked, ½ cup||48|\n|Grapefruit, ½ medium||39|\n|Broccoli, raw, ½ cup||39|\n|Tomato juice, ¾ cup||33|\n|Cantaloupe, ½ cup||29|\n|Cabbage, cooked, ½ cup||28|\n|Cauliflower, raw, ½ cup||26|\n|1 Lemon Yield, 48g||18.6|\n|Potato, baked, 1 medium||17|\n|Tomato, raw, 1 Medium||17|\n|Spinach, cooked, 1/2 cup||9|\n|Green peas, frozen, cooked, 1/2 cup||8|\nDaily Intake of Vitamin C\nThe amount of vitamin C that a person needs may vary with factors like age or whether a person is smoking, pregnant, or even breastfeeding. These are the guidelines provided by the U.S. Office of Dietary Supplements:\n|Recommended Daily Allowances of Vitamin C|\n|Age||Female||Male||Pregnant female||Breastfeeding female|\n|0-6 months||40 mg||40 mg||N/A||N/A|\n|7-12 months||50 mg||50 mg||N/A||N/A|\n|1-3 years||15 mg||15 mg||N/A||N/A|\n|4-8 years||25 mg||25 mg||N/A||N/A|\n|9-13 years||45 mg||45 mg||N/A||N/A|\n|14-18 years||65 mg||75 mg||80 mg||115 mg|\n|19+ years||75 mg||90 mg||85 mg||120 mg|\nDangers of Vitamin C Deficiency\nA lot of people might think “scurvy” is just pirate lingo, but it’s actually a disease caused by a lack of vitamin C. Symptoms of scurvy include fatigue, gum disease, anemia, scaly skin, and easy bruising. Vitamin C deficiency is uncommon in the United States these days but some people remain at risk.\nPeople who get too little variety in their food may not receive adequate nutrition. Normally, when we hear \"malnourished\" many of us think \"starving\", but what it's more likely to mean is that a person is deficient in specific nutrients and it's affecting their health. Those who rely on a carnivorous diet might miss their daily quota for vitamin C as meat and dairy don’t contain much of this critical nutrient. Infants fed evaporated or boiled cow's milk may not get enough vitamin C, especially since cow’s milk is low in vitamin C to begin with. Breast milk and infant formula are both better sources of vitamin C.\nSome medical conditions can cause vitamin C deficiency. Digestive tract injuries or inefficiencies, genetic diseases, and other issues can negatively affect not just vitamin C absorption, but nutrient absorption as a whole. Kidney disease and some types of cancer can also cause vitamin C deficiency.\nSmoking cigarettes is a bad idea for many reasons. One of the effects of the tissue damage it causes is the body using up vitamin C at a faster rate than normal. As a result, smokers and people exposed to second-hand smoke may need an extra 35 mg of vitamin C a day.\nVitamin C Supplementation\nUsually, if you follow a balanced diet with a foundation of organic fruits and vegetables, you’ll get all the vitamin C you need. If you don’t, vitamin C supplementation might be something to consider and discuss with your healthcare provider.\nBe aware of the difference between synthetic and natural vitamins. Synthetic supplements are manufactured with unnatural ingredients and chemicals. They are made to mimic natural vitamins but not everyone is convinced of their efficacy. Conversely, natural supplements are made using ingredients drawn straight from their natural sources.\nVitamin C supplements are usually available as ascorbic acid, sodium ascorbate, or calcium ascorbate. Synthetic and natural ascorbic acid have similar properties, but I always recommend a natural, plant-based source.[15, 16]\nIf your diet isn’t providing you with enough vitamin C, you should consider that it's not providing you with all the other nutrients your body requires, either. In such a case, you may want to skip the vitamin C supplement and look for a solid multivitamin. I recommend IntraMAX® and believe, without a doubt, that it’s the best multivitamin available anywhere. It’s an organic, liquid formula loaded with all the nutrients you need, as well as powerful antioxidant and immune system stimulators. It's as complete as it gets.\nWhere do you get your vitamin C? Supplements? A cold glass of orange juice? Let us know in the comments.\n- \"Vitamin C.\" MedlinePlus. U.S. National Library of Medicine, 9 Mar. 2016. Web. 11 Mar. 2016.\n- Zeratsky, Katherine, R.D., L.D. \"Too Much Vitamin C: Is It Harmful?\" MayoClinic.org. Mayo Clinic, 5 Feb. 2015. Web. 11 Mar. 2016.\n- \"Wounds.\" University of Maryland Medical Center. University of Maryland, 5 Jan. 2015. Web. 11 Mar. 2016.\n- Boyera, N., Galey , I. and Bernard, B.A. (1998), Effect of vitamin C and its derivatives on collagen synthesis and cross-linking by normal human fibroblasts. International Journal of Cosmetic Science, 20: 151–158. doi: 10.1046/j.1467-2494.1998.171747.x.\n- Lynch, S. R. and Cook, J. D. (1980), INTERACTION OF VITAMIN C AND IRON. Annals of the New York Academy of Sciences, 355: 32–44. doi: 10.1111/j.1749-6632.1980.tb21325.x.\n- Osganian, S.k., M.j. Stampfer, E. Rimm, and D. Spiegelman. \"Vitamin C and Risk of Coronary Heart Disease in Women.\" ACC Current Journal Review 12.5 (2003): 27. PubMed. Web.\n- \"Vitamin C (Ascorbic Acid).\" University of Maryland Medical Center. University of Maryland, 16 July 2013. Web. 11 Mar. 2016.\n- Juraschek, Stephen P et al. “Effects of Vitamin C Supplementation on Blood Pressure: A Meta-Analysis of Randomized Controlled Trials.” The American Journal of Clinical Nutrition 95.5 (2012): 1079–1088. PMC. Web. 11 Mar. 2016.\n- Ness, A. R., D. Chee, and P. Elliott. \"Vitamin C and Blood Pressure–an Overview.\" J Hum Hypertens Journal of Human Hypertension 11.6 (1997): 343-50. PubMed. Web. 11 Mar. 2016.\n- \"High-Dose Vitamin C.\" National Cancer Institute. National Cancer Institute, 11 Dec. 2015. Web. 11 Mar. 2016.\n- Bobroff, Linda B., and Isabel Valentin-Oquendo. \"Facts About Vitamin C.\" University of Florida IFAS Extension. University of Florida, n.d. Web. 11 Mar. 2016.\n- \"Vitamin C Fact Sheet for Health Professionals.\" National Institutes of Health. U.S. Department of Health & Human Services, 11 Feb. 2016. Web. 11 Mar. 2016.\n- \"Vitamin C Fact Sheet for Consumers.\" National Institutes of Health. U.S. Department of Health & Human Services, 17 Feb. 2016. Web. 11 Mar. 2016.\n- Hoffman, Freddie Ann. \"Micronutrient Requirements of Cancer Patients.\" Cancer 55.S1 (1985): 295-300. PubMed. Web. 11 Mar. 2016.\n- \"Micronutrient Information Center: Vitamin C: Supplemental Forms.\" Linus Pauling Institute. Oregon State University, 27 Nov. 2013. Web. 11 Mar. 2016.\n- Yung, Susanna, Michael Mayersohn, and J. Barry Robinson. \"Ascorbic Acid Absorption in Humans: A Comparison among Several Dosage Forms.\" Journal of Pharmaceutical Sciences 71.3 (1982): 282-85. PubMed. Web. 11 Mar. 2016.\n†Results may vary. Information and statements made are for education purposes and are not intended to replace the advice of your doctor. If you have a severe medical condition or health concern, see your physician."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:0c1faada-795a-4ce9-8618-3380e7f51f61>","<urn:uuid:4effb8d9-08e6-47e9-9313-ca873d2ffd53>"],"error":null}
{"question":"Why do boat experts recommend having more than just two fenders, and what are the potential consequences of having insufficient fender protection during rafting situations? Please explain the reasoning behind this safety recommendation.","answer":"Having only two fenders is often inadequate because if one breaks, you're left vulnerable. Additionally, in social boating situations where rafting up to other boats is common, having limited fenders can be problematic. For example, if you raft up to another boat using your two good fenders, and then another boat with inadequate fenders wants to raft up to you, you won't have extra good fenders to protect your boat's other side. Beyond just protecting the boat's finish, fenders serve to protect the structural integrity of your vessel by absorbing shock that would otherwise damage the hull over time. This makes them an essential safety investment that shouldn't be minimized.","context":["Boat fenders are inflatable tubes usually made of vinyl that are meant to be put between the hull of a boat and the dock, or between two boats when rafting up to each other. Fenders are an essential part of any well-equipped vessel.\nThey are pretty much a necessity when docking and also very important when rafting to other boats. When considering boat fenders it’s not simply a matter of protecting the finish of your boat. They do a whole lot more than that. Inflatable boat fenders protect the structural integrity of your vessel by absorbing a huge amount of shock that would otherwise greatly damage the hull over time. In other words, it’s not good to skimp on something this important.\nSome boaters make do with just 2, but in many cases that proves not to be enough. Two fenders might be all that you need in many cases, but what if you break one of them? What are you going to do then? Or imagine this situation: You show up at a boating party and raft your boat up to your friend’s with your very nice pair of good fenders. A few minutes later another friend shows up with his boat and intends to raft up to you. But when you take a good look, his fenders are tiny and inadequate for the size of the boats. Well, since you were too stingy and bought only 2 good ones, there’s nothing you can do about the crappy fenders that will be on the other side of the boat. If you had done it properly in the first time, you would be able to protect your boat on both sides if the need arises. For most small vessels 4 fenders is more than adequate. Larger boats are better off with 6 or even 8 fenders available.\n…since you were too stingy and bought only 2 good ones, there’s nothing you can do about the crappy fenders that will be on the other side of the boat.\nSize and shape matters\nThis should be a simple one based on common sense; bigger fenders go on bigger boats and little ones go on little boats. A small fender would be something like 5 x 20” but even the 8.5 x 27” can be considered small depending on the application. Small fenders intended for small crafts usually feature outer eyelets for the line. Larger fenders tend to feature a channel that goes through the center of the fender from end to end. The line goes through that channel from one end to the other with a knot at one end. Larger fenders are up in the 12 x 34” range. Larger fenders can absorb the higher loads that a heavy craft can produce. Even for smaller crafts, large ones can be a good choice for permanent boat dock fenders that will always stay at the dock. This would provide increased security for your small boat without the hassles of trying to stow them. For the fenders that will be staying aboard the boat, you might want to go with smaller, more convenient ones. For dock fenders there are other options available as well, such as very large, round buoy-types that can be great for additional dock protection.\nFenders are available in a whole array of colors. White fenders are quite popular but they do get dirty quick. Colored fender can be better at hiding dirt, grime and other imperfections. Either way, there are a number of good fender cleaners on the market that can make an old one look great again. For those who want increased protection from light surface scratches, fender covers are available. They are usually made of some type of stretchy fabric with drawstring closures. They help keep the fenders from scratching the boat, but also keep the fenders clean and looking like new. The fenders will last longer too as they are protected from harmful UV rays.\nFender storage is a very important consideration when choosing a set for your boat. Many modern cruisers include dedicated storage areas for them that will fit a certain fender size. For boats that don’t have this sort of storage location, fender storage devices can be purchased. These are usually made out of a stainless steel frame that is attached to the boat’s railing. Usually put near the bow on either side, these porta-fenders can usually carry anywhere between 4 and 8 fenders total. They also make them really accessible.\nIf they are taken care of, fenders can last a long time. Regular cleaning and rubber conditioning can help keep them from rotting prematurely. Buying a set that uses a screw-on cover for the valve can also help increase longevity as the cheaper black-rubber valve types tend to rot sooner. Also, make sure to choose the proper type and length of rope for your fenders. Alternative attachment methods are available for quick installs. These alternatives bypass the need for knots when one is on a hurry to set a fender to the rail.\nNext time you are out shopping for equipment for your boat think about the quality of your current fenders. Then, don’t just go out and search for boat fenders for sale. Think about how many you actually need. Make sure you know what your boat’s size and normal usage requires for fenders then go out and search for them. That way you won’t be caught up on price and features but rather on exactly what it is that you need."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:0328d6f6-e5d7-48dd-8162-e208ee1a3615>"],"error":null}
{"question":"What difference in compression methods between naturally aspirated vs diesel engines?","answer":"Naturally aspirated engines and diesel engines use fundamentally different compression methods. Naturally aspirated engines rely on the vacuum created when the piston moves down to suck the fuel mixture into the cylinder. In contrast, diesel engines use compression ignition where intake air is highly pressurized and fuel is injected into it, causing self-ignition. This compression ignition system is possible because diesel is a very stable, heavy fuel with high compression resistance due to its large hydrocarbon molecules. As a result, diesel engines can use higher compression ratios without risk of knocking, which contributes to their superior thermal efficiency and makes them well-suited for use with superchargers.","context":["Nevertheless, they have a complicated design and style and create low power compared to two-stroke. The dual combustion cycleis a combustion of the diesel cycle and the Otto cycle. A Russian-German engineer Gustav Trinkler introduced the dual mixture cycle. The nozzle converts the received portion of power into high velocity and generates thrust which aids the airplane to move forward.\nOut of all the vehicles manufactured for the duration of the time, only about one particular fourth are really thought of internal combustion. Inside the next couple of years, the internal combustion engine came out to develop into the most popular automotive engine. Sometime within the 19th century, Rudolf Diesel invented a new kind of internal combustion power, utilizing a idea of injecting liquid fuel into air heated solely by compression.\nWhile these engines can have a low quantity of cylinders, a lot of higher-end automobiles use this setup to fit a lot of cylinders. Some engines have superior gas efficiency at the price of energy, whilst other people optimize a low center of mass to enhance handling. You could also want to know why some engines have various numbers of cylinders. Naturally aspirated engines rely on the vacuum developed when the piston moves down to suck the mixture into the cylinder.\nPistons are open at the bottom and hollow except for an integral reinforcement structure . When an engine is working, the gas pressure in the combustion chamber exerts a force on the piston crown which is transferred by way of its web to a gudgeon pin. Each and every piston has rings fitted about its circumference that largely avert the gases from leaking into the crankcase or the oil into the combustion chamber.\nEvery applicant may well service and make minor repairs to the engine through the block tests in accordance with the service and maintenance guidelines submitted in compliance with § 33.4. Six periods of 1 minute at rated takeoff augmented thrust each followed by 2 minutes, including acceleration and deceleration time, at idle thrust. 30-minute OEI energy, continuous OEI power, or maximum continuous power. Five minutes at whichever is the greatest of rated 30-minute OEI energy, rated continuous OEI power, or rated maximum continuous power, except that, in the course of the initial test sequence, this period shall be 65 minutes. In complying with this paragraph, the energy manage lever need to be moved from 1 intense position to the other in not more than one second. Having said that, the applicant will have to add the equivalent engine output energy extraction from the power turbine rotor assembly to the engine shaft output.\nAmong internal combustion engines, diesel engines boast fantastic thermal efficiency and can burn fuel that is not very refined. These engines use a compression ignition method in which intake air is pressurized and fuel is injected into it, causing it to self-ignite. Such systems are not prone to knocking even when supercharging is made use of, so most diesel engines are used in conjunction with superchargers. In the case of the steam locomotive, the combustion requires location in a burner and the heat from the burner is applied to a boiler.\nHKS F-CON merchandise are capable to fine tune ignition timing depending on the users desires. In numerous conventional setups, the quantity of fuel to be injected is calculated though an air flow meter applying what is frequently referred to as an L-Jetronic technique. L-Jetronic systems typically use a hotwire sprung sensor which is placed in the intake piping which can restrict air flow and also has limitations to the volume of air they can measure.\nCurrently, automobiles alone are accountable for virtually 90 percent of the power consumed for travel in the U.S. As name suggests it is designed in such a way to convert linear motion of piston into rotational motion. Material used for generating crankshaft is cast iron generally but we also use forged steel in high energy engines exactly where load on crankshaft is as well high. The effects are sometimes latent, which means it can be a year ahead of plugging, deposits and corrosion harm causes a challenge.\nThe combustion chamber is enclosed with a cylinder head, cylinder walls, piston head where the combustion of fuel has occurred. A Piston slides inside the cylinder in reciprocating motion and transfers mechanical power to the crankshaft with the enable of connecting rod. The body web link of a auto is usually composed of steel or aluminum, though fiberglass and plastic are also utilized.\nA basic 64-page introduction for the youngest of automobile enthusiasts, probably most effective for ages 6–8. As the name suggests, Air is employed as the media in an all air method. Air transports thermal energy from the conditioned space to the HVAC … The cylinder is a form of tube with circular cross-section, closed at 1 finish. A screen typically keeps out most bigger particles, such as insects and leaves, although the air filter catches finer particles, such as dust, dirt, and pollen.\nA flat engine is basically a V-style engine in which the V is opened up to lay flat. Flat engines are known for becoming utilized in Porsches and some Subaru models. It is bolted to the engine block and it covers the engine from the bottom. Turbo performs by adding air into the chamber, and a single of the most substantial rewards of turbocharging an engine is that the turbo isn’t continually firing. It really is only engaged when the driver pushes for a lot more energy, and this keeps fuel consumption down. When the pistons can move with greater force, the combustion will be a lot more potent, and the car or truck will move with greater force.\nThese let you switch in between working with your fuel engine and applying ‘EV’ mode at the touch of a button. These vehicles cannot be plugged into an electrical energy source and rely on petrol or diesel for energy. Plug-in hybrid- These cars mostly run on electrical energy but also have a conventional fuel engine so you can use petrol or diesel also if they run out of charge. When running on fuel, these automobiles will make emissions but when they are operating on electricity, they won’t. Plug-in hybrids can be plugged into an electricity supply to recharge their battery.","Latest Advances in Diesel Technology And What is To Come\nDiesel, in relation to other fossil fuels, is an exceptionally dense fuel. There are a variety of properties that are inherent in dense fuels. Because of the inherent properties of diesel, diesel engines are extremely energy efficient both respect to combustion efficiency and thermal efficiency.\nHowever, while diesel is extremely energy dense and diesel engines are more thermally efficient and have higher combustion efficiency rates than lighter fuels with low energy density, capturing the full potential of diesel can be difficult.\nDiesel engines — while considerably more efficient and less polluting than a gasoline engine and alternative fuel engines — still have limitations. But, the same inherent traits of diesel that make diesel engines efficient give it the potential — as technologies advance — to generate even higher efficiency rates and lower emissions.\nThe properties of diesel — with respect to fuel efficiency, combustion efficiency, and thermal efficiency rates — govern the energy and emissions outputs of diesel engines according to several laws of physics. Ideal Gas Law and the first and second laws of thermodynamics determine the environmental and economic value of diesel engines. As technologies improve efficiency and output rates should increase according to the laws of physics.\nWhile we can develop technologies to increase the efficiency in which we use diesel, the laws of physics also tell us that gasoline and alternative fuels have limitations with respect to how much more we can improve the efficiency of the engines that combust them.\nThe principal reason gasoline has greater potential to improve is because of its energy density and stability. Gasoline and alternative fuels are much lighter and less energy dense fuels and for that reason, improving gasoline and alternative fuel engines is extremely difficult.\nIn other words, diesel is the ideal fossil fuel, potentially.\nThe energy density and stability of a fuel determine potential fuel efficiency and potential energy output.\nEfficiency Potential of Not Just Diesel, but Diesel Engines\nOf all liquid fossil fuel combustion engines, diesel engines are the most thermally efficient and have the highest rates of combustion efficiency. Furthermore, diesel engines produce the least amount of emissions, save nitrous oxides. There are two reasons diesel engines are the best fossil fuel combustion engines with respect to efficiency and emissions: the energy density and compression resistance of diesel fuel. Because of energy density and the compression resistance of fuel, diesel engines have higher rates of both combustion efficiency and thermal efficiency.\nDiesel has a High Energy Density\nDiesel engines highly fuel efficient, for one, because on a volume scale — gallon, liter, square foot or meter — diesel has a much higher energy density than most other solid, liquid, and gas-state fossil fuels. Diesel certainly has a higher energy density than gasoline, natural gas (methane), and propane.\nHigher energy density means there is more energy per volume unit of measure — more energy per gallon — to push a vehicle down the road. The reason diesel has a higher energy density than other fossil fuels is that the hydrocarbons in diesel — the valuable components in every fossil fuel that ignites/burns/combusts — are made of long and complex molecules, molecules with very high carbon-to-hydrogen ratios.\n“The calorific value of diesel fuel is roughly 45.5 MJ/kg (megajoules per kilogram), slightly lower than petrol which is 45.8 MJ/kg. However, diesel fuel is denser than petrol and contains about 15% more energy by volume (roughly 36.9 MJ/liter compared to 33.7 MJ/liter). Accounting for the difference in energy density, the overall efficiency of the diesel engine is still some 20% greater than the petrol engine, despite the diesel engine also being heavier.”\nThe greater the number of carbon atoms in a hydrocarbon, in relation to hydrogen atoms, the higher the fuel density of that fuel. On a volume scale, the energy density of diesel is between 15% and 25% greater than gasoline. The difference is dependent on whether or not the gasoline is low or high octane. The higher the octane of gasoline, the lower it’s energy density. The reason being, the additives used to increase gasoline octane have lower energy densities than gasoline.\nIn other words, octane additives dilute gasoline.\nDiesel naturally has exceptional compressive resistance because it is a heavy fuel, stable fuel made of large, long hydrocarbon molecules.\nDiesel has High Compression Resistance\nThe second reason diesel is highly efficient with respect to fuel efficiency is because diesel is a very heavy fossil fuel. As such, diesel is a very stable fuel. The stability of diesel is the reason diesel engines with high compression ratios are possible. Compression ratio plays into both fuel efficiency and emissions. Compression ratio is particularly important with respect to reducing emissions. The higher the compression ratio, the lower the emissions.\nDiesel Engines are More Thermal Efficient than Other Fossil Fuel Engines\nThe third reason diesel engines are more efficient than any other liquid fossil fuel engine is that of thermal efficiency. Thermal efficiency is the total amount of energy generated by an engine’s combustion of fuel that becomes mechanical energy, an energy that pushes a vehicle down the road. The thermal efficiency of diesel engines is far greater than that of any other type of liquid fossil fuel engine.\nThe thermal efficiency of diesel engines is, in part, due to the energy density and compression resistance of diesel fuel.\nTechnologies that Increase Diesel Engine Compression Ratio\nThere are a number of means by which to increase the fuel efficiency and combustion efficiency — one of the most important variables with respect to emissions — of diesel engines. One of the simplest means of increasing fuel and combustion efficiency is to increase the compression ratio of an engine.\nWhat Compression Ratio Is\nCompression ratio is a measure of how much an engine compresses a gas or vapor-state fossil fuel once the fuel is in the combustion chamber. In piston/cylinder engines, the compression ratio is a measure of the difference between two piston positions, top and bottom center. The ratio difference between when a piston is at bottom center — when there is the most volume in an engine’s cylinder — and when the piston is at top dead center — when the cylinder has the least volume — is compression ratio.\nThe higher the compression ratio of an engine, the more it compresses a vaporized or gas-state fuel. The more a fuel is compressed, the hotter it gets prior to combustion. The hotter a fuel is before compressions, the more efficiently it combusts.\nThe weight and stability of diesel fuel mean it is highly resistant to compression. The compression resistance of diesel means that when it does ignite — being highly compressed, thus extremely hot, — diesel burns far more completely than other fuels with less compression resistance.\nTechnologies that Increase the Compression Resistance of Diesel\nAlready highly resistant to compression, there are technologies available that can further increase the compression resistance of diesel. By increasing the compression resistance of diesel, again, it is possible to increase both the fuel and combustion efficiency of diesel. There are a variety of technologies that increase the compression ratio of a diesel engine.\nSome technologies that increase the compression resistance of diesel are old concepts with new advances. Others are new concepts that have yet to take hold in the diesel engine sector. Even others are old concepts that have potential, theoretically but have yet to be fully developed. And there are also new, proven technologies that work well with respect to increasing a diesel engine’s compression ratio.\nThe easiest way to increase the compression ratio of a diesel engine is with cetane additives. The same way additives can increase the octane of gasoline, cetane additives increase the compressive resistance of diesel fuel. The difference is gasoline engines are set at a particular compression ratio while diesel engines have the potential for variable compression ratios.\nOnce gasoline engine piston reaches a preset compression ratio, the engine’s sparks fire and drives the piston down. But, diesel engines are not spark fired. Diesel engines are compression engines. That means the diesel does not combust in the combustion chamber until it — the diesel — reaches a certain temperature. The temperature rise in diesel is a product of compression. A diesel engine compresses — therefore heats — diesel until it finally combusts.\nIncreasing the flash point temperature of diesel — the temperature at which it combusts — increases the compression ratio.\nDrawbacks of Cetane Additives\nWhile increasing the compression ratio increases the combustion efficiency of a fuel, which increases total energy output and the total amount of the hydrocarbons that combust, it is a measure of the total fuel available. Combustion efficiency is a percentage of the total hydrocarbons in a combustion chamber that burn up. The problem is, cetane additives actually decrease the total hydrocarbons in a fuel.\nIn other words, while the compression ratio increases the combustion efficiency of the total energy available, cetane additives reduce the total amount of energy available. So while a greater percentage of the fuel available burns up during combustion, cetane additives mean a lower amount of total fuel in a combustion chamber at any given time.\nCommon Rail Fuel Injection\nThough the Common Rail Fuel Injection System has been used in diesel trucks and pickups since the mid-2000s — and since 1997 in diesel cars and marine engines, — it is a new technology relative to the age of diesel engines. The Common Rail Fuel Injection System was a major breakthrough both with respect to fuel efficiency and emissions.\nFrom the 1950s until the new millennium, diesel fuel systems used direct injection. “Direct injection systems pump diesel through injectors mounted directly in the cylinder and feeds fuel to a combustion chamber machined into the top of the cylinder itself.” Direct injection systems have a low-pressure fuel pump that feeds each injector. The problem with traditional direct injection is that large droplets of diesel feed into the combustion chamber.\nThe larger the individual droplets of fuel, the less completely they burn. By reducing the size of the droplets fed into a diesel combustion chamber, the total surface area of each droplet increases which promotes oxygenation. The greater the rates of oxygenation of each droplet, the more complete each droplet ignites/combusts/burns.\nAnd that is what a Common Rail Fuel Injection System does, dramatically reduces the size of the droplets of diesel that are fed into the cylinders of the engine. By vaporizing the air/fuel mixture, a Common Rail Fuel Injection System increases combustion efficiency dramatically, but nothing compared to Supercritical Fuel Injection\nSupercritical Fuel Injection\nThe combustion efficiency generated by a Supercritical Fuel Injection System is greater than Common Rail Fuel Injection System. Combustion efficiency means greater fuel efficiency and lower emissions, much lower emissions. “Researchers in New York have demonstrated a supercritical diesel fuel-injection system that can reduce engine emissions by 80 percent and increase overall efficiency by 10 percent.”\nWhile diesel engines are almost always more fuel efficient than gasoline engines, they have a tendency to produce more oxides of sulfur and oxides of nitrogen. Additionally, because diesel is a heavy fuel with extremely complex hydrocarbon molecules, the combustion efficiency is less than perfect. It is the combustion efficiency of diesel engines that a Supercritical Fuel Injection system improves.\nAccording to George Anitescu, a research associate at the Department of Biomedical and Chemical Engineering at Syracuse University in New York state, a Supercritical Fuel Injection System puts diesel in a state that is between liquid and gas.\n“The high molecular diffusion of supercritical fluids means that the fuel and air mix together almost instantaneously. So instead of trying to burn relatively large droplets of fuel surrounded by air, the vaporized fuel mixes more evenly with air, which makes it burn more quickly, cleanly, and completely. In a sense, it is like an intermediate between diesel and gasoline, but with the benefits of both.”\nUnfortunately, Supercritical Fuel Injection is still in the design and development state. There are several issues engineers must contend with prior to Supercritical Fuel Injection becoming commercially viable. For one, in order for diesel to reach a supercritical state, its temperature must be around 450 degrees Celsius. Such temperatures can cause diesel to solidify and choke. “Coking occurs when hydrocarbons in the fuel react, producing sticky deposits that can lead to fuel-system failures.” While there are a number of solutions to the problems presented when attempting to move diesel into a supercritical state, Supercritical Fuel Injection is not yet a complete practical application.\nWhile they have been around for a while, fuel catalysts are still an aftermarket product. Scientists and engineers — even laymen — have been aware of the problem of oxygenizing diesel fuels. As far back as 1936, Chinese fishermen tapped magnets around fuel lines in order to break apart the hydrocarbon clusters inherent in diesel fuel. Breaking up the hydrocarbon clusters increases the oxygenation potential of diesel. In the 1980s, ranchers in Wyoming made national news doing the same, though on gasoline engines. The Washington Post reported,\n“Although cow magnets have been sold in farming areas for half a century, the market has been limited until recently. Now it’s booming as never before since word got around that somehow the magnetic field can boost a car’s gas mileage by improving combustion if a pair of cow magnets is fastened to a car’s gas line close to the carburetor.”\nWhether the magnets truly helped the Chinese fishermen and Wyoming’s cowboys achieve higher rates of fuel efficiency is debatable. What is not is the fact that — in principle — they were onto something. They knew that by increasing the oxygen content in a diesel fuel mixture, they could increase fuel efficiency.\nModern fuel catalysts — made of similar precious metals as those found in catalytic converters — are also engineered to increase diesel fuel oxygenation. But unlike injectors that oxygenate diesel by increasing the surface area of diesel fuel droplets, fuel catalysts change the physical state of diesel on a molecular level.\nBy depolarizing the charges that bind diesel fuel hydrocarbons into clusters, fuel catalysts expose the individual hydrocarbon molecules and molecule chains to oxygen. Again, the greater the oxygenation of a fossil fuel, the more completely it burns. The Rentar Fuel Catalyst, for example, increases fuel efficiency by between 3% and 8% on over the road vehicles and to a greater extent on heavy equipment, machinery, and marine engines.\nWithout question, the latest advances in diesel technology are making the world’s most efficient fossil fuel produce even more energy and, at the same time, reducing the emissions associated with diesel."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:0cbba319-a3a8-4027-835e-0f7ec8522a18>","<urn:uuid:2be7f07b-5cdf-482c-aef9-c78dcbecd24c>"],"error":null}
{"question":"What are the typical symptoms of appendicitis compared to cholecystitis in terms of pain location and characteristics?","answer":"Appendicitis and cholecystitis have distinct pain patterns. In appendicitis, the pain typically begins periumbilically and later localizes to McBurney point in the right lower quadrant. Additional appendicitis symptoms include fever, nausea, and vomiting. The pain location can vary based on appendix position - it may present as pelvic pain, flank pain, or even right upper quadrant pain. In cholecystitis, the pain is characteristically in the upper right abdomen and may radiate to the back or right shoulder blade. Cholecystitis pain typically lasts for more than 6 hours, particularly after meals, and is accompanied by tenderness in the right abdomen and discomfort during deep breathing. Both conditions commonly present with nausea and vomiting.","context":["Appendicitis is inflammation of the vermiform appendix. It is a very common condition in general radiology practice and is one of the main reasons for abdominal surgery in young patients. CT is the most sensitive modality to detect appendicitis.\nAcute appendicitis is typically a disease of children and young adults with a peak incidence in the 2to 3 decades of life .\nThe classical presentation consists of periumbilical pain (referred) which within a day or later localizes to McBurney point with associated fever, nausea, and vomiting . This progression is only seen in a minority of cases and is unhelpful in children who often present with vague and non-specific signs and symptoms. It also relies on the appendix being in a 'normal' position, which is not the case in a significant number of cases (see below).\nGeneral signs and symptoms include :\n- localized pain and tenderness\n- right lower quadrant tenderness over appendix (i.e. McBurney sign)\n- pelvic pain, diarrhea, and tenesmus (pelvic appendix)\n- flank pain (retrocecal appendix)\n- groin pain - appendix within an inguinal hernia (Amyand hernia) or a femoral hernia (De Garengeot hernia)\n- right upper quadrant pain (subhepatic appendicitis )\n- nausea and vomiting\n- atypical location:\n- within the pelvis (30%)\n- extraperitoneal (5%)\n- left iliac fossa (rare), found in patients with a long appendix, intestinal malrotation, situs inversus and those with a mobile cecum\nThe Alvarado score is a clinical score that can be useful to risk-stratify patients. In children clinicians sometimes use other scores such as a PAS or pARC score for the same purpose.\nAppendicitis is typically caused by obstruction of the appendiceal lumen, with the resultant build-up of fluid, suppurative inflammation, secondary infection, venous congestion, ischemia, and necrosis. Obstruction may be caused by :\n- lymphoid hyperplasia (~60%)\n- appendicolith (~33%)\n- foreign bodies (~4%)\n- Crohn disease or other rare causes, e.g. stricture, tumor, parasite\nOne of the biggest challenges of imaging the appendix is finding it. Once confidently identified, assessing its normality is relatively straightforward.\nFecal loading of the cecum is associated with acute appendicitis, which is uncommon in other acute inflammatory diseases of the right side of the abdomen.\nThe location of the base of the appendix is relatively constant, located roughly between the ileocecal valve and the apex of the cecum. This relationship is maintained even when the cecum is mobile.\nThe location of the tip of the appendix is much more variable, especially as the length of the appendix has an extensive range (2-20 cm). The distribution of positions is described as :\n- behind the cecum (ascending retrocecal): 65%\n- inferior to the cecum (subcecal): 31%\n- behind the cecum (transverse retrocecal): 2%\n- anterior to the ileum (ascending paracaecal preileal): 1%\n- posterior to the ileum (ascending paracaecal retroileal): 0.5%\nPlain radiography is infrequently able to give the diagnosis, however, is useful for identifying free gas, and may show an appendicolith in 7-15% of cases . In the right clinical setting, finding an appendicolith makes the probability of acute appendicitis up to 90%.\nIf an inflammatory phlegmon is present, displacement of cecal gas with mural thickening may be evident.\nSmall bowel obstruction pattern with small bowel dilatation and air-fluid levels is present in ~40% of perforations.\nUltrasound with its lack of ionizing radiation should be the investigation of choice in young patients. With a competent user, ultrasonography is reliable at identifying abnormal appendices, especially in thin patients. However, the identification of a normal appendix is more problematic, and in many instances, appendicitis cannot be ruled out.\nThe technique used is known as graded compression, using the linear probe over the site of maximal tenderness, with gradual increasing pressure exerted to displace normal overlying bowel gas.\nFindings supportive of the diagnosis of appendicitis include :\n- aperistaltic, non-compressible, dilated appendix (>6 mm outer diameter)\n- appears round when compression is applied\n- hyperechoic appendicolith with posterior acoustic shadowing\n- distinct appendiceal wall layers\n- implies non-necrotic (catarrhal or phlegmon) stage\n- loss of wall stratification with necrotic (gangrenous) stages\n- echogenic prominent pericaecal and periappendiceal fat\n- periappendiceal hyperechoic structure: amorphous hyperechoic structure (usually >10 mm) seen surrounding a non-compressible appendix with a diameter >6 mm\n- periappendiceal fluid collection\n- target appearance (axial section)\n- periappendiceal reactive nodal prominence/enlargement\n- wall thickening (3 mm or above)\n- mural hyperemia with color flow Doppler increases the specificity\n- vascular flow may be lost with necrotic stages\n- alteration of the mural spectral Doppler envelope\n- may support diagnosis in equivocal cases\n- a peak systolic velocity >10 cm/s suggested as a cutoff\n- a resistive index (RI) measured at >0.65 may be more specific\nConfirming that the structure visualized in the appendix is clearly essential and requires demonstration of it being blind-ending and arising from the base of the cecum. Identifying the terminal ileum confidently is also helpful.\nA dynamic ultrasound technique using a sequential 3-step patient positioning protocol has been shown to increase the detection rate of appendix . In the study, patients were initially examined in the conventional supine position, followed by the left posterior oblique position (45° LPO) and then a “second-look” supine position. Reported detection rates increased from 30% in the initial supine position to 44% in the LPO position and a further increase to 53% with the “second-look” supine position. Slightly larger absolute and relative detection rates were seen in children. The authors suggested that the effect of the LPO positioning step improved the acoustic window by shifting bowel contents.\nCT is highly sensitive (94-98%) and specific (up to 97%) for the diagnosis of acute appendicitis and allows for alternative causes of abdominal pain also to be diagnosed. The need for contrast (IV, oral, or both) is debatable and varies from institution to institution. Oral contrast has not been shown to increase the sensitivity of CT .\nCT findings include :\n- appendiceal dilatation (>6 mm diameter)\n- wall thickening (>3 mm) and enhancement\n- thickening of the cecal apex: cecal bar sign, arrowhead sign\n- periappendiceal inflammation\n- fat stranding\n- thickening of the lateroconal fascia or mesoappendix\n- extraluminal fluid\n- phlegmon (inflammatory mass)\n- focal wall nonenhancement representing necrosis (gangrenous appendicitis) and a precursor to perforation\nLess specific signs may be associated with appendicitis:\n- periappendiceal reactive nodal enlargement\nMRI is recommended as the second-line modality for suspected acute appendicitis in pregnancy patients, where available . Protocols vary widely, but most include imaging in three planes with a rapidly acquired sequence with T2 weighting, and some include T2 fat-suppressed imaging. MRI findings mirror those of other modalities, with luminal distension and widening, wall thickening, and periappendiceal free fluid.\nTreatment and prognosis\nTreatment is appendectomy, which can be performed either open or laparoscopically . Mortality from simple appendicitis is approximately 0.1% but is as high as 5% in perforation with generalized peritonitis .\nIn ~30% of cases where the appendix has become gangrenous and perforated, initial nonoperative management is preferred provided the patient is stable. It is in this situation that radiologists have a therapeutic role to play with percutaneous CT- or US-guided drainages of periappendiceal abscess.\nRecognized complications include :\n- perforation: in 10-20% of cases\n- most specifically suggested by appendiceal abscess or extraluminal air, but commonly also seen as periappendiceal phlegmon and fluid\n- generalized peritonitis due to free perforation\n- pylephlebitis: infective thrombophlebitis of the portal circulation\n- hepatic abscess\nClinically, the most common differential is that of mesenteric adenitis, which can be differentiated by the identification of a normal appendix and enlarged mesenteric lymph nodes.\nThe imaging differential includes:\n- inflammatory bowel disease, especially Crohn disease, which may affect the appendix\n- other causes of terminal ileitis\n- appendiceal mucocele\n- lymphoid hyperplasia\n- pelvic inflammatory disease (PID)\n- right-sided diverticulitis\n- appendiceal diverticulitis\n- Meckel diverticulitis\n- acute epiploic appendagitis\n- omental infarction\n- appendiceal malignancy\n- Valentino syndrome (from perforated peptic ulcer)\n- enlarged normal appendix as almost 50% of asymptomatic patients can have an appendix diameter greater than 6 mm on CT\n- on CT, identify first the ileocecal valve, which usually has fatty lips, and then look for the appendix more inferiorly on the same side\n- >6 mm outer diameter is a reliable measurement to characterize appendicitis in all imaging modalities\n- Inflammation may be initially limited to the distal end of the appendix (tip appendicitis). It is crucial (particularly with US) to completely evaluate the appendix, and consider further assessment with cross-sectional imaging if it is only partially visualized, but the patient is clinically suspicious\n- Prior appendectomy does not completely rule out a recurrent stump appendicitis, the risk of which is significant if the appendiceal remnant is greater than 5 mm\n- Appendiceal endometriosis is not uncommon, affecting 4-22% of patients with endometriosis, and is a challenging diagnosis on imaging. Nodular, inhomogeneous appendiceal thickening combined with unspecific, often cyclical symptoms can be hints of this condition","What is cholecystitis?\nCholecystitis is inflammation of the gallbladder, a small organ near the liver that plays a part in digesting food. Normally, fluid called bile passes out of the gallbladder on its way to the small intestine. If the flow of bile is blocked, it builds up inside the gallbladder, causing swelling, pain, and possible infection.\nWhat causes cholecystitis?\nA gallstone stuck in the cystic duct, a tube that carries bile from the gallbladder, is most often the cause of sudden (acute) cholecystitis. The gallstone blocks fluid from passing out of the gallbladder. This results in an irritated and swollen gallbladder. Infection or trauma, such as an injury from a car accident, can also cause cholecystitis.\nAcute acalculous cholecystitis, though rare, is most often seen in critically ill people in hospital intensive care units. In these cases, there are no gallstones. Complications from another severe illness, such as HIV or diabetes, cause the swelling.\nLong-term (chronic) cholecystitis is another form of cholecystitis. It occurs when the gallbladder remains swollen over time, causing the walls of the gallbladder to become thick and hard.\nWhat are the symptoms?\nThe most common symptom of cholecystitis is pain in your upper right abdomen that can sometimes move around to your back or right shoulder blade. Other symptoms include:\n- Nausea or vomiting.\n- Tenderness in the right abdomen.\n- Pain that gets worse during a deep breath.\n- Pain for more than 6 hours, particularly after meals.\nOlder people may not have fever or pain. Their only symptom may be a tender area in the abdomen.\nHow is cholecystitis diagnosed?\nDiagnosing cholecystitis starts when you describe your symptoms to your doctor. Next is a physical exam. Your doctor will carefully feel your right upper abdomen to look for tenderness. You may have blood drawn and an ultrasound, a test that uses sound waves to create a picture of your gallbladder. Ultrasound may show gallstones, thickening of the gallbladder wall, extra fluid, and other signs of cholecystitis. This test also allows doctors to check the size and shape of your gallbladder.\nYou could also have a gallbladder scan, a nuclear scanning test that checks how well your gallbladder is working. It can also help find blockage in the tubes (bile ducts) that lead from the liver to the gallbladder and small intestine (duodenum).\nHow is it treated?\nTreatment for cholecystitis will depend on your symptoms and your general health. People who have gallstones but don't have any symptoms may need no treatment. For mild cases, treatment includes bowel rest, fluids and antibiotics given through a vein, and pain medicine.\nThe main treatment for acute cholecystitis is surgery to remove the gallbladder (cholecystectomy). Often this surgery can be done through small incisions in the abdomen (laparoscopic cholecystectomy), but sometimes it requires a more extensive operation. Your doctor may try to reduce swelling and irritation in the gallbladder before removing it. Sometimes acute cholecystitis is caused by one or more gallstones getting stuck in the main tube leading to the intestine, called the common bile duct. Treatment may involve an endoscopic procedure (endoscopic retrograde cholangiopancreatography, or ERCP) to remove the stones in the common bile duct before the gallbladder is removed.\nIn rare cases of chronic cholecystitis, you may also receive medicine that dissolves gallstones over a period of time.\nOther Places To Get Help\n|American Gastroenterological Association|\n|4930 Del Ray Avenue|\n|Bethesda, MD 20814|\nThe American Gastroenterological Association is a society of doctors who specialize in the digestive system (gastroenterologists). This Web site can help you find a gastroenterologist in your area. They also have patient information on many gastrointestinal diseases and disorders.\n|American Society for Gastrointestinal Endoscopy|\n|1520 Kensington Road|\n|Oak Brook, IL 60523|\n|Phone:||1-866-353-ASGE (1-866-353-2743) toll-free|\nThe American Society for Gastrointestinal Endoscopy is a group of doctors who have special training in using endoscopy to look at the digestive tract. On the website you can find a doctor in your area who does these procedures. The website also has patient education videos and patient information about endoscopic procedures.\n|National Institute of Diabetes and Digestive and Kidney Diseases (NIDDK)|\n|Building 31, Room 9A06|\n|31 Center Drive, MSC 2560|\n|Bethesda, MD 20892-2560|\nThe National Institute of Diabetes and Digestive and Kidney Diseases (NIDDK) is part of the U.S. National Institutes of Health. It conducts and supports research on many of the most serious diseases affecting public health, particularly the diseases of internal medicine. NIDDK sponsors the National Kidney and Urologic Diseases Information Clearinghouse (NKUDIC). It has information about diseases of the kidneys and urologic system for people with these diseases and their families, health professionals, and the public.\nOther Works Consulted\n- Friedman LS (2012). Liver, biliary tract, and pancreas disorders. In SJ McPhee, MA Papadakis, eds., 2012 Current Medical Diagnosis and Treatment, 51st ed., pp. 644–698. New York: McGraw-Hill.\n- Halpin V, Gupta A (2011). Acute cholecystitis, search date April 2011. BMJ Clinical Evidence. Available online: http://www.clinicalevidence.com.\n- Persley KM, Jain R (2008). Gallstones and biliary tract disease. In DC Dale, DD Federman, eds., ACP Medicine, section 4, chap. 6. Hamilton, ON: BC Decker.\n|Primary Medical Reviewer||E. Gregory Thompson, MD - Internal Medicine|\n|Specialist Medical Reviewer||Arvydas D. Vanagunas, MD - Gastroenterology|\n|Last Revised||July 10, 2013|\nTo learn more visit Healthwise.org\n© 1995-2013 Healthwise, Incorporated. Healthwise, Healthwise for every health decision, and the Healthwise logo are trademarks of Healthwise, Incorporated."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:81ddb685-f24e-4e9d-8e5a-301fadc5cdc1>","<urn:uuid:cbbea5d8-94c3-4191-afdc-91e27aae3353>"],"error":null}
{"question":"What are the key differences between the evaluation methods for standard bicycle lanes versus the technical specifications for RRFB light bar installations?","answer":"Standard bicycle lanes are evaluated primarily through operational and behavioral effects, with challenges in gathering pre-installation exposure data and controlling variables like parking and driveway frequency. In contrast, RRFB light bar installations have very specific technical requirements: they must be mounted on both sides of the road, operate at 75 flash cycles per minute, maintain 12 VDC power, and meet Class 1 light intensity standards. While bicycle lane evaluations focus on long-term safety outcomes, RRFB specifications emphasize immediate visibility and standardized performance metrics.","context":["Evaluation of Pedestrian and Bicycle Engineering Countermeasures: Rectangular Rapid-Flashing Beacons, HAWKs, Sharrows, Crosswalk Markings, and the Development of an Evaluation Methods Report\nCHAPTER 2. IDENTIFICATION OF COUNTERMEASURES\nThis chapter documents the process used to identify and select the countermeasures that were evaluated in this project.\nAn extensive literature review of bicycle and pedestrian countermeasure evaluations was conducted. The research team identified published and unpublished reports, papers, and articles that evaluated bicycle and pedestrian countermeasures. From this preliminary list, the team reviewed each source for relevance to the project. References that provided pertinent evaluation information were summarized, and the countermeasure type, number of study sites, experimental design, and study results were noted. The evaluations were also summarized by countermeasure type, indicating the cumulative total number of study sites for each countermeasure. Requests to conduct experimental evaluations of bicycle and pedestrian-related traffic control devices that were not specifically addressed by the 2009 Manual on Uniform Traffic Control Devices (MUTCD) were also summarized.(2)\nThe following findings were developed based on the information the team gathered:\nThere have been numerous evaluations of bicycle and pedestrian countermeasures, and\nmost of these evaluations focused on surrogate safety measures. The literature review identified several reports, papers, and articles documenting the evaluation of engineering countermeasures. Many of these evaluations used behavioral or operational measures of effectiveness (i.e., measures involving pedestrians, bicyclists, and/or motorists) as opposed to actual safety outcomes (i.e., a reduction in pedestrian-vehicle crashes). For example, many studies of pedestrian crossing countermeasures use pedestrian-vehicle conflicts or motorist yielding as a surrogate for a safety outcome. Other examples of surrogate safety measures for bicyclist and pedestrian countermeasures include pedestrian looking behavior, pedestrian compliance with crosswalks and pedestrian signals, motorist braking and other behavior, motorist speed, bicyclist positioning, and bicyclist compliance with traffic control devices.\nThere may be a direct relationship between the surrogate measure and the safety outcome (i.e., a correlation between conflicts and injury crashes and fatalities) for some surrogate safety measures (e.g., bicyclist-vehicle or pedestrian-vehicle conflicts). With other surrogate safety measures, the relationship is intuitive but not explicit or clearly recognized. For example, advanced stop or yield lines may be effective if a greater percentage of motorists are stopping further away from marked crosswalks to reduce visual screening. However, it has not been demonstrated empirically that having more motorists stop further back from the crosswalk leads to fewer pedestrian-vehicle crashes.\nThe prevailing use of surrogate safety measures in bicycle and pedestrian countermeasure evaluations reflects the difficulty of using crash reduction as a safety outcome. The following factors make crash data analyses more difficult:\n- Exposure data should be collected in the before period; however, this seldom occurs.\n- Bicycle and pedestrian crashes occur relatively infrequently and are typically\nTherefore, a crash-based evaluation of a pedestrian- or bicycle-related treatment might require hundreds or even thousands of treatment sites (plus an equivalent number of control sites) to have a statistically adequate sample of locations for determining the effectiveness of a treatment on pedestrian or bicycle crashes. Other concerns include the following:\n- Regression-to-the-mean effects and site-selection biases, especially for selecting high-crash study sites.\n- Significant variations in crash data quality, particularly among local jurisdictions.\n- The 1- to 2-year lag in crash reporting following countermeasure installation.\n- Difficulty controlling land use or other environmental changes that may affect pedestrian and bicyclist activity levels, behavior, and safety.\nConversely, the following factors make observational studies with surrogate safety measures more appealing:\n- Researchers have better control over the data collection process.\n- Researchers have experimental control over when the countermeasures are introduced at each site.\n- Exposure data can typically be collected in both the before and after periods.\n- There is less lag time (typically 1–3 months after installation) in the analysis\n- Before and after data are collected in a shorter time period, minimizing possible changes in land use or other environmental variables.\n- Researchers have the ability to measure the effects of escalating treatments or varying treatment protocols in a relatively short period of time.\nMany countermeasure evaluations have weaknesses in their experimental design or data collection protocol that limit the value of their results. Even a cursory review of the evaluations in the literature review reveals that many studies have not used control sites or alternately introduced and removed the treatment at the same site to adjust for area-wide changes and other potential confounding factors. In addition, researchers have not used sufficient sample sizes in data collection or addressed regression-to-the-mean biases at study sites with high crash rates prior to treatment installation. Many evaluations were conducted by local transportation agencies with limited resources where engineering judgment was typically used when interpreting study results.\nSome evaluations treat effectiveness and safety as a binary outcome (i.e., safe or not safe) with little consideration for how it may change for various street characteristics and user populations. For example, the in-street pedestrian crossing sign has been found to be fairly effective on low-speed streets. However, other evaluations of this sign had less than promising results but failed to consider the context in which the sign was measured\n(i.e., moderate-speed, high-volume streets). Therefore, it is important for the study design\nand the evaluation plan to address the full range of street characteristics. Based on the literature review and evaluation, five candidate bicycle countermeasures and nine candidate pedestrian countermeasures were identified for potential study.\nThe most promising low-cost bicycle engineering countermeasures that could benefit from additional safety evaluation were as follows (in no particular priority order):\n- Shared lane pavement markings: Shared lane pavement markings (a bike symbol with two chevrons) have been tested in San Francisco, CA, and are in the California MUTCD.(3) However, at the time of this review, these markings were not included in the 2003 MUTCD, and numerous cities in other States were using different variations of this pavement marking.(4) Ft. Collins, CO, Minneapolis, MN, and Portland, OR, are evaluating shared lane pavement markings as part of the official experimentation process. The 2009 MUTCD now includes a provision for shared lane markings.(2)\n- Colored bike lanes (or other signing and marking) in high-conflict areas: Colored bike lanes are still considered experimental and were not included in the 2003 MUTCD.(4) Several cities have experimented with colored bike lanes, most notably Portland, OR, and Cambridge, MA, while others are currently experimenting with them (i.e., New York City, NY). Some cities have used colored bike lanes only in high-conflict areas, whereas others have proposed to use continuous colored bike lanes.\n- Standard width bicycle lanes: Several studies have looked at operational or behavioral effects of standard width bicycle lanes (i.e., approximately 5 ft), but few have quantified the crash experience. Although a sufficient number of study sites could be identified\nfor crash analysis, gathering exposure data prior to treatment installation could be problematic. Various street characteristics (e.g., on-street parking, driveway/curb cut frequency, etc.) would have to be controlled in a crash analysis.\n- Road diet: Road diets are often conversions of four-lane undivided roads into three lanes (two through lanes and a center turn lane/median refuge island), with the fourth lane converted into bicycle lanes, sidewalks, and/or on-street parking. A 2004 FHWA study quantified the crash reduction of road diets for vehicle traffic, but little is known about any potential safety benefits for bicyclists and pedestrians.(5)\n- \"BICYCLISTS MAY USE FULL LANE\" regulatory sign: At the time of this study, the National Committee on Uniform Traffic Control Devices (NCUTCD) was discussing a regulatory sign that would replace the existing \"SHARE THE ROAD\" sign for bicycles because the sign is ambiguous and can be interpreted differently by bicyclists and motorists. However, it is difficult to quantify the safety effectiveness of similar simple sign treatments even when surrogate safety measures are used.\nThe most promising low-cost pedestrian engineering countermeasures that could benefit from additional safety evaluation are as follows (in no particular priority order):\n- Pedestrian countdown signals: Pedestrian countdown signals have been studied in\nSan Jose, CA, and most recently in San Francisco, CA. Results of the crash study in\nSan Francisco, CA, found a significant crash reduction; however, crash reduction was also significant at control sites.(6) The authors indicated that regression-to-the-mean played a major role in the crash decline. Evaluation of pedestrian countdown signals are currently planned as part of FHWA's Intelligent Transportation Systems (ITS) countermeasures study in Miami, FL; Las Vegas, NV; and San Francisco, CA.(7) At this time, there may be a sufficient number of study sites to perform a crash analysis by pooling study sites from several States.\n- Median refuge islands: Median refuge islands are often cited as one of the most cost-effective countermeasures; however, many practitioners have indicated a need for additional quantitative data on safety benefits. There are several evaluations of median refuge islands in the literature review, and the FHWA crosswalk marking study by Zegeer et al. indirectly quantified the effects of median refuge islands.(8)\n- In-roadway warning lights: In-roadway warning lights have become a popular pedestrian enhancement, and they are found in the 2003 MUTCD.(4) There are several studies that document improved motorist yielding and increased braking distance, particularly in lowlight conditions. However, there has been some discussion about their actual safety benefit, and some engineers have suggested that they be removed from the 2003 MUTCD.(4)\n- Rectangular rapid-flashing beacons (RRFBs): The research team has identified a low-cost, solar-powered flashing beacon that includes a strobe display. Preliminary tests in Florida indicate that this beacon may be effective at increasing motorist yielding at uncontrolled crosswalks on multilane, high-volume streets. Since the number of installations is limited, more experimental data are needed.\n- Leading pedestrian intervals: Leading pedestrian intervals provide a \"head start\" for pedestrians before turning traffic is released. There are a few studies that have evaluated leading pedestrian intervals, and it is planned for evaluation in the FHWA ITS countermeasures study in Miami, FL, and San Francisco, CA.(7)\n- Raised crosswalks: The literature review contains few studies on raised crosswalks. All studies focused on surrogate safety measures, such as driver yielding. The city of Boulder, CO, has installed numerous raised crosswalks, particularly at right-turn bypass lanes. Raised crosswalks also serve a traffic calming role, but they have limited application on arterial streets.\n- Advanced stop or yield line with regulatory sign at marked crosswalks: This countermeasure has been evaluated in several studies and is offered as an option in the 2003 MUTCD, but it is not widely used in practice.(4) Advanced stop or yield lines are thought to be effective at reducing multiple-threat crashes on some roadway types; however, their effectiveness may not be as great for high-speed, high-volume streets.\n- Improved crosswalk or intersection lighting: The literature review contains limited evaluations of lighting, with a few studies conducted in the 1970s. The concept of smart lighting, or lighting that becomes brighter in the presence of a pedestrian, is planned for evaluation in the FHWA ITS countermeasures study in Miami, FL, and Las Vegas, NV.(7)\n- High intensity Activated crossWalK (HAWK) or pedestrian hybrid signal: The HAWK has been extensively installed in Tucson, AZ; however, a comprehensive safety study has not been performed yet.\nA practitioner panel was identified and selected to provide feedback and weighting to the candidate countermeasures. The panel was sent the list of candidate bicycle and pedestrian countermeasures and the following rankings were derived:\n- Colored bicycle lanes.\n- Shared lane pavement markings.\n- Standard width bicycle lanes.\n- Advanced stop/yield line.\n- Leading pedestrian interval.\n- Pedestrian countdown signals.\nThe next step of the process was to meet with FHWA staff to select the final list of countermeasures for study. Once the countermeasures were selected, the research team would develop an evaluation plan for each countermeasure.\nIDENTIFY POTENTIAL EVALUATION SITES AND EXPERIMENTAL DESIGN\nAfter the top bicycle and pedestrian countermeasures were identified, researchers began to search for potential evaluation sites. The experimental designs and measures of effectiveness that would be appropriate for the given countermeasure were also considered. This research team made the following recommendations at a meeting with FHWA staff on October 23, 2006:\nCandidate bicycle countermeasure recommendations:\n- Colored bike lanes.\n- Shared lane pavement markings.\n- Standard width bike lanes.\nCandidate pedestrian countermeasure recommendations:\n- Advance yield/stop lines.\n- Countdown signals.\nThe final consensus on the priority ranking of countermeasures to be evaluated was as follows:\n- Shared lane pavement markings for bicyclists.\nFollowing the October 23, 2006, meeting, the research team developed the experimental designs that were used to conduct the evaluation.\nApproximately 18 months after evaluations of RRFBs, HAWKs, and shared lane markings for bicyclists began, additional funding was provided to examine a fourth countermeasure and to develop a user-friendly safety evaluation document. The following possibilities were discussed for the fourth countermeasure:\n- Driver's view (detection distance) of crosswalk markings.\n- Crash rates at midblock crossings.\n- Midblock transit stops.\nThose in attendance at the meeting determined that the driver's view (detection distance) of crosswalk markings should be the fourth countermeasure for this project. A key question to be explored in the study was whether parallel white lines were sufficient for midblock crosswalks. Additionally, the following components were recognized as necessary for a potential update to the 2003 MUTCD:(4)\n- Additional figures or illustrations for crosswalk markings similar to the figures that already exist for school and construction zones.\n- Text that indicates differences between intersection and midblock pedestrian crossings.\nParticipants at the meeting liked the systematic approach of the proposed crosswalk marking study, with one participant expressing the importance of having good basic data.\nThe development of an evaluation methods report for pedestrian and bicycle traffic control devices was also added as part of the project. The purpose of the report is to teach practicing engineers, planners, and public works employees at the local, county, and State levels how\nto conduct an evaluation of traffic control device effectiveness. The need for this report became apparent because many of the evaluations that were reviewed lacked solid experimental design and research methods.","Light Bars & Systems\nThe Federal Highway Administration (FHWA) has granted interim approval for optional use of Rectangular Rapid Flashing Beacons (RRFB) to supplement uncontrolled pedestrian and school crosswalk signs, functioning solely as a warning beacon.\nThe RRFB is a rectangular shaped, high intensity signal head, which flashes in a wig-wag, rapid flickering pattern. The alternating signals provide direct, ultra-bright concentration as well as wide-angle intensity. The beacons are pedestrian activated: push button or passive detection (several options available).\nStudies confirm very high rates of motorist compliance to “yield to pedestrians” (approx. 80%-95%) compared to standard (round) beacons (15%-20% range).\nThe combination of the following requirements makes RRFB’s extremely effective:\n- Signal’s high visibility (light intensity + 2/4−1 strobe pattern).\n- RRFB’s installed on both sides of the road facing approaching traffic.\n- Supportive signage.\nELTEC‘s Rectangular Rapid Flashing Beacon is FHWA compliant including the updated requirement of Class 1 light intensity. As recently specified by the FHWA, Class 1 RRFB signals (used by emergency vehicles: police, fire and ambulances) must be rated to 200 cd (candela or ‘candle power’). Surface area of the signals does not determine the level of brightness. The type of LED and reflector used within the signal head determines how many must be used to provide the required Class 1 light level. ELTEC has always used lab Certified Class 1 LED’s.\nThe FHWA requires signals on both sides of the road for approaching traffic. Because of diverse traffic patterns, ELTEC has designed two styles of RRFB light bars. Both light bars have recessed signals to minimize vandalism and offer an optional pedestrian verification signal housed on the end of each light bar.\nOne-sided with 2 RRFB’s: Used on divided highways with a median or one-way streets. This light bar mounts to tapered, wooden, standard 4 1/2” O.D, or other diameter pole sizes where banding is appropriate. Optional: One or two end-mounted signals for pedestrian verification.\nTwo-sided wraparound with 4 RRFB’s: Used with two-way streets/highways, or for median use in conjunction with the one-sided light bar. It mounts to a 2 3/8” or 4 1/2” O.D. pole, or 2 1/2” Telespar. Optional: One or two end-mounted signals for pedestrian verification.\nThe FHWA does not specify any light bar finish. ELTEC has two ‘off-the-shelf’ options: Federal Yellow or brushed aluminum. Optional powder coated custom colors are also available (community or school colors, for example).\nBoth light bars can be retrofitted to existing (poles) pedestrian crossings that have no signals or are currently using round flashing beacons. The light bars work with either DC (solar) or AC systems that incorporate a 120VAC to 12VDC power supply. ELTEC also manufactures complete solar powered or AC systems.\nSome municipalities and state DOT’s require night dimming. ELTEC’s custom RRFB flasher offers optional 6-stage night dimming without altering the 2/4-1 strobe pattern.\nAll ELTEC solar powered (DC) systems are sized for optimal performance to ensure the light intensity never fades or fails. Should a crossing have less than 350 activations a day or more than 1,200 we guarantee our DC systems will not be undersized for the number of average daily activations. With all solar powered systems, we will give you a sizing report confirming the reliability of system performance.\nUnits/poles are typically connected by radio for wireless operation, eliminating the need to trench or bore. The radios have 65,000 different addresses to ensure that only the desired units operate from a signal. Units may be hardwired if desired.\nFHWA UPDATES: OFFICIAL INTERPRETATIONS\nOn September 27, 2012, the FHWA determined that daytime dimming of RRFB indications is not allowed (applies to solar powered systems). All existing DC systems with ‘automatic dimming/power management’, etc., are no longer in compliance. Dimming at night is acceptable due to the “excessive glare during nighttime conditions”. FHWA Daytime Dimming Interpretation Letter\nOn June 13, 2012, the former 2/3 flash pattern was updated to reflect the actual flash pattern initially tested. FHWA Flash Pattern Interpretation Letter\nOn August 8, 2012, systems installed or shipped prior to July 6, 2012 with the former flash pattern are ‘grandfathered’ and not required to be modified/updated to the new flash pattern. FHWA Former Flash Pattern Interpretation Letter\nOn January 9, 2012 the FHWA clarified the SAEJ595 light intensity standard. Only “Class 1 yellow lights are to be used for RRFB’s…” FHWA Light Intensity Interpretation Letter\nRRFB LIGHT BAR SPECIFICATIONS\nDimensions (one side/2 RRFB’s)………………………3.5” H x 20” W x 2.625” D\nDimensions (wrap-around)………………………………..3.25” H x 20” W x 8” D\nPower required……………………………………………………………….12 VDC\nSAE J595 Class 1 Certified LED’s……………………AMECA Accredit Laboratory\nFlash rate …………………………………………………..75 flash cycles/minute\nOptional: 6 stage night dimming…………………reduces light intensity by 70%\nAll components are designed, manufactured and assembled in the U.S.A."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:c0ab60ac-1cf9-4e12-b191-24f1d3beda5f>","<urn:uuid:83021815-b8b6-4982-881f-6621a45d0ef3>"],"error":null}
{"question":"What was the specific design change request that contributed to the Hyatt Regency Hotel disaster?","answer":"In early January 1979, the fabricator's engineering manager requested to change the continuous rods supporting the second and fourth floor walkways and make them discontinuous and offset at the fourth floor. While the project manager verbally agreed, the formal change request was never submitted.","context":["- /Eng302 – Task 1\nEng302 – Task 1\nSemester 1, 2017\nRachael Bridges – student no. 1099071\nOn July 17, 1981, the United States experienced one of their worst structural failures. Two walkways, suspended from the ceiling, collapsed in the Hyatt Regency Hotel in Kansas City, Missouri. 114 people were killed and 216 injured in this preventable tragedy (Khudeira, 2011). Although the immediate cause of this incident was an upper rod and box beam failure, there were numerous project management errors that led to the construction of this unstable connection. By analysing the five processes of project management it becomes clear how these errors occurred and how the walkway collapse could have been avoided.\nThe Hyatt Regency Hotel project was initiated and funded by the Crown Center Redevelopment Corporation in early 1976, with the initial scope to design and build a Hyatt Regency Hotel. In July the same year, Gillum Colaco, Structural engineers (known as GCE International, Inc., since 1983) were chosen as the consulting structural engineering firm and entered a standard contract (project charter) to complete all structural engineering services for the hotel (Texas AM University, 2009). The project manager was Daniel M. Duncan and the Engineer of Record (EOR) was Jack D. Gillum (Texas AM University, 2009). It appears that the initiation processes were completed appropriately in accordance with the steps outlined by (Project Management Institute, 2013).\nDuring the planning stage the total scope for the engineers was established to include all structural engineering for a 35-storey, 750-room concrete guest tower with a revolving restaurant on top and a 4-storey function block with a long-spanning atrium in the middle (Luth, 2000). The objective was to build a hotel in compliance with the Kansas City building codes and to meet the needs of the stakeholders with the major stakeholder being the owner. Owner involvement is encouraged in planning stages to ensure a well-defined project scope and Crown Center was involved in developing various plans and the basic design with GCE and the architects (Luth, 2000).\nA general contractor, Eldridge Construction Company, was employed and chose to use the fast track method of delivery. This method limited the time and quality control applied to the design and construction phases (Luth, 2000). According to Graph 1 from (Peebles, 2017), there should be significant effort placed into the planning of a project and this would be directly related to the amount of time spent on planning. Therefore, either the fast track method should not have been used or the project manager should have been aware of the effort required during planning and thus ensured they met this standard.\nGraph 1: Planning and Control Effort Profile\nThe execution of the project involves completing the work outlined within the plans. One aspect of this is to co-ordinate the people and resources involved with the project such as acquiring the project team and assigning roles. Prior to completion of the project two key team members left the engineering firm so only the project manager had any history with the design and planning of the project (Luth, 2000). This would not have been an issue if the project manager had spent time developing the new team and communicating with them effectively so that they understood the project to date, the expected outcomes and their roles in achieving them.\nThe general contractor chose a fabricator (Havens Steel Company) for the steel works of the hotel. GCE considered the fabricator’s engineering manager as an expert in designing connections due to previous consultations on other projects. It was common practice in Kansas City at the time for engineers to leave most of the connection details to be decided by the fabricator as this allows them to tailor these details to suit their shop practice (Luth, 2000). This appears to have been a reasonable resource allocation to maintain a good working relationship between Havens Steel and GCE.\nA miscommunication occurred in early January 1979, when the fabricator’s engineering manager called the project manager to discuss a change in the design plans. The request was to change the continuous rods supporting the second and fourth floor walkways and make them discontinuous and offset at the fourth floor. The project manager agreed over the phone that this change would be acceptable, however, he then asked the fabricator to submit a formal request for change which was never completed (Luth, 2000). Not long after, the fabricator removed the project from his engineering department and sent partially completed shop drawings to an outside engineering firm. The outside detailer assumed that the connection design was complete due to lack of detail on the drawings (Luth, 2000). This incident was not appropriately managed as there was no follow up by the project manager when he did not receive the formal change request and the fabricator’s engineer should have ensured the outside detailer was aware that the design was incomplete. These errors lead to the construction of a connection that had never been properly designed.\nAs part of the executing process, the quality requirements and quality control should be audited to ensure the project is meeting the correct standards, to enable quality assurance (Project Management Institute, 2013). GCE did perform design checks and it was noted that during a check the project manager was approached with concerns about the strength of the hanger rod. A technician had calculated that the rod did not work as A36 steel and when asked the project manager responded from memory that the rod was high-strength and he did not attempt to verify this (Luth, 2000). Verification of the rod strength should have occurred by checking the appropriate documentation and this would have led to the discovery of the connection issue. As part of the executing process it is the project manager’s responsibility to manage their team by monitoring their performances, providing feedback, resolving issues and managing changes to optimise the project performance (Project Management Institute, 2013). By not verifying the rod strength the project manager failed to provide feedback or resolve the technician’s issue and did not correct the underlying connection error.\nMonitoring and controlling\nThe monitoring and controlling phase of the Hyatt Regency Hotel project was inadequate. These processes should include monitoring, reviewing and regulating the progress and performance of the project and observing and measuring the performance regularly and consistently (Project Management Institute, 2013). On three separate occasions the EOR was turned down by the owner when requesting site representation as the owner preferred to minimise costs (Luth, 2000). Another process of monitoring and controlling a project is to identify required changes to plans and initiate and control these changes to avoid future complications (Project Management Institute, 2013). The change of the connection detail from the design plan was never properly initiated due to the lack of submission of a formal request for change from the fabricator and it was not controlled by the project manager who did not flag this connection for further review or make any effort to follow up the request with the fabricator.\nThe owner had retained General Testing Laboratories to perform the full-time inspection and materials testing services while the hotel was constructed, however, they were terminated following an incident involving the atrium roof collapsing (Luth, 2000). The project was completed without a testing lab as by the owner’s authority, the EOR recommended an inspection of every connection in the atrium and the owner employed an independent engineer to do so and perform a design check. The EOR performed an in-house check of the steel and concrete connection drawings. During this check, the strength of the hanger rods was questioned again and the project manager still did not attempt to verify his claim that the rod was high-strength (Luth, 2000). No problems were discovered during the independent engineer’s or the EOR’s in-house checks (Luth, 2000). This indicates that the checks were not thorough enough and a standard checking process should be devised to include close examination of all aspects of the design plans.\nClosing a project involves formally completing the project and contractual obligations, finalising and verifying all activities are complete, archiving project documents and closing out procurements. Acceptance from the client should be obtained and a post-project review should be conducted (Project Management Institute, 2013). Before the project was complete the general contractor filed for bankruptcy so it was the owner who finalised the construction and the project (Luth, 2000). There is no mention of GCE performing a post-project review. Instead an inspection company, hired by the owner, conducted a review and did not notice any deformations of the connection or walkway deflection. However, seven weeks before the opening of the Hyatt a workman noticed the walkways deflecting up to ¾ of an inch and reported this to the architect’s representative with no follow up (Gillum, 2000). Also, during the hotel’s first year of operation it was noted in a memo that the walkway handrails were deforming with no follow up and when covering the box beams with drywall a workman noticed bending in the box beam and did not mention this to anyone (Gillum, 2000). The rest of the closing processes were completed and the hotel opened in July 1980 (Luth, 2000).\nSummary of Outcomes/Lessons Learnt\nThe Hyatt Regency Hotel would operate smoothly for approximately one year before the collapse of the second and fourth floor walkways. The cause of the collapse was due to the construction of an incomplete connection design on the fourth-floor walkway, lack of communication between the project manager and fabricator regarding the connection, poor detail in design drawings, poor review of design drawings and poor field inspections during and post-construction.\nEventually the hotel did rebuild and replaced the suspended walkways with a single crossing on the second floor supported by large pillars (Think Reliability, Accessed 2017). However, the walkway collapse contributed to several changes in engineering practice in the United States based on the lessons learnt from this disaster. These lessons show that the project management processes should include implementing a formal review process that includes every detail of all structural designs and drawings, all concept changes must be formally processed and completed, project managers should ensure that all answers to questions about potential design flaws should be verified by reference to documents and all designs completed outside the firm should be verified by a competent professional (Luth, 2000).\nI’m a freelance writer with a bachelor’s degree in Journalism from Boston University. My work has been featured in publications like the L.A. Times, U.S. News and World Report, Farther Finance, Teen Vogue, Grammarly, The Startup, Mashable, Insider, Forbes, Writer (formerly Qordoba), MarketWatch, CNBC, and USA Today, among others."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:e5e390e0-589d-4b78-add6-0cabee8090ea>"],"error":null}
{"question":"What's the difference in box office performance between 'A United Kingdom' and 'John Carter', and which one mentions Swarovski crystals in its costumes?","answer":"While 'A United Kingdom' earned a total worldwide box office of $13.8 million against a $14 million budget, 'John Carter' featured elaborate costumes including Dejah Thoris' Zodangan wedding outfit that used over 120,000 Swarovski crystals, all applied by hand. The box office performance of 'John Carter' is not mentioned in the provided documents.","context":["THE EARTHMEN (From the planet Earth of the late 1800s — light years from Barsoom, a.k.a. Mars)\nJOHN CARTER (Taylor Kitsch) – -“No good’ll come out of me fightin’ your war.” — Born in Virginia, John Carter served as an officer in the Confederate army in the Civil War. He is an honorable and courageous hero, but the ravages of the Civil War have left him broken, dispirited and personally defeated. Accidentally transported to Barsoom (Mars), Carter begins to realize that his strength and jumping abilities are greatly amplified in the low gravity of the planet. Carter reluctantly begins a journey to rediscover his humanity while at the same time saving his newfound world.\nCOLONEL POWELL (Bryan Cranston) — “Captain, I’m finding it difficult to reconcile the man on this piece of paper with the one I’m looking at.” — Colonel Powell is a seasoned, by-the-book, tough-as-nails U.S. cavalry officer. Powell’s mission is to enlist John Carter to fight the Apaches from his unit’s outpost in the Arizona Territory. He is thwarted in this by John Carter’s abject refusal to have anything to do with the military—or any cause, no matter how just.\nEDGAR RICE BURROUGHS (Daryl Sabara) — “My mother always said Jack never really came back from the war.” — Edgar Rice Burroughs is John Carter’s inquisitive 18-year-old nephew. Edgar adores his Uncle John and as a child enjoyed listening to wild tales he spun that took him on journeys to places Edgar could hardly even imagine. Burroughs receives an urgent telegram from his Uncle and rushes to him — only to find it may be too late.\nTHE INHABITANTS OF BARSOOM\nMars or Barsoom, as it is called by the natives of the planet, is home to a host of different races, ranging from the “Red Men:” the sophisticated Heliumites and war-like Zodangans, to the tribal, primitive “Green Men,” the Tharks, and the mysterious, advanced Therns.\nHELIUMITES – Human-like, red-tattooed inhabitants of the city of Helium characterized by their sophisticated and conservationist policies. They proudly wave the blue flag that symbolizes their nation, and their longing for the oceans long gone.\nDEJAH THORIS (Lynn Collins) — “If you had the means to save others, would you not take any action possible to make it so?” — Dejah Thoris, the beautiful, raven-haired princess of Helium, is a passionate advocate for the Heliumites and their way of life. Dejah is Regent of the Royal Academy of Science, and was trained to rule and fight. She is on the verge of a discovery that could permanently shift the balance of power between her nation Helium and their enemy Zodanga. But time is running out, and Dejah must convince John Carter to enlist in the fight to save Helium.\nTARDOS MORS (Ciaran Hinds) — “Helium is lost. My people. I have failed them all.” — Tardos Mors is the Jeddak (King) of Helium and father to Dejah Thoris. He is a tough and pragmatic ruler, who is forced to find a solution to save his beloved Helium—even if it means breaking his heart and Dejah’s to do it.\nKANTOS KAN (James Purefoy) — “Hello, ladies.” — Kantos Kan is the Odwar (Captain) of the Helium air navy and is fiercely loyal to Tardos Mors and his daughter, Dejah Thoris. Intelligent, handsome and brave, Kantos will do anything in his power to fight for Helium and protect the royal family.\nZODANGANS – Human-like, red-tattooed inhabitants of Zodanga; war-like, manipulative and exploitive and always on the move—a predator race. They are represented by a bold red flag that symbolizes their aggressive and destructive nature.\nSAB THAN (Dominic West) — “Death to Helium!” — Sab Than is the Jeddak (King) of Zodanga. He is impulsive, arrogant and aggressive, promoting war and conquest as the Zodangan way of life. With a dangerously calculated charm, Sab will even try to make a deal with the devil to destroy Helium and rule all of Barsoom.\nTHERNS – In the religion of Barsoom, Therns are the heralds of the Goddess Issus. In fact, they are an inconspicuous race and Barsoom’s most highly advanced beings, whose motives are always self-serving.\nMATAI SHANG (Mark Strong) — “We do not cause the destruction of a world, Captain Carter. We simply manage it. Feed off it, if you like.” — Matai Shang is the Holy Hekkador (King) of the Therns. Using their advanced technology, the mysterious Therns represent themselves as the messengers of the Barsoomian Goddess Issus in order to manipulate their own plans.\nTHARKS – The “Green Men” of Barsoom. Tusked, 9-10 foot tall, four-armed creatures, who are tribal and primitive. Historically a once great race but now nomadic and dispersed; their survival-of–the fittest beliefs often fuel their aggressive, combative behavior.\nTARS TARKAS (Willem Dafoe) — “When I saw you leap into the sky, I wished to believe it was a sign that something new can come into this world.” — Tars Tarkas is a fierce green Martian warrior who is the Jeddak (King) of the Tharks. The last vestige of nobility runs in his blood and is the only thing that keeps the Thark tribe from turning into beasts. Blessed with a good sense of humor and patience, Tars befriends the earthman John Carter and gives him the Thark name Dotar Sojat, which roughly translates as “my right arms.”\nTAL HAJUS (Thomas Haden Church) — “I claim the right of challenge! Who will pledge their metal to mine?” — Tal Hajus would like nothing better than to become the leader of the Tharks and depose Tars Tarkas by force. He is a brutal and conniving Thark warrior, with a single-minded belief that only the strong have the right to survive.\nSOLA (Samantha Morton) — “May the Goddess find me worthy.” — Sola is a caring and nurturing Thark, which makes her a pariah in the cruel Thark society. She is often at odds with the Thark way of life because she thinks with her heart, not her head. She is the runt of the litter and is given the responsibility of stewarding John Carter after he is adopted by the tribe.\nSARKOJA (Polly Walker) — “Sola can take the little white worm.” — Sarkoja is the ideal Thark; calculating, cold and cruel. Like Tal Hajus, she believes that only the strong should survive, and she has survived a long time. She targets Sola at every opportunity for she has no patience with Sola’s humanity, which she perceives as weakness.\nWOOLA — “Woola would find you anywhere on barsoom,” sola to john carter — Woola is a Calot, a large, lizard-like dog, that takes John Carter as his master. Calots are incredibly fast with 10 legs and a mouth full of sharp teeth. Woola is fiercely protective of Carter for he is the first person to ever come to his rescue.\n‘JOHN CARTER’ FUN FACTS\n- ‘John Carter’ is based on Edgar Rice Burroughs’ first novel, A Princess of Mars. An American writer, Burroughs was born in Chicago and is best known for writing and creating Tarzan — still one of the most successful and iconic fictional creations of all time.\n- 2012 marks the 100th anniversary of the character John Carter, the original space hero featured in Edgar Rice Burroughs’ Barsoom series. Heroic John Carter has thrilled generations with his adventures on Mars.\n- Since 1935, various filmmakers have attempted to make a movie based on A Princess of Mars — the first was intended to be an animated feature film by Bob Clampett of ‘Beany and Cecil’ fame. If it had been made, it would have been America’s first full-length animated film, prior to Disney’s Snow White and the Seven Dwarfs, which premiered in 1937.\n- A fan of Edgar Rice Burroughs’ Barsoom series of books since childhood, Director/Writer Andrew Stanton says he was inspired to bring John Carter to the big screen—in his first foray into live action—because he had always been attracted to the concept of a human finding himself on Mars, among the creatures of a strange new world.\n- John Carter screenwriters Andrew Stanton, Mark Andrews and Michael Chabon discovered they had something in common when they met: they all still possessed the John Carter drawings and artwork that they had done when they were boys.\n- Filming of John Carter began in the UK on January 4, 2010. The bulk of the movie’s stage work (along with exterior sequences set on Earth) was filmed at Shepperton Studios, London and Longcross Studios in Chelburn, over a four-month period. Then production moved to Utah for an additional 12 weeks of shooting, with locations in Moab, Lake Powell, the Delta salt flats, Hanksville (where the US space agency, NASA, has tested robotic vehicles), and Big Water—a vast mesa of granulated shale and sandstone set before a towering ring of red cliffs that border the Grand Staircase National Monument.\n- On Saturday, June 5, 2010, crewmembers, working on location in Utah, found a large bone protruding from the ground. The Bureau of Land Management confirmed it was in fact a Sauropod bone — either a femur or scapula — from a dinosaur that could have been 60 feet in length. An excavation is currently taking place to retrieve the rest of the prehistoric skeleton discovered by the John Carter crew.\n- Battling the extreme conditions of the desert, the film unit worked in temperatures in excess of 120 degrees in Hanksville, Utah, and consumed over 360 gallons of water per day.\n- Lake Powell, Utah, the location used for the River of Iss in the film, is over 180 miles in length and has over 2,000 miles of shoreline — more than the whole of the west coast of America.\n- For the battle scenes between the Zodangans and the Heliumites, over 1000 extras were given a professional, if slightly darker than average, St. Tropez fake tan.\n- The Ancient Barsoomian typography carved into the walls of the sacred temples in John Carter took their original design from actual markings found on the surface of the planet Mars.\n- Working from the original source material, a linguist was hired to create the entire Thark Martian language, using just a few words mentioned in Edgar Rice Burroughs’ novels.\n- The actors playing the nine-foot tall, green Thark characters had to learn to walk on stilts to film the scenes with John Carter, giving the correct eye-line contact for the dialogue.\n- Over 120,000 Swarovski crystals were used in Dejah Thoris’ Zodangan wedding outfit, including her dress, the train, crown and cuffs, and each stone was applied by hand one by one.\n- Stunt Coordinator Tom Struthers was delighted and amazed that Taylor Kitsch did 98% of his own stunt work, including an 85-foot jump in the learning-to-walk sequence, a 65-foot jump in the arena, battling the ferocious white apes, and a 250- foot long series of jumps in the Martian wilderness.\n- Cinema audiences will be astonished to see actress Lynn Collins, when not donning her Dejah Thoris look, has strawberry blonde hair and fair skin.\n- The approximate number of costumes designed by Mayes C. Rubeo for the film was 1,800.\n- 383 yards of material were used for just one of Matai Shang’s silver Thern robes and the robe took approximately 250 man-hours to make by hand.\n- While filming in Utah, the film crew came across a small space center called the Mars Society Desert Research Station. No one was home but the Website reads: “Teams of hard-working volunteers, working in full simulation mode in the barren canyon lands of Utah, continue to explore the surrounding terrain, cataloging more waypoints, and analyzing the geology and biology of this fascinating and remarkably Mars-like region.”","A United Kingdom\nA United Kingdom is a 2016 British biographical romantic drama film directed by Amma Asante and written by Guy Hibbert, based on the true-life romance between Seretse Khama, heir to the throne of Bechuanaland (later Botswana, of which he was President), and his wife Ruth Williams Khama. David Oyelowo and Rosamund Pike portray Seretse and Ruth, respectively.\n|A United Kingdom|\nTheatrical release poster\n|Directed by||Amma Asante|\n|Screenplay by||Guy Hibbert|\n|Based on||Colour Bar|\nby Susan Williams\n|Music by||Patrick Doyle|\n|Edited by||Jonathan Amos|\n|Box office||$13.8 million|\nThe film is based on the true story of the heir to the throne of Bechuanaland, Seretse Khama of the Bamangwato people, who studies law in London immediately after World War II. There he meets a white woman, Ruth Williams, whom he eventually marries, despite the protests of both their families and opposition from the British government, which is concerned about relations with South Africa and the stability of the entire region of southern Africa. The National Party government in South Africa fears that the marriage of a black king to a white woman in neighboring Bechuanaland will inspire unrest, and pressures the British government to end the marriage.\nKhama's uncle, the Regent, demands that he end his marriage to Ruth, and marry a Bamangwato princess, a demand that Khama rejects. The British administrators use the dispute between the King and the Regent to argue that the marriage of Seretse and Ruth is causing unrest in Bechuanaland. Seretse discovers that the British have allowed a US mining corporation to prospect for precious stones, and is eager to make sure that, if anything is found, the exploitation of the country's resources should solely be done by the people of Bechuanaland.\nSeretse wants his people to support him as king and manages to win their backing, while the British government decides to exile him from his own country. Meanwhile, Ruth has their baby in Bechuanaland and becomes accepted by the local people by \"walking the road with them\". When the British want to proclaim an administrator to the Bechuana people instead of their king, the tribe refuses to convene a meeting to do so. The prime minister, Clement Attlee, tells the backbencher Tony Benn, that Britain needs gold from South Africa and he is willing to pay any price such as attempting to destroy the Khamas' marriage to stay in the good graces of South Africa. During this time, diamonds are found and Seretse makes sure that the British government publicly declares that the Bechuana people have the sole right to exploit these resources.\nWinston Churchill promises, if he is elected in the 1951 general election, to lift the exile on Seretse, however, after his victory he turns the five-year ban into a lifelong one. In London, powerful people start supporting Seretse's claim, and he also receives support from the US government. Meanwhile, apartheid develops in South Africa and begins to overshadow Bechuanaland as well. Eventually, with the help of pressure from local people, he is allowed to return to Bechuanaland and negotiates its independence from the British. Seretse shows his uncle a leaked British government document showing he is qualified to be king, and that only opposition from South Africa is motivating the actions of the British government. Post-ending text reveals that Seretse oversees the creation of present-day Botswana, and that their son subsequently becomes the country's fourth elected president in 2008. It is revealed that Ruth and Seretse are buried side by side on a hilltop overlooking Serowe village, where they had lived for the remainder of their lives.\n- David Oyelowo as Sir Seretse Khama\n- Rosamund Pike as Ruth Williams Khama\n- Terry Pheto as Naledi Khama, Seretse's younger sister\n- Vusi Kunene as Tshekedi Khama, Seretse's uncle, who is Regent of the Bangwatho Kingdom\n- Abena Ayivor as Ella Khama, Tshekedi's wife and Seretse's aunt\n- Anton Lesser as Clement Attlee, Prime Minister of the United Kingdom\n- Jack Davenport as Alistair Canning, the British government representative in Southern Africa\n- Jack Lowden as Tony Benn\n- Tom Felton as Rufus Lancaster\n- Charlotte Hope as Olivia Lancaster\n- Nicholas Lyndhurst as George Williams, Ruth's father\n- Anastasia Hille as Dot Williams, Ruth's mother\n- Laura Carmichael as Muriel Williams-Sanderson, Ruth's sister\n- Jessica Oyelowo as Lady Lilly Canning\nPike joined the cast in May 2015, with Asante joining shortly afterwards. In September 2015 Asante revealed that shooting would be split between Botswana and London, and that it would begin in October in preparation for a 2016 release coinciding with the 50th anniversary of independence in Botswana.\nIn October 2015 actors Jack Davenport and Tom Felton joined the cast. In November 2015 some filming took place around Hyde Park/Kensington Gardens including Imperial College Union. The cinematographer was Sam McCurdy and the production designer was Simon Bowles.\nThe film had its world premiere at the Toronto International Film Festival on 9 September 2016. It will also screen at the BFI London Film Festival on 6 October 2016. Shortly after, Fox Searchlight Pictures acquired U.S distribution rights to the film.\nA United Kingdom grossed $3.9 million in the United States and Canada and $9.9 million in other countries for a worldwide total of $13.8 million, against a production budget of $14 million.\nOn review aggregator website Rotten Tomatoes, the film has an approval rating of 84% based on 150 reviews, with an average rating of 6.8/10. The website's critical consensus reads, \"Well-acted, solidly crafted, and all-around worthy, A United Kingdom presents an absorbing look at a singular true-life love story.\" On Metacritic, the film has a weighted average score of 65 out of 100, based on 41 critics, indicating \"generally favourable reviews\".\nGlen Kenny, in The New York Times, described the filmmaking as \"staid\" but with \"an acute sense of pace\". He was complimentary about the performances and described Oyelowo's as \"remarkable, genuinely riveting work\". In Time Out, Tom Huddleston wrote that \"David Oyelowo and Rosamund Pike are strong in this compelling and moving, if basic, true-life tale\" but that the film \"is just a little too cosy and sentimental for its own good.\"\n- \"A United Kingdom (2016)\". British Film Institute. Retrieved 23 July 2017.\n- Goldberg, Matt (26 August 2016). \"'A United Kingdom' Trailer: David Oyelowo and Rosamund Pike Take on the British Empire\". Collider. Complex Media. Retrieved 23 July 2017.\n- \"A United Kingdom\". Pathe Productions. Retrieved 13 October 2017.\n- \"A UNITED KINGDOM (12A)\". British Board of Film Classification. 7 September 2016. Retrieved 9 September 2016.\n- Campbell, Christopher (11 December 2017). \"The Disaster Artist' and 'I, Tonya' make their mark in an otherwise poor year for biographical movies\". Film School Rejects. Retrieved 26 June 2018.\n- \"A United Kingdom\". Box Office Mojo. IMDb. Retrieved 9 March 2017.\n- Kit, Borys (26 May 2015). \"'Belle' Filmmaker to Direct David Oyelowo, Rosamund Pike in 'A United Kingdom' (Exclusive)\". The Hollywood Reporter. Prometheus Global Media. Retrieved 22 September 2015.\n- Jaafar, Ali (26 July 2016). \"Toronto To Open With 'The Magnificent Seven'; 'La La Land', 'Deepwater Horizon' Among Galas & Presentations\". Deadline Hollywood. Penske Business Media. Retrieved 26 July 2016.\n- Korsner, Jason (21 June 2016). \"A United Kingdom To Open London Film Festival 2016\". What's Worth Seeing... Retrieved 21 June 2016.\n- Jaafar, Ali (8 May 2015). \"Rosamund Pike In Talks To Join David Oyelowo In 'A United Kingdom' : Cannes\". Deadline Hollywood. Penske Business Media. Retrieved 11 October 2015.\n- Malefho, Lame (24 September 2015). \"Batswana being auditioned for Sir Seretse Khama movie\". The Botswana Gazette. Retrieved 11 October 2015.\n- Barraclough, Leo (10 October 2015). \"'Pirates of the Caribbean' Star Jack Davenport Boards Amma Asante's 'A United Kingdom' (EXCLUSIVE)\". Variety. Penske Business Media. Retrieved 11 October 2015.\n- \"A United Kingdom\". Toronto International Film Festival. Retrieved September 15, 2016.\n- Barraclough, Leo (21 June 2016). \"Amma Asante's 'A United Kingdom' to Open BFI London Film Festival\". Variety. Penske Business Media. Retrieved 15 September 2016.\n- \"A United Kingdom\". BFI London Film Festival. British Film Institute. Archived from the original on 28 September 2016. Retrieved 15 September 2016.\n- Lang, Brent; Seetoodeh, Ramin (15 September 2016). \"Toronto: Fox Searchlight in Final Talks for 'A United Kingdom' (EXCLUSIVE)\". Variety. Penske Business Media. Retrieved 15 September 2016.\n- Murthi, Vikram (25 August 2016). \"'A United Kingdom' Trailer: David Oyelowo and Rosamund Pike Fight For Love & Country\". IndieWire. Penske Business Media. Retrieved 1 October 2016.\n- Pederson, Erik (September 30, 2016). \"Fox Searchlight Bringing 'A United Kingdom' To North America\". Deadline Hollywood. Penske Business Media. Retrieved September 30, 2016.\n- Morales, Wilson (19 December 2016). \"Fox Searchlight To Release Amma Asante's 'A United Kingdom' On Feb. 6, 2017 at The Paris Theatre in New York City\". Black Film. Retrieved 20 December 2016.\n- \"A United Kingdom (2016)\". Rotten Tomatoes. Fandango. Retrieved 24 August 2018.\n- \"A United Kingdom Reviews\". Metacritic. CBS Interactive. Retrieved 19 March 2017.\n- Kenny, Glen (9 February 2017). \"Review: 'A United Kingdom' With Love That Tested Racial Tolerance\". The New York Times. The New York Times Company. Retrieved 21 October 2017.\n- Huddleston, Tom (10 September 2016). \"A United Kingdom\". Time Out London. Time Out Group. Retrieved 21 October 2017."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:62b8f865-0fc2-4a67-bb0a-cb42d6b17e52>","<urn:uuid:b928645e-06e8-4bbf-b14f-4d464ab8616b>"],"error":null}
{"question":"How do environmental factors affect both textile weaving patterns and marine adhesive performance, particularly in terms of visual appearance and structural stability?","answer":"In textile weaving, environmental factors like thread positioning create visual effects - for instance, black warp ends from the bottom layer being raised to the surface create stripe-like patterns that change with each pick of the pattern. For marine adhesives, environmental conditions significantly impact performance - testing shows that high temperatures and humidity (40°C and 80% relative humidity) reduce fatigue resistance compared to room temperature (23°C), while low temperatures (-40°C) actually increase fatigue resistance. These environmental considerations are crucial for both aesthetic outcomes in weaving and structural integrity in marine applications.","context":["July has been a very busy time, what with all the watering (it’s been hot and dry), squishing of bugs, and weeding, not to mention flax harvesting. However, I recently did a tiny bit of weaving for my double-weave study group with the Pioneer Valley Weavers Guild, led by the elegant and brilliant Barbara Elkins.\nDoubleweave is a versatile technique that lets you weave two layers of cloth at the same time. The layers can be joined at the right or left edges, joined at both edges, they can be totally separate, or they can exchange periodically (i.e., the bottom layer comes to the top and the top layer goes to the bottom). Our samples used four shafts, which is the minimum number you need.\nThe whole process has been full of visual surprises, beginning with winding the warp. For our samples, we wound a warp with two alternating colors. I chose black and white for maximum contrast. On the left, below, is the cross with my counting thread. You can see the separation of the white and black layers. On the right is the warp as I was beaming on. The alternating black and white ends get sorted into their respective layers when they go through the lease sticks. In the section of the warp that hasn’t yet been beamed on there is a cool transition between where they alternate and where they become separated. I warp back to front, so this un-separated section is in the front of the loom.\nHere is how the warp looked passing through the lease sticks (which maintain the cross, which keeps the threads in order). This is towards the back of the loom.\nThe first sample I did on this warp was Colonial doubleweave. This technique takes an overshot draft and translates it into a plain weave, doubleweave structure. Usually with overshot, weft floats (threads on the surface of the cloth that travel over more than one warp end) make the pattern, but they can get long and impractical. With traditional overshot, the cloth is stabilized with alternating rows or picks of plain weave (called tabby) to form the ground that holds the cloth together. In plain weave, the weft passes over one warp end, then under one, so it has no long floats.\nWith the doubleweave version of overshot, the pattern is made by the intersection of the bottom and top layers of the cloth. There are no long floats. The cloth is a little dense because it’s two layers woven together, but you sett it more loosely than you would for regular plain weave. I used 5/2 cotton for these samples.\nHere is one of my overshot samples still on the loom. The warp isn’t striped, even though it looks that way. The stripes appear because some black warp ends from the bottom layer are raised to the surface with each row, or pick, of the pattern. In the last pick at the fell line (top of the cloth) you can see where I just wove these parts of the pattern. I like how it looks as if the warp threads are zooming into the cloth (well, they are in a sense). As soon as you change sheds, these stripes disappear, to be replaced by the next set of pattern threads.\nHere’s a finished sample hanging up outside. Yes I have a couple weft skips. It’s hard to avoid when you can’t see the underside of your cloth. Depending on which color weft you use, and which side of the cloth you look at, you get different effects.","By J.R. Weitzenböck (Eds.)\nAs a mode of becoming a member of with financial, performance-related and environmental merits over conventional welding in a few functions, adhesive bonding of joints within the marine setting is more and more rising in popularity. Adhesives in marine engineering offers a useful review of the layout and use of adhesively-bonded joints during this demanding environment.\nAfter an advent to using adhesives in marine and offshore engineering, half one specializes in adhesive resolution layout and research. the method of choosing adhesives for marine environments is explored, through chapters discussing the explicit layout of adhesively-bonded joints for send functions and wind generators. Predicting the failure of bonded structural joints in marine engineering can also be thought of. half reports trying out the mechanical, thermal and chemical homes of adhesives for marine environments including the moisture resistance and sturdiness of adhesives for marine environments.\nWith its amazing editor and overseas crew of specialist individuals, Adhesives in marine engineering is a vital advisor for all these fascinated with the layout, construction and upkeep of bonded constructions within the marine atmosphere, in addition to proving a key resource for educational researchers within the field.\n- Provides a useful evaluation of the layout and use of adhesively-bonded joints in marine environments\n- Discusses using adhesives in marine and offshore engineering, adhesive resolution layout and research, and the layout of adhesively-bonded joints for send purposes and wine generators, between different topics\n- Reviews trying out the mechanical, thermal and chemical houses of adhesives for marine environments, including the moisture resistance and sturdiness of those adhesives\nRead or Download Adhesives in Marine Engineering PDF\nSimilar polymers & textiles books\nMan made fibers account for approximately half all fiber utilization, with functions in each box of fiber and cloth know-how. even though many periods of fiber according to man made polymers were evaluated as probably important advertisement items, 4 of them - nylon, polyester, acrylic and polyolefin - dominate the industry.\n\"Written for graduate scholars, researchers, and practitioners, this booklet presents an entire advent to the technological know-how, engineering, and advertisement purposes of polymer-clay nanocomposites. beginning with a dialogue of basic strategies, the authors outline particular phrases utilized in the sphere, delivering novices with a powerful origin to the realm.\nThat allows you to adapt the homes of dwelling fabrics to their organic features, nature has built exact polyelectrolytes with notable actual, chemical and mechanical habit. particularly polyampholytes will be appropriate components to version protein folding phenomenon and enzymatic task so much of organic macromolecules as a result of the presence of acidic and simple teams.\nA desirable perception into why polymer items fail, and the way we will examine from the error of the earlier. This e-book describes many of the mechanisms of polymer degradation, and illustrates every one failure mechanism with a few case stories. This e-book used to be written with the aid of the united kingdom division of alternate and undefined.\n- Recent Advances in Smart Self-Healing Polymers and Composites\n- Handbook of antiblocking, release, and slip additives\n- Fatigue and Tribological Properties of Plastics and Elastomers\n- Application of Fracture Mechanics to Polymers, Adhesives and Composites, Volume 33\nExtra info for Adhesives in Marine Engineering\n1 Cross-section of a rotor blade (schematic). Adhesive joints are shown as hatched areas. See text for further details. 2 Requirements for adhesively bonded joints for wind rotor blades Rotor blades are usually designed for a service life of 20 years. Within this time span, materials and joints are subject to 108–109 load cycles due to wind and waves. In order to avoid fatigue cracks which may develop at such high cycle numbers, stresses need to be kept sufficiently low. This is usually referred to as high cycle fatigue (HCF).\nAttachment of bulkheads to the hull shell and hull transverse frames including the structural fillet prior to overlamination. 4 shows the structural fillet in a transverse frame. • Attachment of deck and wheelhouse longitudinal and transverse stiffeners. The RNLI typically use the top hat type but L flange type stiffeners have also been used. © Woodhead Publishing Limited, 2012 38 • • • Adhesives in marine engineering Connection of structural soles to hull/wheelhouse. This is largely by gluing the sole bearers to the hull with the soles then being glued to the bearers.\nData of a two-part methacrylate adhesive tested at different environmental conditions are depicted in Fig. 3. 2 using un-notched bulk adhesive tensile bars. The nominal tensile stress is shown. At 40°C and 80% relative humidity, the S–N curve is located beneath the S–N curve measured at 23°C, whereas at −40°C, the S–N curve is located above the S–N curve measured at 23°C. This indicates that low temperatures increase fatigue resistance and high temperatures reduce fatigue resistance with respect to room temperature."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:c4417536-1499-47ad-bf53-a653234876bd>","<urn:uuid:f4d151df-bfc6-460a-aba0-2aab7b9ec230>"],"error":null}
{"question":"How do hot air balloons achieve flight capability, and which type of lithium battery would be most suitable for their navigation equipment?","answer":"Hot air balloons achieve flight through the use of heated air in a large, tough nonrigid bag with a car attached for aerial navigation. Based on the battery requirements for navigation equipment, lithium iron phosphate batteries would be most suitable due to their high safety profile, long life, and good discharge capacity. These batteries are commonly used in power and energy storage applications, making them ideal for aviation equipment. Additionally, they have lower environmental impact compared to other lithium batteries since their positive electrode material doesn't contain heavy metals.","context":["Definitions for balloonbəˈlun\nThis page provides all possible meanings and translations of the word balloon\nlarge tough nonrigid bag filled with gas or heated air\nsmall thin inflatable rubber bag with narrow neck\nride in a hot-air balloon\n\"He tried to balloon around the earth but storms forced him to land in China\"\nballoon, inflate, billow(verb)\n\"The sails ballooned\"\nAn inflatable buoyant object, often (but not necessarily) round and flexible.\nSuch an object as a childu2019s toy.\nSuch an object designed to transport people through the air.\nA sac inserted into part of the body for therapeutic reasons; such as angioplasty.\nA speech bubble.\nA type of glass cup, sometimes used for brandy.\nTo increase or expand rapidly.\nTo go up or voyage in a balloon.\nOrigin: 1570, \"a game played with a large, inflated leather ball\" (possibly via ballon) from pallone \"large ball\" from palla \"ball\", of origin, from palla \"ball\" from ballô, from bholn-, from . Akin to Old High German ballo, bal \"ball\" ( Ballen \"bale\"; Ball \"ball\"). More at ball.\na bag made of silk or other light material, and filled with hydrogen gas or heated air, so as to rise and float in the atmosphere; especially, one with a car attached for aerial navigation\na ball or globe on the top of a pillar, church, etc., as at St. Paul's, in London\na round vessel, usually with a short neck, to hold or receive whatever is distilled; a glass vessel of a spherical form\na bomb or shell\na game played with a large inflated ball\nthe outline inclosing words represented as coming from the mouth of a pictured figure\nto take up in, or as if in, a balloon\nto go up or voyage in a balloon\nto expand, or puff out, like a balloon\nA balloon is a flexible bag which can be inflated with a gas, such as helium, hydrogen, nitrous oxide, oxygen, or air. Modern balloons are made from materials such as rubber, latex, polychloroprene, or a nylon fabric, while some early balloons were made of dried animal bladders, such as the pig bladder. Some balloons are used for decorative purposes, while others are used for practical purposes such as meteorology, medical treatment, military defense, or transportation. A balloon's properties, including its low density and low cost, have led to a wide range of applications. The rubber balloon was invented by Michael Faraday in 1824, during the course of experiments with various gases.\nChambers 20th Century Dictionary\nbal-lōōn′, n. an inflated air-tight envelope of paper or silk, constructed to float in the air and carry a considerable weight when filled with heated air or light gas: anything inflated, empty: (obs.) a game played with a large inflated ball.—v.i. to ascend in a balloon: to puff out like a balloon.—n. Balloon′ist, an aeronaut. [It. ballone, augmentative of balla, ball.]\nBritish National Corpus\nRank popularity for the word 'balloon' in Nouns Frequency: #2963\nThe numerical value of balloon in Chaldean Numerology is: 1\nThe numerical value of balloon in Pythagorean Numerology is: 8\nSample Sentences & Example Usage\nWhen we found out it was like a balloon deflating.\nThey want to let go of the balloon and see how markets respond.\nThis is a trial balloon, it's an opening in the overall discussion.\nIf you stuck a balloon over the leak, it would fill up the Rose Bowl.\nThis is like a balloon, it can be popped or it can be a real growth spurt. It's entirely the responsibility of The JRFU.\nImages & Illustrations of balloon\nTranslations for balloon\nFrom our Multilingual Translation Dictionary\n- منطاد, بالونArabic\n- şar, balonAzerbaijani\n- балон, издувам се, аеростатBulgarian\n- globus, balóCatalan, Valencian\n- ballon, luftballonDanish\n- Ballon, Heißluftballon, LuftballonGerman\n- αερόστατο, μπαλόνιGreek\n- õhupall, kuumaõhupallEstonian\n- puxika, globoBasque\n- پوقانه, بالون, بادکنکPersian\n- laajeta, kuumailmapallo, pullistua, vappupallo, kasvaa, ilmapalloFinnish\n- montgolfière, ballon, ballon gonflable, ballon de baudruche, ballon en baudrucheFrench\n- boulHaitian Creole\n- lufi, hőlégballon, léggömbHungarian\n- փուչիկ, օդապարիկArmenian\n- balon, balon udaraIndonesian\n- blaðra, loftbelgurIcelandic\n- 気球, 風船, バルーンJapanese\n- ჰაერბურთი, აეროსტატიGeorgian\n- ballonngiKalaallisut, Greenlandic\n- 氣球, 기구Korean\n- pifdank, balon, بالۆنKurdish\n- balonus, BalloonLatin\n- oro balionas, balionasLithuanian\n- balons, gaisa balonsLatvian\n- агаарын бємбєлєгMongolian\n- gelembungan, gelembung, belonMalay\n- ballon, luchtballonDutch\n- ballong, luftskip, luftballongNorwegian\n- bexiga, balãoPortuguese\n- воздушный шар, баллон, аэростат, шарикRussian\n- balonë, aerostatAlbanian\n- ballong, luftballongSwedish\n- mabofu, putoSwahili\n- howa sharyTurkmen\n- balun, loboTagalog\n- bälun, lutabälunVolapük\n- ipaloni, ibhaloniZulu\nGet even more translations for balloon »\nFind a translation for the balloon definition in other languages:\nSelect another language:","Pros and cons among different lithium batteries\nNot only smartphones and laptops, but even bicycles and cars, all kinds of tools we use in our daily life are powered by electricity. Improving battery performance has important implications for improving the ease of use of these devices. Among them, lithium batteries have attracted the attention of the industry in recent years.\nHere we talking about the classification and application of different lithium batteries\n1. What is a lithium battery\nStrictly speaking, lithium batteries are divided into two types: lithium metal batteries and lithium ion batteries. This is defined according to the form in which lithium exists.\nLithium metal batteries use metal lithium as the electrode, while lithium ion batteries exist in the electrode in the form of ions. Lithium metal batteries generate electricity through the corrosion or oxidation of metal lithium, and they are useless when they are used up and cannot be charged, so they are also called primary batteries.\nLithium-ion batteries are a type of rechargeable batteries that use graphite or other carbon materials as the negative electrode and lithium-containing compounds as the positive electrode, so they are also called lithium secondary batteries. It is a type of battery that uses lithium metal or lithium alloy as the positive/negative electrode material and uses a non-aqueous electrolyte solution.\n2. The classification and characteristics of lithium-ion batteries\nAccording to the different metal materials used in the positive electrode, lithium-ion batteries are divided into several types. The metal material used in the positive electrode of the original lithium-ion battery is cobalt. However, the output of cobalt is almost as small as lithium, and it is also a rare metal with high manufacturing costs. Therefore, cheap and environmentally friendly materials such as metals such as manganese, nickel, and iron have been used.\nLithium-ion batteries are classified according to the materials they use. Let's take a look at the characteristics of each type.\nCobalt lithium-ion battery\nUse Lithium cobaltate for the positive electrode. Lithium cobaltate is relatively easy to synthesize and easy to use, so the earliest mass production of lithium-ion batteries is lithium-cobaltate batteries. But because cobalt is a rare metal and expensive, it is hardly used in auto parts.\nManganese lithium-ion battery\nUse lithium manganate for the positive electrode. The advantage is that the voltage can be similar to that of cobalt lithium-ion batteries, and the manufacturing cost is cheap. The disadvantage is that manganese may melt into the electrolyte during charging and discharging, shortening the life of the battery.\nIron phosphate lithium-ion battery\nUse lithium iron phosphate for the positive electrode. The advantage of the iron phosphate lithium-ion battery is that it is difficult to damage the internal heating structure, has high safety, and uses iron as the raw material, so the manufacturing cost is lower than that of the manganese lithium-ion battery. But the voltage is lower than other Lithium-ion batteries.\nTernary lithium-ion battery\nThe ternary lithium-ion battery is a battery made of three materials, cobalt, nickel, and manganese, in order to reduce the amount of cobalt used. At present, most of the ternary lithium-ion batteries have a high proportion of nickel. Although the voltage is slightly lower than that of cobalt-based and manganese-based, it can reduce manufacturing costs. However, despite this, the synthesis and preparation of each material is difficult, and the stability is low, and there are still problems to be solved as practical materials.\n3. Lithium battery pollution\nAccording to the composition of the lithium battery, lithium iron phosphate in the positive electrode material does not contain heavy metals and basically has no pollution, while lithium manganese, ternary lithium, and lithium cobalt have heavy metal elements (manganese, cobalt, nickel) and have heavy metal pollution. Compared with lead-acid and nickel-chromium batteries, lithium iron phosphate battery’s pollution is very small, but for the environment, chemicals are still harmful.\nThe electrolyte is composed of organic solvents and lithium salts. Organic solvents generally include PC, EC, DEC, DMC, DME, etc., among which DMC is slightly toxic, and others are non-toxic. The lithium salt is lithium hexafluorophosphate (the most used, and there are other lithium salts), it will be hydrolyzed into HF when it meets water, which is poisonous. The shell, diaphragm adhesive will cause white pollution, and the rest of the battery materials can be recycled without pollution.\nWe don't need to be careful about environmental pollution when we use batteries normally, but we need to pay attention to recycling when used batteries are scrapped to prevent the leakage of battery materials from causing pollution and burden to the environment.\n4. Working performance comparison(cell)\n5. Lithium battery application\nLithium cobalt : Because of its excellent energy density, it has a smaller weight and volume under the same energy and is used as a small energy battery, becoming a popular choice for mobile phones, notebook computers and digital cameras.\nLithium manganate: Although the overall performance is average, industrial applications require a battery system with good load capacity, long life, and safety. It’s commonly used in power tools, medical equipment, electric transmission systems, etc.\nLithium iron phosphate: It has good safety and long life, moderate energy density and strong discharge capacity, and is used as power lithium battery and energy storage battery.\nTernary lithium: It has high energy density and low temperature resistance, the biggest application is in new energy vehicles, such as Tesla's ternary lithium power battery.\nAbove we talked about the five aspects of lithium batteries, each of which has its own unique advantages and has a very wide range of applications in individual fields.\nOf course, now and in the future, different lithium batteries will appear and be applied in more fields, providing continuous development for the new energy industry."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:01907c29-45d7-4059-ad49-2f44ca868756>","<urn:uuid:62b575df-76d9-4e6e-905f-3a3cb5b98153>"],"error":null}
{"question":"Compare audience reach: 1920s Broadway theatres vs historic Paris cinemas - which had larger capacity?","answer":"Based on the information provided, 1920s Broadway had greater audience capacity. By 1928, Broadway reached its peak with 76 theaters putting on 264 shows in one season. In contrast, Paris' largest historic cinema, Le Grand Rex, had a capacity of 2,800 seats in its Grande Salle, while other mentioned Paris cinemas like Le Louxor had around 1,000 seats. Additionally, Broadway was highly accessible via mass transportation, allowing thousands of potential audience members to attend shows daily.","context":["What was the heyday of Broadway? When was New York thick and rich with Broadway theatres? From 1918 through 1928, there was a major building boom on Broadway. That boom occurred between the end of World War I and the start of the Great Depression/ World War II. In 1918, there were 48 Broadway theatres. By 1928, that number peaked at 76. After that it was all downhill. What was the cause of the Broadway theatre building boom? What was Broadway like back then?\nAmerica Turns Inward\nAfter World War I, America turned its focus away from Europe and the great carnage that had occurred and towards life in the U.S. We became isolationists and with that we became very interested in what we could accomplish. This included a focus on all types of art, including theatre. This is an amazingly active time in the theatre world.\nEugene O’Neill, Susan Glaspell, Edna St. Vincent Millay and others created a theatre group known as the Provincetown Players. They were one of many little theatre groups that sprung up across the U.S., creating new works for the theatre. The Little Theatre Movement started in 1912 and by 1918 some of those groups, the two most prominent being the Provincetown Players and the Washington Square Players went professional. (Member of the Washington Square Players formed The Theatre Guild.)\nThe Little Theatre Movement was dedicated to doing smaller, more innovative productions and was a reaction against Broadway. However, many of those in the movement would become an important part of the Broadway boom, as they matured as playwrights, directors and designers and became professionals.\nImmigration and Migration\nThere was also a great influx of immigrants from Europe. Between 1910 and 1920 about 14.5% of the U.S. population was from other countries and between 1850 and 1930 about 25 million came from Europe to the U.S. One of the largest immigration periods was the decade starting in 1910. Immigrants sought out their own people, language and culture. In New York, there were Irish, Italian, Yiddish and other such theatres. This created a theatergoing population and those stages also helped develop up and coming professional talent.\nAlso, it was a lot easier for people to access big cities and New York with its mass transportation system was now easy for those outside of the city to get to. That meant there were thousands more potential audience members in New York each day who could go to a show and then travel home that night.\nFinally, there was a major economic resurgence after the war, which meant more cash to be spent on a night out at the theatre. By the way, you didn’t have to be rich to go to the Broadway theatre. For less than a dollar you could get a good seat to a hit show. Plus, there was a lot of big money around and that was cash that could be invested in new shows. In 1918, there were 156 Broadway productions, and by the end of the theatre season in 1928, there were 264 shows on The Great White Way. (That number still stands as the one-year record.)\nThe Jazz Age, the 1920s, was a time when people had a lot of expendable income. Much of that cash was spent on going out and a night out in NYC could include dinner, theatre and dancing. The stock market crash in 1929 would mark the end of the Jazz Age as well as the end of the theatre building boom. Many Broadway houses would become movie houses, and eventually they might be turned into TV studios. With the advent of the talking (and singing) picture, audiences could stay in their hometown and see a film that rivaled the expansiveness or a New York show. Broadway would not die, but in the decades to come it would certainly be on life support.","Beautiful Historic Cinemas You Must Visit in Paris\nParis has been featured prominently on the silver screen, but its importance in cinema history is more than just an on-screen star. The first ever public film screening was held in the City of Light in 1895, instantly sparking a strong national love of cinema. The once-200 cinemas have gradually dwindled to less than half, but thankfully—in an age of multiplexes—a third of these are still independently run (and have played a vital role in the careers of filmmakers such as Jean Cocteau and Francois Truffaut). Here are some of the most intriguing and historic independent cinemas across the French capital.\nCinéma du Panthéon: In the heart of the Latin Quarter, the Panthéon, opened in 1907, is the oldest functioning movie theater in Paris. It was bought in 1929 by Pierre Braunberger, a producer who “discovered” Nouvelle Vague icons like Jean-Luc Godard, Jean-Pierre Melville, and Alain Resnais. Braunberger avidly promoted the French New Wave, while also being one of the first to show foreign films in their original language. A special highlight of the theater is its living room-esque “salon,” designed by on-screen legend Catherine Deneuve in 2006. (13 rue Victor-Cousin)\nLe Champo: First stop for many cinéphiles, the Champo is a Parisian film institution. Established in 1938, it boasts a screening room with an unusual mirror-based “periscope” projection technology that allows for the projector and the screen to be housed in different floors of the building. It has attracted local Sorbonne students and former President François Mittérand (who lived nearby), in addition to being considered by François Truffaut as his “headquarters” and Claude Chabrol his “second university.” (51 rue des Écoles)\nLa Pagode: Of all the movie theaters in Paris, the Pagoda least resembles a cinema. This much-loved secret site of the Left Bank was originally offered as a gift by the director of the Bon Marché department store to his wife in 1895 at the height of French Sinophilia and Japanophilia. The building was imported piece by piece from Japan and was initially used mainly for receptions. It was converted into a cinema in 1931 and became an important feature of the film landscape in the 1950s and 60s, with screenings of movies by Ingmar Bergman, Jean Cocteau, as well as the Nouvelle Vague’s Jacques Rozier and François Truffaut. Today it features art house international movies which can be discussed afterwards over tea in the lush Japanese garden. (57 bis, rue de Babylone)\nLe Grand Rex: The Grandest of Parisian historic cinemas, this Art Deco palace features the largest screening room in Europe: la Grande Salle, with 2800 seats. Its pillared tower, dazzlingly advertising its location on Les Grands Boulevards, has been drawing in crowds since it was completed in 1932. Inspired by American movie theatres of the time, its vast baroque interior includes a starry night sky adorning the 100-foot-high ceiling of the grande salle, along running fountains and reliefs evoking an old Mediterranean village. Its days darkened during the Occupation when the cinema was requisitioned by the German army and reserved exclusively for German soldiers. While the programming includes mainly blockbusters (and concerts), the cinema is still independently owned and just the sight of it takes cinephiles back to another era. (1 blvd. Poissonière)\nLe Studio 28: A quiet street in Montmartre hides the cinema with probably the most tumultuous history: the Studio 28. Dubbed “the cinema of masterpieces, the masterpiece of cinemas” by Jean Cocteau, Studio 28 opened in 1928 with Abel Gance’s “Napoléon” and by 1930, it was already making headlines. On November 29th of that year, Studio 28 premiered Luis Bunuel and Salvador Dali’s provocative film entitled “L’Age d’or,” a project intended to criticize the Roman Catholic Church and its strict views on sexuality. The film caused such a furor that “L’Age d’or” was banned after less than a week and Studio 28 was ransacked by right-wing rioters who went so far as to destroy artwork by Joan Miro, Dali, Max Ernst, Man Ray, and Tanguy that had prominently occupied the lobby. Fortunately, the cinema survived the uproar and today it’s perhaps best known for its cameo in the 2001 international success Amélie. (10 Rue Tholozé)\nLe Louxor: There’s been much talk about Le Louxor since its reopening in April 2013. Inaugurated in 1921, its appearance lives up to its name; a neo-Egyptian façade highlighted by colorful mosaics with floral/exotic animal motifs greets filmgoers as they enter the renovated theater. At the time, it was one of the largest cinemas in the city with just over 1,000 seats. While it originally screened French and American movies, the 1970s saw the cinema turn toward Indian and Arab films in keeping with the population of the neighborhood. A shift occurred in the late 1980s with the Louxor transformed into the biggest gay nightclub in Paris before being largely abandoned for a decade. It was bought by the city of Paris in 2003—and is proof that the projection camera is not about to be shut off on the city’s film scene just yet. (10 Rue Tholozé)"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:d88d7b43-4099-4034-b0b6-7a674b23fc4f>","<urn:uuid:e213a30b-a738-4247-a02f-4f3da494e4f3>"],"error":null}
{"question":"What are the key functions of the bump handle in a Hayward Perflex D.E. filter, and what are the advanced monitoring solutions available for maintaining optimal filtration performance?","answer":"The bump handle in a Hayward Perflex D.E. filter serves to shake D.E. powder from the filter fingers inside the tank. When lifted up and down, it moves the tube sheets, causing the D.E. to loosen and move around inside the filter tank. This process is essential for regeneration, which allows reuse of existing D.E. without replacement. For monitoring filtration performance, advanced solutions include Inline Particle Counters (IPC) for real-time monitoring, Inline Viscosity Sensors (IVS), and Inline Water Sensors (IWS). Some sophisticated systems even use sensors that measure changes in fluid's dielectric characteristics to detect particle contamination, water presence, or depleted additives, continuously monitoring fluid condition and alerting to any changes.","context":["Hayward Perflex D.E. Filters: Bumping Vs Back Washing\nThe Hayward Perflex D.E. Pool Filter operates in a different way then most D.E. pool filters. This type of filter cannot only be back washed but the filter also has an option called “regeneration” which allows you to get the most from your D.E. powder. The Perflex filter also has something called a “bump handle” that most D.E. pool filters do not have. This bump handle allows you to shake the D.E. from the pool filter fingers that are inside of the tank.\nThe Hayward Perflex filter has man options that may seem confusing at first, but once you read and learn how to use this type of pool filter you will have no problem keeping your swimming pool clear and blue. You will need a bag of D.E. powder before you can operate this type of pool filter, So if this is your first time working with this type of swimming pool filter, then the first thing you are going to need is a bag of D.E. powder that can be bought online or locally at any pool supply store.\nWhat Does Bumping The Handle Do?\nBumping is when you lift the bump handle on the top of the Perflex filter up and down. When you bump the handle you move the tube sheets inside of the filter up and down which causes the D.E. to loosen up and move around inside of the filter tank.\nWhat Is Back Washing The Filter Mean?\nBack Washing is the process of removing dirt, debris and also D.E. powder from the pool filters tank. This is done using the swimming pool filter systems pump. You first have to bump the handle on top of the filter a few times and then open a valve to back wash the filter. See below for a full lesson on how to properly back wash your Hayward Perflex D.E. Pool Filter.\nHow Does The Hayward Perflex D.E. Pool Filter Work?\nThere are a few main parts that you will always be working with when you operate your Hayward Perflex D.E. swimming pool filter. The main parts are the filter gauge, the bump handle, the back wash valve and you will also need to have a supply of D.E. filter powder. When a filter is brand new or just has been back washed there is no D.E. powder inside of the filter. Inside of the filter is something called “fingers”. These filter fingers are plastic tubes that are covered by mesh that allow the water to flow through them but not the D.E powder.\nWhen you add D.E. powder through the skimmers, the D.E. powder travels through the swimming pool plumbing, then enters the filter where the D.E. powder then coats the filter fingers. Once the filter fingers are coated with D.E. powder the pool water flows through the fingers and then the D.E. powder catches all the debris. Once all of the D.E. inside of the filter gets covered with dirt and debris, it will be time to regenerate or back wash the filter.\nWhat Is D.E. Filter “Regeneration”?\nRegeneration is a bit different than actually back washing the pool filter. When you regenerate you are basically “flipping” & “re-using” the existing D.E. inside of the pool filter. When you back wash you are removing the old D.E. powder from the pool filter and then replacing it with new. Regeneration does not require you to replace the D.E. powder because you are just “bumping” it around and its sticking back to the filter fingers inside of the tank.\nHow To Regenerate The D.E. Inside The Filter\nRegenerating your D.E filter will allow you to get a bit more filtering action from the D.E. inside of the filter tank. The first thing you will want to do is shut the filter system down. Once you have shut the filter system down you will want to bump the handle up and about 10 times and then you will want to turn the filter back on again. What the bump does is loosen all of the D.E inside of the filter, turning it over and then once you turn the filter back on the D.E. re sticks to the filter fingers. You will want to regenerate if you see the flow of your filter start to slow down. If you have regenerated your filter but you still have poor flow, then your best bet would be to just back wash the filter which removes all of the D.E. from the filter.\nHow Often Do I Back Wash My Perflex Filter?\nOn the side of your filter you will have something called a pressure gauge. This pressure gauge measure the amount of pressure that is inside of your pool filter tank. When your filter has just been back washed you should take a look at the number on that gauge and see what your “normal operating pressure” is. When the pressure on the gauge raises 5 – 10 LBS above the normal operating pressure the filter will have to be back washed.\nHow To Back Wash The D.E. Out Of The Hayward Perflex Filter\nWhen the pressure inside of your filter tank rises you will have to back wash the pool filter. To do so, the first step is to shut down the filter system. Once you have shut down the filter system you will want to bump the bump handle up and down slowly at first but in the end you will want to bump that handle 15 or so times. Once you have bumped the handle you will want to open up the valve that is located on the bottom of the filter tank. This is called the back wash valve and when you open it pool water and D.E. will start coming out. Once you have opened the valve you will want to turn the filter system back on for about two minutes to forcefully flush all of the D.E. out of the filter.\nNow that all of the D.E. powder has been flushed from inside of the filter tank, you are going to need to add more D.E. powder to the filter. You can do so by making sure that the filter system is turned on and running and then you will want to walk over to the pool skimmer and add the required amount of D.E. to the pool filter. You can do so by scooping the D.E. powder into the filter slowly and 1 LB at a time.\nWhen & How Do I Add More D.E. Powder?\nEvery time you back wash the Hayward Perflex filter you will need to re-add some D.E. powder to the filter. Once you have finished back washing you will want to turn your filter system back on. Once the filter system is back on you will want to look on the side of the filter tank and see how much D.E. you are supposed to add to the filter. Once you find out how much D.E. you need to add to the filter you will want to walk over to the skimmer and add that amount slowly inside the skimmer until it all has worked its way to the filter.\nCleaning, Storing & Maintaining Your Hayward Perflex Pool Filter\nThe best way to get the longest life from your pool filter is to properly take care of it. You should take your filter apart at least once in the beginning of the season and once at the end of the pool season. This way you can clean the filter fingers, inspect all of the o-rings, inspect the tube sheets and keep the inside of the filter is perfect shape.\nIf you have any questions, please feel free to ask them below.","Filtration 200: Beyond the Basics\nBy Justin Bitner, Product Sales Manager at Eaton Filtration\nIf working with hydraulics is part of your life, you’ve almost certainly been reading “Filtration 101” articles since day one. You know, the articles that say “Keep the fluid clean” and “Change the filters regularly” and “Put them here or there”—in short, the common-sense things that any hydraulic professional worth his or her salt already knows and does.\nThere is no denying that those things are important. In fact, they’re so important that I’m going to briefly reiterate them here before moving beyond the basics.\n- Filter the fluid before it goes into the reservoir. It doesn’t come from the supplier clean enough to put in your system. Period.\n- Monitor fluid condition regularly. That means laboratory-grade analysis on a schedule determined by your operating conditions, not some arbitrary timetable.\n- Always flush the system to manufacturer specs or ISO standards every time components are replaced or repairs are performed.\n- Monitor the filters and change them before they go into bypass mode. Here again, that requires a schedule based on your operating conditions, not some arbitrary timetable.\n- Make sure the replacement filter elements meet the original manufacturer’s specifications. “Will fit” and “as good as” promises are not acceptable substitutes for verified laboratory testing and qualification.\n- Don’t forget that breathers are filters, too. Unless your system is installed in a clean room, airborne contamination can be a major issue.\n- In almost all cases, filters should not be located at pump inlets. Cavitation is a much greater threat to your pump than contamination—which should not be in your fluid in the first place.\n- Filters should not be placed on the drain lines of piston pumps and motors. Those lines need to be free flowing or you risk the opposite of cavitation, which is equally destructive.\n- The best place for fine filtration is generally on the return side of your system. If you start with clean fluid, any contamination will be generated within the system and caught by a return line filter.\nIf that checklist sounds a lot like your filtration protocol, chances are your hydraulic systems are performing well because you have the basics covered. But in today’s competitive environment, covering the basics is only the beginning. There is a lot more to be considered and implemented if you’re going to maximize the return on your hydraulic investment.\nSo let’s go through that list again and move beyond the basics.\n- If your operating pressures are going up, so should your cleanliness levels. Where 19/17/15 may have been acceptable a few years ago, many of today’s higher-performance systems need 15/13/10 or even better cleanliness levels. Maintaining those levels will probably require more than periodic laboratory analysis of your fluids.\n- One solution is to use a commercially available “laboratory in a suitcase” and do your own testing in-plant. Eaton, and other filter manufacturers, offer highly capable units that will allow you to rest on an accelerated schedule without incurring the costs associated with an outside laboratory.\n- A more advanced solution is to install an Inline Particle Counter (IPC) to provide real-time monitoring. These devices use a variety of technologies to monitor the fluid condition and generate an alarm when anomalies are detected.\n- Inline Viscosity Sensors (IVS) and Inline Water Sensors (IWS) are also available. A comprehensive monitoring solution will include all three types.\n- Even more sophisticated units use a sensor that measures changes in the dielectric characteristics of the fluid. Those changes may be caused by particle contamination, water, or even depleted additives. These systems continuously monitor fluid condition and alert you to any changes in that condition. It’s a different, but very effective, approach.\n- Being proactive during system design can eliminate many common challenges encountered during system operation. For example, mounting any required suction filters outside the reservoir will greatly simplify maintenance. The truth is that suction strainers and filters mounted inside the reservoir are seldom, if ever, serviced.\n- Utilizing manifolds and tank-top filters is another design element that can reduce maintenance challenges. It also eliminates many separate contaminant ingress points, making the whole system more robust.\n- Specifying filters based on maximum published flow rates is another mistake that can be avoided during the design process. Maximum flow rates are exactly that—the maximum the filter can handle without damage to the element. They are most definitely not the flow rates at which the filter can be expected to deliver maximum cost-effective performance.\n- Other factors, such as viscosity changes and cold-start conditions, also impact filter performance and life. As a rule of thumb, sizing the filter for twice the desired maximum flow rate will optimize both filtration performance and cost-effectiveness over the long run.\n- Another good practice is to specify filters equipped with differential pressure gauges or switches. Comparing the inlet pressure to the outlet pressure gives a very good indication of filter element condition. The switch-type units can be hardwired to an annunciator light or another device to notify maintenance personnel of an approaching end-of-life condition before the filter goes into bypass mode.\n- Breathers already have been mentioned, but they are worth a second look. A typical low-cost breather uses a non-replaceable, 10-micron paper element, which means there will be a lot of 10-micron particles allowed into the reservoir.\n- Experience says that if one 10-micron particle goes into the pump, two will come out. Yes, the return line filter will capture them both, but the damage has been done at that point, and the pump’s useful life has been shortened. Spending a few dollars for an effective breather, and then maintaining it like every other filter in the system, will prevent the damage in the first place.\nAs mentioned above, the best location for filters is generally on the return side of the system. In most cases, a finer filter can be installed there than is possible on the supply side because any flow restriction is less likely to impact pumps, motors, and valves.\nFor many systems, an even more cost-effective approach is to take the bulk of the filtration out of the active loop entirely by using off-line filtration in a so-called kidney loop. That is a stationary system that continuously filters the fluid in the reservoir.\nThis approach has several advantages:\n- A kidney loop does not need to operate at high pressure and can, therefore, use less expensive filters.\n- A kidney loop can be shut down for filter maintenance with no impact on system operation.\n- A kidney loop usually can achieve efficient laminar flow to maximize filter performance and deliver dollar/grams of dirt-holding capacity than a filter rated for pressure/return service.\n- A kidney loop can easily incorporate a low-cost, low-pressure cooler to moderate fluid temperature.\n- A kidney loop does not require exceptionally fine filtration since it continuously cleans the fluid. Typical systems use a 25-micron element on the pressure side and a 10-micron element on the return while maintaining specified fluid cleanliness levels.\nDirt destroys more hydraulic systems than any other cause. Effective filtration is your first line of defense. Moving beyond the basics will pay dividends in terms of optimized system performance, minimized operating cost, and eliminated maintenance headaches. It’s definitely worth the effort.\nTagged basics, filtration, maintenance"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:b4571dde-782c-4a58-912a-d35a4e021632>","<urn:uuid:fa2878b9-b46b-430e-86de-c0016b869a12>"],"error":null}
{"question":"How does UHS handle mental health treatment referrals to outside providers, and what insurance requirements exist under mental health parity laws for out-of-network care?","answer":"UHS works with Care Managers to facilitate referrals to off-campus mental health providers for students whose needs exceed UHS's scope of care, using personal insurance for these services. According to federal mental health parity law, access to out-of-network mental health/substance use disorder services cannot be more difficult or restrictive than for medical or surgical services. For example, a plan cannot exclude coverage for out-of-network treatment of mental health conditions when obtained outside the State if there is no similar exclusion for medical benefits. Additionally, for any denial of service, plans must provide written explanation of the reason and appeal steps, and make available the criteria used in their decision-making.","context":["Students, faculty, staff, and teaching assistants are essential when it comes to preventing suicide and promoting help-seeking behaviors among their peers. UHS offers consultation with concerned third parties.\nUHS offers high-quality medical and mental health care, in addition to wellness services to all current UW-Madison students. Most sservices are available at no charge because students pay for UHS services with their tuition and fees. A fee is charged for some extra services and all medications. Most fee-based services at UHS are covered at no cost for members of the UW-Madison Student Health Insurance Program (SHIP).\nOur medical services include a primary care clinic and specialty clinics for immunizations, women's health, travel and sexual health. For students with complex or unstable conditions requiring other types of specialty care, UHS can refer to providers off campus utilizing personal insurance.\nMental health services include individual, couple/partner, and group counseling, crisis counseling, and psychiatric services. Students with mental health concerns that go beyond the scope of care available at UHS can work with Care Managers to obtain referrals to mental health providers off campus.\nMedical and Mental Health do not provide appointments during evening, night, or weekend hours; emergency room care; ambulance services; hospitalization; or home care. We have an after-hours nurse line (608-265-5600, option 1) and a 24-hour mental health crisis line (608-265-5600, option 9) available to students at no cost.\nCare for illnesses\n- 24-hour nurse advice line (608-265-5600, option 1)\n- Evaluation and treatment of acute and chronic illnesses\n- Referral for specialty care (with personal insurance)\n- Basic radiology tests (X-rays) when ordered by a UHS provider\n- Laboratory testing when ordered by a UHS provider\n- Monitoring and management, including diagnostic tests, for stable chronic health conditions such high blood pressure or diabetes.\nCare for injuries\n- Uncomplicated cuts needing stitches\n- X-rays for the evaluation of possible fractures\n- Sale of crutches, splints, or other orthopedic durable medical supplies\n- Physical therapy (fee charged) and athletic training services\nWomen’s health care\n- Problem-focused and preventative care supporting reproductive health and wellness\n- Screening tests, exams, and procedures that provide comprehensive contraceptive options, care for abnormal bleeding, pelvic pain, and pregnancy or STI concerns.\nImmunizations, allergies, & other specialty care\n- No-cost annual influenza vaccines\n- Immunizations including hepatitis A and B, HPV, Tdap, varicella, rabies, meningococcal, MMR (measles, mumps, rubella) and travel immunizations (fee charged)\n- International pre-travel consults regarding health requirements and recommendations for international travel\n- Allergy desensitization injections (the desensitizing solution must be prescribed and provided by an outside physician/allergist)\n- Physical examinations\n- STI screening, cholesterol screening, and flu shots\n- Physical exams required for employment or travel, or required by other third parties (fee charged)\n- Occupational health services such respiratory fit testing, TB screening, and occupational medicine consultation\nPsychological and psychiatric care\n- 24-hour crisis intervention available (608-265-5600, option 9)\n- Brief individual and couple/partner counseling\n- Group counseling\n- Assessment for substance abuse and disordered eating\n- Screenings for attention disorders\n- Gender identity consultations\n- Psychiatric consultation and medication management\n- Care management and referral\n- Self-help online mental health support\n- Stress management\n- Yoga and Yoga for Every Body (BMI>30)\n- Acupuncture (fee charged)\n- Sleep management\n- Smoking cessation\n- Massage therapy (fee charged)\nWho can use UHS?\nAny undergraduate, graduate, or professional student enrolled for the current semester may make appointments at UHS and use\nany service. Students entering UW–Madison in the fall semester will be eligible to receive care at UHS on August 15.\nHealth Insurance Information\nEnrolled UW-Madison students may use UHS regardless of their health insurance coverage. UHS does not bill insurance, and it is considered “out of network” for almost all plans.\nAccess to UHS is not a substitute for having comprehensive health insurance coverage. Students should review health insurance plans before classes begin to see if they are covered in Madison. Many plans cover emergency care but not routine, urgent, or specialty care when students are away from home. UHS sees students who have to interrupt their studies and travel home for care they could have received in Madison had their policy permitted.\nIf you don’t have health insurance, the Student Health Insurance Plan (SHIP) may be your best option. SHIP is administered by UHS and is designed specifically to meet the needs of students. In addition to the primary and preventive care at UHS, SHIP members are protected by a nationwide network of hospitals, clinics, and specialized medical services. Since SHIP is not motivated by profit, it also provides good value, with rich benefits and comparatively low member out-of-pocket expenses. Visit uhs.wisc.edu/ship or call 608-265-5232 for more information.\nImmunizations and Medical Records for Incoming students\nUHS strongly recommends that all students be up-to-date on immunizations before coming to campus. Complete your immunization and health history forms in MyUHS (do not mail us any documents; we only collect this information through MyUHS).\nMyUHS (myuhs.wisc.edu) is a secure online patient portal. Before the semester begins, use MyUHS to complete immunization and health history forms. After the semester begins, students will be eligible to make appointments online, view scheduled appointments, exchange secure messages with providers, view lab and radiology results, and request health records.\nUHS and UW Health\nUHS is not part of UW Health, nor does UHS have any special referral relationship with UW Hospital and Clinics. Students who are referred or transported to any hospital from our clinic, including UW Hospital, are responsible for any emergency room or hospitalization charges.\nWhat if I don’t want to go to UHS?\nThere is no requirement to use UHS. Students may seek health care from the provider who is best for them and their family. Every year, about 50 percent of students visit UHS at least once; nine out of 10 students come to us at some point during their college career, and all students participate in our online prevention programs.\nWhat to bring to campus\n- Health insurance card (and prescription medication card, if separate)\n- Names and phone numbers of home primary care and specialty care providers\n- Prescription medicines and refill information\n- Pain reliever (ibuprofen and/or naproxen)\n- Fever reducer (acetaminophen)\n- Throat lozenges\n- Alcohol-based hand sanitizer\n- Basic first-aid supplies: Band-Aids, antibacterial ointment, hydrocortisone cream","Laws which Offer autism and Mental Health Protections to Consumers\nWHAT IS THE FEDERAL MENTAL HEALTH PARITY AND ADDICTION EQUITY ACT?\nThe Paul Wellstone and Pete Domenici Mental Health Parity and Addiction Equity Act of 2008 (MHPAEA), is a federal law that was enacted in order to address health insurance practices that unfairly limited coverage for mental illness and substance abuse. Generally, the law requires that if plans offer mental health benefits, the financial requirements and treatment limitations for mental health or substance use can be no more restrictive than the predominant financial requirements or treatment limitations applied to substantially all medical and surgical benefits covered by the plan and there are no separate treatment limitations that are applicable only with respect to mental health or substance use disorder benefits.\nThe law applies to nearly all private health plans, including those that are self-funded, fully funded, and individual plans bought on or off the exchange. The law extended to the individual and small group market through the Affordable Care Act. The law does not apply to:\nIn 2016, a Federal Mental Health Parity Task Force issued a report to President Obama which included many recommendations on implementation and enforcement of the Federal Mental Health Parity Act. One of the recommendations included tracking consumer complaints related to mental health and substance abuse. The Kennedy Forum has taken the initiative to track this information and share it with legislators and policy makers. If you (or a loved one or a client) have been denied a mental health treatment, please consider reporting your experiences here.\n1. Benefit Classifications: All health care benefits are categorized into six benefit classifications. Services for MH/SUD must be at parity with medical/surgical benefits in each of these categories:\nFor example, if a plan requires prior authorization requirements for behavior treatment for autism, or intensive outpatient therapy for mental health, they must require pre-authorization requirements for substantially all medical/surgical treatments.\n2. Consumer Cost-Sharing and Treatment Limitations: Consumer cost-sharing such as co-pays, deductibles or co-insurance and treatment limitations cannot be more restrictive or burdensome for MH/SUD than for medical or surgical benefits.\nFor example, if a health plan allows unlimited outpatient medical visits per year, it cannot limit MH/SUD outpatient visits to a specified amount.\n3. Nonquantitative Treatment Limitations: NQTLs applied to MH/SUD can be no more restrictive than treatment limitations applied to substantially all medical and surgical benefits covered by the plan and there are no separate treatment limitations that are applicable only with respect to mental health or substance use disorder benefits.\nSome examples of NQTLs may be found here , and include:\nFor example, a plan cannot exclude coverage for inpatient, out-of-network treatment of substance abuse disorders when obtained outside of the State, if there is no similar exclusion for medical or surgical benefits within the same classification. Similarly, a plan cannot require Joint Commission Accreditation for Mental Health Facilities but not for medical facilities within the same class.\nAn example of Fail-first/step therapy protocols that we see frequently are denials for residential treatment if clients have not previously tried partial hospital or intensive outpatient. Plans cannot do that if they do not make similar requirements on the medical/surgical side.\nThe law also states that there are no separate treatment limitations that are applicable only to MH or SUD benefits. Examples of these that we see all the time are exclusions for specific types of evidence based mental health treatments that do not have direct analogs on the medical/surgical side, including:\n4. Transparency of Health Plan Information: For any denial of service, the plan must include in writing the reason for the denial (if it is not medically necessary, the plan must say why), and steps on how to appeal. They also must make available to you criteria used in making their decision.\n5. Out-of-Network Benefits: Access to out-of-network MH/SUD services cannot be more difficult or restrictive than it is for medical or surgical services.\nAs of this writing, all states have meaningful legislation or regulation that requires funding for autism treatments. Nearly all address behavioral therapy, and some include requirements around speech, occupational and physical therapies as well. Not all autism laws are the same, and it is important to understand the law governing your state. For a list of autism laws by state and what they cover, click here.\nThe Kennedy Forum offers a state by state analysis of mental health parity legislation and regulation. To see what protections are available by state, click here. Don’t be too discouraged if your state got an F, as they are in good company. It is more important to understand the protections offered.\nIn California, there is a law in place called AB 88, also known as the California Mental Health Parity Act of 2000. This law requires coverage for the diagnosis and medically necessary treatment of the following \"severe mental illnesses\" in parity with other medical conditions:\nCalifornia’s active autism mandate, AB 796, can be found here.\nIt has no restrictions on age, or caps on visits or annual spending. Unfortunately, this state mandate does not apply to Medi-Cal. Children on Medi-Cal are able to access ABA services through interpretation of federal Early Periodic Screening, Diagnosis, and Treatment (EPSDT) law. Effective 2014, services were available to those with autism, under age 21. Effective 2018, services were expanded to include other conditions, when medically necessary and recommended by a physician or a psychologist. At this time, these services are only available for those under age 21.\nThe SED qualification can be used for children who do not have a formal \"severe mental illness\" diagnosis or ASD diagnosis, but are experiencing many similar challenges to justify the need for behavior treatment, residential treatment, or other intensive type treatment.\nIt is important to note that the CA Mental Health Parity Act entitles you to a diagnostic evaluation if there is a suspicion of any of the above listed conditions. Your primary care provider can authorize this. The plan is still responsible for this evaluation even if the child is later found not to have any of the above listed conditions.\nIt is also important to know that due to significant litigation (Harlick v Blue Shield of CA and Rea vs Blue Shield of CA), the CA parity act requires that all medically necessary treatment be provided to those that meet its criteria. This argument has been used to prevent health plans from enforcing categorical denials for things like wilderness therapy, residential treatment, and other evidence based treatments for autism/mental health conditions.\nBoth Massachusetts and NY have laws which require that the health plan or insurance company make a determination within required timelines for both expedited and standard appeals. Failure to adhere to the timelines shall be deemed to be a reversal of the health plan’s adverse determination. Laws in both states apply to fully funded plans.\nThe state of Oregon has a law which allows the Director of the Department of Consumer and Business Services to seek restitution on a consumer’s behalf for the actual damages the consumer suffered as a result of the insurer’s violation of state or federal law, or breach of contract."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:36a92241-f7bd-4128-863a-fbccf4189afa>","<urn:uuid:ce381ba1-c141-4f04-b2c2-69f3c31025bc>"],"error":null}
{"question":"What are the environmental impacts of fracking on water quality, and how deep was the unusually shallow earthquake it caused in Sichuan, China in 2019?","answer":"Fracking can contaminate water with chemicals linked to breast cancer, including benzene, toluene, and DEHP. The fracking fluids and wastewater contain bromine salts, minerals and radioactive materials that can contaminate underground water sources. As for the earthquake, the February 25, 2019 magnitude 4.9 earthquake in Rongxian County, Sichuan occurred at an extremely shallow depth of about 1 kilometer, which is unusually shallow even for fracking-induced earthquakes. The event caused two fatalities and resulted in approximately $2 million in economic losses.","context":["Air & Water Exposures\nNothing's more fundamental to life than air and water. Unfortunately, both air and water can contain chemicals that are harmful to us.\nWhen it comes to the air we breathe, it's not just our lungs that are in danger. Air pollutants account for 35 of the 216 chemicals associated with increases in mammary gland tumors in animals. There is widespread exposure to many of these chemicals in the air we breathe outside, as well as in our offices, homes, restaurants and schools.\nAlthough that sounds scary, it's important to note that most of the air pollutants are from just a few sources: primary and secondhand tobacco smoke, diesel exhaust and specific occupational exposures.\nChemicals related to breast cancer also make their way into lakes, streams and groundwater systems. Of particular concern are pesticides from agricultural and home use, dioxins and pharmaceutical hormones that make their way down household drains.\nHydraulic fracturing, commonly referred to as fracking, is a process used to increase production in oil and natural gas wells. More recently, fracking has been used in combination with horizontal drilling through shale layers to reach natural gas reserves that were previously not easily accessed. Large quantities of water and other fluids are pumped into the ground at high pressure, which causes rock to break and allows gas to be extracted. Fracking fluids can contain chemicals linked to breast cancer, including known and suspected carcinogens such as benzene and toluene, and endocrine-disrupting compounds such as the phthalate DEHP. Evidence is beginning to emerge that these chemicals may contaminate underground water sources. Researchers have also found that ground and surface water near fracking sites has more endocrine disrupting activity than water from other locations. In addition, waste water containing fracking fluids, bromine salts (which interfere with wastewater treatment), minerals and radioactivity from deep in the earth flows back out of wells and must be stored and disposed of safely. There have been a number of spills of fracking waste water, and underground storage of this waste has been implicated in the increased incidence of earthquakes around some storage wells. A summary of the chemicals used in fracking can be found here.\nDioxin is formed when chlorine breaks down, and can be found in both water and air. Dioxins are known human carcinogens and endocrine disruptors. One dioxin has been classified by the International Agency for Research on Cancer (IARC) and the Environmental Protection Agency (EPA) as a known human carcinogen.\nSmall amounts of hormones from medications like hormone-replacement therapy and oral contraceptives can make their way from people's bodies into municipal wastewater systems. Similarly, hormone-disrupting compounds from personal care products also go down household drains. These chemicals are not fully removed during water treatment processes, and end up in household tap water and water used to irrigate lawns and gardens.\nOrganic solvents are a class of chemicals that includes chlorinated and other solvents, including toluene, methylene chloride, trichloroethylene and formaldehyde. Sources of exposure include outdoor and indoor air pollution, waste incineration, cleaning products and some cosmetics. They are also used in the manufacture of computer parts.\nMany pesticides, including herbicides and other pest-killing poisons, have been labeled as human or animal carcinogens. A 2006 report demonstrated that lifetime use of residential pesticides may be associated with an increase in risk for breast cancer. Studies have found that many of these chemicals are present in water supplies, as well as in samples of air and dust from homes.\nDDT was widely used in the United States as a pesticide in agriculture and insect control until it was banned in 1972. DDT and its breakdown product, DDE, persist in the environment, in the food chain and in the human body. The main source of human exposure is through consumption of meat, fish and dairy products. The pesticide is still used in some countries to control mosquitoes. Recent studies show that women exposed to DDT during childhood and early adolescence have an increased risk of developing breast cancer.\n1,3-butadiene is an air pollutant created by internal combustion engines and petroleum refineries. It is also used in the manufacture and processing of synthetic rubber products and some fungicides, and it is found in tobacco smoke. The EPA found that it is carcinogenic to humans, with the main route of exposure being inhalation.\nAromatic amines are a class of chemicals found in the plastic and chemical industries, and they are found in environmental pollution such as diesel exhaust and tobacco smoke. One aromatic amine is known to cause mammary tumors in rodents. They can also have direct effects on cell division, which may enhance the development of tumors.\nVinyl chloride may be released into the air or wastewater when polyvinyl chloride (PVC) is made. Vinyl chloride has also been found in the air near hazardous waste sites and landfills and in tobacco smoke. Vinyl chloride was one of the first chemicals designated as a known human carcinogen by the National Toxicology Program (NTP). It has also been linked to increased mortality from breast cancer among workers involved in its manufacture.\nPolycyclic aromatic hydrocarbons (PAHs) are byproducts of combustion, from sources as varied as coal burners, diesel engines, grilled meats and cigarettes. PAH residues are often found in the air and in house dust. Exposure is primarily through inhalation. They have been shown to increase risk for breast cancer.\nExposure to light-at-night (LAN), such as that experienced by night-shift workers and flight attendants, lowers levels of melatonin, a hormone that appears to have anti-cancer properties. Research suggests a link between night-shift work and increased risk of breast cancer, possibly through this melatonin-LAN pathway.\nTIPS FOR PREVENTION\nWhat can you do personally to protect yourself from toxic exposures in air and water?Tips for protecting yourself and your environment >\nElectromagnetic waves are a type of non-ionizing radiation. They are produced by cell phones, wireless networking, radio towers, computers and electric lighting. The International Agency for Research on Cancer (IARC) has classified electromagnetic fields as possible human carcinogens; but consensus has been difficult to reach.\nTobacco smoke contains polycyclic aromatic hydrocarbons (PAHs), which may explain a potential link between increased breast cancer risk and both active and passive smoke inhalation. Tobacco smoke contains hundreds of other chemicals, including three known human carcinogens. A recent study found that both active and passive smoke inhalation increase the risk of breast cancer in premenopausal women.\nBenzene is one of the highest volume petrochemical solvents currently in production, and global production rates are expected to continue to grow. It has been designated as a known human carcinogen. Exposure comes from inhaling gas fumes, automobile exhaust and tobacco smoke. Benzene poses a serious hazard for people exposed through manufacturing and refining industries.\nPolychlorinated biphenyls (PCBs) have been banned since 1976, but as many as two-thirds of all insulation fluids, plastics, adhesives, paper, inks, paints and other products containing PCB manufactured before the ban remain in daily use. One type of PCB acts like an estrogen; a second, like an anti-estrogen; and a third appears not to be hormonally active. Therefore, most studies look at total PCB levels.","A Shallow Shock: The 25 February 2019 ML 4.9 Earthquake in the Weiyuan Shale Gas Field in Sichuan, China by Hongfeng Yang; Pengcheng Zhou; Nan Fang; Gaohua Zhu; Wenbin Xu; Jinrong Su; Fanbao Meng; Risheng Chu, Seismological Research Letters (2020). DOI: 10.1785/0220200202\nThe complete paper.\nEarthquakes rarely occur at extremely shallow depths, for example, less than 2 km. Even for induced earthquakes that are typically shallower than tectonic events, only very small ones have been reported in such depths. The MLML 4.9 earthquake (MwMw 4.3) that struck the Rongxian County, Sichuan, China on 25 February 2019 was an extremely shallow event. Seismological and geodetic data constrained the mainshock depth at ∼1 km∼1 km with a thrust‐faulting mechanism, consistent with the Molin fault orienting northwest. Two foreshocks with magnitudes larger than 4 occurred on an unmapped fault striking northeast, right next to an injection well where hydraulic fracturing (HF) was conducted. The focal depths of the two foreshocks were at ∼2.7 km∼2.7 km, coinciding with the depth of HF. Coulomb failure stresses of the two foreshocks on the Molin fault was ∼3 kPa∼3 kPa, smaller than typical static triggering threshold (10 kPa), and thus their triggering effects were mild. As the fault was hydraulically sealed from HF, we suggested that the MLML 4.9 earthquake was possibly triggered by nearby HF activities through poroelastic stress transfer. Such findings held significant implications for shale gas development by considering seismic hazard associated with shallow faults. …\nFigure 1. Surging earthquakes in the Sichuan basin.\n(a) Seismicity with local magnitudes larger than 1 since December 2008 are shown by black circles. White lines represent mapped faults. Blue focal mechanism plots denote moment tensor solutions of induced earthquakes in the Changning region (Leiet al., 2017, 2019a). Red focal mechanism plot indicates the 25 February 2019 Mw 4.3 (ML 4.9) earthquake. WYSF, Weiyuan shale gas field. Inset shows the location of the study region.\n(b) Daily number of earthquakes (ML > 1) in the Rongxian–Weiyuan region with location shown in (a) by the red dashed lines. Red line denotes seismic moment release (converted from ML = 1:3Mw − 0:88 that was empirically estimated in the region) from December 2008 to March Red dot marks the occurrence time of the 25 February 2019 mainshock. The color version of this figure is available only in the electronic edition.\n… By far, the largest HF triggered earthquake (the 2018 Xingwen earthquake with a local magnitude ML 5.7) occurred in the southern Sichuan basin (Lei et al., 2019a), where the Changning–Weiyuan shale gas block (Fig. 1a) had been discovered and developed since 2011.\nA few other Mw > 4 earthquakes had been linked with HF in the Changning shale gas block, including five ML 4–5 earthquakes in 2017 (Lei et al., 2017; Meng et al., 2019) and an ML 5.3 earthquake in 2019 (Lei et al., 2019a). In addition to HF triggered earthquakes, fluid injection\nfor salt mining in the Changning area had been conducted for three decades, which possibly led to an Mw 6.0 earthquake in June 2019 (Lei et al., 2019b).\nIn contrast, the Rongxian–Weiyuan region, located ∼150 km north of Changning, had infrequent seismicity with ML larger than 1 before mid-2015 (Fig. 1b). Then, earthquakes\noccurred more often, but the magnitudes were up toMw 3.4 before 2018 (Lei et al., 2017). The number of earthquakes with ML > 1 increased drastically from 2018, with a few ML > 4 damaging events (Fig. 1b). On 25 February 2019, an ML 4.9 earthquake struck the region at 1:15 p.m., with a reported intensity of VI. As reported by The Paper, the earthquake caused two fatalities in the Gaoshan Town and 12 injuries, resulting in numerous damaged houses, and an estimated economic loss of 14 million RMB (∼2 million U.S.). The earthquake was preceded by two M 4+ foreshocks, one at 5:38 p.m. on 24 February and the other at 8:40 a.m. on 25 February. HF wells within 2 km to their epicenters were in operation, before the occurrences of these earthquakes. Immediately\nafter the mainshock, HF activities in the Rongxian County were shut down. Identifying the responsible faults of the earthquakes and finding the potential link with HF are critical not only for seismic hazard assessment in the region, but also for sustainable development of shale gas industry in China. …\nUnusually shallow earthquake ruptures in Chinese fracking field by Seismological Society of America, Oct 7, 2020, phys.org\nAn unusually shallow earthquake triggered by hydraulic fracturing in a Chinese shale gas field could change how experts view the risks of fracking for faults that lie very near the Earth’s surface.\nIn the journal Seismological Research Letters, Hongfeng Yang of The Chinese University of Hong Kong and colleagues suggest that the magnitude 4.9 earthquake that struck Rongxian County, Sichuan, China on 25 February 2019 took place along a fault about one kilometer (0.6 miles) deep.\nThe earthquake, along with two foreshocks with magnitudes larger than 4, appear to be related to activity at nearby hydraulic fracturing wells. Although earthquakes induced by human activity such as fracking are typically more shallow than natural earthquakes, it is rare for any earthquake of this size to take place at such a shallow depth.\n“Earthquakes with much smaller magnitudes, for example magnitude 2, have been reported at such shallow depths. They are understood by having small scale fractures in such depths that can slip fast,” said Yang. “However, the dimensions of earthquakes are scale-dependent. Magnitude 4 is way bigger than magnitude 2 in term of rupture length and width, and thus needs a sizeable fault as the host.”\n“The results here certainly changed our view in that a shallow fault can indeed slip seismically,” he added. “Therefore, we should reconsider our strategies of evaluating seismic risk for shallow faults.”\nTwo people died and twelve were injured in the 25 February earthquake, and the economic loss due to the event has been estimated at 14 million RMB, or about $2 million. There have been few historic earthquakes in the region, and before 2019 there had been no earthquakes larger than magnitude 3 on the fault where the main earthquake took place.\nSince 2018, there have been at least 48 horizontal fracking wells drilled from 13 well pads in the region, with three well pads less than two kilometers (1.2 miles) from the Molin fault, where the main earthquake took place.\nYang and his colleagues located the earthquakes and were able to calculate the length of the main rupture using local and regional seismic network data, as well as InSAR satellite data.\nIt is unusual to see clear satellite data for a small earthquake like this, Yang said. “InSAR data are critical to determine the depth and accurate location of the mainshock, because the ground deformation was clearly captured by satellite images,” he noted. “Given the relatively small size of the mainshock, it would not be able to cause deformation above the ‘noise’ level of satellite data if it were deeper than about two kilometers.”\nThe two foreshocks took place on a previously unmapped fault in the area, the researchers found, underscoring how difficult it can be to prevent fracking-induced earthquakes in an area where fault mapping is incomplete.\nThe researchers note that the Molin fault is separated from the geologic formation where fracking took place by a layer of shale about 800 meters (2625 feet) thick. The separating layer sealed off the fault from fracking fluids, so it is unlikely that the pressures of fluid injected into rock pores around the fault caused the fault to slip. Instead, Yang and colleagues suggest that changes in elastic stress in rock may have triggered the main earthquake on the Molin fault, which was presumed to be stable.\n“The results here certainly pose a significant concern: we cannot ignore a shallow fault that was commonly thought to be aseismic,” Yang said, who said more public information on fracking injection volume, rate and duration could help calculate safe distances for well placement in the future.\nRefer also to:\nOne of Canada’s foremost experts on earthquake hazards recently told an audience of Calgary engineers that earthquakes triggered by hydraulic fracturing can exceed “what the natural hazard was in the first place” and pose risks to infrastructure only built to withstand natural earthquake hazards.\nAs well, earthquakes induced by fracking can produce more damaging ground motion at lower magnitudes than natural quakes due to their shallowness, said Gail Atkinson, the NSERC/TransAlta/Nanometrics Industrial Research Chair in Hazards from Induced Seismicity at Ontario’s Western University.\nNatural earthquakes have an average depth of 10 kilometres, whereas industry-made tremors are much shallower and closer to the ground surface where people can feel them more strongly.\nNatural earthquakes typically cause structural damage in buildings at a magnitude of 5.0, Atkinson said. But earthquakes triggered by fracking could possibly cause damaging ground motions at magnitudes as low as 3.5 to 4.0, due to their shallowness. …\nIndustry doesn’t share data\nAccording to Atkinson’s preliminary estimate, as many as one in five wells in the Fox Creek region may be triggering seismic activity.\nRight now, scientists have no accurate way of predicting whether one-in-five horizontal wells will provoke a felt man-made earthquake, or whether one-in-1,000 wells will do so. The industry simply doesn’t know where all the faults are, nor the likelihood of triggering fault movement.\nNor do they know how large or destructive an earthquake trigged by hydraulic fracturing might be. To reduce uncertainty, Atkinson appealed for more seismic data and open access to that data, as well as timely access to operational data.\nMany oil and gas companies currently collect their own seismic data, but do not share this information with the public or earthquake scientists.\n“There are hundreds and hundreds of scientists working on this issue right now, but if they are not able to see the data, there is no scientific benefit from collecting it,” Atkinson said.\nIn Alberta, two or three years may pass before regulators report on earthquake events caused by the oil and gas industry.\n… A recent talk by Usman Ahmed, the vice president of Baker Hughes, a major fracking company, highlighted the chaotic and non-linear nature of cracking shale rocks which are already under high stress.\nAhmed said that 70 per cent of unconventional wells in the U.S., even with fracking, do not met their production targets; that 60 per cent of all fracture stages are ineffective; and that 73 per cent of operators say they do not know enough about the subsurface, let alone where the faults are.\nHe ended his talk by asking that the industry “avoid faults and geohazards.”\nA few of the comments:\nThe world is running out of and billions are suffering from the lack of clean drinking water, while these crooks are poisoning and pumping incredible amounts underground . Not for real economic, but fraudulent monetary reasons to enrich a few.\n“Atkinson appealed for more seismic data and open access to that data, as well as timely access to operational data.\nMany oil and gas companies currently collect their own seismic data, but do not share this information with the public or earthquake scientists.”\nThat’s not surprising, apparently that information is “proprietary,” just like the secret chemicals companies are injecting.\n“Many researchers also repeatedly raised the issue of access to quality data, a clear necessity to advance the science. Larger events detected on national arrays are available through open databases, enabling researchers to develop new processing techniques such as signal matching to revisit data sets to find weaker, undetected background seismicity.\nIn many cases, companies are installing their own proprietary local arrays, which provide unique and much more sensitive recording to obtain a more complete seismic data set.\nEven in the case of open data sets, there is a clear need for complimentary reservoir engineering data including reliable records of injection volumes, rates, and pressures that are often lacking. Long-term data related to stress and strains before, during, and after injection are also missing pieces of the puzzle.”\n“These man-made events are so much more frequent in a low seismic area such as Fox Creek and most of Alberta that they could challenge the adequacy of current seismic hazard assessments now used to set current building and critical infrastructure codes.\n‘In low seismic environments like Fox Creek where the natural earthquakes are infrequent, the hazards from an induced seismic event can exceed the hazards from a natural source,’ warned Atkinson.”\nI sincerely hope the residents of Fox Creek (and everywhere else companies are frac’ing) are documenting daily the state of their homes, outbuildings, offices, infrastructure etc, because you just never know when you and your town are going to be “in the wrong place at the wrong time.”\nAnd things like, “a number of water main breaks” or declining water levels, should definitely be scrutinized and coordinated with further scrutiny of the “proprietary” data companies refuse to provide.\n“We understand that there have been issues with the discolouration of the water in Town lately. Due to recent events (which include the recent fire and a number of water main breaks) the Town has not been able to catch up properly on the required water levels.”\nAt the end of the day, regardless of whether we work in the industry or not, worship the industry or not, or have promised our first deformed child to the industry or not, we are fools to expect anything more than the complete and utter destruction of our communities, as long as this industry is allowed to continue to run amok.\n“The fears of residents have not been assuaged by comments from Chiel Seinen, the spokesman for the Nederlandse Aardolie Maatschappij (NAM), a gas consortium including Royal Dutch Shell Plc and Exxon Mobil Corp, who conceded that people’s lives might be in danger.\n‘You can never exclude anything if people are in the wrong place at the wrong time,’ he told the BBC last month.”\nThank you Dr. Atkinson, you are an incredibly bright scientific light in this dark and dismal resource tunnel, I just wish there were more of you. Please keep going.\n2016: Questerre’s partner to frac Quebec is Repsol, creator of 4.8M world record frackquake, day of Ernst vs AER Supreme Court of Canada hearing. “The Alberta Model” Knocks Quebec’s People to their Knees: Gov’t of Quebec Takes Your Land & Rights, Gives Them to the Frackers – For Free\n2017: Fox Creek, Alberta Frac Quakes start up again; New Study by Standford Scientists: Small earthquakes at frac sites may be early indicators of bigger quakes to come; Surprising Finding: Arkansas earthquakes mostly caused by hydraulic fracturing, only some by wastewater injection, None caused by trucks\n… One fracked well set off a cluster of earthquakes with magnitudes as high as 4.9 that killed two people said one report, and at least four according to another.\nThe tremors also damaged thousands of buildings and left hundreds homeless in Rongxian county.\nIn response to the quakes, thousands of angry protestors descended on government offices to demand action.\nThe government told the protesters it would shut down fracking operations in the region.\nSeismic experts have long established that the injection of pressurized fluids into the ground over short or long periods of time can reactivate faults and cause earthquakes.\nSichuan basin, the focus of China’s shale gas fracking industry, is a densely populated area and has a grim history of tremors induced by industrial activity.\nOne quake triggered by the filling of dam with water, set off a massive earthquake that killed 80,000 people in 2008.\nIn January 2017 an earthquake triggered by China’s fracking industry damaged 571 homes.\nOver the last three years fracking has triggered more than 15,000 earthquakes with magnitudes ranging up to 4.9 primarily in the Zhaotong and Changning shale gas fields of Sichuan. …\n… The three earthquakes killed two people and wounded 13. More than 20,000 homes in three villages suffered damage and nine collapsed completely, according to a statement by the county. About 1,600 people were displaced….\n2019: Nikiforuk: New report by BC regulator admits frac quake risk is high with formations “in a near critical state, meaning only small fluid pressure increases are sufficient to cause specific sets of fractures and faults to become critically stressed.” Researchers still can’t say where or why; Public complaints surging as frac quakes escalate. Have you read the small print of your home insurance policy?\n2019: Terrifying! Injected oilfield wastewater may trigger earthquakes for ‘decades.’ More terrifying: Percentage of high-magnitude quakes felt at the surface increases with depth of waste injected & may create greater magnitude quakes years after injection rates decline or stop.\n2019: 4.6M earthquake, 1 km in depth, most powerful yet in central Alberta, hits SW of Red Deer, cracks walls in homes, knocks power out to thousands. Vesta Energy reports quake to AER, shuts down frac’ing. AER investigating. Geological Survey of Canada says looks like fra’cing didn’t do it.\n2020 02 23: Scrubbadubbadub! Happy Frac’ing Holidays! Two earthquakes west of Alberta’s Fox Creek Frac Hub: 4.0M on Dec 25; 4.1M on Dec 30. Like a coronavirus, it spreads. Earthquakes Canada already scrubbed the 4.1M; nothing reported in the media or by AER, again"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:2937a45f-ac93-4a63-a538-405d5f97bdea>","<urn:uuid:e762cb75-1878-4475-8ab8-3fa8b64b295f>"],"error":null}
{"question":"How do the Louvre and the Eiffel Tower compare in terms of their original intended purposes when they were built?","answer":"The Louvre and Eiffel Tower were built for very different purposes. The Louvre was originally constructed in the 12th and 13th centuries as a fortress under Philip II's orders and later became the main residence of French Kings. In contrast, the Eiffel Tower was specifically built as the entrance and centerpiece of the 1889 World's Fair to mark the 100th anniversary of the French Revolution. While the Louvre evolved into one of the world's oldest and largest art museums opening in 1793, the Eiffel Tower was initially meant to be a temporary structure, permitted to stand for only 20 years before being dismantled.","context":["France is one of the most popular destinations for travelers, many of whom take interest in the country’s rich culinary scene, artistic lineage, and beautiful countryside. But there are others who are interested in the country’s long and storied history, with its famed monarchy and engagement in multiple influential wars. For those interested in days past, here are some places you must visit when you come to the country dubbed “l’Hexagone” for its six-sided shape.\n1. The Côte d’Azur\nThis section of gorgeous land, which extends around the Mediterranean Sea in the southeast corner of the country, is known in English as the French Riviera, and has seen multiple periods of historic interest. It seems that important civilizations just couldn’t keep away from the stunningly beautiful view of the sea. It became what it is today after becoming a resort home for wealthy Englishmen in the 1800s, but prior to that it was influenced by the Greeks, colonized by the Romans, and converted to Christianity in the 4th century. Frejus Cathedral, built in the 5th century, is a place possessed of a sense of ancient peace. Elsewhere, you can visit Cannes, home of the famed film festival, and Saint-Tropez, where the jet-setters of the 50s parked their yachts.\n2. The Louvre\nThis is it: the world’s largest art museum, housed in a historic monument that is one of the defining features of the City of Lights. Paris’ most visited site was originally built in the 12th and 13th centuries as a fortress by order of Philip II, but later became the main residence of the Kings of France. The museum that currently occupies the space opened in 1793, making it one of the world’s oldest collections of fine art. Today, it still houses some of the most recognizable pieces of artistic and historical import, including the Mona Lisa, the Venus de Milo, and the Code of Hammurabi.\n3. The Palace of Versailles\nWhile the Louvre served as the palace of the French Kings from 1546 to 1682, it wasn’t good enough for the famously demanding Louis XIV, who made his home instead at the Palace of Versailles, where he also held meetings of the royal court. It was a massive symbol of his almighty power, a monument to excess and extravagance that cost untold amounts of money and whose gaudiness potentially triggered the historic French Revolution. It is just as ostentatious and beautiful today as it was then, and now, nearly five million people visit the palace and museum each year.\n4. Notre Dame Cathedral\nThis building is perhaps the defining symbol of Medieval architecture. Built between 1163 and 1345, the massive structure, with its naturalistic sculptures and awe-inspiring stained glass, is one of the first buildings in history to use the architectural feature known as a flying buttress. The church is a marvel of architecture and human will that has been memorialized in numerous works of art, most notably Victor Hugo’s novel The Hunchback of Notre Dame.\n5. Mont Saint-Michel\nThis island commune in Normandy is the seat of a historic monastery that has existed for centuries. The architecture is largely unchanged from when it was constructed, a fortified structure that reflects the organization of feudal society in its very organization. It is like stepping into a world you could only imagine previously. It has been an abbey, a prison, and more, but is now one of France’s most recognizable sites, recognized by UNESCO as a World Heritage Site.\nFrance is a country imbued with history. Visit the sites above, and you’ll leave with an understanding of how this relatively small country came to influence the course of human events so deeply.","The Eiffel tower in Paris is one of the notable landmarks today. Its unique shape, structure, and design have made it every tourist’s dream, you surely can’t say you’ve been to Paris without visiting this amazing piece of French engineering.\nIn this post, we’ll be discussing some interesting facts about this gigantic metal tower that may just surprise you.\n1. It Was Completed in Just 26 Months.\nConsidering how big and complicated the tower’s design looks, it was completed relatively fast. It took the workers 2 years, 2 months, and 5 days to complete it. That is about 26 months in total.\n2. Gustave Eiffel Didn’t Actually Design It\nWhile the tower was named after Gustave Eiffel- the owner of the engineering firm that built it, it was actually designed by Maurice Koechlin and Émile Nouguier- two engineers that worked for Eiffel’s company.\n3. Its Design Was Inspired by The Latting Observatory in New York City\nEiffel admitted that the tower’s design was American-inspired. The Latting Observatory was only around for a few years- between 1853 and 1856. It was made primarily of wood and was destroyed by a fire that started in a nearby shop.\n4. It Was Built As The Entrance to The 1889 World’s Fair\nThe tower was purposefully built as the centerpiece of the 1889 world’s fair to mark the 100th year anniversary of the French revolution. It was also built to be the tallest man-made structure at the time.\n5. It Was The Tallest Building In The World For Decades\nWhen it was constructed, the tower stood at 300 meters (984 feet)- the equivalent of a 75-story building. It was the tallest man-made structure on earth, overtaking the Washington Monument which was about half the Eiffel Tower’s height. It maintained this record for 41 years until 1930 when the Chrysler Building in New York was completed.\n6. Some Extra Height Was Added Decades Later\nThe tower is a little bit taller than what it was initially. In the 1950s, broadcasting antennae were added to its top and some extra work was done in the year 2000 that increased its height by 24 meters (79 feet). Its current height is 324 meters (1063 feet).\n7. It Was To Be Brought Down After 20 Years\nThe building was permitted to stay only for 20 years, after this, it was to be brought down. In fact, part of the design requirements from the city’s officials was that it should be easy to dismantle. The city decided against bringing it down when it had become a prominent symbol, and a useful communication tower.\n8. Gustave Eiffel Owned The Rights To Its Commercial Exploitation For 20 Years\nBecause Eiffel footed a huge chunk of the tower’s costs, he was given the commercial rights to this building for 20 years, after which it became the property of the City of Paris.\n9. It is The Most Visited Paid Monument in The World\nAbout 7 million people pay to visit this iconic mega-structure every year. Out of this figure, about 75% are foreigners. Also, more than 300 million people have visited it since it was first commissioned in 1889. This gives some insight as to how popular the tower is. Here are some tips to help you save money on a trip to Paris.\n10. There Were Protests Against its Erection\nNot everyone agreed with the city’s decision to permit the tower’s construction, in fact, prominent architects, painters, artists, and sculptors protested against it. In a publication, the tower was likened to the tower of Babel and even to a black factory chimney. There were huge concerns that it will dwarf other important artistic French expressions with its huge size and metallic design.\n11. It has 3 Floors Available To Visitors\nThe Eiffel tower is not just a huge metal structure, it has three floors that house exhibition rooms, restaurants, shops, and even a special room that recreates Eiffel’s office with wax figures of him, Thomas Edison and Claire- Eiffel’s daughter.\nThe first two floors can be accessed by elevators and stairs while the topmost floor can only be accessed by elevators.\n12. It’s Made of 7,3oo Tons Of Metal\nThe impressive tower is very heavy too. It was constructed with 7,300 tons of puddle iron, 18,038 iron parts, and 2.5 million rivets to put the structure in place. When you add the weight of its extra features like shops, rooms, antennae, and elevators, the combined weight is about 10,100 tons.\n13. It is Hand-Painted Every 7 Years\nOnce in about 7 years, 25 specialists paint the tower by hand. The painting typically takes about 18 months to complete and incredibly involves about 60 tons of paint. This is done to preserve the integrity of the metal and costs about 4 million Euros to accomplish.\n14. It was almost destroyed by Hitler\nDuring the Second World War, during the German occupation, the French resistance cut the cables to the tower’s elevators, making it less accessible to the Germans. When the allies were closing in on Paris, Hitler ordered the German governor of Paris to destroy the tower. Thinking Hitler was insane, the governor- General Dietrich von Choltitz didn’t obey this order.\n15. There Are More Than 50 Replicas Around The World\nThere’s a chance that you might have seen a structure that looks like the Eiffel tower in another city. While most of the replicas aren’t exactly the same design and height, they are usually very similar and on different scales. Popular examples are:\n- Blackpool Tower (UK)\n- Tokyo Tower (Japan)\n- Las Vegas Eiffel Tower (USA)\n- Eiffel Tower of Window of the World (China)\n- Paris, Texas Eiffel Tower (USA)\n- Eiffel Tower- Paris, Tennessee (USA)"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:6fadcc42-69a3-43f6-9c98-1030def7817a>","<urn:uuid:e921e7ed-8e3c-4e0f-9331-6f83e8ba7828>"],"error":null}
{"question":"How do Panos Caribbean and LGBTQ advocacy groups address discrimination against vulnerable populations, and what specific barriers do these communities face?","answer":"Panos Caribbean works to amplify the voices of vulnerable and marginalized communities, developing media partnerships to communicate development agendas and enable communities to drive their own development. In terms of discrimination barriers, LGBTQ Asian and Pacific Islander communities face multiple challenges including housing discrimination (with one in five experiencing discrimination in rental and home-buying processes), limited access to healthcare services, and stigma related to their LGBTQ identities. These communities also face additional barriers due to cultural traditions that may not fully embrace their identities, while lack of federal non-discrimination protections based on sexual orientation and gender identity further compounds these challenges.","context":["Panos Caribbean's goals are to enable the people of the Caribbean to conceive, drive and communicate their own development agenda. To develop media, information and communication partnerships, to communicate towards development.\nTo amplify the voices of the vulnerable, the marginalized and the excluded.\nKINGSTON, Jamaica, Friday October 5, 2018 (IPS) – In the face of the many challenges posed by climate change, Panos Caribbean, a global network of institutes working to give a voice to poor and marginalized communities, says the Caribbean must raise its voice to demand and support the global temperature target of 1.5 °C.\nAhead of the United Nations climate summit in December, Yves Renard, interim coordinator of Panos Caribbean, said advocacy, diplomacy and commitments must be both firm and ambitious.\nHe said this is necessary to ensure that the transition to renewable energy and a sharp reduction in emissions are not only implemented but accelerated.\nPICTURED: YVES RENARD,INTERIM COORDINATOR OF PANOS CARIBBEAN (PHOTO DESMOND BROWN)\nPanos Caribbean is part of the Advisory Group assembled by CARICOM Energy to formulate a Region-wide communications strategy for sustainable energy\n(CARICOM Secretariat, Turkeyen, Greater Georgetown, Guyana) - The Energy Unit of the CARICOM Secretariat has launched an initiative to formulate a Region-wide communications strategy for sustainable energy. The purpose of the strategy will be to create and increase awareness of challenges and opportunities in the energy sector; to facilitate behavioural change at all levels; to encourage innovation; and to facilitate the transition to new energy systems.\nOver the coming weeks, an Advisory Group facilitated by the CARICOM Secretariat will conduct research and consultations to identify ways in which challenges and opportunities related to energy access, energy security, energy efficiency, environmental protection and adaptation to climate change can best be communicated to all sectors of the Caribbean society.\nThe Advisory Group brings together representatives of key regional organisations involved in communications in the energy sector. They include the Caribbean Development Bank (CDB), the Caribbean Electric Utility Services Corporation (CARILEC), the Caribbean Media Corporation (CMC), the CARICOM Regional Organisation for Standards and Quality (CROSQ), the Organisation of American States (OAS), the OECS Commission and Panos Caribbean.Read more ...\n- REVISED 17 MAY: SUBMISSION OF EXPRESSION OF INTEREST AND FOCUS GROUP DATES -\nWith the support of the Planning Institute of Jamaica (PIOJ) as part of the Jamaica Pilot Programme for Climate Resilience (PPCR), Panos Caribbean is implementing the Voices for Climate Change Education Initiative. The purpose of this project is to promote climate change awareness at the community, sectoral and national levels through the engagement and use of popular local artists and performers and through the production and dissemination of creative materials and messages. Community-level activities will focus on four locations (two rural communities and two coastal communities).\nAs part of this initiative, Panos Caribbean is seeking expressions of interest from suitably qualified persons or groups to provide two sets of services:\nExpression of interest should be provided in a short letter (maximum two pages) that includes a statement of capacity, examples of previous work involving similar tasks, and any other information that may assist Panos Caribbean in the evaluation of submissions. These evaluations will be based on three sets of criteria: relevant skills and experience: 60%; interest in climate change and development issues: 30%; knowledge of Panos Caribbean and its work: 10%. The same person or group may express interest for both activities. Following the evaluation, Panos Caribbean will approach selected applicants and will make a financial offer based on available budget.\nOn the occasion of the 25th edition of World Press Freedom Day, May 3, 2018, Panos Caribbean shares with the Caribbean press a reflection on the state of Haitian press. This reflection, in the form of a mini-report, was presented and discussed by Panos in November 2017, with Mr. Edison Lanza Rabatto, the Special Rapporteur for Freedom of Expression of the Inter-American Commission on Human Rights.\nDOWLOAD: \"FREEDOM OF EXPRESSION, AN ACQUIRED RIGHT TO BE PROTECTED: REPORT ON THE STATE OF FREEDOM OF EXPRESSION, THE MEDIA AND ACCESS TO INFORMATION IN HAITI\" - NOVEMBER 2017 (PDF, 228.93KB)\nIn February 2018, in response to the invitation from the United Nations Framework Convention on Climate Change (UNFCCC) Secretariat and the High-Level Champions to non-Party stakeholders to provide inputs to the Talanoa Dialogue, Panos Caribbean, with the support of Climate Analytics, has organised a process aimed at: (a) informing civil society, the private sector and other non- State actors of this Facilitative Dialogue, (b) highlighting its relevance and importance to the Caribbean region, and (c) encouraging inputs into the Dialogue. This process builds on the campaign initiated by Caribbean stakeholders in July 2015 in support of ambition and of the 1.5 degrees target. Climate Analytics and Panos Caribbean are committed to sustain this Talanoa process among non-State actors in the Caribbean over the coming months and to provide a comprehensive statement in advance of the October deadline.\nThe Paris Agreement of 2015 was a significant milestone in global efforts to limit dangerous climate change, but it requires radical measures and strong ambition in order to achieve its goals. At present, Parties’ pledged actions (Nationally Determined Contributions) put the world on a pathway to a 3 or 4 degree Celsius increase in average global temperatures. This is a far cry from the Paris Agreement goal to hold the increase in global average temperature to well below 2 degrees Celsius and pursue efforts to limit the increase in global average temperatures to 1.5 degrees Celsius above pre-industrial levels. An increase in average global temperatures by 3 or 4 degrees would be catastrophic for the countries of the Caribbean region that are already experiencing deadly impacts of climate change with a 1 degree average increase.\n|An island concept encountered throughout the South Pacific archipelago, talanoa is a Fijian term referring to an inclusive, transparent dialogue based on a process of sharing stories, building empathy and reaching decisions for the collective good and, as such, relies on the pooling of ideas, skills and experience from all participants. This Caribbean process will be inspired by this concept.|\nThere are important opportunities in 2018 for the Caribbean region to engage in these issues. At COP21, the Parties in the Climate Change Convention decided to convene a Facilitative Dialogue, later renamed the Talanoa Dialogue (see box, right), to take stock of the collective efforts of Parties in relation to progress towards the long-term goal of the Paris Agreement and to inform the preparation of new and / or revised nationally-determined contributions. The Dialogue offers the opportunity for all actors to contribute to the discussions and negotiations that will put the Paris Agreement into action, and the Secretariat of the Convention is inviting inputs. The first deadline is 2 April 2018 for discussions in conjunction with the April/May session of the COP. A second round of consultations will take place later in the year.\nWe encourage concerned organisations in the Caribbean – government agencies, civil society and faith-based organisations, trade unions, community groups, scientific institutions, private sector groupings – to make their voices heard in this process.\nWhere are we in our response to climate change? Where do we want (and need) to go? How do we get there?\nContributions can be submitted:\nDOWNLOAD LA PROBLÉMATIQUE DE LA COMMUNAUTÉ LGBT EN HAÏTI À TRAVERS LE PRISME DES MÉDIAS (FRENCH - PDF - 2,81MB)\nPort-au-Prince, Haiti, 10 October 2017 - A new study by the LINKAGES project and Panos Caribbean highlights the past, current and potential role of the media in promoting equity and social justice in Haiti, looking at the coverage of issues affecting the Lesbian, Gay, Bisexual and Transgender (LGBT) community.\nAccess to health is a fundamental human right, but a large proportion of the Haitian population does not have access to essential care. For the LGBT community the situation is much worse than for the rest of the population, because of discrimination, prejudice and victimisation, and the situation is even worse for people living with HIV, with recent studies having revealed that a gay man is 24 times more likely to be infected by the HIV than others are. Yet there is no public policy in Haiti that considers this reality and seeks to provide essential health care to this segment of the population.\nAccording to Steeve Laguerre, the LINKAGES country representative for Haiti, “one of the goals of this report is to have an Haiti in which the human rights of LGBT persons are respected and they are able to live with dignity, free from discrimination, persecution, and violence. No one should be punished”, says Laguerre, “for who they are or who they love. LGBT rights are basic human rights; an LGBT person should have access to all services offered by the Haitian Government. LGBT persons are an integral part of every society and they are our colleagues, neighbours, friends, and family members, each and every Haitian citizen should be recognised and equally valued.”Read more ...\n|Representatives from Jamaica at Nanjing University of Information Science and Technology. From left: Kahuina Miller of the Caribbean Maritime Institute; Alicia Sutherland of the Jamaica Observer and Wesley Burger of the RJR Communications Group, with Petre Williams-Raynor, Country Director for Panos Caribbean - Jamaica and Patricia Williams-Bignall, a human resources professional turned writer.|\nPanos Caribbean is among the more than 30 representatives from organisations across the developing world, gathered in China this month for a training programme to boost their knowledge of climate information services.\n“There is no question of the value of being a participant here. Climate change education and advocacy around climate justice forms a part of the core of what we do at Panos Caribbean,” said Petre Williams-Raynor, Country Director for Panos Jamaica.\n“Only a week into the course and already my knowledge of climate change has increased. Also, my appreciation for the rigour of the research that goes into arming us with the needed information to inform our projects and, ultimately, empower our beneficiaries in the region has been significantly enhanced,” she added.Read more ...\nThe years-long wait goes on for a decision on a boundary for the Cockpit Country one of the few remaining forest-cover gems in Jamaica, an area rich in biological diversity and one seen as invaluable to the island's freshwater security.\n\"I understand that there was a protracted negotiation between the various government entities and a compromise position was reached, and that recently there has been an attempt to make that compromise position much smaller,\" revealed Diana McCaulay, chief executive officer for the Jamaica Environment Trust (JET).\nPanos Caribbean is reproducing here an article that was first published on Petre Williams-Raynor's blog, Green Seeds.\nUp to last June, energy was a subject to which I directed little of my attention unless and until it came up in the context of the climate change challenge facing the Caribbean and — of course — on the monthly occasion of my electricity bill appearing in the mail.\nCSEF 2017 delegates during a working group session on Monday, January 23.\nThings have changed as my education has deepened — fuelled by an ever-ballooning interest and the development imperative with which I must contend as, inter alia, country head of a NGO, Panos Caribbean, which has, in particular, vulnerable and marginalised people as our focus.Read more ...\nPanos Caribbean is reproducing here an article first published by Caribbean News Service.\nNASSAU, The Bahamas, Jan 23 2017 – An official of the Caribbean Development Bank (CDB) has reiterated a statement made by its president in 2014, which points to the need to move away from imported fossil fuels.\n“Unless we can reduce our dependence on imported fossil fuels, and unless we can substantially reduce energy costs, we will not succeed in improving our competitiveness and reducing our vulnerability to external shocks,” Head of Renewable Energy and Energy Efficiency at the CDB, Tessa Williams-Robertson said.\nSpeaking here at the opening of the fifth Caribbean Sustainable Energy Forum (CSEF), Mrs. Williams-Robertson said the meeting plays an important role in facilitating dialogue on sustainable energy development; creating a space for sharing good practices, ideas and lessons learned; and in driving decision-making, policy and action across the Caribbean.Read more ...","Being Asian/Pacific Islander & LGBTQ: An Introduction\nLesbian, gay, bisexual, transgender and queer (LGBTQ) Asian and Pacific Islander people have long played important roles in their respective communities. Journalist Helen Zia, who, with her partner Lia, would become one of the first same-sex couples married in the state of California, covered the now-infamous murder of Vincent Chin in Detroit, Michigan. Openly gay actor George Takei has become a popular advocate for LGBTQ rights, and Hawaii Civil Rights Commissioner Kim Coco Iwamoto became the first transgender woman to win statewide office when she was elected to Hawaii's Board of Education in 2006. B.J. Cruz has had a long and distinguished career in Guam, serving previously as Chief Justice of the Supreme Court and now as Vice Speaker of the Guamian Legislature, and Jose Antonio Vargas is an undocumented journalist, filmmaker and immigrant rights activist.\nAccording to the Pew Research Center, there are approximately 18 million Asians currently living in the United States, which amounts to 6 percent of the nation's population. Native Hawaiian and other Pacific Islanders make up roughly 0.4 percent. Data analysis by the Williams Institute suggests there are at least 325,000 LGBTQ Asians and Pacific Islanders currently living in the U.S., and nearly 33,000 are in same-sex partnerships. One-third of those couples live in California, Hawaii or New York.\nWhat are some important issues affecting LGBTQ Asian and Pacific Islander communities?\nBecause of the interconnected nature of many Asian and Pacific Islander people, families and communities––both within their countries of ancestry, residency and citizenship, and as members of global diasporas––the issues facing Asian and Pacific Islander LGBTQ people are as complex as their communities, including:\n- Economic Insecutiry: In the U.S., there is a wide range of poverty rates among Asian and Pacific Islander communities. Nationally, about 14 percent of Asians live in poverty. While Filipino, Japanese and Indian communities are at the lower end of this spectrum, with poverty rates between 5 and 8 percent, Hmong, Bangladeshi, Cambodian and Laotian communities have poverty rates between 20 and 27 percent. Nationally, about 20 percent of Pacific Islanders are living in poverty, ranging from Fijian communities on the low end of the spectrum at 5 percent, and Marshallese communities at the high end at 49 percent.\n- HIV & Health Inequity: Lack of access to HIV prevention and testing services is a seious concern in Asian and Pacific Islander communities. In the U.S., more than one in five Asians living with HIV are unaware of their status. Some of the factors contributing to this problem include language barriers, stigma related to LGBTQ identities, fear of discrimination and harassment and family pressures. Native Hawaiians and other Pacific Islanders have the fourth highest rate of HIV diagnoses in the U.S., although these numbers are likely conservative because of inadequate data collection.\n- Access & Discrimination: In the U.S., roughly 32 percent of Asians and Pacific Islanders have limited English proficiency, which can be a serious barrier to accessing a range of crucial services in housing, healthcare and education. Additionally, a study by the U.S. Department of Housing and Urban Development found one in five Asians and Pacific Islanders has experienced discrimination in the rental and home-buying process. Rates are likely higher among LGBTQ Asian and Pacific Islander people due to the lack of federal non-discrimination protections based on sexual orientation and gender identity.\n- Immigration: Asian and Pacific Islander people are the fastest-growing racial and ethnic population in the U.S. Between 2012 and 2013, the Asian population grew by 2.9 percent and the Pacific Islander population grew by 2.3 percent, compared to a 2.1 percent growth in the Latino/Hispanic population and a 1.2 percent growth in the African American population. This growth is largely due to immigration, as 74 percent of Asians in the U.S. are foreign-born, and 16 percent of Pacific Islanders are foreign-born. Of the at least 267,000 LGBTQ undocumented adults in the U.S., 15 percent are Asian or Pacific Islander, which underscores the need for humane immigration policies.\n- Stigma & Persecution: Because of the wide variety of countries and cultures across Asia and the Pacific Islands, attitudes toward LGBTQ people vary greatly across the region and among Asian and Pacific Islander people in the U.S. In general, many of these nations are far less accepting of LGBTQ people than other parts of the world––especially when it comes to legal protections like marriage equality and non-discrimination laws. The countries widely regarded as safest for LGBTQ individuals in Asia are Taiwan, the Philippines and Vietnam. In the Pacific Islands, nations like Fiji and Vanuatu have been described as tolerant and accepting of LGBTQ people. In a sign of progress, New Zealand has legalized marriage equality and the U.S. territory of Guam has both marriage equality and inclusive LGBTQ workplace protections. Despite such progress, LGBTQ Asian and Pacific Islander people in the U.S. often have to contend with families and cultural traditions that are not entirely embracing of their identities.\nWhere can I find resources that are relevant to the LGBTQ Asian and Pacific Islander community?\n- National Queer Asian Pacific Islander Alliance\n- GLAAD Asian Pacific Islander Resource Kit\n- PFLAG Families of Color Network Resources for Asian-American/API Communities\n- Q&A Space: Stories from LGBTQ Asian and Pacific Islanders & Allies\n- UCLA LGBT Resource Center Asian and Pacific Islander Resources\nThis resource is specific to the experiences of LGBTQ people living in the United States who identify as Asian and Pacific Islander. For more on the experiences of Asian and Pacific Islander LGBTQ people living outside of the U.S., click here."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:c70f7eb9-7d15-4e57-904e-9dbcb16ebed3>","<urn:uuid:069ffe49-a8fd-4a23-bdd5-0eff11dbe3a5>"],"error":null}
{"question":"What role do expert advisers play in both horse auction purchases and home buying processes?","answer":"In horse auctions, experts like veterinarians with equine medical expertise are considered ideal advisers who help avoid costly mistakes that novices often make, and depending on operation size, a team of advisers may be beneficial. In real estate purchases, expertise comes primarily through real estate agents who specialize in specific neighborhoods, help understand market value, and assist in negotiations, though they primarily represent the vendor's interests in New Zealand. Both contexts emphasize the importance of professional guidance for major purchase decisions.","context":["Purchasing At Auction\nBuying horses through an auction is one of the most popular avenues of purchasing. It also is one of the most exhilarating aspects of the horse business. Imagine a horse race where bets are taken up to the finish line. A fictitious race of that type is similar to an auction where prospective bidders duel with one another over the horse of their choice.\nSeveral thousand horses are sold each year through auctions. Various types of auctions are held, the most popular of which are yearling sales and mixed stock sales. Yearling sales are exclusively for horses which are one year of age, while mixed stock sales feature broodmares and other horses of various ages. For individuals in the horse industry, particularly persons just entering the sport, an auction can be the best source from which to purchase. Normally the choices of horses are plentiful and are available for a wide range of prices. However, like any business venture, a sound game plan based on much research and preparation is essential. Some helpful guidelines are as follows:\nDo Your Home Work\nBegin educating yourself about the horse business. Structured avenues exist in the industry through which to study husbandry, nutrition, genetics and breeding management, but the true aspects of this business are basically self-taught. Various trade publications will provide you with much of the information you need to get started.These trade journals publish upcoming sale dates in their calendar of events.Various sale companies also advertise their upcoming sales in the publications, describing the type of sale and posting sale dates.\nCheck Out The Sale Company\nSeek an auction company that holds a valued place in public trust. Industry advertisers and specialists can guide you to these reputable companies.\nStudy The Catalog\nThe sales catalog is considered the \"Bible\" for all prospective bidders attending an auction. Contained in each catalog are the sale conditions, the legal terms that govern purchases. In addition, a page is published for each horse offered. This page is much like the provenance on a painting or a prospectus on a stock offering. It identifies the animal, the consignor and provides extensive details about the relatives of each horse offered.\nSeeking The Advice Of Experts\nChoose an adviser who will focus on the goals you have established for your horse business. A reputable adviser will help to avoid costly mistakes that a novice often makes. A veterinarian with knowledge of the horse business as well as equine medical expertise is an ideal adviser. Depending on the size of your operation, having a team of advisers to help properly guide you may be beneficial.\nAttend An Auction And Observe\nIt is essential to get a sense of how the market is behaving.The auction is in effect the most reliable barometer, charting the highs and lows of current conditions. Reading the price list will tell you the final results. However, it will not reflect the competition, interest and demand for a particular lot.\nGet Familiar With Auction Terms And Conditions\nThe fever of a good auction can bring out the high roller lurking in all of us.Therefore, it is important to become familiar with the terms and conditions of an auction prior to bidding.These terms and conditions dictate the rule \"you bid for it, you pay for it.\" The successful bid is irrevocable and legally binding. So, if you are the firsttime buyer whose arm seems to have a mind of its own, your purchases might be costly ones, if you have not done your homework. As all successful people in business realize, you must look before you leap. Many other shrewd investments have been purchased through the auction ring. Of course, there have been some lucky buys, but many of the best have been the result of thorough research and foresight. The broodmare Harems Choice, with her seven day-old foal at side, proved to be an outstanding find for $20,000. Her foal, later named Royal Quick Dash, went on to win the 1991 All American Futurity, thus increasing Harems Choice's value considerably.The 1999 three-year-old champion Old Habits was purchased as a yearling for $18,500 and by the completion of his second year of racing he had earned more than $672,000.\nThe American Horse Council can provide you with tax tips for horse owners. Contact the AHC for your copy or to purchase a copy of the Horse Owners and Breeders Tax Handbook.","Buying a home is a big decision and an exciting one. Property ownership is likely to be one of the most important financial decisions you make so it's essential to arm yourself with the right information to ensure you get the best result.\nTo make the process easier, here we take you through the key steps involved in buying a property in New Zealand. Using this information you'll be ready to start house hunting for the home of your dreams.\nWhen it comes to buying a house, one size does not fit all. It's important to find the right type of property for you and your future, so the first step is making a list of what you are looking for. Think about your aspirations and what sort of property will fit these. Are you planning a family? Do you intend to have pets? Do you like to entertain? Do you want a swimming pool? Just remember that the more particular you are, the more difficult it will be to find the right home.\nSome factors to consider:\nPrioritise the list into needs and wants and then do your homework. There are thousands of properties for sale every week so you don’t need to rush in and make an offer on the first one you see. Take the time to inspect a reasonable number of homes to give yourself a true understanding of the market value of the properties and area you’re looking at.\nIt’s always a good idea to keep a list of the properties viewed and their features, and even take a photo so you can remember them in more detail. In searching, the first homes you see can quite often, in retrospect, have more appeal as your market knowledge increases. At other times your first impressions will help you define your priorities and preferences.\nFind a real estate agent who specialises in the neighbourhoods that you want to live in. As you look at the homes they are selling, talk to the agent about the type of home you’re looking for, give them an idea of what you can afford and explain your priorities.\nImportantly, choose and build a good rapport with an agent who will seek the property you want, understand what is important to you and who is willing to listen and go the extra mile to find the right home for you.\nThe best course of action is different for everyone but usually selling before you buy means freedom and financial assurance. By selling first your financial arrangements have been taken care of, and it gives you the freedom to bid at an auction or make an offer knowing you’re in a position to negotiate on price and time. It also gives you certainty around how much money you’ll have to put toward the next property and eliminates the risk of selling under pressure.\nBut this approach isn’t the right answer for everyone. In fact some may go on to kick themselves for going with this conservative method. The truth is, when the place of your dreams becomes available, you’ll be compelled to jump right in. And in many cases why wouldn’t you, given the fiercely competitive nature of NZ real estate?\nBuying first can be a viable option, especially when selling first can mean the arduous process of two moves by temporarily renting. But if you choose to buy first, ensure that you're never in a position where you're forced to sell in desperation, as this may lead to a high interest loan and further costs.\nBuying a home is a time of mixed emotions, from excitement to anxiety, and no doubt you just want to get started. Remember, there’s no black and white approach to house buying. What we do want to hammer home is that you properly evaluate the pros and cons of each decision to ensure you’re making the best choice, for your situation now, and in the future.\nTip: In New Zealand, real estate agents act on behalf of the vendor. However, if you've got a property to sell, a good agent will be more than willing to help you negotiate the purchase of your new home as well.\nReal estate trends are constantly changing, with supply and demand, economic factors, politics and population growth all having an impact. Timing is also particularly important as this can dictate whether it's a buyer's or seller's market.\nIt's helpful to know what's happening in the current market when you're looking to buy. Knowing this will give you an indication of what sort of properties are being sold, how quickly and for how much, so you know whether a property you're interested in represents value for money.\nKeep in mind that seasonal factors also influence the market. There are generally fewer properties for sale during the winter months, while spring is traditionally the most popular time of year to list a property for sale. However, homes are bought and sold throughout the year, so don’t let the season stop you from looking and if you find the right property, from buying.\nEach type of market has its own set of characteristics. Do your research so you have a clear understanding of the current market and how it relates to the wider housing cycle. An experienced agent can provide further insight on this.\nFew people can afford to buy a home without borrowing money. Before you step foot inside an open home, your finances need to be in order so you know how much you can afford to borrow. Once you have confirmed how much money you have to spend, stick to your limit and be realistic.\nThere are a number of additional costs to consider when buying a property, on top of the purchase prices so it's important to also be aware of these.\nSome of these extras include:\nAs part of your financial preparations, you'll also need to assess which type of home loan will be best for you. You can go directly to a bank or other financial institution to make a home loan application. There are a number of home loan products available so you may prefer to talk with a mortgage broker who is registered with the Mortgage and Finance Association of Australia or the New Zealand Mortgage Brokers Association. Mortgage brokers are independent and specialise in finding the most appropriate home loan for you.\nHome loan packages differ from bank to bank, however the following options are generally available:\nIt’s important you understand the cost of your mortgage and what your commitments are. Use a home loan calculator to get an estimate of your fortnightly and monthly repayments.\nThere are several ways of buying property including, auction, sale by tender, sale by advertised price and by negotiation.\nThe sale of a property by a bidding process on a given day. Properties usually have a reserve (minimum) price and if a bid doesn’t reach this minimum the property is \"passed in\". If it does not reach the reserve price, it is still to your advantage to be the highest bidder so you have the first right to negotiate with the seller.\nInvolves potential purchasers placing confidential bids for a property by a specific date. The bids may or may not include conditions and any bid can be accepted or rejected by the owner.\nThis is a property that is advertised with a set price. This method of sale still allows the buyer to negotiate on price.\nA buyer make an offer based on what they believe a property is worth. The seller can then negotiate with you on price through the agent.\nNegotiating with the seller is a normal part of the process when buying a home. The more attractive you can make your offer in terms of price, and the fewer conditions you’ve included as part of the offer, the more likely you are to have your offer accepted.\nWhen you are ready to put in an offer, the agent will write up a Sale and Purchase/Offer and Acceptance contract. This is an official document for the authorisation of the selling and purchase of a home. In the contract you can include conditions on the sale.\nAfter the offer has been accepted, your lawyer will check all the details of the title and prepare any necessary documentation. You will need to pay a deposit within three business days of acceptance of the offer, sign any mortgage documents and arrange your finances for payment of the balance of the purchase price.\nIt is a normal condition of sale that you have one pre-settlement inspection to ensure the property is in the same condition as when you agreed to purchase it. Check that all the chattels are still in place and any repairs agreed upon have been made.\nOnce your offer has been accepted and all conditions have been met, the sales agent will forward the contract to your lawyer. They will administer the settlement which includes exchange of titles and transfer of funds.\nNow that you have your settlement date it’s time to organise your move. Pick up a copy of Professionals Pathway to Moving booklet for a full checklist to assist you. There are several things to arrange. You lawyer should finalise the mortgage documents, arrange signing of the transfer with your bank, allocate rates and insurance and collection of the keys. Your insurance broker should arrange cover from the unconditional date. You should also organise to have your mail forwarded and book in a removal company, or a group of friends.\nOnce final payment has been made, settlement is confirmed. The keys of the property are handed over to you on the agreed date. Congratulations and welcome to your new property!"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:cec45053-0e73-49a1-953e-7080e30bbc00>","<urn:uuid:35b6ad7d-25b9-4e2a-9bd1-e50e64fa011c>"],"error":null}
{"question":"growing single corn vs multiple corn: possible?","answer":"Both growing single corn and multiple corn plants is possible, but there are important differences. A single corn stalk can grow alone as long as the seed is viable and has adequate warmth, light, water and nutrients. However, to get full-size ears from a single plant, you must manually take pollen from the tassel and dust it on the silk since corn is wind-pollinated. In contrast, growing multiple corn plants is more effective - planting in blocks of four to six rows allows for better pollination since corn is wind-pollinated. The more plants you have, the more pollen you'll create, resulting in more kernels per ear.","context":["Popcorn has grown into a favorite snack food since the tasty confection of Cracker Jack hit the scene at the World's Fair in 1893. We eat it plain or buttered; seasoned with herbs, spices or cheese; rolled into sweetened balls; and candy-coated with chewy caramel and nuts. You can find this tasty treat at theaters, fairs and festivals as well as sporting events, street corners and department stores. It's even popping up in home gardens.\nThough popcorn (Zea mays) and sweet corn share similarities, one way they do differ is that the popcorn kernels have a hard moisture-sealed hull and a dense starchy filling. When perfectly cured popcorn is heated, the kernels explode, inside out, into popped corn.\nPopcorn varieties are not limited to kernels of yellow or white. Options also include blue, yellow, pink, or even mahogany. And while varieties do play a role in popcorn quality, taste and popability, the ultimate secret to this gourmet treat lies with how it is grown, harvested, dried and stored.\nPopcorn thrives in the same growing conditions as sweet corn, so choose a sunny site and deep, fertile, well-drained soil.\nIf you're growing popcorn and sweet corn in the same season, be sure to separate the two to avoid cross-pollination. You can do this either by distance (250 feet), planting time (sow two weeks apart) or maturity date (for example, a 90-day variety versus a 120 day variety). If a crossing does occur it may result in tough, starchy kernels in the sweet corn.\nSow seeds directly in the ground one to two weeks after the danger of frost has passed and soil temperature has warmed to 60 degrees. You can get a jump on the growing season by starting seeds in 2 inch pots and transplanting to the garden when seedlings reach about 3 inches tall.\nGive your corn a tight spacing, sowing seeds or transplanting seedlings every 6 to 10 inches -- depending on the variety -- with rows spaced from 12 to 18 inches apart. For full, well-filled ears, plant your popcorn in blocks of four to six rows rather than individual long rows. Corn is wind-pollinated, so the more plants you have, the more pollen you'll create. And that means there will be more kernels per ear to pop.\nPopcorn is a hungry feeder, especially when it comes to nitrogen. Give seeds a jump start with a smooth seed bed enriched with plenty of compost or aged manure. Follow up with a high nitrogen fertilizer every two to four weeks or a foliar spray every one to two weeks until the corn begins to tassel. Examples of a natural fertilizer high in nitrogen includes composted manure, fish meal, alfalfa meal, or other organic sources. Cut back on nitrogen if plants turn a dark shade of green.\nWater plants regularly and deeply, especially when the stalks begin to tassel, which is the feathery flower at the top that releases pollen. Be sure to thoroughly wet the entire root zone. (Mulching around plants with compost or composted manure will feed plants, conserve soil moisture, and help prevent weeds.) Water less frequently once the ears have filled out. This will help produce the best yields and quality of popcorn.\nEnjoying the harvest\nPopcorn is ready to harvest when the silks turn brown and the kernels are fully mature, firm, and well colored. Leave corn drying on the stalks as long as possible, allowing the kernels to dry down naturally on the ear. Harvest and husk the popcorn and allow the ears to cure further in a dry and well ventilated location. Drying time can vary from one week to several weeks or more, depending on weather conditions.\nYour ears of popcorn are ready to shell when the kernels come easily off the cob, which is when the moisture content is around 13 to 14 percent. Test the popcorn by popping a few kernels. (To pop, put kernels or an ear in a folded paper bag in the microwave.) If they pop, it’s time to shell the corn. To shell the corn, roll the kernels from the cob with your hand, pushing firmly with your thumb. Wearing a sturdy glove is helpful when shelling.\nStore the shelled corn in a moisture-proof, airtight plastic or glass container in a cool, dry location. Avoid storing popcorn in a warm location or in the refrigerator, which can dry out the kernels. A moisture loss of as little as three percent can render your popcorn unpopable. If kernels dry out, adding a tablespoon of water per quart of popcorn may help revive their popability. Shake or stir the kernels until the moisture is absorbed, close up the container, and try popping again in a few days.\nWhen properly cured and stored, popcorn can remain popable for a long, long time. In fact, researchers found ancient kernels of popcorn believed to be 1,000 years old in tombs on the east coast of Peru. And guess what--the kernels still popped!\nPopcorn is as much fun to grow as it is to eat. But as any popcorn connoisseur knows, there is definitely a difference in taste among types.\n'Tom Thumb', 'Robust' and other yellow types explode into golden yellow snowflake or butterfly-shaped popcorn with a corny taste that's light and airy. Yellow popcorn also yields up to 46 times its original volume.\nWhite popcorn varieties like 'Japanese White Hulless' burst into smaller snowy white mushroom-shaped popped kernels that are tender and slightly sweet. This type yields 35 to 40 times its kernel size.\nBlue, pink and multi-colored types like 'Calico' typically pop into deliciously tender nuggets with nutty undertones. Mahogany varieties such as 'Strawberry' take on the characteristics of white popcorn.\n-- Kris Wetherbee\n-- Kris Wetherbee","Questions on: Corn\nRon Smith, Horticulturist, NDSU Extension Service\nQ: I've heard that if you cut the top off corn, it will grow taller and produce more. Is this true and where do you cut it? Also, half my corn stalks are tall and the other half short. It's like going down the line from tallest to shortest. What causes this problem? (e-mail reference)\nA: I have grown corn for commercial purposes and worked for farmers who did the same. We never cut the tops off because it makes no sense if you understand the growth of monocots, which corn happens to be. The problem could be water or nutrient availability or sunlight exposure. Something in the environment is not uniform.\nQ: Is it possible for dead corn stalks (used for decoration) to emit pollen? (e-mail reference)\nA: I really doubt it because the pollen was dispersed long ago. The likelihood of any being left is very remote. Also, it is very dense pollen by comparison, so the pollen would have washed away or decayed by now.\nQ: We planted four long rows of corn this year. The ears ended up being very short or what you call nubbins. The bees worked hard on pollinating the corn. What am I doing wrong? (e-mail reference)\nA: Instead of planting four long rows, try planting eight short rows next year. Obviously the pollen, which is wind driven, did not reach the silk in sufficient quantity to fill out the ears. I think if you alter your planting next year to a more block system, the results will be much better.\nQ: This summer my corn had a white and yellowish foamy substance shooting out of the plant. Some sections looked like the insulation foam in the can you get from your local hardware store. Some of the plants fell over and at least half of my sweet corn was infected. What is the disease? (e-mail reference)\nA: You had corn smut (Ustilago maydis), a common fungus disease of sweet corn, popcorn and field corn. In Mexico, it is considered a culinary treat. If you have any Mexican restaurants in your area, you might contact them to see if they would be interested in purchasing some. You could make more money selling it for ethnic cuisine than as straight sweet corn. No sprays are available to alleviate the problem, so try to find varieties/cultivars that are bred for resistance and clean up the garden.\nQ: Can one corn stalk grow alone where no other corn is planted? (E-mail reference)\nA: You can grow just one corn plant but you need to take the pollen from the tassel and dust it on the silk. Full-size ears will not develop unless you do that. It will grow as long as the seed is viable (alive), has adequate warmth, light, water and nutrients.\nQ: I know a family that wants to grow sweet corn for local farmers markets. They want to plant a number of different varieties but are worried about cross pollination. What distance is needed to avoid cross pollination? (Cavalier, N.D.)\nA: Sometimes the maturity of the different varieties of corn will prevent cross pollination. If that isn't the case, then as much distance as possible needs to be kept between the varieties, sometimes as much as 500 feet since corn is a wind-pollinated crop. Im grossly dating myself now, but I grew an acre of sweet corn for market purposes when I had my small farm in New York. I simply planted three varieties -- early, mid-season and late. By the time the early one tasseled out and fertilized the ears, the mid-season was just starting to tassel.\nQ: I have a question about so much smut on the sweet corn. We have been getting sweet corn from my wife's brother. He has a good size plot and likes to raise corn and give it away to his friends. He was quite concerned about the problem of smut this year. He has had different maturity corn but I don't know the seed company. The last corn we got was a later maturity and it had a thinner ear, smaller kernels and a few white kernels. It was just maturing. Could have used a couple more days but it was good. The amazing thing was it had very little smut. Next to none. Could the later maturity have something to do with this? (Breckenridge, Minn.)\nA: Corn smut thrives in warm weather, with the optimum being in the 80 to 90 degree F range. The best control is to follow good sanitation practices and plant corn hybrids noted for good vigor and resistance to this fungus. Crop rotation may help somewhat, although it can be spread via birds and insects from other adjacent areas.\nQ: Does a corn stalk just produce one corn cob? (Napoleon, N.D.)\nA: Corn stalks often produce at least two, sometimes three, cobs. The second and third ones are smaller, sometimes down to the \"nubbin\" size, but still good eating.\nQ: I have a lady who says she has raised sweet corn all her life and has never had this problem. The corn in her garden has tiny black flies on the tassels. I thought it was just a fly that was attracted to the tassels and would do no harm. (Steele, N.D.)\nA: They are likely confused chinch bugs that should be feeding on the leaves but perhaps find the silk more tasty. If they are truly flies, then I think they are going after the \"nectar\" on the silk and are nothing to worry about.\nQ: I would like to know why I have not been able to grow corn for about the past four years. I can only get four sprouts from two packages of seed. Previously, I have had great success. I have had the same garden spot for 20 years and rotate my crops religiously I also have fertilized with urea, but not consistently. (Lansford, N.D., e-mail)\nA: Why won't your corn grow now where is has grown in the past? Low sunlight? Too cold or wet? Birds get the seed? Cutworms? Old seed? Late frost? Herbicide residue?\nI cannot think of any other possibility than what I've listed here. Why not try a different variety? There are several great ones out there.\nQ: What chemical product can be used to control weeds and thrips in a plot of gladiolas? I prefer to garden organically, but I am also having problems with weeds in a plot of sweet corn. (Lake Benton, Minn.)\nA: You'll have a tough time controlling thrips in your glads organically. I have never been successful. You can try insecticidal soap if there are no predatory insects present. Otherwise, use Orthene (a contact/systemic) to control them.\nI would suggest presprouting the weed seed and killing off the seedlings with Roundup. Or, you may want to try solarizing the area by covering it with heavy clear plastic for about two weeks prior to planting. The weeds will sprout and stay soft, with some drying. Those that don't are easily rogued out when the plastic is removed. Plant your sweet corn close. Hand cultivate while canopy is open (usually until July 4th or so) then let them go. The corn will form a dense enough canopy so that the weeds beneath it will be weak enough to be noncompetitive. Otherwise, there are many herbicides that canbe used in sweet corn.\nQ: Can you tell me what is wrong with my corn plant? The bottom leaves are turning brown and yellow and I don't know why. I also have a cacti, but I don't know if it is a Christmas or an Easter cactus. Is there a big difference between the two? (Enderlin, N.D.)\nA: The corn plant could probably stand to be propagated. Cut the plant back to about a 6-inch stub, then cut the removed trunk into roughly 4-inch-long pieces. Place them on their sides in damp sphagnum peat, and in about six weeks or so new growth should be evident. Repot the mother plant in fresh potting soil in a free-draining container. Refer to \"Home Propagation Techniques\" (NCR274).\nYes, the two cacti are different. They are either different species of the same genus, depending on the taxonomist you wish to go with. To me, they will always be different species: Schlumbergera truncata (Christmas cactus) and S. gaertneri (Easter cactus).\nQ: Please find enclosed some leaves from my corn plant, it is over 6 feet tall and 10 years old. The leaves have started getting brown and turning yellow, then brown and leathery. The stem turns to a bark looking covering from the bottom where most of the leaves turn brown. I have it in a large pot, and I try to keep it moist. Should I repot, or what should I do? (Cleveland, N.D.)\nA: Refer to NCR publication No. 274, \"Home Propagation.\" I want to suggest that you may wish to propagate this if the plant does not recover from repotting.\nThe cause of your plant problem could either be too much water during the winter or the plant has been exposed to too many cold drafts. When you repot, make sure it is into a free-draining container and that it can be located where cold cannot reach it.\nQ. What kind of chemical could I use in planting sweet corn for weed control whether or not it is a pre-emergence or post-emergence.. What kind of chemical could I use for purslane control in my sweet corn? (Wahpeton, N.D.)\nA. Treflan is the most common weed control (pre-emergence) for most vegetables (tomatoes, beans, peppers, mustard, carrots, cabbage, etc.), but not for corn. Prowl can be used on sweet corn for controlling many weeds like foxtails, crabgrass, barnyardgrass, purslane, spurge and kochia.\nThe active ingredient in Prowl is pendimethalin, also commonly found in turfgrass weed control products.\nThanks for writing.\nQ. We have our sweet corn patch on part of a barnyard that is infested with all varieties of weeds. Is there any kind of spray that can be used that will not harm sweet corn plants? We do cultivate with the tractor, but need something to control the weeds in the rows. (Pelican Rapids, Minn.)\nA. You ask a simple question, but the answer is difficult to come up with. Here are some options I can suggest.\n1. Allow weeds in area to sprout, then kill down with Roundup.\n2. Basagran and 2,4-D are the only non-restricted use products that you can use for broadleaf control.\n3. Prowl, Eradicane and Pendimethalin products are non-restricted for grassy weed control.\nYou may want to try crop rotations to help keep the weed\nQ: I remember someone talking about how a person can grow baby\ncorn on the cob. My husband and I have been having a discussion\nabout this. I think I\nremember that they are just immature regular corn with the silk removed. He thinks that there has to be a dwarf corn plant that produces more than one ear per\nplant. I would like to try growing baby corn ears. Do you have any suggestions? Can you tell me how to go about it? (Grand Forks, N.D., e-mail)\nA: Simply plant your corn and harvest it before it silks. To keep it from becoming fertilized, you can remove the tassel, which is the source of the pollen.\nThen simply harvest the sweet, edible, small cobs that develop. Couldn't be easier. Enjoy!\nQ: A recent column of yours included a discussion about baby\ncorn. Let me relate my experiences. The first time I planted\nseveral rows about 20 feet long. The\nmore you pick it, the more it produces. I'd get a big wheel barrow full at a time. You can't husk tiny, tender ears. It's best to cut a slit down to the ear and lift it out.\nOut of that wheel barrow, I'd get only about two quarts. It was too time consuming to continue all summer, so I pulled the stalks before they had a chance to\nproduce the 40 ears, as advertised. The next year I planted 15 seeds, just enough for a meal at a time or to freeze for a meal. They need to be picked every second\nor third day. (e-mail)\nA: Thanks for the input on the baby corn. I have seen those miniatures advertised but knew that the same basic end result could be achieved via my\nmethod. It is wise of you to cut back on your planting the following year. It is one thing to like something, but to be overwhelmed with it is no pleasure!\nQ: I have a question about what appears to be a fungus on some\nsweet corn stalks. At first small spots show up on the leaves.\nThe spots are about 3 to 5 mm in\ndiameter and of a light cream color. Later a fungus like growth shows up where the leaf and stalk join. This growth later becomes thickened and continues to spread\nalong the main stalk. Is there any product that can be applied to control or prevent this? Last year I also had some problems with the formation of the dark smut. It\nhas dark blue/black appearance. Do you have any suggestions about what can be used for this? Thanks again for your help. (E-mail reference, Faulkton S.D.)\nA: That is known as corn smut or Ustilago maydis, for which there is no cure or useful spray. It occurs when the temperature is in the 80's and 90's,\nand we are experiencing wet, humid weather. It saps the energy from the corn plant, reducing ear development. The best way to handle this is to cut off\nthe galls before they release the black powdery spores, plant varieties of corn known to be resistant to smut, and finally follow good garden sanitation,\ncleaning up all debris in the fall. Do not use manure in your soil if this continues to be a problem.\nto Vegetables/Fruits Menu\nBack to the Hortiscope Table of Contents"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:b274680b-15fa-4d0b-b960-72317dd89778>","<urn:uuid:9ff4a10d-8fb1-4e0e-b490-865cf169afe8>"],"error":null}
{"question":"What are the characteristic marine species one can observe in Jinek Bay versus Hanauma Bay's protected waters?","answer":"In Jinek Bay, visitors can observe clown surgeonfish, butterflyfish, parrots, sixbar wrasse, and large groups of black and white damsels. The bay also features Maori wrasse, yellow-lipped sea kraits, convict surgeonfish, and concentrations of sea anemones with fire clownfish. Sharks and turtles are less common but occasionally spotted. In contrast, Hanauma Bay is home to parrotfish, surgeonfish, and triggerfish, along with many other colorful fish species unique to Hawaii. Green sea turtles can be seen in Hanauma Bay's deeper waters beyond the reef, though they are less frequently observed here than at other Hawaiian locations. Both locations offer diverse marine life, but Jinek Bay appears to have a greater variety of regularly visible species.","context":["Looking over Jinek Bay from the cliffs that surround it, you’ll quickly understand why this must-see site in Lifou is nicknamed “The Natural Aquarium”. Through the surface of its beautifully translucent water, you can already see the magnificent corals that make up the reputation of this spot. Here, it’s an invitation to discover some of the most beautiful reefs of Lifou, where hundreds of species of tropical fish flourish and swim about.\nJinek Bay is located in Easo, on the northwest coast of Lifou island. To get there, it is better to have a rental car. Otherwise, hitchhiking works pretty well on the island. From Wé, the main village of Lifou, it takes about 35 minutes by car. It is recommended to use a geo-tracking application to find the site, though it is poorly indicated.\nThere are stairs installed on the small cliff that allow yourself to be equipped and ready to launch into the water safely.\nThe area to be explored covers the coral reef that has developed in the calm waters of the bay. You can easily spot the coral bommies from the stairs and the different lookouts. In this sheltered area and after the absence of a beach, the corals developed only a few meters from the shore, just below the surface of the water.\nAt this spot, the underwater landscape is rather constant. It alternates between more or less extensive coral plateaus just below the surface of the water (↕0.5m) and then deeper intermediate zones (↕3-8m), with sandy bottoms.\nJinek Bay greatly deserves its nickname of “Natural Aquarium”. Before completely immersed in the water, everything is already an incredible wonder: multicolored corals swept by sun rays, giant clams unfolding their fluorescent mantle in crystal clear water, sea lilies swaying by the movements of the water. Here, the decor is divine. Although some areas are slightly damaged, especially near the stairs, the corals are in overall superb condition on this spot.\nClown surgeonfish, butterflyfish, parrots and sixbar wrasse come and go on the reef. In the deepest areas, groups of hundreds of black and white damsels stand above the drop-offs. During your exploration, you may be surprised by a Maori wrasse (quite regularly seen in the bay), a yellowed-lipped sea krait sneaking between the corals, or a bench of convict surgeonfish storming a rock covered with small algae. The reef is also home to very localized concentrations of sea anemones (↕1.5-2m), around where dozens of fire clownfish gravitate. Sharks and turtles are not as common in Jinek Bay, but are sometimes sighted by the luckiest in the blue.\nThis site is natural and you will not find any restaurants in the immediate vicinity. A water source is available outside the sanitary block on the site, which is often closed.\nThese snorkeling spots are accessible to beginners and kids. You will enter the water gradually from a beach, or in a less than 3ft. deep area. The sea is generally calm, shallow, with almost no waves or currents. These spots are usually located in marked and/or monitored swimming areas. It is not necessary to swim long distances to discover the sea life.\nThis level only apply when the spot experiences optimal sea and/or weather conditions. It is not applicable if the sea and/or weather conditions deteriorate, in particular in the presence of rough sea, rain, strong wind, unusual current, large tides, waves and/or swell. You can find more details about the definition of our snorkeling levels on our snorkeling safety page.\nYou must be logged in to post a comment.\nSnorkeling spots are part of a wild environment and their aspect can be significantly altered by weather, seasons, sea conditions, human impact and climate events (storms, hurricanes, seawater-warming episodes…). The consequences can be an alteration of the seabed (coral bleaching, coral destruction, and invasive seagrass), a poor underwater visibility, or a decrease of the sea life present in the area. Snorkeling Report makes every effort to ensure that all the information displayed on this website is accurate and up-to-date, but no guarantee is given that the underwater visibility and seabed aspect will be exactly as described on this page the day you will snorkel the spot. If you recently snorkeled this area and noticed some changes compared to the information contained on this page, please contact us.\nThe data contained in this website is for general information purposes only, and is not legal advice. It is intended to provide snorkelers with the information that will enable them to engage in safe and enjoyable snorkeling, and it is not meant as a substitute for swim level, physical condition, experience, or local knowledge. Remember that all marine activities, including snorkeling, are potentially dangerous, and that you enter the water at your own risk. You must take an individual weather, sea conditions and hazards assessment before entering the water. If snorkeling conditions are degraded, postpone your snorkeling or select an alternate site. Know and obey local laws and regulations, including regulated areas, protected species, wildlife interaction and dive flag laws.","With its calm and protected turquoise waters, only a few minutes from the road for Honolulu, Hanauma Bay is the main snorkeling destination on the island of Oahu. Despite some drawbacks –among which are entrance fees and large visitor numbers– the lagoon, nestling in an ancient volcano crater, is ideal for beginners, who can observe diverse underwater life in good safety conditions.\nHanauma Bay is about 12 miles (20km) east of Waikiki. Take the Freeway H1 east, which later becomes the Kalanianaole Highway. The site is very well signposted from the main road. Try to arrive early, as parking places are limited ($1 per vehicle) and are very soon taken. It is also easy to get there by public transport. Rather than taking the shuttle service run by the Park, which is quite expensive (from $22 per person for a round-trip ticket), you can take the TheBus line 22 bus from Waikiki, which costs $2.75 for a one-way ticket and will drop you off in front of the Park in around 40 minutes.\nYou can enter the water anywhere along the beach, but you should avoid the area across from the channel if you are a beginner, as the current can be quite strong. The information center abounds in tips for exploring the site (circuits, the different areas, descriptions of the species of fish and shellfish, etc.), so make the most if it.\nThe spot offers a number of areas to explore. While beginners will want to stay in the natural pools between the beach and the reef (↕3-7ft/1-2m), experienced snorkelers will prefer (if the sea conditions permit) to swim to the channel and explore the areas beyond the reef, where the waters are deeper (↕+20ft/+6m) and the seabed is of a better quality. This is where you have the best chance of seeing green sea turtles, but they are less easy to observe here than in a number of other spots in the archipelago.\nIn winter and when the sea is rough, the currents and waves can be strong in the channel (well indicated by buoys). Visibility, in fact, is not always ideal. Lifeguards supervise the spot during the site’s opening hours, and they will quickly issue a reminder over their megaphones if you fail to respect the safety rules.\nUnder the water, you are sure to spot parrotfish, surgeonfish and triggerfish, and a very large number of equally colorful fish, some of which can only be found in Hawaii. The seabeds are rocky and have little coral, especially on the part inside the lagoon.\nThe Park has a wide range of restaurants, but prices are high. You can take your own picnic.\nSea turtles are a very familiar sight on many snorkeling spots in Hawaii, including Hanauma Bay. In order to be a responsible snorkeler, be sure to respect the following rules when observing them:\nThese snorkeling spots are accessible to beginners and kids. You will enter the water gradually from a beach, or in a less than 3ft. deep area. The sea is generally calm, shallow, with almost no waves or currents. These spots are usually located in marked and/or monitored swimming areas. It is not necessary to swim long distances to discover the sea life.\nThis level only apply when the spot experiences optimal sea and/or weather conditions. It is not applicable if the sea and/or weather conditions deteriorate, in particular in the presence of rough sea, rain, strong wind, unusual current, large tides, waves and/or swell. You can find more details about the definition of our snorkeling levels on our snorkeling safety page.\nYou must be logged in to post a comment.\nSnorkeling spots are part of a wild environment and their aspect can be significantly altered by weather, seasons, sea conditions, human impact and climate events (storms, hurricanes, seawater-warming episodes…). The consequences can be an alteration of the seabed (coral bleaching, coral destruction, and invasive seagrass), a poor underwater visibility, or a decrease of the sea life present in the area. Snorkeling Report makes every effort to ensure that all the information displayed on this website is accurate and up-to-date, but no guarantee is given that the underwater visibility and seabed aspect will be exactly as described on this page the day you will snorkel the spot. If you recently snorkeled this area and noticed some changes compared to the information contained on this page, please contact us.\nThe data contained in this website is for general information purposes only, and is not legal advice. It is intended to provide snorkelers with the information that will enable them to engage in safe and enjoyable snorkeling, and it is not meant as a substitute for swim level, physical condition, experience, or local knowledge. Remember that all marine activities, including snorkeling, are potentially dangerous, and that you enter the water at your own risk. You must take an individual weather, sea conditions and hazards assessment before entering the water. If snorkeling conditions are degraded, postpone your snorkeling or select an alternate site. Know and obey local laws and regulations, including regulated areas, protected species, wildlife interaction and dive flag laws."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:e354b278-b721-4adf-9ca3-a10780541125>","<urn:uuid:91df5daa-731c-4f5c-9803-caa813d8f1e6>"],"error":null}
{"question":"Could you detail the various types of reporting systems used for tracking data center status? Looking for comprehensive framework analysis. What are current best practices for implementation?","answer":"Data centers use six main types of reports for tracking status and conditions: 1) Site Walkthrough Reports - shift-based checklists verifying activities and equipment status, 2) Shift Reports - continuous narratives of significant activities for incoming crews, 3) Deficiency Reports - detailed accounts of specific problems with metrics and remediation suggestions, 4) Incident Reports - step-by-step timelines of specific incidents including actions taken and notifications, 5) Failure Analysis Reports - root cause analyses following incidents to prevent recurrence, and 6) Lessons Learned Reports - documentation of important operational and maintenance experiences for other technicians' benefit.","context":["It’s no secret that the single greatest contributor to data center downtime is human error, a fact we’ve mentioned in previous posts such as this one. You can’t spend enough money to eliminate human error but you can mitigate the risk with proper tools, one of which is documentation.\nYour data center likely has stacks of documentation from the vendors that supply your various data center systems, and that can certainly be vital information. But many data centers are missing detailed procedures that their teams need to perform everyday tasks and reports that help them keep on top of the condition of the data center. In this post, we’ll walk through some of the various types of procedures and reports and why you need them.\nVirtually every task that takes place in the data center should have a written procedure attached to it. The most common types of procedures are:\n- Standard Operating Procedure (SOP): A SOP details a common operating procedure and can be referenced whenever needed. Examples include how to rotate equipment using the Building Management System or create a work ticket.\n- Method of Procedure (MOP): A MOP is the detailed, step-by-step procedure that is used when working on or around any piece of equipment that has the ability to directly or indirectly impact the critical load. MOPs may reference a SOP that needs to be performed in the course of the procedure.\n- Emergency Operating Procedure (EOP): An EOP is an emergency response procedure for a predicted or previously experienced failure mode. It covers how to get to a safe condition, restore redundancy, and isolate the trouble. EOPs may also cover disaster recovery scenarios.\nProcedures help you achieve several objectives and benefits, including:\n- Process formalization: Writing down a procedure forces the writer to examine it in a level of detail and logic that may not otherwise occur, and to cover aspects such as safety, tools, material inventory and a back-out plan.\n- Peer review: Having a written procedure facilitates peer review and other types of oversight, creating an opportunity for process improvement.\n- Proper implementation: A well constructed procedure document provides a framework for performing activities in the proper sequence, empowers individuals to stop work when events deviate from expectations, and creates a written record of who did what and when.\n- Training: Having written procedures saves time in training material development, helps ensure appropriate topics are thoroughly covered and provides a framework for testing.\n- Record keeping: Completed procedures are an important record of activities performed, which is of value to the technical team and provides an auditable record of compliance with internal and external regulations.\nAmong the various types of reports that you need to track the status and condition of the data center are:\n- Site Walkthrough Report: A checklist filled out each shift that verifies the activity was performed and documents equipment status.\n- Shift Report: A shift-by-shift report of all significant activity that occurs in the facility. It forms a continuous narrative that the incoming crew can use to determine everything of consequence that occurred since the last time they were on duty.\n- Deficiency Report: A detailed account of a specific deficiency or problem along with any available metrics, risk assessment, suggested remediation and cost estimates. This report is used to document issues and is useful in justifying any related expenditures to decision makers.\n- Incident Report: A detailed account of a specific incident with a step-by-step timeline that tracks what occurred, who was involved, when notifications were sent, what immediate actions were taken and where changes in status took place.\n- Failure Analysis Report: A root cause analysis, typically following up on an incident report, to determine the underlying cause(s) of the event in order to prevent further occurrences.\n- Lessons Learned Report: A method of documenting important lessons learned in the course of operating or maintaining a facility that allows technicians and operators to benefit from the experience of others.\nTo learn more about data center documentation, read the Schneider Electric white paper number 4, The Importance of Critical Site Documentation and Training."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:f456f1e5-b18c-4ca2-b073-413c69cc505d>"],"error":null}
{"question":"What is the key difference between engaging audiences in physical presentations versus virtual event sponsorships in terms of time constraints?","answer":"In physical presentations, the engagement time is strictly bounded by the start and end time of the presentation, requiring speakers to maintain audience attention through techniques like eye contact, movement, and interactive tasks. In contrast, virtual event sponsorships offer more flexible timing since content can be available on-demand and shared after the event, which changes how sponsors can engage with attendees and the weight of different sponsorship offerings.","context":["Tips for Giving a Great Presentation\nPresentations are something that we’re all familiar with. Whether you are watching a presentation or giving a presentation, chances are you know what works and what doesn’t. However, in case you don’t know the good from the bad, we would like to offer some tips to help ensure you are giving a good presentation.\n1. Look at the audience.\nIf you ever wondered where you should be looking when presenting, the answer is: right in front of you. Don’t just single out one person, but instead try to make eye contact with numerous people throughout the room. Use the 3-second method (i.e. look straight into the eyes of a person in the audience for 3 seconds at a time, then move on to another). This is only a guideline and does not have to be precise. Don’t count in your head, just do what you feel comes naturally.Try to make eye contact with each person, not in any particular order, so they know you are focused on them and their needs. Looking around the room at your audience members will make them feel as if you are focused on them as much as they are focused on you. This communicates to them that you are there reaching out to them personally. If you don’t do this then you aren’t engaging the audience, you are just talking to yourself. This can result in an utter lack of attention from your audience.\n2. Show your personality.\nIt doesn’t matter if you are presenting to a corporate crowd or to senior citizens, you need to show some character when presenting. Nobody wants to hear a dull presentation. Try to have a little fun because if you do, your audience will too. If you make an error, have fun with it and let it blow over, then continue with your presentation. Even the world’s biggest presenters goof up from time to time.\n3. Make them laugh.\nSimilarly, although you want to educate your audience, you need to make them laugh as well. In essence, it keeps the audience alert and they’ll learn more from a humorous narrative than from some dry, educational, droning lecture.\n4. Talk to your audience, not at them.\nPeople hate it when they get talked at, so don’t do it. You need to interact with your audience and create a conversation. An easy way to do this is to ask your audience questions as well as letting them ask questions of you.\n5. Give them a task.\nStart the presentation by giving people something to do during or at the conclusion of the presentation. By giving people a task—something to listen for or a challenge to think about—you increase their interest and lengthen their attention span.\n6. Be honest.\nA lot of people present to the audience what they want to hear, instead of what they need to hear. Make sure you tell the truth even if they don’t want to hear it because they will respect you for that and it will make you more human.\n7. Prepare, but don’t over prepare.\nThe use of audio-visual aids or props for enhancement is great if appropriate and necessary. Master the use of your presentation software (i.e. PowerPoint) well before your presentation. Know how to go backwards or to a specific slide if necessary, then how to restart where you left off rather than from the beginning. Remember – These audio-visual tools are just that…tools, not the presentation in its entirety. The presenter is the presentation. If you rehearse your presentation too much it will sound like it (in a bad way). Granted, you need to be prepared enough to know what you are going to talk about but make sure your presentation flows naturally instead of sounding memorized. Usually if you ask experienced speakers what you shouldn’t do, they’ll tell you not to rehearse your presentation too much because it won’t sound natural.\n8. Show some movement.\nYou probably know that you need to show some movement when speaking, but naturally you may forget to do so. Make sure you show some gestures or pace around a bit (not too much) on the stage when speaking. Remember, no one likes watching a stiff. People are more engaged with an animated speaker.\n9. Watch what you say.\nYou usually don’t notice when you say “uhm”, “ah”, or any other useless word frequently, but the audience may. If you know your material well this shouldn’t be a problem.\n10. Differentiate yourself.\nIf you don’t do something unique compared to all the other presenters the audience has heard, they won’t remember you. You are branding yourself when you speak, so make sure you do something unique and memorable.\n11. Make a little game.\nAfter the presentation, quiz the audience to see how much information they retained during your presentation. (Idea: make company paper money and give a company dollar to each correct answer. The audience member with the most company dollars receives a gift. Or toss out a candy bar or company logo gift to those who provide the correct answer.)\n12. Incorporate a “quiz” into your presentation.\nHesitate before key words in your sentences and encourage the group to fill in the missing word or phrase. This keeps them on their toes and makes them pay more careful attention.\n13. Provide handouts.\nHave your handouts ready and give them out at the appropriate times. Tell your audience ahead of time if you will be giving out an outline of your presentation so that they will not waste time taking unnecessary notes during your presentation. Have plenty of business cards on hand, as well as brochures describing your company. Make sure everyone has your telephone numbers, and key individual’s names. Have some giveaways available with your company logo (e.g. key chains, magnets, calendars, etc.)\n14. Close with Q and A.\nEnd your presentation with a Question and Answer period. Have a sign-in sheet available for your audience. Make sure you capture their names, telephone numbers, email addresses, and the company they represent.\n15. Follow-up afterward.\nSend everyone who attended a thank you note and make sure they get on your mailing list. Stay in touch with them regularly. Don’t be shy… Ask for referral business if that’s what you’re looking for.\nBeing an expert presenter doesn’t happen overnight and most people are not born with this ability. If you are nervous…that’s okay, everybody goes through the exact same anxieties. However, if you allow yourself to be too nervous, you may try to rush through in order to hurry up and get out of this uncomfortable situation. This can cause you to end up talking too fast, too quietly or even slurring words. Remember to breathe and try to relax. Know that if you feel nervous or uncomfortable, you are not alone. Be easy on yourself and do not critique yourself harshly. With each presentation you give, you will continue to grow and develop.","Creating an event sponsorship package and finding event sponsors is a key part of meeting and event planning. Increasing your sponsorship dollars is the quickest way to impact your bottom line. But, how does sponsorship change for virtual events? While in-person events have sponsorship down to a science, virtual events cannot rely on the same sponsorship packages. How do you create valuable virtual event sponsorship packages?\nBenefits of Sponsorship at Events\nStart by asking the question – what’s in it for them? Sponsorship is quid pro quo. Your sponsors need to understand and see value in what you’re offering, otherwise, they will be disinclined to give you money. Just as you have to account for every line item on the budget, so do they. When deciding what to offer sponsors, think about their goals for the events they attend. Make it interesting. Your audience is your most valuable bargaining chip. Sponsors choose events based on the leads they can gather, the connections they can make, and the brand recognition they can build. Therefore, most of your sponsorship offerings should center around connecting your audience and your sponsors.\nAlign with Sponsor Goals and Objectives\nAs always, think about your sponsors first. What do they hope to achieve? If you’re not sure, then take time to sit down with potential sponsors or past sponsors and ask them about their goals for sponsorship. Sponsorship ROI is tied to brand awareness and direct audience engagement, but not all companies hope to achieve the same thing. For top-tier sponsors, consider working with them to build a sponsorship package that meets their goals as well as yours.\nStart with What You Know\nWhat you’re able to offer sponsors for in-person, virtual, and hybrid events is not that different. These events are similar. Where they differ is in the medium. As you begin to create your virtual event sponsorship packages, start with what you know. Consider what you would offer sponsors at an in-person event and if those options still work. Event technology options such as a mobile event app will still allow you to offer sponsors the same opportunities. Virtual events don’t require a complete departure from what you normally offer.\nCommon sponsorship offerings that also work for virtual events:\n- Sponsored sessions\n- Email marketing opportunities\n- Sponsored posts on the activity feed\n- Event websites\n- Virtual trade show booth\n- Survey question during registration\n- Log-in screen\n- Check-in branding\n- Session background branding\n- Splash Pages\n- Banner Ads\n- Sponsored Listings & Highlighted Exhibitors\n- Surveys & Interactive Polling\n- Push Notifications\nWhere In-Person Event and Virtual Event Sponsorship Varies\nAs you plan a virtual event, think about what you would do if it was in-person, then brainstorm. You can’t make a one-to-one change between the events. Think about time when planning. Your in-person events have a hard start and end time – this is the amount of time sponsors get their logos shared in front of attendees and get the chance to shake hands and make connections. The length of a virtual event is not as strict. Content can be available on-demand and shared out after the event. This may change the weight of different sponsorship offerings. Treat virtual events as something new. You have the framework of what you are used to doing but think outside the box and reimagine as you go.\nPart of sponsorship is proving impact. The data you gather during the event can prove the value of sponsorship, namely what they got for their investment in your event. Use the analytics and data from your event technology platform to show their impact.\nData to Provide Sponsors to Show Impact\n- Number of Attendees\n- Social Media Reach\n- Leads Captured\n- Brand Awareness\n- Direct Audience Engagement\n- Survey Results\n11 Virtual Sponsorship Ideas\n1. Utilize Virtual Environments\nVirtual environments can be expensive, but they provide sponsorship opportunities that are more in line with what you are used to offering at in-person events. These environments create a video game-like computer-generated place for your attendees to “walk” around and interact. For large conferences and events, these environments add another level to your event allow you to offer sponsor signage, trade show booths, or drop-in appointments.\n2. Logo Placement on Home Screen\nSponsors want attendee attention. While you can’t have a giant banner with a sponsor’s logo at a virtual event, take advantage of event technology. Some virtual events have home screens that allow attendees can flip through sponsors on the home screen. This increases brand awareness and can be tracked by site traffic and click rates.\n3. Sponsored Sessions\nThere is prime real estate available during live or on-demand sessions. Have sponsors contribute content or choose a session to be associated with. You can include their logo at the bottom of the screen, have the speaker announce the sponsor name at the beginning and end, or have a sponsor ad play at the start of the session.\n4. Prizes from Engagement and Gamification\nGamification keeps attendees engaged during the event. Send gift cards, offer free appointments or swag for those attendees that top the leaderboard.\n5. Agenda Highlight\nYour online agenda is the hub of your event. Offer sponsors the ability to place their logo or ads in the agenda for high visibility.\n6. Happy Hours\nVirtual doesn’t mean the end of networking. Have sponsors host happy hour sessions that pair attendees in small meeting rooms.\n7. Office Hours\nLeads are one of the greatest draws for sponsors. While it’s not as easy to capture leads, allow sponsors to host office hours or appointments for attendees, hosted through their own personal zoom link.\n8. Virtual Trade Show Booth\nTrade shows look different when you go virtual. While the experience is different, there are virtual event providers that allow you to create the trade show experience online. If virtual event tech isn’t in your budget, you can build out a trade show experience in your event website. Logos will act as booths. Offer sponsors different sizes of logos or group them based on sponsorship levels.\n9. Email Marketing to Push Out Content\nAllow sponsors an email that’s sent to all or a specific segment of attendees to share content or a message about the sponsor. Email marketing provides sponsors with a direct link to attendees and could be a vehicle to set up appointments or information about an upcoming webinar.\n10. Branded Swag\nJust because your attendees are online, doesn’t mean they don’t deserve a free pair of sunglasses or a t-shirt. Swag is the gift that keeps on giving. The better, more useful piece of swag, the more attendees will use it. Sponsors will get their logo out in the world via a notebook or mug, reminding attendees about their company with each use. Think beyond pens and send out food or cocktail kits.\n11. Host a Cooking Class, Yoga, or Entertainment\nGive top-tier sponsors a chance to host high-interest sessions. Bring in entertainers or well-known chefs for a fun break from content that can keep attendees engaged. If sponsors have a skill that attendees could learn from, have them host a session on that topic."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:961779e9-a047-462d-ae75-5cf1228b6063>","<urn:uuid:42a985bb-3e70-4fba-b958-ac75fd50524e>"],"error":null}
{"question":"How do the cooking times compare between traditional thattai and suji dhokla? Can you explain the key factors affecting their preparation duration?","answer":"Thattai and suji dhokla have significantly different cooking times and preparation requirements. Suji dhokla cooks very quickly, taking just 3 minutes to steam once the batter is prepared, though it needs a 20-minute resting period for the batter. The total preparation time for suji dhokla is around 45 minutes. Thattai, on the other hand, requires more extensive preparation, including soaking chana dal for 1 hour, making the dough, shaping individual pieces, and deep frying them in batches until golden and crisp. The frying process needs to be done on medium-high heat, with careful attention to ensure proper cooking without browning.","context":["Thattai recipe with video & step by step photos. Thattai are popular deep fried Snacks made with rice flour, urad dal flour, salt and herbs. These crunchy rice crackers are from the Tamil cuisine and are also known as thattu vadai. During the festive season thattai & murukku are made in most South Indian homes as festivals are incomplete without fresh homemade delicacies.\nThattai are known as Nippattu in karnataka and chekkalu in Andhra. However all these 3 are different in texture and taste as they are made with different proportions and ingredients.\nEach home has their own recipe of making these to suit their personal preference. This recipe yields light, tasty and crispy thattai that you can make for a tea time snack.\nMaking perfectly crunchy traditional rice flour snacks begins with rinsing the rice well, draining and drying. Then milled to flour as the fresh ground flour enhances the aroma & texture of these snacks.\nTo make thattai and murukku, I follow the same traditional method & make rice flour at home using raw rice during festivals. However this time I have made these using store bought rice flour.\nIf you have a helping hand home then I suggest making thattai with homemade rice flour as they taste the best.\nIf using store bought rice flour make sure you use the one from an Indian brand preferably South Indian brands. There are tons of varieties of rice flour available in the market – made with long rice, sticky rice, glutinous rice, boiled rice etc.\nMany of these do not work well to make these rice crackers. Unknowingly I had tried these snacks a few years ago with different kinds of flours and they turned out to be soft within hours.\nSo the key to tasty and crunchy thattai is good rice flour. If you are a beginner, I would highly recommend watching the thattai recipe video and the following the step by step photo instructions.\nThattai recipe or thattu vadai\nIngredients (1 cup = 240ml )\nTo roast and powder\n- 1½ tsp urad dal or 1½ tbsp peanuts\nIngredients for thattai\n- 1 cup rice flour\n- 1 tbsp butter (unsalted)\n- 2 tbsp fried gram or roasted gram or pottukadalai\n- 1 tbsp chana dal or bengal gram (soaked for 1 hour)\n- 1 tbsp sesame seeds (crushed, optional, use fresh)\n- ½ tsp red chilli powder (use 1 tsp for spicy)\n- ¼ tsp asafoetida or hing\n- Salt as needed\n- 1 sprig curry leaves chopped finely\n- Water as needed\n- Oil for deep frying as needed\nHow to make the recipe\n- Wash and soak chana dal for 1 hour. Drain and set aside.\n- Dry roast urad dal or peanuts until lightly golden and cool them. If using peanuts, remove the skin.\n- Add urad dal to a blender jar along with fried gram. Make a fine powder. If using peanuts, then powder fried gram very fine, then add skinned peanuts and make a coarse powder. You can also powder sesame seeds.\nMaking thattai dough\n- To a mixing bowl, add rice flour, urad dal & fried gram powder, red chili powder, hing, salt, sesame seeds & chopped curry leaves.\n- Drain the soaked chana dal and add it to the bowl.\n- Also add soft butter & mix all of them well to incorporate the butter.\n- Pour little water and begin to mix everything to make thattai dough.\n- Add more water as needed and make the dough.\n- Dough has to be non sticky, stiff and smooth.\n- Too moist dough will make your thattai greasy as the excess moisture will soak up oil.\n- Next too little moisture in the dough will make the thattai crack a lot while spreading the dough and make them hard.\n- Taste the dough and add more salt if required.\n- Divide the dough to 14 to 16 balls. Keep it covered.\nHow to make thattai\n- Heat oil on a medium flame in a wide kadai.\n- Spread a dry cloth, grease your fingers.\n- Place a ball on the cloth or greased sheet.\n- Begin to spread them moderately thin.\n- Very thin thattai will break when you remove from the cloth. Very thick ones will not turn crisp.\n- If the edges begin to crack then join them together.\n- Make as many thattai as possible till the oil heats up.\n- Check if the oil is hot by dropping a tiny flat piece of dough. It should rise and not sink.\n- Transfer one thattai at one time to the hot oil.\n- You can fry more than one thattai at one time if there is space in your kadai. But do not crowd them as they will not fry properly.\n- Make sure the flame is set to medium high. Low flame will make them oily and high flame will brown them.\n- Flip them when fried on one side. Flip as needed to both the sides and fry until evenly golden & crisp.\n- When they are fried fully, bubbles will begin to reduce in the oil.\n- Drain them on a kitchen tissue.\n- Repeat frying them in batches.\n- When they cool down, transfer them immediately to a tight air tight container.\n- Serve thattai as a snack. They keep good for about 2 weeks if fried in fresh oil.\nVideo of thattai recipe\nNUTRITION (estimation only)\nRecipe notes for thattai recipeTo prevent thattai from turning soft and to keep them crisp for many days, make them as thin as possible, Fry them on a medium high heat until crispy. Transfer them immediately once cool down to an airtight jar / box. If you plan to offer this as naivedyam then replace chilli powder with pepper. Urad dal is added for flavor and to make the thattai light, you can also use peanuts. Do not over fry them for long time on a low flame they turn hard.\nIf you are a beginner or new to Indian cooking, I highly suggest you to check the supporting step by step photos for best results. Step by step photos with description available below after the recipe card.\nPreparation for thattai recipe\n1. Wash and soak chana dal for 1 hour, drain it completely and set aside.\n2. Roast urad dal or peanuts on a low to medium flame till golden. Cool completely. If using peanuts, then remove the skin.\n3. Add roasted dal and fried gram to a blender jar. If using peanuts, first powder the fried gram very fine. Then add peanuts and make a coarse powder. You can also powder sesame seeds and use.\n4. I used urad dal & fried gram so i made a fine powder together.\n5. Add rice flour, urad dal and fried gram flour, salt, red chili powder, drained chana dal and sesame seeds. Sometimes sesame seeds splutter while frying, so make sure they are lightly crushed.\n6. Add curry leaves and butter.\n7. Mix up gently to incorporate the butter and then add water little by little. Do not pour lot of water at one time.\n8. Make a stiff and non sticky soft dough.\n9. Divide the dough to 14 to 16 balls.\nHow to make thattai recipe\n10. Spread a dry cloth. Grease your fingers. Begin to make thattai by flattening the dough ball.\n11. Flatten the dough as much as possible. You will see the balls begin to crack towards the edges. That is just fine, join up the cracks. Grease your fingers as needed. You can also flatten these with the base of a greased steel bowl or a greased lid. I am comfortable making these with fingers as the thattai turns out even with fingers.\n12. Make these thin as shown in the picture. Too thin thattai will break while you lift and too thick ones will not turn crisp. So make them moderately thin.\n13. Heat oil in a deep kadai. When the oil is hot enough, drop a small flat piece of dough to check if the oil is hot enough. The dough should come up and not sink to the bottom.\nSlide thattai in the hot oil from the sides. Take cake while you slide it. Flip and fry on both sides until golden. You can fry more than one thattai at one time if there is enough space in the kadai.\n14. The bubbles begin to reduce when they are well fried. Drain them to a kitchen towel. Cool them completely.\nThey will look very oil as soon as you remove them from oil but then nothing much would be on the surface or in the thattai.\nNow comes the very important part of storing them well. Not only the method of preparing thattai even the way they are stored is very important to keep them fresh and crispy for many days.\nDo use a clean and moisture free air tight container. I use air tight stainless steel containers to store thattai, chakli, murukku.\nDo not leave them too long to the air/fan/ air con once they are cooled down. As soon as you notice them cooled transfer them to the jar.\nThattai should be completely cool before moving to the jar. These keep good for 2 weeks.","Suji/Semolina is used in the preparation of several dishes such as Upma, Laddoos, Idli, Dosa and sheera. Dhokla is another addition to this long list. The conventional dhokla which I put up here is very popular but somewhat time consuming and volatile in the sense that it might just not turn out right every time. Suji Dhokla though can be prepared almost instantly and tastes very good too. And surely therefore a good option to have.\nWhat you need to have:\n-Semolina/Sujee (Thin): 1 cup\n-Yoghurt/Curds: 1/4 cup\n-Water: 3/4 cup\n-Cooking oil – 2 tablespoons\n-Eno fruit salt: 1 sachet\n-Ginger(optional): 1/2″ piece\n-Green chilli(optional): 1\n-Sugar: 1/2 teaspoon\nIngredients of Sujee Dhokla\nIngredients for Seasoning:\n– Mustard seeds 1 Teaspoon\n– Cumin seeds 1/2 Teaspoon\n– Sesame seeds 2 Teaspoons\n– Asafoetida powder 1/2Teaspoon\n– Turmeric powder 1/2 teaspoon\n– Red chilli pieces a few\n– Curry leaves a few\nIngredients for Topping:\n– Chilli powder 1 Teaspoon\n– Grated coconut 2 Tablespoons\n– Coriander leaves a handful\nIngredients of Topping & Seasoning\nWhat you do with what you have:\n1. Wash and chop ginger and Green chili to a consistency as shown in the image above.\n2. Run water and yogurt in the mixer for a few seconds.\n3. Mix Semolina, oil,salt and sugar in a bowl. Add the water curd/yogurt mix from step 2 to it slowly in such a way that there are no lumps. Also add chopped ginger & green chili from step 1 and keep it aside for 20 minutes.\n4. Heat an idli maker on the gas and when the water starts boiling empty the contents of the Eno sachet to the Sujee mix.\n5. Stir the mix and steam it as shown in the image below covering the lid of the vessel with a clean cloth. This is done to prevent the steam from falling back into the dhokla and make it soggy.\nDhokla being steamed\n6. It is cooked in about 3 minutes. Remove it and cut it and immediately sprinkle Chili powder when hot. The image is as shown in the image below.\nCooked Dhokla topped with chilli powder\n6. Decorate it with fresh grated coconut and chopped corriander leaves .\n7. Seasoning: Place a spatula with 4 teaspoons of cooking oil in it on the flame. On heating add mustard seeds to it. On sputtering add cumin seeds, turmeric powder, Asafoetida powder, red chilli, and lastly sesame seeds and curry leaves. Spread the seasoning on the top of it . The image is here below.\nCooked Dhokla being topped with seasoning\n8. Enjoy with either Onion wet chutney or Tomato ketchup as shown in the image below.\nWhat to remember:\n1. Use fresh Semolina only – do not use the one which people warm up and store in containers to avoid it from getting spoilt.\n2. Use the full sachet of Eno salt for 1 cup of semolina. Dhokla takes just 3 minutes to cook – not 30 minutes ! If it is not done in that stipulated time, that would mean that that the consistency of the dough is not quite what it should be.\nTime taken in all :45 minutes\nServes for 4 people"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_formulation","category_name":"sensitive"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:e57f9e3a-38f0-4247-b4d5-1a6c281feaad>","<urn:uuid:2c790d72-56dd-4fe6-b66e-206e52f5c4cf>"],"error":null}
{"question":"When comparing quadratic failure envelopes in composites versus circular hollow steel sections, which one requires more geometric parameters for full definition?","answer":"Circular hollow steel sections (CHS) require fewer geometric parameters for full definition, needing only two parameters: external diameter D and wall thickness t. In contrast, quadratic failure envelopes for composites require multiple strength parameters including tension allowables in both 1 and 2 directions (XT, YT), compression allowables in both directions (XC, YC), and in-plane shear allowable (S). Additionally, for criteria like Tsai-Wu, an interaction coefficient F*12 is also needed.","context":["This Tip & Trick will explain the difference between the failure index and strength ratio and their respective applicability when using composite material quadratic failure criteria.\nIn a uniaxial loading situation, predicting failure obviously reduces itself to comparing the internal stresses (s) to the material’s strength (F) in the loading direction. In this situation, the failure index (FI) and the strength ratio ® are defined as:\nIn this simple scenario, the failure index and strength ratio are clearly related as they are the inverse of one another. Extending this example to a composite material layer (Figure 1) and comparing each component of the stress state to the material strength properties, one can draw the ply failure envelope for the maximum stress criterion (Figure 2).\nFigure 1 - Composite Layer Stress State\nFigure 2 – Maximum Stress Ply Failure Envelope\nXT: Tension Allowable in 1-direction\nXC: Compression Allowable in 1-direction\nYT: Tension Allowable in 2-direction\nYC: Compression Allowable in 2-direction\nS: In-Plane Shear Allowable\nA stress state (The red dot in Figure 3) contained within the envelope is considered to be within the acceptable limits of the material. This stress state, multiplied by a positive value (d1/d=R), would eventually cross the envelope boundary (the green dot). Because the envelope is a finite volume, the boundary can also be reached if the stress state is multiplied by a negative number (-d2/d) (the purple dot). This point, while mathematically correct, is usually neglected as it does not represent the exaggerated physical stress state.\nFigure 3 – Stress State within the Ply Failure Envelope\nThe same reasoning applies to other failure criteria such as the quadratic failure envelope family. A typical quadratic ply failure envelope is illustrated in Figure 4.\nFigure 4 – Quadratic Ply Failure Envelope\nA quadratic failure envelope boundary can be defined within a single equation.\nFor example, the Hill failure envelope can be expressed as:\nIf the stress state is contained within the volume surrounded by the ply failure envelope, no failure is predicted. One would still like to know by what strength ratio R the stresses can be multiplied so as to cross the envelope, producing failure. Simply multiplying all the stresses from the Hill failure envelope by the value R yields an expression that can readily be solved:\nFrom which, only the positive value is retained. In this case, it makes sense to define the ply failure index as:\nYielding the relationship:\nClearly, failure can be ascertained when the failure index has a value of 1 (ply envelope boundary) or above. A value between 0 and 1 will also provide an indication of how close to failure is the ply.\nIf one instead uses the Tsai-Wu Failure criterion:\nAnd F*12 is a user-defined interaction coefficient.\nThe strength ratio can be obtained by solving the following equation:\nNote that some terms are of second order while others are not. Solving and keeping only the positive root yields:\nNow, for consistency with the other quadratic failure criteria (and for historical reasons), the Tsai-Wu failure index is defined as:\nIn this case, there is no direct relationship between the failure index and the strength ratio. The failure index cannot provide valuable insight on failure unless it has a value of 1. In fact, depending on the stress values, it is even possible to obtain a negative failure index.\nAs a rule of thumb, whenever a failure criterion involves mixed order terms (e.g. Tsai-Wu), there will not be relationship between the failure index and the strength ratio. In these situations, failure predictions should be based on the strength ratio.","Design properties for circular hollow steel sections (CHS) according to EN1993-1-1\nDefinition of the cross-section\nFor typical circular circular steel sections (CHS) the geometric properties of the cross-section are defined in the following standards:\nThe geometric properties that fully define the cross-section are: external diameter D and wall thickness t.\nThe notation is defined in EN1993-1-1 §1.7 which is reproduced in the figure above.\nThe basic geometric properties of the cross-section are calculated by using the fundamental relations of mechanics.\nDue to symmetry the centroid of the cross-section (center of mass) as well as the shear center are located at the center.\nThe geometric quantities include the total area of the cross section A and the second moments of the area I, which is constant for any axis of bending due to symmetry.\nThey are calculated by adding the contribution of the external boundary and then subtracting the contribution of the internal void.\nA = π⋅D2 / 4 - π⋅(D-2⋅t)2 / 4\nI = π⋅D4 / 64 - π⋅(D-2⋅t)4 / 64\nThe shear area Av for the case of circular hollow sections is specified in EN1993-1-1 §6.2.6(3) as:\nAv = 2⋅A / π\nDue to symmetry the shear area is constant for shear load along any axis.\nElastic section modulus\nThe elastic section modulus Wel is calculated by dividing the second moment of the area I with the corresponding distance from the centroid to the most distant edge:\nWel = I / (D / 2)\nPlastic section modulus\nThe plastic section modulus Wpl corresponds to the maximum plastic bending moment when the axial force of the cross-section is zero and the stress profile is fully plastic.\nDue to symmetry when the full plastic bending stress profile is reached with zero axial force the section is divided into two parts separated by the axis of symmetry.\nThe plastic section modulus corresponds to the sum of first moments of the area of the two halves about a bending axis passing through the cetroid.\nThe plastic section modulus Wpl is calculated by adding the contribution of the external boundary and then subtracting the contribution of the internal void.\nThe centroid of a semi-circular segment is located 2D / 3π from the center of the arc.\nThe following result is obtained:\nWpl = 2⋅(π⋅D2 / 4 / 2)⋅(2⋅D / 3⋅π) - 2⋅(π⋅(D-2⋅t)2 / 4 / 2)⋅(2⋅(D-2⋅t) / 3⋅π) ⇒\nWpl = [D3 - (D-2⋅t)3] / 6\nFor circular cross-sections and tubular cross sections the torsional constant IT is equal to the polar moment of inertia of the area IP that is given by the following relation:\nIT = IP = 2⋅I\nFor circular cross-sections and tubular cross sections the maximum shear stress due to St. Venant torsion τ is related to the maximum torque T by the following relation:\nT = τ ⋅ IP / (D / 2)\nTherefore the torsional modulus WT is obtained as:\nWT = T / τ = 2⋅Wel\nDesign cross-section resistance\nThe design resistance of the cross-section in axial force, shear force, and bending moment are calculated in accordance with EN1993-1-1 §6.2.\nThey correspond to the gross cross-section resistance reduced by the steel partial material safety factor applicable for cross-section resistance γM0 that is specified in EN1993-1-1 §6.1 for buildings, or the relevant parts of EN1993 for other type of structures, and the National Annex.\nThe aforementioned design resistances do not take into account a) flexural buckling, b) local shell buckling, c) interaction effects of axial force, shear force, bending moment, and d) interaction effects of biaxial bending.\nTherefore the presented cross-section resistances are indicative values applicable for special cases.\nIn general the overall element resitance is smaller and must be verified according to the relevant clauses of EN1993-1-1 Section 6.\nDesign axial force resistance\nThe design plastic resistance of the cross-section in uniform tension is specified in EN1993-1-1 §6.2.3(2).\nThe design plastic resistance of the cross-section in uniform compression for cross-section class 1, 2, 3 is specified in EN1993-1-1 §6.2.4(2).\nThe aforementioned axial force resistances correspond to the gross cross-sectionial area A and the steel yield stress fy:\nNpl,Rd = A⋅fy / γM0\nDesign shear force resistance\nThe design plastic shear resistance of the cross-section is specified in EN1993-1-1 §6.2.6(2).\nIt corresponds to the relevant shear area Av multiplied by the steel yield stress in pure shear fy / √3 corresponding to the yield criterion in EN1993-1-1 §6.2.1(5):\nVpl,Rd = Av ⋅ ( fy / √3 ) / γM0\nDesign torsional moment resistance\nThe design torsional moment resistance of the cross-section for the case of St. Venant torsion is specified in EN1993-1-1 §6.2.7.\nThe shear stress due to St. Venant torsion is derived from the theory of elasticity as specified above.\nFor elastic verification the yield criterion in EN1993-1-1 §6.2.1(5) is applied, i.e. the shear stress τ is limited the steel yield stress in pure shear fy / √3:\nTRd = WT ⋅ ( fy / √3 ) / γM0\nDesign elastic bending moment resistance\nThe design elastic bending moment resistance of the cross-section is specified in EN1993-1-1 §6.2.5(2).\nIt corresponds to the relevant elastic section modulus Wel multiplied by the steel yield stress fy:\nMpl,Rd = Wel ⋅ fy / γM0\nThe elastic bending moment resistance is applicable for class 3 cross-sections.\nFor the case of circular hollow sections that cannot be classified as Class 3 their strength and stability verifications should be based on EN 1993-1-6: Strength and Stability of Shell Structures.\nDesign plastic bending moment resistance\nThe design plastic bending moment resistance of the cross-section is specified in EN1993-1-1 §6.2.5(2).\nIt corresponds to the relevant plastic section modulus Wpl multiplied by the steel yield stress fy:\nMpl,Rd = Wpl ⋅ fy / γM0\nThe plastic bending moment resistance is applicable for class 1 or 2 cross-sections.\nThe classification of cross-sections is specified in EN1993-1-1 §5.5.\nThe role of the classification is to identify the extent to which the resistance and rotation capacity of the cross-section are limited by local buckling of its parts.\nFour section classes are identified:\nClass 1: Plastic bending moment resistance develops and plastic hinge develops with rotation capacity adequate for plastic analysis.\nClass 2: Plastic bending moment resistance develops but the rotation capacity is limited by local buckling.\nClass 3: Elastic bending moment resistance develops but local buckling prevents the development of plastic resistance.\nClass 4: Elastic bending moment resistance cannot develop because local buckling occurs before the yield stress is reached at the extreme fiber. Effective widths are used to account for the effects of local buckling of compression parts.\nThe classification of the circular hollow sections (tubular sections) is specified in EN1993-1-1 Table 5.2.\nThe class of the cross-section in bending and/or compression depends on the ratio of its diameter D to the wall thickness t, adjusted by the factor ε that takes into account the value of the steel yield stress fy:\nε = (235 MPa / fy)0.5\nThe diameter to wall thickness limits D / t for cross-section classification according to EN1993-1-1 Table 5.2 are presented below:\nClassification of tubular sections according to EN1993-1-1 Table 5.2\n|Ratio D / t\n|D / t ≤ 50ε2\n|D / t ≤ 70ε2\n|D / t ≤ 90ε2\n|D / t > 90ε2\nFor the case of circular hollow sections (tubular sections) that cannot be classified as Class 3 their strength and stability verifications should be based on EN 1993-1-6: Strength and Stability of Shell Structures.\nThe appropriate buckling curve for circular hollow sections is specified in EN1993-1-1 Table 6.2 depending on the steel yield stress fy, and whether the section is hot finished or cold formed as described in the following table:\nBuckling curve of circular hollow sections according to EN1993-1-1 Table 6.2\n||S235, S275, S355, S420\n||S235, S275, S355, S420"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:68097bcc-dd79-4845-9131-6c8bef7f2077>","<urn:uuid:81a8e571-4ea9-41a4-ac08-6b9fc10eee34>"],"error":null}
{"question":"How does Siberia's permafrost contribute to its natural resource wealth, and what environmental risks does its melting pose to industrial infrastructure in the region?","answer":"Siberia's permafrost, which covers about 55% of Russia's terrain, underlies vast deposits of natural resources, including huge oil and gas fields that make Siberia a treasure trove of natural wealth. However, the melting of this permafrost poses significant environmental risks to industrial infrastructure. This was demonstrated in the catastrophic oil spill near Norilsk in May 2029, where a storage tank collapsed due to melting permafrost that weakened its supports. A 2017 report to the Arctic Council warned that global warming and melting ice would weaken foundations in permafrost regions, making them unable to support industrial loads as they did in the 1980s. This risk has prompted Russian prosecutors to order checks at 'particularly dangerous installations' built on permafrost.","context":["Siberia, a vast region comprising the Asian portion of Russia as well as northern Kazakhstan. Siberia is a treasure trove of natural resources, with huge deposits of oil, gas, and minerals and vast stands of timber. Historically, the region was notorious as a bleak place of exile for Russian criminals, and, when the area was part of the Union of Soviet Socialist Republics (USSR), for those considered opponents of the Communist regime.\nSiberia is bounded on the west by the Ural Mountains; on the north by the Arctic Ocean; on the east by the Pacific Ocean and the Bering Strait; and on the south by China, Mongolia, and the hills of north central Kazakhstan. The name Siberia comes from the Tatar term Sibir, meaning 'sleeping land.'\nThe region of Siberia spans 13,488,500 sq km (5,207,900 sq mi) and is even larger than Canada, which is the second largest country in the world after Russia. The region is divided into three major geographic areas. In the west, between the Ural Mountains and the Yenisey River, is the West Siberian Plain, which contains large amounts of swampland. Between the Yenisey and Lena rivers lies the Central Siberian Plateau, with elevations ranging between 300 and 1200m (1000 and 4000 ft). And to the east is a complex system of mountain ranges and uplands extending from the Lena River to the Pacific coast.\nSiberia has several major mountain ranges. The mountain chain composed of the Yablonovyy and Stanovoy ranges extends from just north of the Mongolian border northeast to the Sea of Okhotsk. Also on the Mongolian border, south of the Central Siberian Plateau, are the Sayan Mountains.\nThe highest mountains in Siberia are generally in the Altay range, south of the West Siberian Plain. Spanning portions of Russia’s borders with Mongolia, Kazakhstan, and China, the Altay Mountains generally measure between 3000 and 4000m (10,000 and 13,000 ft) in height, reaching their highest elevation at Mount Belukha (4,506 m/ 14,783 ft).\nAt Siberia’s northeastern extreme, a chain of volcanic peaks—some of which are still active—extends along the entire length of the Kamchatka Peninsula. One volcano, Klyuchevskaya Sopka, is the tallest peak in Siberia at 4,750m (15,584 ft).\nSiberia is traversed from north to south by three great rivers, whose tributaries intersect like branches of huge spreading trees. From west to east, these rivers are the Ob’, the Yenisey, and the Lena, all of which flow north and drain into the Arctic Ocean. The three rivers are frozen from six to nine months of each year. Of Siberia's major rivers, only the Amur flows east, following a sharply winding course to the Pacific Ocean.\nSoutheast of the Central Siberian Plateau, near the Mongolian border, is Lake Baikal, the world's deepest lake. Lake Baikal holds one-fifth of the earth's fresh surface water and contains a great diversity of plant and animal species, many of which cannot be found anywhere else on earth.\nExcept in the south, Siberia experiences long, cold winters that last for seven to eight months in most parts of the region and even longer in the far northeast. Summers in Siberia are short and generally moderate. The average temperature tends to rise as one moves south.\nSiberia is rich in animal life. Among its more common mammals are foxes, otters, wolves, hare, moose, reindeer, polar and brown bears, sable, seals, and walruses. Leopards, tigers, and antelope inhabit the Amur River region. Sturgeon, salmon, and rare freshwater seals inhabit Lake Baikal.\nVast oil and gas deposits constitute Siberia’s most valuable natural resources. The region also has huge reserves of mineral resources, most notably coal, gold, copper, and iron ore. Siberian mines have placed Russia, and before it the USSR, among the world's leading producers of gold.\nTourism in Siberia is a perspective and rapidly developing branch. Year by year more and more people choose this region to spend their vacations. The diversity of firms, that render tourist service lead to the improvement of the quality of this service.\nThe Siberian tourism recently gains bigger popularity not only with the Russians, but also with the citizens of countries like England, Germany, Finland, and Czech Republic and so on. The active and extreme kinds of sport are the most attractive ones. The Siberian Rivers are a perfect place for hiking of different levels on all kind of rolling boats, ranging from kayaks and catamarans to rafts. Windsurfers and kitesurfers train and compete on Siberian lakes. Lake Baikal, the deepest lake in the world, has been chosen by divers from all the countries for unique beauty and peculiarity.\nMountain chains and ranges are of particular interest for tourists in any season. Those who are fond of rock climbing, mountaineering and speleological tourism come there. In winter mountain sides become the place of pilgrimage for snowboarders and downhill skiers.\nMoreover, cycling tourism becomes more and more widely spread. The competitions are being held; the participants usually come from other regions of the country.\nDeveloping of the region makes it possible to raise the level of tourist comfort and security. Wide coverage of cellular communications, comfortable hotels, number of restaurants and snack-bars, museums, exhibitions, theatres and art galleries make a visit to Siberia unforgettable for everybody and more people get convinced of it coming there again and again.\nOverall, the region is sparsely inhabited, with the population concentrated mainly along the Trans-Siberian Railroad in southern Siberia, and in the southwest, where the climate is relatively mild. Most major cities lie along or near the Trans-Siberian Railroad.\nSiberia’s harsh climate, poor roads, and limited food supplies kept the Russian population in the region small until 1861, when the Russian imperial government freed the country’s serfs (peasants legally bound to the land they worked) and significant migration began. When construction of the Trans-Siberian Railroad began in the early 1890s, hundreds of thousands of Russian settlers arrived in the region, and farming began to develop in Siberia on a commercial scale. Before this time, Russians living in the region had been mainly soldiers, government officials, runaway serfs, peasants, and religious dissidents.\nToday Siberia plays an important role in the Russian economy, although it still faces some of the problems that impeded its development in earlier times. The region’s remoteness and harsh climate obstruct the exploitation of natural resources and make it a difficult environment for human existence. Perhaps the most serious problem facing Siberia today is its severe pollution, which is largely a result of the aggressive, careless ways in which the Soviet government pursued industrialization.\nFacts about Siberia\n2/3 of Russia's Territory\n7 different time zones\nLess than one inhabitant per square kilometer\nThe world’s richest territory in natural resources","Oil Spill in Russia Could Pollute the Arctic Ocean after Large Lake\nA catastrophic diesel oil spill in Russia has polluted a large freshwater lake in the region. Evidently, the huge spill poses a risk of spreading into the Arctic Ocean. Emergency response teams have been trying to contain the oil for a while, which had now traveled about 20 km (12 miles) north of Norilsk from a collapsed fuel tank.\nAccording to environmentalists and officials, this is the worst accident of its contemporary times in Russia’s Arctic region.\nThe Worst Disaster\nThe oil leaking began on May 29. So far 21,000 tonnes have contaminated the Ambarnaya River and surrounding terrain.\nInvestigators are of the belief that the storage tank near Norilsk sank owing to the melting permafrost, which deteriorated its supporters. The Arctic has had weeks of strangely warm weather, which could be a result of global warming.\nPermafrost is a term used for ground that is frozen continuously for two or more years. Nearly 55 percent of Russia’s terrain, predominantly Siberia, is permafrost and home to its main oils and gas fields. The power plant, where the accident occurred, is administered by Norilsk Nickel, the world’s leading nickel and palladium producer.\nThis oil spill in Russia has polluted the Lake Pyasino, which serves as the basin for the Pyasina River that flows to the Kara Sea, part of the Arctic Ocean. From the months of October to June, the river is usually ice-bound.\nGovernor of Krasnoyarsk region, Alexander Uss said,\nThe fuel has got into Lake Pyasino. This is a beautiful lake about 70km [45 miles] long. Naturally, it has both fish and a good biosphere. Now it’s important to prevent it from getting into the Pyasina river, which flows north. That should be possible.\nReportedly, the clean-up teams have removed as much as 23,000 cubic meters of polluted soil.\nVasily Yablokov of Greenpeace Russia said,\nThe pollution will have a negative effect on the water resources, on the animals that drink that water, on the plants growing on the banks.\nGreenpeace has compared this catastrophe to the 1989 Exxon Valdez disaster in Alaska.\nGreenpeace director of Russia Vladimir Chuprov said that it would be a disaster if 10,000 tonnes or more of fuel had reached the lake. He criticized the authorities for not giving more information about the extent of the spill.\nRussian prosecutors have ordered to check at “particularly dangerous installations” built on permafrost.\nDelayed Reports Angered Putin\nPresident Vladimir Putin has been furious as the reports were delayed over the collapse of the oil tank. He declared a state of emergency after 21,000 tonnes of diesel was leaked.\nMeanwhile, the director of the power plant has been taken into custody. The Russian Investigative Committee has launched a criminal case over pollution and alleged negligence.\nThere was another oil spill in Russia on May 29th. 20,000 tons of oil spilled into the Artic Circle due to a collapsed storage tank. Russia declared a state of emergency yesterday following the spill. My heart is heavy. pic.twitter.com/YX7xuFKVYC\n— Karlie Alexander (@KarlieAlexande7) June 5, 2020\nA 2017 report to the Arctic Council, an international forum which includes Russia, warned that global warming and melting ice would weaken the foundations in permafrost regions and they would no longer be able to support loads of power plants as they did in the 1980s.\nThe oil spill has turned the long stretches of the Ambarnaya River crimson.\nNorilsk Nickel revealed in a statement that the incident had been reported in a “timely and proper” way. The company has pledged to pay for the clean-up, which so far amounts up to $146 million.\nDisastrous Environmental Impacts\nNorilsk is famed as a pollution hotspot already, owing to the contamination from the industry that dominates the city. In 2016, Norilsk Nickel admitted that an accident at one of its plants was responsible for turning a nearby river red.\nThe recent oil spill has polluted the ground and waterways, activating a major clean-up effort. Officials in the Siberian region of Krasnoyarsk said that a high concentration of contaminated water had been discovered beyond floating barriers set in place to stop the fuel from spreading.\nUnited States Secretary of State Mike Pompeo announced on Twitter that the US “stands ready to assist Russia to mitigate this environmental disaster and offer our technical expertise.”\nSaddened to hear about the fuel spill in Norilsk, Russia. Despite our disagreements, the United States stands ready to assist Russia to mitigate this environmental disaster and offer our technical expertise.\n— Secretary Pompeo (@SecPompeo) June 6, 2020\nLooking toward the future, the company said that it will explore the possibility that this could happen again as permafrost continues to melt.\nCurrently, NTEC teams are conducting an inspection of emergency diesel fuel storage facilities, with special attention paid to assessing the risks of sinking soil under hazardous objects installed in permafrost.\nIf not controlled soon, the oil spill in Russia will go on contaminating the surrounding water sources and terrain, subsequently harming the ecosystems and its inhabitants. If oil reaches the Arctic Ocean, many marine species will perish, creating a huge imbalance in the ecosystem.\nAlthough it is hoped that it would be soon under control, the damage done is irrevocable."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:a0529800-160e-48d6-8b80-516aca23ebde>","<urn:uuid:d6c08928-08a1-46b4-bb8b-bcfe24276d8e>"],"error":null}
{"question":"What steps are needed for post-wildfire pool recovery, and what bacterial risks should be monitored in pool water systems?","answer":"For post-wildfire recovery, pools require immediate cleaning to prevent staining, including skimming ash/debris (using cloth-covered nets), brushing surfaces, vacuuming, filter cleaning/backwashing, water level adjustment, and pH balancing (7.2-8.0 ppm). Stain removers may be needed for residual marks. Regarding bacterial risks, two main types need monitoring: legionellae, which thrive in 25-45°C water and can cause respiratory infections when inhaled through vapor, and coliforms (including E. coli) which indicate fecal contamination and can cause gastrointestinal issues if ingested. These bacteria are particularly concerning in stagnant water and poorly maintained systems.","context":["Fire Recovery: How To Clean Soot And Ash From Your Pool\nUnfortunately, there has been a rise in wildfires in the United States over the past few years - especially in California. These unthinkable disasters may cause lasting negative impacts to our homes, yards and swimming pools. Even if your home is, say, 10 miles from the fire, your pool may still find debris and ash in the water. We know it’s not always the first priority for a homeowner after a natural disaster, but we recommend cleaning your swimming pool as soon as possible to avoid any serious and lasting damage.\nHere are our tips to quickly recover your swimming pool from the impacts of a fire.\nSkim Water Surface for Ash and Debris\nSkim and clean the pool of all debris, ash and soot. It is important to remove larger debris from the water surface before turning on your filtration system. This will make the next few steps a lot easier. We recommend covering your skimmer net with an old t-shirt or cloth to trap small particles and debris as you skim the water surface.\nAsh and soot may cause staining on above ground pool liners, in-ground plaster pool surfaces and the surrounding deck area. The quicker you can remove the ash and soot, the less of chance for permanent staining.\nBrush Walls, Steps and Floor\nBrush the walls and pool bottom to loosen debris and contaminants. After brushing the pool surfaces, we recommend vacuuming the pool with a manual pool vacuum or plug-in your automatic pool cleaner to help the process.\nClean and Backwash Pool Filter\nPlease note that your pool filter may quickly fill up with dirt and debris, so remember to backwash and clean the filter often. We recommend checking with your city code for proper waste space (perhaps your lawn or gravel).\nRunning the filtration system is also important because it will begin circulating the stagnant water. Running the pump and filter also help distribute pool chemicals throughout the swimming pool.\nIncrease or Decrease Water Level\nNow, let’s check the water level. Your pool may have lost a significant amount of water from backwashing, so be sure to bring water back up to the recommended level - typically in the middle of the wall skimmer opening. It is important not to bring the water level higher than that so your skimmer can work properly.\nCheck pH Level\nAfter checking the water level, let’s make sure that the pH level is in a healthy range. Ash and soot may alter the pH, so it is extremely important to avoid swimming until pH is between 7.2ppm - 8.0ppm. Try adding Leslie’s Soda Ash to bring the pH level back to a balanced range.\nIf you need to increase your pool's Alkalinity level, without raising the pH level, try adding Leslie's Alkalinity Up. This pH neutral chemical is a quick and effective way to increase the Alkalinity level and avoid potential pool damage.\nCheck Chlorine Level\nAsh and soot from a wildfire can also alter the chlorine level in the your pool water. We recommend adding pool shock and make sure you have at least one 3 inch chlorine tablet in the chlorine dispenser.\nRemove stains on pool surface\nIf you have any remaining residue or stains on the pool surface, try adding Leslie’s Stain and Scale Remover. This pool chemical was developed in partnership with Natural Chemistry and is safe on all pool surfaces. Stain and Scale Remove eliminates stains within 2-4 weeks, so be sure to add this product as soon as possible to avoid further damage.\nFor extremely stained pool surfaces, you may need to hire a pool maintenance professional to acid wash the plaster. Leslie’s offers a Pool Acid Wash Service (in qualified areas) to take all worry and hassle out cleaning the pool surface.\nDownload Leslie's Pool Fire Recovery Checklist\nCheck out our downloadable Fire Recovery Guide for a detailed checklist on how to clean your pool after a fire. Download it here.","The installations to be tested\nAll drinking water is exposed to a risk of bacteriological contamination. Monitoring certain specific points in the water system, or certain installations which are more sensitive, is essential to ensure the safety of users.\nArtificial water systems are particularly conducive to the proliferation of legionellae. Oxygen, limescale (rich in calcium), corrosion (rich in metallic ions), the presence of a biofilm (a layer of organic depositions on the walls of the system which is rich in nutrients), and the temperature are all factors which are conducive to their growth and their development. All water points in the home are affected by this risk. They require extreme vigilance and regular maintenance suitable for the quality of its water.\nColiforms (including E. coli) are the sign of an animal or human faecal contamination. They are found to be present above all in bathing water, water tanks or wells.\nLegionellae develop particularly in water with a temperature between 25°C and 45°C. Hot water tanks, showers, taps and hot tubs (or balneo baths), are therefore installations at highest risk.\nIn the hottest countries, the summer temperatures are very often greater than 25 °C. They make the cold water system just as exposed to the risk as the hot water system.\nFostered by these good conditions, legionellae can multiply until colonies numbering millions of individual bacteria per litre of water are formed. Once legionellae are inhaled via splashes or water vapour, legionellae come to be lodged in the lungs until an infection is generated.\nA coliform contamination in these installations indicates a fault in the system for purifying and treating the water system. In case of ingestion, gastrointestinal infections of greater or lesser severity can arise. According to the WHO, the threshold for potable water which cannot be exceeded is 0 in 100 mL.\nSpas, hot tubs, and other jacuzzis combine all the conditions which are favourable to the growth and development of these bacteria. Hot tubs and the water vapour which they diffuse are particularly conducive to the inhalation of contaminated microdroplets.\nAll bathing installations (fresh water or sea water) are at risk. Cases of faecal contamination occur frequently. Whether they are those of human origin, notably during bathing by young children, or of animal origin (for open outdoor installations), these contaminations can be revealed by the presence of coliforms in your water. The infection can occur following ingestion or contact of the water with the mucous membranes during bathing.\nIf badly maintained, air-conditioning and misting systems may become devices which are particularly conducive to the development of legionellae. They are therefore all the more dangerous because the risk of contamination can affect a large number of people at the same time via the propagation of microdroplets of contaminated water which are then inhaled.\nIn the case of air conditioners, the water which circulates inside to cool the air forms an ideal home for legionellae colonies. For misters which are not connected to running water, the stored water is often not replaced enough. Since it is subject to temperature variations from the exterior, it becomes very conducive to the growth of legionellae which are then diffused directly onto the users.\nAny stagnant water source represents a serious risk of bacteriological contamination which needs to be monitored regularly. Since it is subject to temperature variations from the exterior, the stagnant water from a well or a tank will heat up and then cool down again, and then heat up again… These variations promote the formation of a biofilm and the growth of legionellae. They can therefore grow to several millions of individuals per litre of water once the right conditions come together. The contaminated water therefore becomes harmful to health if it is vaporised or projected (example: sprinkler water).\nLikewise, the water from these installations is exposed to a real risk of contamination with human or animal feces and therefore to the development of coliform bacteria (including E. coli).\nLegionellae present no, or very little, risk in these environments.\nBathing waters such as at beaches, rivers and lakes can be infected by faecal bacteria. Whether this is caused by a fault in the purification system for wastewater which is dumped into these water courses or into the sea, or is down to poor hygiene of an excessively large number of users, beaches are closed to bathers each year due to this type of pollution. Coliform contamination occurs by ingestion or by contact with the mucous membranes while bathing.\nHow can the water in my system be contaminated?\nThe bacteria are naturally present in the environment. However, a greater concentration than normal can occur if certain favourable conditions come together.\nIn the case of legionellae, the corrosion and limescaling of the system promotes the creation of a biofilm on the walls of pipes. This is a layer of organic deposition containing nutrients which are necessary for their development. This biofilm is a good breeding ground for the proliferation of legionellae if the temperature of the water is between 25°C and 45°C.\nStagnant water therefore constitutes extremely favourable ground for the formation of legionellae colonies.\nColiform contaminations (including E. coli) are due to a fault in the treatment of wastewater. Their presence is a sign of a faecal contamination which makes the water unfit for consumption. If your drinking water system is fed by a well or a cistern, the risk is multiplied and calls for a high degree of vigilance.\nHow do I know if my water is contaminated?\nBacteria are invisible to the naked eye. The only way to reveal their presence is to perform a microbiological test on your water.\nWhat should I do in the event of contamination?\nThis depends on the point of contamination, the pathogenic bacteria responsible, and its level of concentration in the water.\nIn the event of contamination with legionellae, it is recommended that you contact the manager of the water system in order to have a professional engaged. He/she will carry out a high-temperature heat treatment and/or a chlorine chemical treatment in order to eliminate the bacteria. However, it is very difficult to eradicate legionellae completely. There are frequently recurrences, which make it necessary to regularly monitor your water system once it has been contaminated.\nIf you suspect you are exhibiting the symptoms of legionellosis (high fever, cough, muscular pain, headaches…), contact your doctor. Depending on the country, legionellosis may be a disease which must be declared by law. For example, in France, it gives rise to a medical and environmental inquiry by the Agence Régionale de Santé (ARS – Regional Health Agency) to identify the source of contamination.\nIn the event of your running water system being contaminated with coliforms (including E. coli), it is recommended that the water not be used for drinking, cooking or for cleaning teeth. It is advisable to contact the system manager immediately, who will inform you of the protocol to be followed in accordance with the instructions of the responsible health authorities.\nCan my boiler which heats in real time be contaminated with legionella?\nA boiler which heats in real time, i.e. without storing the water, does not constitute a risk.\nHowever, if certain outlet points are far from the boiler, or are very little used, there is a danger due to the stagnation of water in these pipes. The stagnant water greatly promotes the creation of a biofilm on the walls of the system. This layer of organic depositions is very rich in nutrients and promotes the development of legionellae colonies.\nAfter a long absence or period out of use, it is advisable to run the water for a number of minutes and to flush the circuit regulary at high temperature in order to detach the biofilm and remove a proportion of the bacteria. Make sure that you do not breathe close to the flushed-out water. However, it is possible that this flushing will eliminate only a superficial part of the biofilm and a proportion of the bacteria. This is why it is vital to regularly check the quality of the water at these specific points.\nCan my cold water be contaminated by legionella?\nYes, in summer, temperatures do often exceed 25°C over a long period. Legionellae develop particularly in water with a temperature between 25°C and 45°C. The frequency of heatwave episodes also increases the risk of contamination of the cold water network. This heat risk is compounded by the risk posed by installations which are little used during the rest of the year, in particular summer kitchens, outbuildings, automatic sprinkler systems or outdoor taps. It is therefore advisable to flush out your system and test it each time it is put back into use.\nI live in a multi-dwelling building. Is there a risk of legionella contamination?\nThe regulations compelling the providers of social housing and co-owners to carry out regular checks on the water systems is not the same from country-to-country. However, cases of legionellosis are constantly increasing throughout Europe and the United States. The countries which have legislated on this matter generally prescribe one obligatory test per year. This is entirely insufficient in the face of a risk which occurs throughout the year. In the event of positive contamination, the treatment will consist of a high-temperature thermal shock and a chemical shock based on biocide. Unfortunately, this may only destroy a proportion of the bacteria and of the biofilm, the layer of organic depositions from which the bacteria draw their nutrients. Recurrences are frequent unless more regular tests are carried out.\nI have a natural swimming pool. What are the risks of contamination?\nAny unchlorinated bathing water presents a serious risk of bacteriological contamination, regardless of the system of phyto-purification selected. It is vital to monitor the composition of the water in order to avoid the human or animal faecal contaminations which can occur, as well as any potential contamination with legionellae if the temperature of the water exceeds 25°C, in particular in summer.\nCan a chlorinated swimming pool be contaminated?\nEven a chlorinated pool can become contaminated if the chlorine concentration is too low. Human or animal faecal contaminations occur very frequently in these installations, whether they are communal or private swimming pools. These can be intentional or accidental, and can come from young children or any other user. The infections can therefore affect all users and can sometimes prove to be very serious for those groups who are the most vulnerable. This is why public swimming pools are subject to daily checks and why it is so vital to check the water of a private swimming pool as often as possible."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:b0cbe362-4f4b-4e47-a43d-bbcb6860f940>","<urn:uuid:7c014064-c67c-470b-8c67-c41ef99fd61c>"],"error":null}
{"question":"What mechanisms allow for optimal threshold adjustment in perceptual decision-making, comparing mathematical models with neurobiological implementations?","answer":"In mathematical models, threshold adjustment occurs through optimization of reward rate functions that balance speed and accuracy. The drift diffusion model allows explicit calculation of optimal thresholds based on error rates and response times. In the neurobiological implementation, threshold adjustments are mediated by the locus coeruleus (LC) norepinephrine system through gain modulation. The LC has two key states: a phasic state with slow average firing and good performance, and a tonic state with fast firing and poor performance. The LC's approximately 30,000 neurons make about 250,000 synapses each, releasing norepinephrine to tune cortical gain and adjust effective decision thresholds. This biological system appears to implement near-optimal threshold adaptation predicted by mathematical models.","context":["Drugowitsch, J., Moreno-Bote, R., Churchland, A. K., Shadlen, M. N., and Pouget, A.\nThe Journal of Neuroscience, 32:3612–3628, 2012\nDOI, Google Scholar\nDecision making often involves the accumulation of information over time, but acquiring information typically comes at a cost. Little is known about the cost incurred by animals and humans for acquiring additional information from sensory variables due, for instance, to attentional efforts. Through a novel integration of diffusion models and dynamic programming, we were able to estimate the cost of making additional observations per unit of time from two monkeys and six humans in a reaction time (RT) random-dot motion discrimination task. Surprisingly, we find that the cost is neither zero nor constant over time, but for the animals and humans features a brief period in which it is constant but increases thereafter. In addition, we show that our theory accurately matches the observed reaction time distributions for each stimulus condition, the time-dependent choice accuracy both conditional on stimulus strength and independent of it, and choice accuracy and mean reaction times as a function of stimulus strength. The theory also correctly predicts that urgency signals in the brain should be independent of the difficulty, or stimulus strength, at each trial.\nThe authors show equivalence between a probabilistic and a diffusion model of perceptual decision making and consequently explain experimentally observed behaviour in the random dot motion task in terms of varying bounds in the diffusion model which correspond to varying costs in the probabilistic model. Here, I discuss their model in detail and outline its limits. My main worry with the presented model is that it may be too powerful to have real explanatory power. Impatient readers may want to skip to the conclusion below.\nThe presented model is tailored to the two-alternative, forced choice random dot motion task. The fundamental assumption for the model is that at each point in discrete time, or equivalently, for each successive time period in continuous time the perceptual process of the decision maker produces an independent sample of evidence whose mean, mu*dt, reflects the strength (coherence) and direction (only through sign of evidence) of random dot motion while its variance, sigma2, reflects the passage of time (sigma2 = dt, the time period between observations). This definition of input to the decision model as independent samples of motion strength in either one of two (unspecified) directions restricts the model to two decision alternatives. Consequently, the presented model does not apply to more alternatives, or dependent samples.\nThe model of noisy, momentary evidence corresponds to a Wiener process with drift which is exactly what standard (drift) diffusion models of perceptual decision making are where drift is equal to mu and diffusion is equal to sigma2. You could wonder why sigma2 is exactly equal to dt and not larger, or smaller, but this is controlled by setting the mean evidence mu to an appropriate level by allowing it to scale: mu = k*c, where k is an arbitrary scaling constant which is fit to data and c is the random dot coherence in the current trial. Therefore, by controlling k you essentially control the signal to noise ratio in the model of the experiment and you would get equivalent results, if you changed sigma2 while fixing mu = c. The difference between the two cases is purely conceptual: In the former case you assume that the neuronal population in MT signals, on average, a scaled motion strength where the scaling may be different for different subjects, but signal variance is the same over subjects while in the latter case you assume that the MT signal, on average, corresponds to motion strength directly, but MT signal variance varies across subjects. Personally, I prefer the latter.\nThe decision circuit in the author’s model takes the samples of momentary evidence as described above and computes a posterior belief over the two considered alternatives (motion directions). This posterior belief depends on the posterior probability distribution over mean motion strengths mu which is computed from the samples of momentary evidence taking a prior distribution over motion strengths into account. An important assumption in the computation of the posterior is that the decision maker (or decision circuit) has a perfect model of how the samples of momentary evidence are generated (a Gaussian with mean mu*dt and variance dt). If, for example, the decision maker would assume a slightly different variance, that would also explain differences in mean accuracy and decision times. The assumption of the perfect model, however, allows the authors to assert that the experimentally observed fraction of correct choices at a time t is equal to the internal belief of the decision maker (subject) that the chosen alternative is the correct one. This is important, because only with an estimate of this internal belief the authors can later infer the time-varying waiting costs for the subject (see below).\nAnyway, under the given model the authors show that for a Gaussian prior you obtain a Gaussian posterior over motion strength mu (Eq. 4) and for a discrete prior you obtain a corresponding discrete posterior (Eq. 7). Importantly, the parameters of the posteriors can be formulated as functions of the current state x(t) of the sample-generating diffusion process and elapsed time t. Consequently, also the posterior belief over decision alternatives can be formulated as a one-to-one, i.e., invertible function of the diffusion state (and time t). By this connection, the authors have shown that, under an appropriate transformation, decisions based on the posterior belief are equivalent to decisions based on the (accumulated) diffusion state x(t) set in relation to elapsed time t.\nIn summary, the probabilistic perceptual decision model of the authors simply estimates the motion strength from the samples and then decides whether the estimate is positive or negative. Furthermore, this procedure is equivalent to accumulating the samples and deciding whether the accumulated state is very positive or very negative (as determined by hitting a bound). The described diffusion model has been used before to fit accuracies and mean reaction times of subjects, but apparently it was never quite good in fitting the full reaction time distribution (note that it lacks the extensions of the drift diffusion models suggested by Ratcliff, see, e.g., ). So here the authors extend the diffusion model by adding time-varying bounds which can be interpreted in the probabilistic model as a time-varying cost of waiting for more samples.\nTime-varying bounds and costs\nIntuitively, introducing a time-varying bound in a diffusion model introduces great flexibility in shaping the response accuracy and timing at any given time point. However, I currently do not have a good idea of just how flexible the model becomes. For example, if in discrete time changing the bound at each time step could independently modify the accuracy and reaction time distribution at this time step, the bound alone could explain the data. I don’t believe that this extreme case is true, but I would like to know how close you would come. In any case, it appears to be sensible to restrict how much the bound can vary to prevent overfitting of the data, or indeed to prevent making the other model parameters obsolete. In the present paper, the authors control the shape of the bound by using a function made of cosine basis functions. Although this restricts the bound to be a smooth function of time, it still allows considerable flexibility. The authors use two more approaches to control the flexibility of the bound. One is to constrain the bound to be the same for all coherences, meaning that it cannot be used to explain differences between coherences (experimental conditions). The other is to use Bayesian methods for fitting the data. On the one hand, this controls the bound by choosing particular priors. They do this by only considering parameter values in a restricted range, but I do not know how wide or narrow this range is in practice. On the other hand, the Bayesian approach leads to posterior distributions over parameters which means that subsequent analyses can take the uncertainty over parameters into account (see, e.g., the indicated uncertainty over the inferred bound in Fig. 5A). Although I remain with some last doubts about whether the bound was too flexible, I believe that this is not a big issue here.\nIt is, however, a different question whether the time-varying bound is a good explanation for the observed behaviour in contrast, e.g., to the extensions of the diffusion model introduced by Ratcliff (mostly trial-by-trial parameter variability). There, one might refer to the second, decision-related part of the presented model which considers the rewards and costs associated with decisions. In the Bayesian decision model presented in the paper the subject decides at each time step whether to select alternative 1, or alternative 2, or wait for more evidence in the next time step. This mechanism was already mentioned in . Choosing an alternative will either lead to a reward (correct answer) or punishment (error), but waiting is also associated with a cost which may change throughout the trial. Deciding for the optimal course of action which maximises reward per unit time then is an average-reward reinforcement learning problem which the authors solve using dynamic programming. For a particular setting of reward, punishment and waiting costs this can be translated into an equivalent time-varying bound. More importantly, the procedure can be reversed such that the time-varying cost can be inferred from a bound that had been fitted to data. Apart from the bound, however, the estimate of the cost also depends on the reward/punishment setting and on an estimate of choice accuracy at each time step. Note that the latter differs considerably from the overall accuracy which is usually used to fit diffusion models and requires more data, especially when the error rate is low.\nThe Bayesian decision model, therefore, allows to translate the time-varying bound to a time-varying cost which then provides an explanation of the particular shape of the reaction time distribution (and accuracy) in terms of the intrinsic motivation (negative cost) of the subject to wait for more evidence. Notice that this intrinsic motivation is really just a value describing how much somebody (dis-)likes to wait and it cannot be interpreted in terms of trying to be better in the task anymore, because all these components have been taken care of by other parts of the decision model. So what does it mean when a subject likes to wait for new evidence just for the sake of it (cf. dip in cost at beginning of trial in human data in Fig. 8)? I don’t know.\nCollapsing bounds as found from behavioural data in this paper have been associated with an urgency signal in neural data which drives firing rates of all decision neurons towards a bound at the end of a trial irrespective of the input / evidence. This has been interpreted as a response of the subjects to the approaching deadline (end of trial) that they do not want to miss. The explanation in terms of a waiting cost which rises towards the end of a trial suggests that subjects just have a built-in desire to make (potentially arbitrary) choices before a deadline. To me, this is rather unintuitive. If you’re not punished for making a wrong choice (blue lines in Figs. 7 and 8, but note that there was a small time-punishment in the human experiment) shouldn’t it be always beneficial to make a choice before the deadline, because you trade uncertain reward against certain no reward? This would already be able to explain the urgency signal without consideration of a waiting cost. So why do we see one anyway? It may just all depend on the particular setting of reward and punishment for correct choices and errors, respectively. The authors present different inferred waiting costs with varying amounts of punishment and argue that the results are qualitatively equal, but the three different values of punishment they present hardly exhaust the range of values that could be assumed. Also, they did not vary the amount of reward given for correct choices, but it is likely that only the difference between reward and punishment determines the behaviour of the model such that it doesn’t matter whether you change reward or punishment to explore model predictions.\nThe main contribution of the paper is to show that accuracy and reaction time distribution can be explained by a time-varying bound in a simple diffusion model in which the drift scales linearly with stimulus intensity (coherence in random dot motion). I tried to point out that this result may not be surprising depending on how much flexibility a time-varying bound adds to the model. Additionally, the authors present a connection between diffusion and Bayesian models of perceptual decision making which allows them to reinterpret the time-varying bounds in terms of the subjective cost of waiting for more evidence to arrive. The authors argue that this cost increases towards the end of a trial, but for two reasons I’m not entirely convinced: 1) Conceptually, it is worth considering the origin of a possible waiting cost. It could correspond to the energetic cost of keeping the inference machinery running and the attention on the task, but there is no reason why this should increase towards a deadline. 2) I’m not convinced by the presented results that the inferred increase of cost towards a deadline is qualitatively independent of the reward/punishment setting. A greater range of punishments should have been tested. Note that you cannot infer the rewards for decisions and the time-varying waiting cost at the same time from the behavioural data. So this issue cannot be settled without some new experiments which measure rewards or costs more directly. Finally, I miss an overview of fitted parameter values in the paper. For example, I would be interested in the inferred lapse trial probabilities p1. The authors go through great lengths to estimate the posterior distributions over diffusion model parameters and I wonder why they don’t share the results with us (at least mean and variance for a start).\nIn conclusion, the authors follow a trend to explain behaviour in terms of Bayesian ideal observer models extended by flexible cost functions and apply this idea to perceptual decision making via a detour through a diffusion model. Although I appreciate the sound work presented in the paper, I’m worried that the time-varying bound/cost is too flexible and acts as a kind of ‘get out of jail free’ card which blocks the view to other, potentially additional mechanisms underlying the observed behaviour.\n Bogacz, R.; Brown, E.; Moehlis, J.; Holmes, P. & Cohen, J. D. The physics of optimal decision making: a formal analysis of models of performance in two-alternative forced-choice tasks. Psychol Rev, 2006, 113, 700-765\n Dayan, P. & Daw, N. D. Decision theory, reinforcement learning, and the brain. Cogn Affect Behav Neurosci, 2008, 8, 429-453","Does Math Matter to Gray Matter?(or, The Rewards of Calculus). Philip Holmes, Princeton University with Eric Brown (NYU), Rafal Bogacz (Bristol, UK), Jeff Moehlis (UCSB), Juan Gao, Patrick Simen & Jonathan Cohen (Princeton); Ed Clayton, Janusz Rajkowski & Gary Aston-Jones (Penn). Thanks to: NIMH, NSF, DoE and the Burroughs-Wellcome Foundation. IMA, December 8th, 2005.\nContents Introduction: The multiscale brain. Part I:Decisions and behavior, or Making the most of a stochastic process. Part II:Spikes and gain changes, or Let them molecules go! Morals: Mathematical and Neurobiological, or You bet math matters!\nIngredients:~1011 neurons, ~1014 synapses. Structure:layers and folds. Communication:via action potentials, spikes, bursts. The multiscale brain: Sources: www.siumed.edu/~dking2/ssb/neuron.htm#neuron, webvision.med.utah.edu/VisualCortex.html\nMultiple scales in the brain and in math: Part II Part I … or Cultural Studies …\nWhat neuroscience is and will become: A painstaking accumulation of detail: differentiation. Assembly of the parts into a whole: integration. And what does math do well? Integration and differentiation! (This is not just a corny joke.)\nPart I: Decisions and behavior, orMaking the most of a stochastic process.(A macroscopic tale: integration) Underlying hypothesis: Human and animal behaviors have evolved to be (near) optimal. (Bialek et al., 1990-2005: Fly vision & steering)\nA really simple decision task: “On each trial you will be shown one of two stimuli, drawn at random. You must identify the direction (L or R) in which the majority of dots are moving.” The experimenter can vary the coherence of movement (% moving L or R) and the delay between response and next stimulus. Correct decisions are rewarded. “Your goal is to maximize rewards over many trials in a fixed period.”You gotta be fast, and right! 30% coherence 5% coherence Courtesy: W. Newsome Behavioral measures: reaction time distributions, error rates. More complex decisions: buy or sell? Neural economics.\nAn optimal decision procedure for noisy data:the Sequential Probability Ratio Test Mathematical idealization: During the trial, we draw noisy samples from one of two distributions pL(x) or pR(x) (left or right-going dots). The SPRT works like this: set up two thresholds and keep a running tally of the ratio of likelihood ratios: When first exceeds or falls below , declare victory for R or L. Theorem: (Wald, Barnard) Among all fixed sample or sequential tests, SPRT minimizes expected number of observations n for given accuracy. pL(x) pR(x)\nInterlude: a mathematical DDance: Take logarithms: multiplication in becomes addition. Take continuum limit: addition becomes integration. The SPRT becomes a drift-diffusion (DD) process (a cornerstone of 20th century physics): drift rate noise strength and is the accumulated evidence (the log likelihood ratio). When reaches either threshold , declare R or L the winner. But dohumans (or monkeys, or rats) drift and diffuse? Evidence comes from three sources: behavior, neurons, and mathematical models.\nBehavioral evidence: RT distributions Human reaction time data can be fitted nicely to the first passage threshold crossing times of a DD process. (Ratcliff et al., Psych Rev. 1978, 1999, 2004.) thresh.+Z drift A thresh.-Z\nNeural evidence: firing rates Spike rates of neurons in oculomotor areas rise during stimulus presentation, monkeys signal their choice after a threshold is crossed. thresholds J. Schall, V. Stuphorn, J. Brown, Neuron, 2002. Frontal eye field recordings. J.I Gold, M.N. Shadlen, Neuron, 2002. Lateral interparietel area recordings.\nModel evidence: integration of noisy signals thresh. 2 We can model the decision process as the integration of evidence by competing accumulators. (Usher &McClelland, 1995,2001) Subtracting the accumulated evidence yields a DD process for . thresh. 1 OK, maybe. But dohumans (or monkeys, or rats) optimize?\nRT D RT D The task: maximize your rewards for a succession of trials in a fixed period. Reward Rate: (% correct/average time for resp.) response-to-stimulus interval Optimal decisions redux 1 • Threshold too low • Too high • Optimal $ $ X X X D RT D RT RT D RT D RT D $ $ RT D RT D RT $ $ $ X D D D RT RT RT RT\nOptimal decisions redux 2 How fast to be? How careful? The DDM delivers an explicit solution to the speed-accuracy tradeoff in terms of just 3 parameters: normalized threshold and signal-to-noise ratio and D. So, setting we can express RT in terms of ER and calculate a unique, parameter-free Optimal Performance Curve: RT/(total delay) = F(ER)\nA behavioral test 1 Do people adopt the optimal strategy? Some do; some don’t. Is this because they are optimizing a different function, e.g. weighting accuracy more? Or are they trying, but unable to adjust their thresholds? OPC NOT TODAY A mathematical theory delivers precise predictions. Its successes and failures generate further precise questions, suggest new experiments.\nA behavioral test, 2 A modified reward rate function with a penalty for errors gives a family of OPCs with an extra parameter: the weight placed on accuracy. (It fits the whole dataset better, but what’s explained?) accuracy weight increasing data fit OPC Short version: Holmes et al., IEICE Trans., 2005. Long version (182pp): in review, 2004-2006. Bottom line:Too much accuracy is bad for your bottom line.(Princeton undergrads don’t like to make mistakes.)\nChoosing a threshold Q: Suboptimal behavior could be reckless (threshold too low) or conservative (threshold too high)? Why do most people tend to be conservative? Could it be a rational choice? Which type of behavior leads to smaller losses? A:Examine the RR function. Slope on high threshold side is smaller than slope on low threshold side, so for equal magnitudes, conservative errors cost less. threshold too high threshold too low threshold\nThresholds and gain changes How might thresholds be adjusted ‘on the fly’ when task conditions change? Neurons act like amplifiers, transforming input spikes to output spike rates. Gain improves discrimination. (Servan-Schreiber et al., Science, 1990.) gain output (spikes) threshold input Neurotransmitter release can increase gain. Specifically, norepinephrine can assist processing and speed response in decision tasks, collapsing the multilayered brain to a single near-optimal DD process.\nPart II: Spikes and gain changes, orLet them molecules go!(A microscopic tale: differentiation.) Underlying hypotheses: Threshold and gain changes in the cortex are mediated by transient spike dynamics in brainstem areas. Transients determined by inherent circuit properties and stimuli. (Aston-Jones & Cohen, 1990-2005.)\nA tale of the locus coeruleus (LC) The LC, a neuromodulatory nucleus in the brainstem, releases norepinephrine (NE) widely in the cortex, tuning performance. The LC has only ~30,000 neurons, but they each make ~250,000 synapses. Transient bursts of spikes triggered by salient stimuli cause gain changes, thus bigger response to same stimulus. Devilbiss and Waterhouse, Synapse, 2000 Aston-Jones & Cohen, Ann. Rev. Neurosci., 2005. same stimulus\nLC dynamics: tonic and phasic states In waking animals, the LC ‘spontaneously’ flips between two states: tonic (fast average spike rate, poor performance) and phasic (slow average spike rate, good performance). Tonic: small transient resp. Phasic: big transient resp. Spike histograms (PSTHs) Usher et al., Science, 1999. Transients are crucial: the LC delivers NE just when it’s needed.\nModeling LC neurons 1 Hodgkin & Huxley (J. Physiol., 1952) developed a biophysical model of a single cell. Charged ions pass through the cell membrane via gates. Electric circuit equations + gating models fitted to data describe the dynamics. The HH model (for squid giant axon) has been generalized to many types of neurons. It’s a keystone of neuroscience; it describes the spikes beautifully, but the equations are really nasty! Rose and Hindmarsh, Proc. R. Soc. Lond. B., 1989. However, …… LC cells are spontaneous spikers and we can use this to reduce the HH equations to a simple phase model. Voltage\nModeling LC neurons 2 In phase space, periodic spiking is a closed curve: Ion gate fire Voltage So we may change to ‘clock face’ coordinates that track phase -- progress through the firing cycle -- and by marking time in a nonuniform manner, we collapse HH to simply:\nModeling LC neurons 3 Well, it’s not quite that simple: External inputs, stimuli and synaptic coupling from other cells, are all ‘filtered’ through the phase response curve (PRC), which describes inherent oscillator properties: but given this, we can compute their effects. And we can find the PRC: (external stimuli speed up the spikes most at 9 o’clock)\nModeling LC neurons 4 There are many such oscillating ‘clocks’ in LC, and the stimulus reorders and coordinates their random phases. Phasic LC: slow on average, gives a big burst. Tonic LC: fast on average, gives a small burst. The size of this effect depends upon the intrinsic frequency.\nModeling LC neurons 5 Adding noise and weak coupling, we can match the experimental PSTH data. decay and reset After stimulus ends, noise and random frequencies redistribute the phases.\nComparison with LC PSTH data data theory simulations model Matching the PSTHs reveals that intrinsic frequency and its variability and stimulus duration are key parameters. Slower oscillators deliver bigger coherent bursts. Burst envelopes decay exponentially. Depressed firing rates follow short stimuli. (Brown et al., J. Comp. Neurosci. 2004.) The latter may be responsible for attentional blink. (Niewenhuis et al., J. Exp. Psych. 2005.)\nSummary and Morals Neural activity in simple decisions is like a DD process: the model predicts optimal speed-accuracy tradeoffs. 2. Threshold adjustments can optimize rewards. 3. The LC-NE system provides a control mechanism: the model reveals roles of intrinsic vs. stimulus properties. 4.There’s very pretty mathematics at all scales: stochastic ODE, dynamical systems, freshman calculus. Large gaps remain: we must bridge the scales. Morals: Good mathematical models are not just (reasonably)faithful; they’re also (approximately)soluble. They focus and simplify. _____________________________________________________________________ Thanks for your attention!\nLearning a threshold An algorithm based on reward rate estimates and a linear reward rate rule can make rapid threshold updates by iteration. But … Can RR be estimated sufficiently accurately? Can the rule be learned? Does noise cause overestimates? (Simen et al., 2005.) Threshold"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"language-ambiguous"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:a052b925-361d-4738-a59e-8a7bb6cc2eb0>","<urn:uuid:50c78b0e-aac3-499f-8ce9-49180323f806>"],"error":null}
{"question":"What are the resource conservation benefits of vertical farming systems compared to traditional agriculture, and how do online photo privacy controls help manage digital resource access?","answer":"Vertical farming significantly reduces resource usage compared to conventional agriculture by using 90% less water and enabling nutrient and water flow reuse through vertical designs. These systems also require less space while increasing yield per unit area. Additionally, they minimize the need for pesticides through enclosed, controlled environments. In the digital realm, photo privacy controls offer resource management through features like selective sharing and tagging permissions. On platforms like Facebook, users can control who sees their photos through privacy settings, untag themselves from others' photos, and develop proper tagging etiquette by asking permission before tagging others - especially for minors or non-platform users. Both systems represent different approaches to resource management in their respective domains.","context":["We live in a social era, where posting images to Facebook and Twitter is (to many people) second nature. Whether you’re an avid uploader or the occasional photo-sharer, posting photos online is not without risks, especially to your privacy.\nTo ensure your photo privacy online, you’ve got to take a few basic steps:\n1. Don’t put them online. I know, I know – what kind of advice is that? But the truth is, once you’ve uploaded your images to a third party’s servers, no matter how reputable, they’re at risk. Flickr accidentally deleted one users account, wiping out 4,000 photos. Facebook has been caught restoring posts and images that were supposedly “deleted” by a user.\nSuffice it to say, if you’re really, really concerned about photo privacy, don’t upload your images at all.\n2. When you do put them online, read the fine print. Chances are, you’re not going to heed point one (and that’s fine, we’re just covering our bases). But when you do select a website or app to upload photos to, be sure to read the fine print. Yes, it’s tedious, awful lawyer-speak, but it contains important information about how your photos are treated and what rights you have should you feel your privacy has been violated.\n3. Develop proper tagging etiquette. Let’s say you’re the type of person that uses Facebook but avoids posting personal images there. Unfortunately, personal images can still find their way online through your friends who upload them and “tag” you in them. While you can’t (and shouldn’t) tell other people what they can and cannot do online, you can certainly inform anyone who posts/tags images of you or your children online how you feel about that. You can also untag yourself, which disassociates your name from the photo.\nThe reverse is also true. If you’re an avid Facebook user with no reservations about posting your images online, you should still respect and be aware that other people in your social circle are not so inclined. It seems only proper to ask any individual who appears in a photo if they care to be “tagged” before you go ahead and do it. It also seems only proper not to tag anyone under 18, who is not a consenting adult. Additionally, don’t tag anyone who isn’t on Facebook, since they do not have the ability to untag themselves if they so choose.\n4. Disable Geo-Tags. Geo-tags are pieces of information inside your photograph that tell people where you were when you snapped the picture. Combined with time and date stamps, geo-tags can help snoopers discover where you live and your daily patterns. If you shoot a lot of photos with a smartphone, like the iPhone or an Android phone, geotags are automatically added to your images. Eye Fi memory cards can also add geographical coordinates to images and some cameras offer built-in GPS chips for geo-tagging purposes. In all three cases, you’ll have the option to disable geo-tagging before you start snapping photos, if privacy is a concern.\nWhile you probably don’t want to disable geo-tags for your big European vacation, it’s a good idea to disable them if you’re shooting around the house or in your neighborhood. Alternatively, you can remove the GPS coordinates before you upload. An app for iPhone owners called deGeo can remove these geo-tags for you before you post them to sites like Flickr. Geo-Eraser performs a similar function for Android phones.\n5. Strip the metadata from your photo before you post it online. Every digital photo you snap contains information inside of it: the camera used, the various settings and resolution of the image, the focal length of the lens and, if you have GPS capability, your location. This information is called “metadata” and programs can access this information from your online images whether you want them to or not. Now, most of this information is harmless. It doesn’t really matter if someone knows the aperture of the lens in a specific photo. But if you don’t like the thought of any information traveling with your photo as you upload it, you can strip the metadata from your photograph using a free program such as JPEG & PNG Stripper.\n6. Remember your audience. Depending on your photo-sharing site of choice, you may be posting images for public consumption or in invite-only galleries. If you’re sending them to Facebook, your friends will see them and if your privacy settings aren’t set to maximize your privacy, there’s a chance others can see those images as well. So, common sense rules — if there are people out there that hold a grudge or are of questionable ethics (none of your friends, of course) keep galleries private and keep the photos off Facebook. (You can learn about Facebook’s photo privacy settings here.)","Agricultural systems around the world need to adapt to the rapidly changing environmental, demographic, and socioeconomic landscapes, and new alternative practices, such as vertical agriculture, may offer new opportunities to accelerate such adaptation.\nNext Gen Farming Without Soil and 90% Less Water | GRATEFUL\nWhat is vertical farming and why is it important\nModern agricultural systems encompass an estimated 1.5 billion hectares of the world’s surface area. With a growing population and resource needs, the availability of arable land is shrinking rapidly.\nSince the agricultural revolution, conventional agriculture has focused on practices requiring considerable quantities of space, water, fertilizer, and pesticides. The past 50 years have seen an accelerating rate of increase in these requirements as modern food production aims to increase productivity in the hopes of addressing growing food insecurity.\nLooking into the future, yield production is forecasted to decrease due to widespread environmental and socioeconomic changes that will generate unpredictable consequences on food systems.\nIn response, many strategies have been developed as alternatives to conventional agricultural practices. These strategies have focused on key principles and their combination to be effective: require less space, less water, and increase yield per unit of area. Moreover, due to the negative effects of agrichemicals, modern practices have also aimed to use significantly less to avoid potentially adverse effects for humans and animals.\nOne such alternative is the development of vertical agriculture, also referred to as vertical farming. As the name implies, vertical agriculture relies on expanding production vertically and not horizontally. Vertical agriculture is a multilayer indoor plant production system that allows for precise control of growth factors, such as light, temperature, humidity, carbon dioxide concentration, water, and nutrients.\nThis allows for the growing and production of crops year-round, completely independent of solar light and other external conditions. Indeed, vertical agriculture makes use of key concepts within ecology and physiology to optimize growing and fertilization within controlled conditions. For instance, elements of photobiology, thermomorphogenesis, hydroponics, and genetic breeding, are all used commonly across systems of vertical agriculture.\nBenefits, challenges, and disadvantages moving from horizontal to vertical farming\nAs a result of tight control over crop breeding, growing, and harvesting, vertical farming provides several benefits relative to conventional methods of ‘horizontal’ food production. This was the topic of a literature review by Kalantari et al. published in 2016 in the Journal of Landscape Ecology.\nFrom a systems perspective, the enclosed design prevents pests and diseases from entering by the adoption of a high level of hygiene, continuous monitoring, and non-chemical disinfection, providing security from crops. Moreover, recent technology has also allowed for automated control over environmental conditions by using sensors and imaging techniques in combination with crop simulation models and artificial intelligence, limiting the need for physical labor.\nVertical farming also allows for flexible organization, with designs ranging from large vertical walls covered with crops to large hangars or re-used shipping containers that can be transported. Consequently, vertical agricultural systems, can comprise many varying sizes and be located within many different areas from the middle of highly urbanized cities to more suburban or rural areas.\nMoreover, the verticality element of this system also provides nutrient and water flow, helping to reuse costly resources. The reduction in space also means there is a significant increase in yield per area, holding extensive potential for a future world of urbanization.\nFrom an economic perspective, vertical farming also provides for more jobs in localized areas and is community-focused by addressing the needs of immediate areas, which in turn can provide food at a lower price. Finally, the optionality of location for vertical systems also allows producers to reduce transport costs, as consumers may access them within urban areas, or transport can be minimized to nearby areas.\nHowever, despite the design, environmental, and economic advantages, vertical farming also incorporates several issues that remain a challenge to its broader implementation as a system.\nVertical farming has a high energy requirement and needs extensive investment costs to implement and develop successfully. Moreover, indoor issues relating to excessive UV, heat, and ozone-induced plant damage may have unpredictable repercussions for plant growth.\nAdditionally, vertical systems are difficult to adapt to a larger scale. They are costly to build and maintain and have yet to demonstrate the ability to provide food for larger areas than community-scale populations. This would make it difficult to implement in areas at higher risk of food insecurity, such as developing agricultural nations.\nThe lack of empirical research on a broader scale has meant that vertical farming has yet to develop past the concept stage on community levels, as persistent issues make it difficult to break through to a larger scale.\nImage Credit: YEINISM/Shutterstock.com\nGrowing skywards - the implications of vertical farming in a rapidly populating and changing world\nAmong the development of alternative agricultural practices, vertical agriculture provides a promising solution for many of the challenges facing current agricultural policies. However, for vertical systems to be integrated on a larger scale requires further technological progress and economic investment.\nNevertheless, gradually implementing more verticality, or combining it with other practices aiming for more sustainable practices may be promising. For instance, the combination of verticality with other practices such as intercropping may be particularly beneficial for developing more sustainable food systems.\nIncorporating technological progress into vertical systems also holds promise, with automated sensors and machinery able to operate near-independently. Progress in gene editing and plant genome modifications will also allow for faster, bigger, and healthier crops, allowing vertical agriculture to produce more over time.\nThroughout agricultural history, farming systems have typically spread over large spans of land, yet the reduction in arable land, as well as the increase in demand to house growing populations, means that such strategies need to be reconsidered, and vertical agriculture may play a role looking into the future.\nContinue Reading: Benefits of Vertical Agriculture and Hydroponics\n- Beacham, A. M., Vickers, L. H., & Monaghan, J. M. (2019). Vertical farming: a summary of approaches to growing skywards. The Journal of Horticultural Science and Biotechnology, 94(3), 277–283. doi: 10.1080/14620316.2019.1574214\n- Chaudhry A. R. and Mishra V. P.,(2019) A Comparative Analysis of Vertical Agriculture Systems in Residential Apartments, Advances in Science and Engineering Technology International Conferences (ASET), 2019, pp. 1-5, doi: 10.1109/ICASET.2019.8714358\n- Sarkar, A., & Majumder, M. (2015). Opportunities and Challenges in Sustainability of Vertical Eco-Farming: A Review. Journal of Advanced Agricultural Technologies, 2(2). doi: 10.12720/joaat.2.2.98-105\n- SharathKumar, M., Heuvelink, E., & Marcelis, L. F. (2020). Vertical Farming: Moving from Genetic to Environmental Modification. Trends in Plant Science, 25(8), 724–727. doi: 10.1016/j.tplants.2020.05.012"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"search_synthesis"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:fc563a2a-7cbc-49ff-a9f0-4ae337dd17dd>","<urn:uuid:3566e03d-b8ac-4d36-b13c-9d56f4d7ba0e>"],"error":null}
{"question":"Based on the Lerner Index and market dynamics, how does the measurement of market power differ between perfectly competitive markets and monopolistic ones?","answer":"In perfectly competitive markets, price equals marginal cost, while in markets with monopoly power, price exceeds marginal cost. This difference is measured by the Lerner Index, which is calculated as (P-MC)/P, where P is price and MC is marginal cost. The value of the Lerner Index always falls between zero and one, with larger values indicating a higher degree of monopoly power. For example, when price is $60 and marginal cost is $30, the Lerner Index equals 0.5, indicating significant market power. The index relates to the elasticity of demand for the firm (not market demand), and is inversely related to it. In perfectly competitive markets, where firms have no market power, the Lerner Index would be zero since price equals marginal cost.","context":["1. Suppose the demand for output is given by Q = 120 – P and the marginal (and average) cost of production is constant, at 30. Assuming two firms and Cournot competition, compute the Nash equilibrium outputs, prices, and profits. Graph the reaction curves. Calculate the Lerner index for the typical firm in this market.\n2. Can you provide definitions of the following concepts in economics for me?\n- Values Q and P\n- Cost of production, especially average cost of production and marginal cost of production\n- Cournot competition model\n- Nash equilibrium\n- Reaction functions curves\n- Lerner index\nIn the Cournot competition model developed in France in 1838 by mathematician Augustin Cournot to reflect a duopoly, Q and P represent quantity of output (Q) and product price (P). On a graph, P is the vertical (up-and-down) axis (line) while Q is the horizontal (side-to-side) axis.\nCosts of production are classed as total cost, average cost and marginal cost. Total cost is the sum of all variable costs, such as the variable cost of raw materials, and all fixed costs, such as the fixed cost of operating costs.\nAverage cost is the average cost per each unit produced: Average cost is total cost divided by the total number of units produced during a fiscal period. Consequently, average cost can be stated as the cost to produce one unit of product.\nMarginal cost builds on the average cost (cost of one unit) to calculate the added cost of one unit more of the product. In other words: If production is X and average cost Y, then X+1 will equal Y+?. The formula for calculating the cost that results from a one unit change in production output is this:\nMarginal Cost (MC) = Change in Total Cost = ΔTC\nChange in Output Δq\nCournot competition assume a duopoly restrict, per definition, to two firms. [Research has shown the model can be expanded to multiple firms.] Cournot assumes that quantity is the variable and price is the constant.\nIn other words, companies fix their production on a predetermined price range so that price is stable and so that quantity of output is variable. [Research has shown that, in fact, it is the other way round: quantity is stable while price that is the variable (changeable) factor.]\nThe Nash equilibrium reflects conditions when prices are stable, as in the Cournot model, and is thus used instead of the price taking competitive equilibrium model that reflects variable prices. Nash equilibrium is appropriate to the Cournot duopoly model because it assumes stable prices with variable quantity output.\nWith stable prices for two companies--both of which operate under the same assumptions of stable price and homogenous (identical) products--the Nash equilibrium reflects the industry price set by the demand curve, thus reflects the revenues of each company in the duopoly. The Nash equilibrium show the intersection where both firms are choosing optimal production output in consideration of the output of the other firm.\nIn other words, with prices stable, the only variable is production output. The Nash equilibrium shows the optimal output for each company base upon, or given, the output of the single competitor in the duopoly.\nReaction function curves: With R being the reactions of firms 1 and 2 (R1 and R2), this is shown in graphed reaction functions curves where q1=R1(q2) gives one firm's optimal output in reaction to a given output (known output) for the competitor q2 firm. The vertical axis is R2(q1) while the horizontal axis is R1(q2). Equilibrium is where q1 and q2 intersect on the R2-R1 graph (see image).\nThe Lerner index uses exact price information, cost structure of a firm, or price elasticity of demand to measure market power. The level of market power for each firm is measured on the Lerner index by measuring price (P) to marginal cost (MC). When using price elasticity of demand, the Lerner index is the inverse of elasticity to maximized price. The formula is:\nL = P-MC = 1\n[Image from Wikipedia Commons and provided by Twisp, Bluemoose (Own work) (Public domain).]\na) The demand equation is:\nAverage cost=Marginal cost=30\nTo determine the Cournot-Nash equilibrium, the reaction function for each firm has to be calculated first.\nProfit for Firm 1=total revenue-total cost\nDifferentiating this profit function with respect to Q1, and setting the derivative equal to zero gives the reaction function for the first firm,\nBy symmetry, reaction function for the second firm,\nSubstituting the value of Q2,\nAnd also, `Q_2=$30`\nTo determine the price at profit maximization, Q1 and Q2 has to be substituted into the demand equation:\nPutting the values for price and quantity into the profit function,\n`P_2 ` is also equal to $900.\nb) The price is $60, marginal cost is $30\nSo, Lerner index `=(P-MC)/P=(60-30)/60=0.5`","Market Power: Monopoly and Monopsony\nA market in which buyers and sellers have all the information about product and it makes comparison of prices easy as they are identical; we call it as Perfectly Competitive Market. There are many buyers and many sellers in this market. There are no barriers to entry or exit in such market.\nMonopoly and Monopsony are equally opposite of Perfect competition. In this context, a Monopoly is a kind of market which has one seller but several buyers. A Monopsony can be said just opposite of monopoly, as in this kind of market there is many sellers but only one buyer. But Monopoly and Monopsony are related to each other.\nLet us deliberate the behavior of a Monopolist. A monopolist can be said a price maker. He decides the price of the good to be sold. He can change the price or quantity of the goods. It can be higher quantity at a low price in a very elastic market and lower quantity at a high price in a less elastic market. Another characteristic of monopolies is there is no need of advertising product to increase share in market. They use the channel of public relation and maintain good relationship with their buyers. There are no close substitutes of the product in monopoly kind of market. For example, providers of water, natural gas, telecommunications and electricity are granted rights to provide service through local government is a perfect example of monopoly. A monopolist should shut down when it becomes impossible to cover the variable cost. In such case, the demand curve is wholly below the average variable cost curve. Under these situations, average revenue would be less than average variable costs and this suggests the monopolist to shut down.\nPure monopoly is infrequent.In many markets, competition is only between few firms. Like there is a company which is a single source of a product with no close substitutes. The structure of such market is complex and difficult to interact among the firms. Strategies play a role in such monopoly and firms can charge higher price as they find it good moneymaking. To maintain pure monopoly, there must be barriers like legal barriers, control of resources, economies of scale, etc., for the competitors to enter the market.\nThe next type of market is to discuss is Monopsony. It is a type of market structure in which there are many sellers and one buyer interacts with them. Here, single buyer controls the market. Just like monopolist, a monopsony employer finds it profitable if prices are discriminated. It simply means paying different wages to different group of workers even if Maximum Retail Price is same. Monopsonies take different size and shapes, but commonly it takes place when a single employer controls the entire labor market. Technologies can be considered as a perfect example of Monopsony.\nBy considering how the choices are being made, we can validate the close relation between monopoly and monopsony. Pure monopsony is rare, a buyer’s monopsony is a situation in which buyer can ask for concessions from the seller. Sellers have no choice other than selling products to the buyer. These buyers have monopsony powers. We will discuss about monopsony power, also its measurement, and price effects.\nMonopolists do not think about their competitors, they hold an exceptional position. They don’t worry about who are decreasing their prices to sell products. If a monopolist wants to increase the price of the product, he can do so without thinking about the market’s share of the competitors. Being a sole producer a monopolist can control the output presented for sale.\nCharacteristics of a Monopolist-\nEntering the market of monopoly is restricted. There are three major barriers- Economic, deliberate and legal barriers. Addition to these barriers there is exit barrier. Barriers to exit means the condition of market in which it is difficult for the company to end its existence in market or to quit from market. A company will shut down if price decreases below minimum average variable costs.\nControlling the price by monopolists does not mean that they can charge any value for price to maximize profit. For this, the cost and characteristics must be examined or determined. To make a decision regarding price of products, knowledge of costs and demand must be known. The monopolist analyze the profit output maximized by profit through finding that quantity where marginal revenue equals marginal costs, then notice the market demand curve quantity to decide what market price resembles to that quantity.\nShifts in Demand\nThere is a rich bond between price and quantity supplied in competitive market. This is defined by supply curve. How much to produce at given price is what supply curve shows. There is no supply curve in monopoly because the decision of output depends on marginal cost and shape of demand curve.\nThus we can say that shifts in demand do not show the prices and quantities which agrees to supply curve. We can be clear in this by referring the following figure-\nThe upward movement of demand shows the shifting of market with new equilibrium. This will be in short run and might offer higher price along with the possibility of lower quantity. In monopoly market, the new market equilibrium will shift the market towards larger quantity of goods produced so that it can remain in good condition. We can see the example by looking at the above figures and both highlights the principle of demand curve. We can even see that the shifting of demand curve offers the new marginal curve and revenue curve of the firm.\nIn the above figure, the line MR2 gets intersected with marginal cost curve MR1 line. This is the actual reason of shifted results in the firm. Price might fall or rise and with this, the curve plotted above shifts.\nIn case, if these two curves are overlapped with each other and such that the larger quantity will be found, price might not be charged more. But the shift changes the values of price and quantity at the same time. For special cases, the above plotted graph shoes the difference between monopoly as well as competitive market. If the firm supplies several quantities of goods, in that case, the monopolist power will shift the market.\nA Rule Of Thumb for Pricing\nAs we know price and output must be decided keeping in mind marginal revenue should be equal to marginal cost, it is important to know that how manager of the firm could find correct price and output level? Restricted knowledge of average curve and marginal revenue curve by the managers create difficulties.\nMathematically, the relationship\nIt is the rule of thumb for pricing where (P – MC)/P indicates markup over marginal cost and negative Ed shows inverse of elasticity of demand.\nIt means if demand is elastic, this will be beneficial for monopolist. Remember that it is not possible for monopolist to produce output on the inelastic region of demand curve (the area where the value of demand is less than one in the absolute value).\nSuppose monopolist produce output at a point in the demand curve – 0.5, it is possible to acquire greater amount of profit. For this, theproduction should be less and selling of the item should be at higher cost price.Here, the shifting of demand curve towards the value more than one in the absolute value is possible. This means it satisfies markup rule of equation.\nIf we consider the marginal cost becomes zero (anyhow), the equation cannot be used directly for obtaining profit-maximizing price.Here, we should take the point at which elasticity of demand is equal to –1 to produce the output. So, in this case, the value of maximizing profit will be equal to maximizing revenue. It means the revenue gets maximized if the value of Ed = –1.\nThe Effect of Tax\nGenerally the amount of tax is less than the rise in market price per unit in competitive industry. Considering the fact, if burden of tax is shared by consumers and the producers, the effect of tax is different in case of monopoly. Under Monopoly, price rises more than the value of tax amount sometimes. Let us analyze the effect of tax in case of monopoly. It is simple to understand the effect. Let’s take tax as t dollars per unit, which monopolists pay to the government according to the units he sold. By this the firm’s marginal and average cost will increase by the tax amount i.e., t. if MC is the firm’s original marginal cost then its production decision can be explained as-\nMR = MC + t\nThe effect of tax on a monopolist can be explained by the following figure-\nWe can see the marginal cost curve is shifted by an amount of tax t, and new intersection formed. The figure shows Q0 and P0 as quantity and price respectively before the tax is levied, and Q1 and P1 are the quantity and price after the tax. The upward shifting of marginal cost curve gives a result of rise in price with smaller quantity. Sometimes price rise is less than the amount of tax, but in figure we can see price increases more than the tax amount. It can only happen in case of monopoly. It is not possible in competitive market as the connection between price and marginal cost rely on the demand elasticity.\nThe Multiplant Firm\nAs we know a firm makes profit by backgroundproductionwherever marginal revenue equals to marginal cost. The term Multiplant firm means production process takes place in more than one place whose operational costs can be differ from each other. Choosing production levels is same as it is in one plant firm. Consider a firm has more than one plant, say two plants. In this case, what should be the total output of the firm and how much of this output value should each of these plants yield? We can get the answer by these two steps-\nStep 1- The total output will then divided so that the value of marginal cost remains same in each of two plants. If we don’t divide the total output then the firm could decrease its prices and raising its profit by transferring production. Let’s take an example to clear the view; if marginal cost of 1st plant is higher than the 2nd, the firm could generate the similar level of results that too at a lower value just by producing less at 1st and more at 2nd plant.\nStep 2- As we know, the total output should be at a level, the marginal revenue will be equal to marginal cost. For example, consider that marginal costs are same, but marginal revenue beaten marginal cost at each plant. In such situation, the firm would prefer manufacturing more at both the plants since the revenue made from additional units and this would outstrip the price. As marginal costs kept same, and marginal revenue will be equal to marginal cost, we notice that profit gets maximized when the marginal revenue becomes equal to marginal cost.\n10.2 Monopoly Power\nPure monopoly can be said as a single supplier. Monopoly power is much widespread in such case. Monopolies are formed under following conditions-\nThe monopoly power can be maintained by maintain barriers to exit which includes, economies of large scale production, dropping of price too low in a demonstration of power and put pressure on the competitors, limit pricing, by ownership of scarce resources, high set up cost, high expenditure on advertising, maintaining brand loyalty, and by taking exclusive contracts to restrict the entry of other retailers.\nFor example, there are four firms that are producing toothbrushes. If these four firms produce a total of 20,000 units on an aggregate daily which gives the result to 5000, if they set the price of toothpaste to $1.50 then its demand curve will be obtained as inelastic. In this case, the factor will give the elasticity of demand as a decision to get the value of –1.5.\nIn case first firm is willing to lower the price and increase its sales, then we can see changes in the demand curve which leads to oppose the previous value of its market demand curve.\nWhen any of the firm decides to increase the price of toothpaste to reach $1.60, the demand curve will again shift and the numbers of consumers will be changed. It is likely that if the quality of the product does not change than its sales will be affected. Whatsoever the condition is, it is true that sales will never come to zero. Considering the competitors, the number of consumers they have varied from this firm. And there is a possibility that any other will also raise the prices to make the things a bit change.\nTaking the first case, if the firm has lowered the price by $0, it will set to $1.40. This is obvious that it increases the sale as well as market revenue without affecting it. But, there is no certainty whether this firm would capture the whole market or not. In this situation, the demand curve will depend on market demand and the existence of products of other firms. If the quality of the toothpaste is dissimilar, then the best with quality will lead the market. This tells the story of entirely competitive market.\nProduction, Price and Monopoly Power\nDetermination of elasticity of demand and market demand is not difficult when the firm’s product is in the market shows better output. They do research and find out the variation in demand so that their demand curve can be shifted to offer more profit.\nConsidering the figure (a) in which the Firm A knows how to shift its market as per the conditions and know the details of market demand curve. But the fact is, how Firm A will do production to earn profit? In this context, profit-maximization is a big factor which is related to marginal revenue as well as marginal cost of the firm.\nIn figure (b), we can see that 5000 units are produced and the prices are for $1.50. It indicates that this price has already exceeds marginal costs.The presence of monopoly power will be seen when this price becomes higher than the value of marginal cost. Suppose the power is quite less and have no potential to drive the market so the firm might drive away. Here two different questions arise that include- how monopoly power should be compared and why firms should have high monopoly power than its competitors? The answer is- to make a balance in the market so that they can stand there.\nMeasuring Monopoly Power\nThere is an important dissimilarity between competitive firm and those firms with monopoly power. For the competitive firm the price equals to the marginal cost. In case of monopoly power of any firm, the price will be exceeded to marginal cost. Thus, most of the time, firms changes their strategy and apply the law of thumb for valuing. This is how the existence of these firms is there and holds better revenue.\nThe transformation between price & marginal cost is divided by price. This value can also be represented mathematically to show its present scenario. Taking the help of Lerner Index, the value will always show below one and above zero. In case, the value of Lerner Index is large, then it is possible to have higher degree of monopoly control. When these facts are calculated and plotted in graphs, it can also be considered as the elasticity of demand. Remember, in this case the value will be for elasticity of demand for firm. So the elasticity of market demand is not considered.\nWe have previously seen the example of toothpaste. If we consider the elasticity of demand and degree of monopoly power, the later might not produce any higher amount of profits. But average cost with respect to the price changes can offer this higher value of profit. Comparing Firm A and Firm B, the higher value of monopoly with Firm A. In this case, Firm B will earn lower amount of profit because of the higher average costs. And the amount of profit to Firm A will remain greater than Firm B still it is in monopoly power.\nThe Rule Of Thumb for Pricing\nFor determining the value of price changes to markup over marginal cost, the equation will be given by-\nThe above relationship helps in calculating the value of rule of thumb when the firm has monopoly power. In this case, Ed refers elasticity of demand. No one should confuse about elasticity of market demand which was previously used. It reflects the story how the competitors of the market will act so that the unit sale can be increased at every point of time by just making 1% change in price. Every firm follows similar kind of strategies.\nLinks of Previous Main Topic:-\nLinks of Next Microeconomics Topics:-"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:bdf68058-4d72-49a7-a14a-335b6cf24bb4>","<urn:uuid:4f426988-4b4d-4e33-93e2-9a062589f67d>"],"error":null}
{"question":"When comparing granite to urbanite for wall construction, what are the key considerations regarding structural integrity and aesthetic appearance?","answer":"Granite and urbanite have distinct characteristics for wall construction. Granite is noted for its incredible strength and density, making it perfect for massive structural work like walls and monuments, while also offering mineral-rich colors and natural patterns for ornamental value. Urbanite walls require specific construction techniques for structural integrity, such as lapping blocks so joints don't align vertically, and can be enhanced aesthetically by chiseling exposed faces and incorporating varied thicknesses. Both materials can create long-lasting walls, but granite provides more consistent appearance with little variation between pieces, while urbanite's varying colors and textures require more careful selection and arrangement for aesthetic appeal.","context":["If you’re wanting to build beautiful stone walls for your landscape – urbanite rocks! “Urbanite,” better known as waste concrete, is plentiful; lasts pretty much forever; is easy to work with and in most cases … it’s free! Surprisingly, few people take advantage of this great material.\nUrbanite replaces our need for stone or new concrete blocks – the primary materials used for landscape walls. Stone requires mining and often has to be transported great distances. Concrete is an energy hog. Its fabrication accounts for 5% of our global emissions. Reducing our need for new material and making good use of what we have makes ecological sense. If you’re concerned there may not be enough of this for your needs, don’t be. Our rapidly changing environments create more of the stuff every year. It’s rock-bottom price should give you a pretty good idea of the ratio of supply to demand.\nWe’ve seen some installations of this material that were … ahem… aesthetically challenged, so we decided to collaborate with Hector Santos, a professional stone mason and sculptor. We wanted to bypass the learning curve and see what was really possible. It was a great decision. Hector brought a wealth of knowledge and stone craft to the process and patiently shared how those techniques could be adapted to urbanite for a beautiful result.\nHere’s an account of our journey and what we learned:\nWe stopped by the local landscape yard to pick up some materials. As you can see – we had plenty to choose from. This pile is about half an acre in size and more kept showing up every day. The yard owners were extremely generous and allowed us to take as much as we wanted.\nMost waste concrete is from concrete slabs and measures about 3″-5″ thick. We sought out material that was relatively uniform (flat on both sides), free of reinforcing and manageable for 1-2 people to transport. We tried to bring home a variety of thicknesses (to add interest to the wall) and were lucky enough to find some scrap slate shingles (good for shims) and some round rocks – which added some artistic interest here and there.\nIn all it took us about eight trips. With the supply yard close by, that allowed us to use up each load as we went and end the project with very little left over.\nWe decided to build two sets of walls. The first – a carefully dressed and tapered barrier between the Cargo Shed and the parking area. Its purpose: to enclose a pair of rain garden which slow and filter the road runoff prior to releasing it into a bioswale. The second set of walls would be conventional retaining walls for the landscape beds. These were much easier to build, so for the purpose of this post, we’re going to focus on the free-standing elements.\nTo start, we excavated a shallow footing (ideally about 12″ deep) and filled it with crushed rock (free of binder). Eliminating the binder allows the footing to drain water easily. Hector prefers a heavier ballast rock for this application, but we found the 1-1/4″ rock to work quite well. The footing needs to extend beyond the footprint of the wall (for stability).\nWe utilized a rotary laser mounted to a tripod for uniform leveling of the wall. This is an important detail as having a level top really helps to give the wall a finished appearance.\nElsewhere on our property, we’ve used recycled gin bottles as landscape lights. Carrying the theme one step further, we integrated them into the structure of the wall at even intervals. The square nature of the bottle compliments the blocky urbanite and the aqua color adds a little interest. At night, these are illuminated to a soft glow by low voltage LED lamps.\nIn this photo, you can see the rebar stakes that Hector used for consistent alignment of the sloped wall. The strings are moved up as the wall courses higher. Round stones are added here and there for whimsy and artistic value. When needed, they can be cut or flattened with a diamond blade on a 4″ grinder.\nBlocks are laid out to lap onto other blocks below i.e. joints do not align vertically through the wall. For a dry-stacked wall, this ensures structural integrity and reduces settling. Block heights are randomized to avoid a coursed or “layer cake” look. Mortar (Type “S”) was used only where round rocks were used, to stabilize the top cap, or where the blocks weren’t able to penetrate at least 8″ into the wall interior. The bottles are laid loose in the wall in fitted slots – so that they can be removed for light bulb access.\nPerhaps the most important step in making a professional looking wall is to take the time to shape the blocks. This is where Hector’s experience really came through. Most people rely on fitting stones together, but for a tightly jointed wall, shaping is necessary. It’s actually not that hard and can be done with just a few tools:\nTo trim a block, scribe a line with a diamond bladed grinder. The cut relieves the surface tension and helps the block to break along that edge. This can be done to the top and bottom surfaces for better control. Then, using a cold chisel and a hammer, whack along the kerf until the block breaks. It takes some practice. The deeper the kerf, the more likely the block is to break along that joint.\nTo give the concrete a more uniform appearance (resembling stone), we chiseled the exposed face of the smoother blocks. That may sound hard, but it actually goes pretty fast. We would cut a shallow kerf about 3/8″ from the face of the block on the top and then spall off the face. We elected not to do this for the landscape walls and it still looked OK, but this attention to detail really results in a higher quality finish.\nAnother technique we employed was splitting the larger pieces into smaller chunks. This was done with “feathers and wedges.” Basically, you drill holes (with a roto hammer) evenly along a slot cut into the top surface. The holes are about half the depth of the material. You then insert steel wedges and L-shaped “feathers” and pound away. The goal is to drive the wedges in at the same rate so that even pressure results until … presto the block snaps in two. This whole process takes about five minutes and can quickly turn a large unwieldy slab into smaller useful pieces.\nIf you’re feeling lucky and want to try a faster method, you can try just cutting a deep groove on the top and bottom of a block and whacking the slot with a cold chisel. If the combined cuts are about 2/3 of the block depth, this tends to work pretty well. Less than that and you’ll need some luck.\nIf you do this professionally, or just happen to love tools, then a concrete wet-saw makes quick work of block shaping. Here’s a picture with Hector unleashing its might on a corner block. It should go without saying that safety gear is essential.\nIn our case, we wanted an architectural wall reminiscent of the CCC era masons. Their work is still in service in our local parks and is testament to the longevity of this type of construction. Toward that end, we felt it was worth a little more effort for something that will be around a long … long time. Hector likes to say that “stone is forever” … and in the context of our lifetimes, that’s a very true statement.\nHere’s a picture of Hector and Matthew sitting atop the finished wall. Optimal sitting height is about 18 inches. While the ground slopes along the wall length, it averages about that height.\nNatural color variation in the urbanite adds interest. Some of our material must have come from a boat ramp as barnacles have encrusted the surface. It just blends in … until you study it closely and then you’re like “Hey Wait a Minute!?”\nI love it when architecture reveals more to us the deeper we look.\nHere’s a few parting images. The first shows the whole assembly in the early morning. For the rain garden, Sarah complimented the native reeds with dogwood, iris, juncus, camas lily and gunnera. The background wall steps slightly where the higher parking lot wall meets the lower path wall. Visually, the two flow into one another.\nThe latter image shows the landscape wall along the path. Here, the back side of the urbanite is buried into the soil, so uneven pieces are easy to fit into the wall assembly. Gravel is backfilled behind the blocks for stability and drainage.\nIf you decide to use urbanite on your next project, send us a photo … we would love to see what you come up with. If you’re nearby and want a skilled artist to help you realize your vision, give Hector a call. He’s currently plying his skills in Vermont, but is willing to make the journey west during the long cold New England winters.","Choosing the right stone... from raw material to the finishing touches.\nType, finish and color are three key characteristics to consider when purchasing natural stone for your architectural project. Properties such as durability and being cool to the touch make our stone highly attractive options for installation both inside and out. Here are some basics to know about each category as you research the perfect natural stone for your project. Please contact us at any time with additional questions. Our design consultants can guide you to the ideal stone selection.\nWhat is Natural Stone?\n\"Natural Stone\" refers to a number of products quarried from the earth, used over many thousands of years as building materials and decorative enhancements. These products include Granite, Marble, Limestone, Travertine, Slate, Quartzite, Sandstone, Adoquin, Onyx, and others. They are more than just rocks – natural stone is hand selected from the best, most consistent sources for permanence and beauty. Natural stone products differ in composition, color, and texture even among pieces from the same source. This is usually considered a benefit, lending itself to one-of-a-kind designs and distinctive, dramatic applications.\nNatural stone can be used in both commercial and residential settings, within exterior and interior applications. Outdoor uses might include wall cladding, benches, columns and statuary objects. Indoor use of stone could include floors, tabletops, stairs and decorative stonework. For example, luxurious bathrooms covered in tile can create an inviting spa feeling.\nThe muted, soft tones of limestone are perfect for today's casual and comfortable lifestyles. With hues of soft beige, tan and sometimes orange, and available in a variety of finishes, limestone products are ideal for many interior applications such as bathrooms, fireplaces, and countertops. Outside, limestone is popular on patios, walkways, and around pools. In the hottest climates, limestone is ideal because many types are heat resistant and cool to walk on with bare feet.\nFor maintenance-free elegance and resilience, granite is unmatched. Its incredible strength and density makes granite the perfect choice for massive structural work – walls, monuments and supports. Though it is the hardest of structural stones, the amazing variety of mineral-rich colors and natural patterns gives it ornamental value, as well. Granite products are ideal for flooring, countertops, vanities and decorative exterior applications.\nPrized for its timeless style, texture and high-gloss polish, along with a rich palette of beautiful colors, marble has a place anywhere in the home. Available in solids or dramatic veined varieties, marble may be carved or sculpted in many ways, making it one of the most versatile decorative stones. Often seen as a symbol of luxury, modern technology brings beautiful marble products even to budget-conscious homeowners.\nAlso referred to as Verde Antique, Serpentine Marble is a dramatic green color with strong white veining.\nFormed over thousands of years of sedimentary deposit and compression, slate splits naturally into beautifully textured layers. The various shades of slate products – brown, yellow, dark gray, pink, lavender and more – may even occur within the same piece of stone. Durable and stain-resistant, slate products are often used for flooring, cladding, and landscaping.\nShimmering and sparkling with tiny quartz crystals, Quartz is a rock similar to slate with a medium grained texture and incredible durability. Differing mineral content creates many color variations, from the sedate white, gray or beige to more adventurous shades of purple and pink. Quartzite is widely used for wall veneers and decorative tiles. A naturally non-skid texture makes it an exceptional candidate for flooring indoors and out, including areas with heavy traffic and exposure to the elements.\nValued for its banded, pitted “distressed” appearance, travertine adds rich, distinctive character to a variety of indoor and outdoor building projects. Its patterns and veining effects were formed by hot spring waters percolating through underground limestone. When used for interior applications, travertine is often filled with cement, grout or resin and sealed to create a smooth, stain-resistant surface.\nWith a uniform texture, an appealing variety of colors and finishes, and weather resistant durability properties, it's easy to see why sandstone products have been used for thousands of years for walls, floors, and pavers. As with other types of rock, its variations result from differing mineral composition – there's a sandstone product to match any décor.\nOften used for home renovations and popular for floors, kitchen countertops, vanity tops, bathrooms, patios, walkways, fireplaces, facades, wall cladding, and garden landscaping.\nHow many different colors of stones are available?\nNatural stone is available in a nearly endless variation of colors, patterns and veining. These may include shades of beige, gray, gold, red, pink, blue, and green. The colors of the orange limestone are rich, colorful, textured and diverse.\nWhat criteria do I use to select stone color?\nThe criteria for selecting stone color will depend on the application. Color choice can make a room appear larger or smaller, formal or warm and inviting.\nConsider the following characteristics:\nLighter colors tend to make a smaller room seem larger.\nDark colors tend to make a room more intimate and cozy.\nSolid colors, smooth, and polished tiles show more dirt and require more maintenance.\nOrange, chilies, paprika and ochre are nature-inspired and evoke sociability.\nDramatic patterns can help highlight and accent portions of the room, including architectural features.\nHow much variation can I expect in the same sample of stone?\nEach stone is unique, and some types of stone display more variation between the pieces than others. Granites show little variation in color, but may have differing patterns and grain density. Slates tend to show a wide variation in color, even within the same pallet of stone.\nWhat are the neutral stone colors?\nThe neutral tones found in natural stone include beige, tan, and cream. Most people enjoy these colors, and find that they complement all types of furniture and fixtures.\nWhat are the accent stone colors?\nAny color may become an accent color, contrasting with the main color in the room. For example, a white stone border can accent a black floor.\nEdges And Finishes\nVarious edge finishes include chipped, pillowed, bull-nosed, beveled, chamfered, and others. Why are some finishes preferred for a particular application? There are three important reasons for choosing one finish over another in certain applications:\n1. Safety. When choosing flooring, it's important to choose a slip-resistant surface for outdoor applications where floor may become wet. Highly polished surfaces should only be used for interior floors. Also, highly clefted, uneven surfaces may cause a tripping hazard when used for flooring.\n2. Maintenance. Unlike wood or carpeting, natural stone is much more resistant to dirt and wear. Easy to clean and polish, stone is the ideal option for areas subjected to heavy everyday use, especially as floors that support high foot traffic or in homes with kids and pets!\n3. Usability. The application should be consistent with the type of finish selected. For example, a rough finish, such as brushed, might not be a suitable choice for countertops, due to the potential difficulty in cleaning it. Clefted material should not be used for tabletops, because it would present an uneven surface. We can expertly guide you to select the best stone and finish for your particular project.\nIs a polished floor recommended for a commercial application?\nPolished flooring may be used in a commercial application if the floor is unlikely to become wet and slippery. It is advisable to have the floor material professionally tested prior to installation. Sealers are available that can improve the slip resistance of the surface without removing its gloss.\nWhy is a honed finish so popular for homes?\nA honed finish creates a soft, matte, appearance that is more suited to casual, comfortable environments than a formal, polished surface.\nWhy are travertines filled or unfilled?\nTravertine is characterized by the presence of many tiny holes, caused by trapped gas bubbles during its formation. This creates a porous, uneven surface, which is referred to as Unfilled Travertine. When these cavities are filled with cement or another material, the result is called Filled Travertine and may be honed and polished to provide a uniform surface similar to marble.\nIs cleft finished slate a tripping hazard?\nSlate with a heavily cleft finish may create a tripping hazard. Most slates are lightly clefted and suitable for flooring in kitchens, bathrooms and on patios. A pallet of slate may contain a few pieces with heavy clefting, but these are generally not used for the flooring installation.\nWhy can some finishes not be used outside?\nPolished stone surfaces may become slippery when wet, and tend to lose their shine in a short time due to weathering.\nWhat is thermal or flame finish?\nThe thermal, or flamed, finish is achieved by subjecting the stone to the high-temperature flame of a torch. This burns off most of the carbon content, creating textured quartzites with gentle coloration. Only granite is tough enough to withstand this treatment, and the piece must be fairly thick or it may crack or break under heat and pressure. This is a popular finish for commercial wall and flooring applications.\nWhat is stone tumbling?\nTumbling stones in a solution of sand, water and mild acid creates an old world, weathered look. Typically sizes of 5/8\" X 5/8\" to 6\"X 6\" and sometimes even 8\"X 8\" are true tumbled pieces. Larger sizes are given a \"Tumbled\" finish, manually. Very small pieces like 5/8\" X 5/8\" & 1\" X 1\" are usually, mounted on 12\" X 12\" meshes for ease of installation. Most commonly used size is 4\" X 4\" and it is used in straight & diamond patterns, or as accent pieces. When mixing different size tumbled pieces, the look may vary.\nIs the sizing always exact in tumbled material?\nTumbled stone pieces are intended to produce a rustic, old-world look. Therefore, they are not created with precision and may vary slightly in size. Some pieces may have large chips on the edges or may have a corner missing. Care must be taken to ensure an even surface when installing tumbled stone flooring."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"code-switched"},{"categorization_name":"question_formulation","category_name":"natural_inference"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:de040f6a-71c2-4ccc-86b6-5be419af4dac>","<urn:uuid:9c0fac97-112c-4479-aa91-e6c2e6cb779c>"],"error":null}
{"question":"How do service dogs help veterans with PTSD manage their anxiety and stress in public spaces?","answer":"Service dogs help veterans with PTSD manage anxiety and stress in public spaces in several ways. They alert veterans when cars backfire or when people are approaching around corners, helping them focus on the dog rather than potential triggers that could cause increased anxieties. The dogs can also alert their handler to an impending panic attack, bring required medication, or guide them to a safe place outside if in a crowded area. Additionally, service dogs are trained to keep people from getting too close, allowing veterans to go into public while the dog maintains watchful vigilance, reducing the need for the veteran to be hypervigilant.","context":["Why a Service DogPositive Effects Every Single Day\nDISABILITIES AND SERVICE DOGS: Big Paws Canine Foundation provides service dogs to veterans and former first responders suffering from Post-Traumatic Stress Disorder (PTSD), Traumatic Brain Injuries (TBI), and respiratory, and mobility disabilities. While there have been several studies done on mobility trained service dogs, and they are more common to the public, PTSD and TBI service dogs have a much different view from not only the public, but the medical world as well. According to the Dialogues in Clinical Neuroscience1, PTSD is not just a psychological disability it is actually an injury to the brain. Studies have shown people with PTSD have alterations in the brain including the amygdala, hippocampus, and prefrontal cortex as well as neurochemical stress response systems. This causes heightened startled responses, memory loss, numbing/avoidance, and sleep disturbance. It also causes higher depression rates. Oxytocin helps to release the brain and body’s response to social and environmental challenges by reducing stress. According to Psychiatric Annals2, dogs offer a safe, effective, and relatively inexpensive way to increase a brain’s oxytocin in a person suffering from PTSD. A service dog must do more than just help reduce stress, it has to provide specific tasks to be within the regulation of the Americans with Disabilities Act. Warrior Canine Connection (WCC) has been providing soldiers with PTSD and TBIs the ability to train service dogs for other soldiers that have physical impairments as mobility training dogs. Some of the research shown proves to be effective in getting soldiers with PTSD back into a normal life while with the service dog in training. Many soldiers suffering from PTSD will isolate themselves. Part of the service dog training is making sure the dogs are exposed to several different experiences in the public. This requires the soldier to be in public with the dog and when the dog alerts the soldier to when a car backfires or when people are coming around a corner they focus more on the dog than the potential trigger that could cause increased anxieties. This helps the soldier to focus on other things than racing/intrusive thoughts, etc. It also helps the soldier to decrease their startle reflex which can cause severe flashbacks and panic attacks. Dogs are also very sensitive to chemical changes in a person’s body. Service dogs can alert a person to a panic attack before they happen, bring them required medication, or get them to a safe place usually outside if in a crowded area. This is very similar to a diabetes alert service dog or any other medical service dog. Service dogs also learn to keep people from getting too close so they are able to go into public and lead normal lives while the service dog helps to keep the watchful eye so the soldier doesn’t have to be hyper vigilant. They are also trained for the specific needs of each person. Many soldiers coming back have respiratory3 issues and may have to wear CPAPs or BiPAPs at night. Service dogs can be trained to alert the person to leaking masks or wake a person from nightmares to keep them from going into a flashback. Many people suffering from PTSD and/or TBIs have found service dogs get them back into society and improve their lives considerably. It not only provides a companion, but also helps give the person the ability to de-escalate issues attributed to PTSD and TBIs quickly and lets them carry on with their daily activities instead of isolating themselves making for a more productive community as a whole.\n1 Bremner, MD, J Douglas.. (2006, Dec.). In Dialogues in Clinical Neuroscience. (chap. Traumatic stress: effects on the brain) Retrieved Nov. 23, 2014, from http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3181836\n2 Yount, MS, LSW, Rick, and Elspeth. Ritchie, MD, MPH, and Matthew. St. Laurent, MS, OTR, and Perry. Chumley, DVM, MPH, and Meg. Daley Olmert. (2013). The Role of Service Dog Training in the Treatment of Combat-Related PTSD. Psychiatric Annals, 43 (6), PP 292-295.\n3 VonFeldt, Kalie, MS, PA-C. (2012, May 3). Lung Disease Following deployment in Iraq and Afganistan. RT for Decision Makers in Respiratory Care.Retrieved Nov 26, 2014, from http://www.rtmagazine.com/2012/05/lung-disease-following-deployment-in-iraq-and-afghanistan/ .\nMEASUREMENT OF SUCCESS: We measure our progress and outcomes of our program by the personal success stories of each and every one of our service dog & companion dog teams. We will also have regular reviews from each of the recipients and members to ensure each team is training for what is specifically needed as not all teams are the same. These reviews and success stories will not only let us know how to better our program but let us know how we have helped in the recipient’s life.\nWe will use questionnaires and regular reviews to measure our outcomes. This is the best way to see if we are providing the best possible service we can for each service/companion dog team.\nWe will use the application from each initial recipient to see how life is before the service dog is received. We also interview and get to know each of our teams to ensure each team is well fitted for each other and training is going in the correct direction. Along with these regular reviews, we will ask each recipient to voluntarily fill out a questionnaire to make sure they feel they are benefiting from a service dog.\nSo far we have had recipients go from never going out to restaurants or movies, to being able to attend public events and become part of our speaking team. Imagine not being able to shop at a large grocery store, so instead all your groceries are bought at a local convenience store. There have been recipients that have spent years avoiding crowds and public places such as grocery stores who are now participating regularly in events such as Festivals, Parades, and Bike Rallies. It is these types of success stories that we continue to strive for but also expect to continue to see from each and every one of our recipients.\nWe see the positive effects every single day we train with each of the teams. Even the smallest of victories to you and me may be a huge step of freedom for these teams. Our recipients have seen some dark places and we have personally experienced these dogs saving lives. This doesn’t only affect the recipient, but our community. It is our community that is directly benefiting from service dog teams. We have recipients starting businesses because they found a passion that drives them. What these injuries have taken, these service dogs have given back and more."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"multilingual_categorization","category_name":"cross-lingual-multisentence"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_intent","category_name":"comparison"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:189feb20-6fee-4a03-bba3-669b0bdf5fac>"],"error":null}
{"question":"What are the traditional aging requirements for Chianti Riserva DOCG and Amarone Riserva DOCG wines, and how do their production methods differ?","answer":"For Chianti Riserva DOCG, wines must be aged for 18 months, with 6 of those months in wood. In contrast, Amarone Riserva DOCG requires a minimum aging period of 4 years following the vintage. Additionally, their production methods are quite different - while Chianti is made through traditional vinification, Amarone requires the specialized apassimento method where grapes are dried until they lose 40% of their moisture, followed by a slow fermentation period of 35-50 days. This drying process can take up to 120 days before the grapes are pressed into wine.","context":["It seems to me that with the exception of the Chianti Classico sub-zone, Chianti DOCG has an identity crisis. The Chianti Classico sub-zone is the “original” zone between Florence and Siena. It has its own Consortium and since 2005, when the government seal is put on a bottle it includes the Gallo Nero (black rooster) symbol. The Classico Consortium seems to want to distant itself from the rest of Chianti.\nThe other Chianti sub-zones joined together to a formed their own Consortium, called IL Consorzio Del Chianti Putto. Its symbol was a cherub draped in grapes. I say “was” because IL Consorzio Del Chianti Putto does not exist anymore nor does its symbol.\nWhen I was invited to attend a seminar and tasting by the Consorzio Vino Chianti, I was very interested in attending. How was this “new” Consortium going to promote Chianti and make it less confusing for the consumer? So many sub-zones, so many different grapes, the rules changing too often (adding new sub-zones, changing the grapes that can be used and the percentage of grapes). With 2,650 members in the Consortium, they have a big job in front of them.\nThe panel for the seminar was made up of Giovanni Busi, president of the Consorzio and owner of the Travignoli winery, Nicola Marzovilla, Giovanni’s importer and translator, Laura De Pasquale from Palm Bay international and wine writer Bill Marsano. The moderator was Robin Kelly O’Connor of Christie’s fine wine auctions.\nAfter the introduction and some background information, Mr. O’Connor asked Mr. Busi to speak about Chianti and the Consorzio. Mr Busi began by speaking about the Chianti sub-zones that were members of the Consortium.\nThe Chianti production zone consists of areas which are determined by Italian law in the provinces of Arezzo, Florence, Pisa, Pistoia, Prato and Siena. Giovanni said that he viewed the whole area as one large “Chianti Valley” characterized by hills with large terraces and valleys crossed by rivers.\nThe wine can just have Chianti on the label or have one of the seven designated zones: Colli Aretini, Colli Fiorentini, Colli Senesi, Colli Pisane, Montalbano, Rufina, Montespertoli. In addition there is the Colli Dell’Etruria Centrale as well as the return of the Superiore classification.\nThe Colli Dell’Etruria Centrale area is everything that has been left out of the other areas and at the same time included in them-I think? The designation is positioned alongside the Chianti DOCG and permits the production in the same area of wines of a different quality from Chianti, with red wines being joined by white, rose, novella and Vin Santo del Chianti.\nChianti can be 70-100% Sangiovese, a maximum of 10 white grapes (Malvasia and Trebbiano) and 15% of authorized red grapes such as Cabernet, Merlot and Syrah.\nChianti Superiorecan be produced in all of the Chianti sub-zones with the exception f Chianti Classico. Producers in these other sub-zones can make a Superiore but it cannot have the name of the sub-zone on the label. Superiore means that it has higher quality standards like lower yields and higher alcohol. It can be 75-100% Sangiovese, a max. of 10% Canaiolo, and 20% of other authorized grapes such as Cabernet, Merlot, Syrah etc.\nI asked Giovanni if the “new” Consorzio had a symbol and he said that it did not have one and that the old symbol of the Chianti Putto was a thing of the past.\nOne of the subjects that came up was the blend used to make Chianti. Of the wines we tasted most of the panelists seemed to favor the wines that included native grapes and not international ones. Giovanni went as far as to say that Chianti should be made from 100% Sangiovese. He believes that when the Sangiovese 2000 project was completed they were able to single out the best Sangiovese clones. These clones were better and healthier than those used in the past and therefore Sangiovese did not need to be part of a blend but could stand on its own.\nI never understand why Chianti in straw-covered bottles is always mentioned. People seem to believe that 40 years ago Chianti only came in this type of bottle, but this is not true. Recently I had a 1964 Villa Antinori and a 1958 Ruffino Riserva Ducale Gold Label and both were in Bordeaux- type bottles. The Ruffino was not a Chianti Classico –the label just said Chianti. All the Chianti I brought 40 years ago was always in a Bordeaux type bottle.\nIt was mentioned that Chianti in the past was made using the “governo method” (10% of the grapes, usually Canaiolo, were dried) and because of this it would not age and did not make a good wine. I disagreed. The 1947 and 1958 Ruffino Gold Label were made with the governo method as were a number of other old wines which are still drinking today. One of the reasons it is no longer done was that it was too expensive and “old fashioned”. Giovanni said that the new clones of Sangiovese that they are using now are so much better that there is really no need to use the governo method.\nAll of the wines were Riservas from the 2007 vintage. 2007 was a very good year in Tuscany right after 2001 and 2004. The number of bottles produced by each producer was very low, ranging from 3,000 to 20,000 bottles. If I understood Giovanni correctly the Riserva has to be aged for 18 months, and 6 of the months in wood. The price of the wines because they have the sub-zone on the label and are also Riservas are more expensive than a wine with just Chianti on the label, would be between $20 and $30. The only retail price that we knew was the Travignoli at $28 because the importer was on the panel.\nI agreed with the panel that the best wines were those made from with the local grapes. Some of the wines were aged in cement tanks, which might be making a comeback.\nChianti DCOG Riserva 2007– Az.Agr. Corbinelli The vineyards are located in the Certaldo/Montespertoli area. The wine is a minimum of 80% Sangiovese and other approved red grapes. Fermentation is on the skin for fifteen days. The wine is aged for 12 months in cement tanks and for three months in bottle before release. For this wine there is no wood aging mentioned and the total aging is 15 months-3 months less than the law allows according to Giovanni. One panel member said that the producer must have left out the three months in wood on the tasting sheet. Is it 3 months in wood or 6 months in wood- this was not made clear to me.\nChianti Colli Fiorentini “Villa Marcialla” DOCG Riserva 2007– Fattorie Giannozza The vineyards are in Marcialli and the wine is 90% Sangiovese and 10% Merlot. Fermentation takes place for 3/8 days. Maceration for about 15 days is stainless steel tanks. The wine is aged in big oak barrels (botti) for 26 months and 6 months in bottle before release.\nChianti “Ugo Bing” DOCG Riserva 2007– Fattoria di Fiano The vineyards are in Certaldo, Loc. Fiano and are between 200/300 mt above sea level with a South-East/North-East exposure. The grapes are Sangiovese,Canaiolo, Merlot, Colorino and Syrah. Traditional fermentation with pumping over and delestage – 7/9 days. The wine is aged in 27hl cement vats and barrels.\nChianti “Cignozza” DOCG Riserva 2007- AZ, AGR. La Cignozza di Roberto Del Bruno. Location of Vineyards, Chianciano. 80% Sangiovese and 20% Canaiolo. They only produce Riserva during the best vintages. Fermentation takes place in stainless steel tanks for about 12 days with three pump-overs a day. Because of the density, the pump over is then substituted by the delestage (empting and refilling the tank). The juice is then left to settle in stainless steel tanks. After malolatic fermentation 50% of the wines is aged in tonneaux barrels to mature between January and February and the rest in large oak barrels for 24 months. It remains in the bottle for 5 months and is then released.\nChianti “Vigna La Quercia” Colli Fiorentini DOCG Riserva 2007– AZ. AGR. Castelvecchio. Location of the vineyards San Casciano Val di Pesa. The wine is 90% Sangiovese and 10% Cabernet Sauvignon. Maceration for 48 hours and fermentation at controlled temperature for 15 days. The wine is aged in oak barriques for 12 months and another 12 months in bottle before release.\nChianti Colli Fiorentini DOCG Riserva 2007– Castello di Poppiano Guiccardini. Location of vineyards, Montespertoli. 75 % Sangiovese, 20% Melo Cabernet and 5% Canaiolo. Fermentation in stainless steel vats and skin contact for 18 days. The wine is aged for 18/24 in oak barrels and three months in bottle before release.\nChianti Rufina “Del Don” DOCG Riserva 2007 Ag. Agr. Colognole. Location of vineyards Colognole (Pontesieve) 100% Sangiovese. There is skin contact for 12/15 days with frequent punching down. 50% is aged in Slovenian and French oak casks 20-30 hl and the rest in Allier tonneau of 500lt. It is aged 18 months in bottle before release.\nChianti Rufina “Tegolaia” DOCG Riserva 2007– Travignoli Di Conte G. Busi SRL Location of the vineyards, Pelago 100% Sangiovese. Fermentation in stainless steel for 20 days. The wine is aged in oak barrels of 2,500 liters for 18 months and for 8 months in bottle before release.","Amarone wine or as it’s officially named, Amarone della Valpolicella, is one of those wines that you buy and sit on and pray your marriage stays together long enough so that you can drink it on your 20th anniversary. It’s one of those holy-jesus-I-may-now-die-complete wines that, if you’re lucky, you can pick up for around $100. No, Amarone della Valpolicella is not cheap, but it shouldn’t be, it’s just too difficult to make–and too scarce.\nLet’s take a detailed look into what Amarone wine is all about and why it’s special, from a taste profile of great Amarone to its defining features so you can find great wines on your own. This is an advanced guide, so open up a bottle of Ripasso and start sipping!\nGuide to Amarone Wine\nThe Taste of Amarone Wine\nExpect bold aromas of cherry liqueur, black fig, carob, cinnamon and plum sauce along with subtle notes of green peppercorn, chocolate and crushed gravel dust. Sound intriguing? On the palate Amarone wines often have medium-plus to high acidity balanced with high alcohol and flavors of black cherry, brown sugar and chocolate. By the way, the older the wine the more it will offer flavors of brown sugar, molasses and fig. What might surprise you about this wine is the presence of a touch of natural residual sugar (RS) in the wine, usually around 3–7 g/L (or about a 1/4 teaspoon per serving). The RS helps compliment the wine’s natural high acidity and adds to its boldness–if you didn’t know Amarone had residual sugar, you’d think it was dry.\nThe Styles of Amarone della Valpolicella\nTime for a quick history lesson: In 1963 the Italian government adopted a system of quality assurance labels for its food products, especially wines and cheeses. The labels rate how authentic and regional the methods of a food’s production are, and increase in strictness from IGT, to DOC, to DOCG. Only a few wines get to become DOCGs (Denominazione di Origine Controllata e Garantita), and Amarone della Valpolicella officially became one of them in 1968. With the designation came many rules about planting, vine production and vineyard location; but more important to us is the production method called apassimento, and the styles of Amarone and Amarone Riserva. You can read more about wine designations here.\nAmarone vs. Amarone Riserva\nThe major difference between Amarone “normale” and Amarone Riserva is time. Amarone is aged 2 years following the vintage, whereas Amarone Riserva is required to age 4 years. Now, you’ll find that in reality great producers tend to age the wine longer than the minimums and release when they believe it to be ready. This is good considering that some Amarone wines should really continue to age for 10 or 15 years longer to develop those keen flavors of fig, carob and mexican chocolate. So, “the older the better” tends to reign true with this particular wine. There is one thing you should really pay attention to when picking an Amarone wine, and it’s the methodology used to make them.\nThe Apassimento Method and Traditional vs. Modern Winemaking\nCorvina grapes are laid out in drying lofts where they will lose 40% of their moisture. Image courtesy of Bertani\nTechnically, there is only one way to make Amarone wine:\n- pick grapes\n- dry grapes until there is 40% less liquid (called apassimento and can take as long as 120 days)\n- slowly press dried grapes\n- slowly ferment grapes into wine over a period of 35–50 days (this is a long time for wine!)\nHowever, due to modern technology two distinct styles have emerged. There are those who practice the traditional method of naturally drying their grapes and using neutral oak or chestnut barrels to age them and there are those who use a modern method of quickly drying grapes using temperature and humidity-controlled rooms and aging their wines in new oak barrels. Both methods can make excellent tasting wines but they will taste a bit different on first release and also tend to age differently.\nAmarone della Valpolicella made in the traditional method tend to maintain their acidity longer and, thus, will also potentially age quite a bit longer too. In taste trials it appeared that traditional method Amarone could easily last 40 years! As great as this is, these wines also take a bit longer to come around, meaning you’ll want to be sure to hold them for around 20 years to really let the wine shine. It’s common to see producers practicing the traditional technique to only use the regional grapes of Corvina, Corvinone and Rondinella in the blend. In terms of flavors on release, tasting notes for this style often have flavors of red cherry, cinnamon and green peppercorn. If you drink them sooner (and let’s be honest, this happens) be sure to decant them for a couple of hours and they’ll still be awesome.\nExamples of traditional producers\nAmarone della Valpolicella made in the modern method tend to be quite a bit bolder upon release because of the help of new oak aging which adds flavors of chocolate, molasses and vanilla along with cherry liqueur. It’s also more common to see non-indigenous varieties blended into the modern-styled wines. Legally, it can be up to 25% of other grapes including Cabernet Sauvignon, Merlot and Sangiovese. The wines taste awesome right out of the gates but aging-wise tend to taper off a bit faster. Some will only last 8–10 years, whereas others with bolder red fruit characteristics will go 20 or so years. As always, a bit of decanting is great for any Amarone wine.\nExamples of modern producers\nThe Grapes of Amarone Wine\nThere are less than 12,000 acres in the world of the most important Amarone grapes–Corvina and Corvinone, and they only grow in Valpolicella. To make the situation a little more intense, Valpolicella has a regulatory committee that protects the historic nature of the land around Verona. It means if a winery wants to plant a new vineyard, they’ll have to rip out an old vineyard to allocate space. There are 4 main grapes of Amarone and a total of 20,000 acres (8,200 ha).\n- Corvina (technically Corvina Veronese)\nWinemakers in the region will tell you that the best Valpolicella wines come from the Corvina (and more rare Corvinone) grapes. Historically, Rondinella and Molinara were very dominant in the region, however they tend to produce lower quality grapes due to their high productivity. Thus, the wines made with primarily Corvina grapes offer up the heady aromas of rose, cherry liqueur and cinnamon and they also consistently get the highest ratings.\nThe Region of Amarone Wine\nThe Valpolicella wine region lies in the lowest foothills of the Alps just north of Verona and has 3 primary zones: Classico, Valpantena, and Est (meaning “East”). Most of us will hone our focus on the Classico zone for quality (which does contain 5 notable sub-areas), but within each of the 3 main zones there are many excellent wines.\nWithin the Classico zone there are 6 designations within the 3 valleys of Negrar, Marano and Fumane. This is the “Original Gansta” area for Amarone and Recioto della Valpolicella wines. The Classico zone even has an order of knights called SNODAR (Sovereign Noble Order of Ancient Recioto) established in 1969 –a year after the DOC was first officiated, to promote and protect Valpolicella’s wines. Within the Classico region you’ll find many of the largest producers–save for a few.\n- San Pietro in Cariano (lower valley)\nHeading east from the Classico zone is Valpantena. The best vineyards have been noted around Grezzana and Cerro Veronese which is midway up the valley.\n- Cerro Veronese\nThis region is next to the Soave wine region (a Veronese white wine made with Garganega grapes) and is considered a newer region for producing Amarone wines. The best vineyards have been noted in the mid-point up the valley around Illasi, Cazzano di Tramigna, Mezzane and Tregnago.\n- Cazzano di Tramigna\n- San Mauro di Saline\n- Colognola ai Colli (low valley)\n- Montecchia di Crosara (far east, next to Soave)\n- San Martino Buon Albergo (low valley)\nTasting Amarone Wine\nTasting Amarone is a fascinating experience. You’ll want to be sure and decant the wine and serve it in oversized glasses to collect its aromas. Younger wines can typically be served just below room temperature and older wines slightly cooler. Hopefully this guide will get you into the perfect bottle. Salut!"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:5e21ca35-4162-40d8-951c-a9ac4b6b1035>","<urn:uuid:458df5a0-a5b8-4646-a3a0-033e5b8ec859>"],"error":null}
{"question":"How can countries implement transitional justice after mass violence?","answer":"Implementing transitional justice after mass violence requires a comprehensive approach that spans multiple disciplines. It involves addressing political, legal, economic, and psycho-social dimensions of reconciliation. The process requires careful consideration of peace-making and mediation efforts that can be justified and effectively address moral wounds. This may include measures for acknowledging harm, facilitating healing, and learning from previous struggles. The approach must be tailored to each situation, as demonstrated by various case studies from different countries including Cambodia, Guatemala, South Africa, and Canada.","context":["Dilemmas of Reconciliation\nCases and Concepts\nPaper 368 pp.\nOnline discount: 25%\nHow can bitter enemies who have inflicted unspeakable acts of cruelty on each other live together in peace?\nAt a time in history when most organized violence consists of civil wars and when nations resort to genocidal policies, when horrendous numbers of civilians have been murdered, raped, or expelled from their homes, this book explores the possibility of forgiveness.\nThe contributors to this book draw upon the insights of history, political science, philosophy, and psychology to examine the trauma left in the wake of such actions, using, as examples, numerous case studies from the Holocaust, Russia, Cambodia, Guatemala, South Africa, and even Canada. They consider the fundamental psychological and philosophical issues that have to be confronted, offer insights about measures that can be taken to facilitate healing, and summarize what has been learned from previous struggles.\nDilemmas of Reconciliation is a pioneering effort that explores the extraordinary challenges that must be faced in the aftermath of genocide or barbarous civil wars. How these challenges of reconciliation are faced and resolved will affect not only the victims’ ability to go on with their lives but will impact regional stability and, ultimately, world peace.\nCarol A.L. Prager is an associate professor of political science at the University of Calgary. Trudy Govier is a Canadian philosopher with an enduring interest in the ethics and politics of peace. She is the author of the widely used text A Practical Study of Argument and several other books.\n“[A] timely collection of essays and case studies....Many of the essays are provocative and intriguing. Some of them demonstrate a profound willingness to address difficult and unwelcomed issues.”\n— Leo Groarke, University of Toronto Quarterly—Letters in Canada 2003\n“The variety of issues, disciplinary approaches and levels of inquiry represented in this book makes it interesting and instructive reading for postgraduate students and researchers within the areas of politics, peace studies, human rights law, anthropology, and contemporary philosophy. The volume is...successful in accomplishing its objectives in that it both provides an extensive mapping of the research territory of transitional justice and produces in-depth and thorough analysis of its different aspects.”\n— Magdlena Zolkos, Copenhagen University, Political Studies Review\n“This vital collection challenges anyone living in a violent world—which means all of us—to consider when and how survivors can reconcile rather than recapitulate the violence. With cogent essays and detailed case studies, philosophers, political theorists, historians, and activists join here to move beyond platitudes into deep analysis of why and how acknowledgement of harm matters, and what kinds of peace-making and mediation can be justified and can actually address moral and psychic wounds. Important grounds for doubt and reasons for hope gathered here shed light on the past and offer illumination for the future.”\n— Martha Minnow, author of Between Vengeance and Forgiveness: Facing History after Genocide and Mass Violence\n“A brilliant mix of theoretical analysis and empirical case studies that brings out clearly and concisely the political, legal, economic, and psycho-social dimensions of post-conflict reconciliation.”\n— Howard Adelman, York University"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"conceptual_explanation"},{"categorization_name":"user_profile","category_name":"expert_specialist"}],"document_ids":["<urn:uuid:ef394956-9335-4bab-8ada-b1c217f95e22>"],"error":null}
{"question":"How do the environmental advocacy approaches of transportation justice activists compare with Simon James's perspectives on environmental philosophy?","answer":"Transportation justice activists focus on practical equity issues, advocating for better transit options and safer streets for poor people and people of color, while questioning government subsidies that benefit white and affluent commuters. In contrast, Simon James's environmental philosophy takes a more theoretical approach, engaging with various philosophical issues from Buddhist approaches to wildlife conservation to moral relations with natural formations. While both are concerned with environmental justice, they operate at different levels - transportation justice works at the immediate societal level addressing concrete inequities, while James's work explores deeper philosophical questions about human relationships with nature and environmental ethics.","context":["Para a tradução Português clique em Traduzir no menu superior.\nThe transportation justice movement calls into question government subsidies of transportation forms that tend to benefit largely white and affluent urban and suburban commuters and advocates for better transit options and safer streets for poor people and people of color. This population of cyclists is largely uncounted, unrecognized, and unrepresented. Put simply, these are the invisible cyclists. In many cases, invisible cyclists are the constituents of transportation justice organizations, but only insofar as they are poor people of color. As cyclists, they remain invisible.\n– Julian Agyeman and Steve Zavestoski\nAll cyclists are invisible, some more than others\nRecently Steve was preparing to teach a course in which students would develop a bicycle transportation plan for the University of San Francisco, so he began to look into the range of issues the class would need to understand in order to situate the plan in the broader context of the bicycle advocacy and bicycle culture bursting from what seemed like every corner of San Francisco.\nTrained as en environmental sociologist, and working at a university that takes its social justice mission seriously, transportation justice was one issue Steve knew the class would have to examine. So he delved into the literature on the transportation justice movement and looked at the websites of major environmental justice organizations doing transportation justice work. He found little to no mention of the role of the bicycle in transportation justice.\nJulian came at this from a slightly different perspective. Trained in geography and environmental policy and planning, he was getting interested in streets as the public space that most people interact with daily. He began to see streets as contested spaces, as sites where rights were afforded, often and certainly in the US, based on the size of your vehicle. His growing interest in ‘spatial justice and streets’ made him realize that the democratization of streets must become a priority if we are to move toward more just and sustainable cities. Julian and Steve met through their common interests and this Blog is the result.\nWe noted that mainstream bicycle advocacy organizations, like the bicycle coalitions found in most major cities, seemed to pay little attention to the work of transportation justice advocates (with a few notable exceptions that we’ll profile in future posts). Perhaps more significantly, we began to see signs that some mainstream bicycle advocacy organizations were even being criticized for what appeared to be their bias towards bicycle infrastructure projects that primarily serve middle-class and largely white urban cyclists.\nFor example, Chicago resident and founder of the African American Pioneers Bicycle Club, Oboi Reed, criticized Chicago’s priorites in a New York Times article, “City Bike Plan is Accused of a Neighborhood Bias.” According to Reed, “The lion’s share of the resources” of the city’s $150 million bike plan “are going to go [to the wealthier neighborhoods] downtown and to the North Side–the South and West will only see a sprinkling.” In New York City, a report by graduate students from the Urban Affairs and Planning Program at Hunter College, “Beyond the Backlash: Equity and Participation in Bicycle Planning,” concluded that “traditionally underserved areas outside of the core of Manhattan and northwest Brooklyn have inadequate bicycle infrastructure. These areas have many cyclists and residents who are largely new immigrants and people of color.”\nNext we turned to the bicycle blogosphere to see who was discussing the intersections of bicycle advocacy, race, and class, and what they were saying. Are Bike Lanes Expressways to Gentrification? over at shareable.net described a contentious neighborhood meeting to discuss proposed traffic changes to increase bicycle safety along N. Williams Ave. in Portland, OR. Portland resident Donna Maxey tried to explain the frustration of people of color with Portland’s bicycle support efforts:\n“What is causing the anger and resentment is that it’s only an issue of safety now that whites are the ones who are riding bicycles and walking on the streets. Because we have been in this community for years and it has not been an issue and now it’s an issue. So that’s the resentment you’re hearing…years of people being told, you don’t count, you don’t matter…but now that there’s a group of people who’s coming in that look like the people who are the power brokers — now it’s important. That’s the anger. That’s the hurt.”\nA recent comment on a Streetsblog article titled “On Gentrification and Cycling,” hammered the point home:\n“As a person of color who works to get more bike lanes in low-income areas in Los Angeles, … It’s high time the bike advocacy community, which is heavily dominated by white men unaware of social justice principles, step back and say, ‘how can we include MORE marginalized, low-income people of color in this struggle??’”\nIn an LA.Streetsblog.org article co-authored with Adrian Leung, “Bicycling is for Everyone: The Connections Between Cycling in Developing Countries and Low-Income Cyclists of Color in the U.S.,” Allison Mannos, Urban Strategy Director for the Los Angeles County Bicycle Coalition, raises specific concerns about mainstream bicycle advocacy groups’ failure to reach out to communities of color:\n“In terms of advocacy, outreach efforts should expand ideas of target communities … to create a comprehensively transformative movement. Frequently, for example, discussions of the inequity in bicycling between men and women tend to focus on educated, middle-class white women (especially mothers), and usually do not examine the barriers to bicycling for, say, women of color. This narrow approach in advocacy and planning often misses solutions to engage and serve the existing, dedicated population of low-income cyclists of color; in fact, it instead ignores them or takes their lifestyles for granted.”\nThese conversations point to an important constituency seemingly overlooked by both the bicycle advocacy and transportation justice movements. This population of cyclists is largely uncounted, unrecognized, and unrepresented. Put simply, these are the invisible cyclists.\nThrough a series of conversations, we delved deeper into this apparent conundrum. On one hand, a new bicycle culture is finally flourishing in North America. Major cities are competing with one another to see which can add more bike lanes the fastest. But the bicycle boom is driven by relatively narrow segments of the population where individuals with disposable income, and the option to choose a bicycle over an automobile or other forms of transit, are turning what was previously a utilitarian device into a celebration of design, style and simplicity. But this movement overlooks the invisible cyclists, those for whom cycling is not a choice but a necessity.\n[Note: We did not coin the concept of “invisible cyclists.” A future post will explore the lineage of the term, which begins with Dan Koeppel’s 2006 “Invisible Riders” article in Bicycling Magazine, available here.]\nOn the other hand, the transportation justice movement calls into question government subsidies of transportation forms that tend to benefit largely white and affluent urban and suburban commuters and advocates for better transit options and safer streets for poor people and people of color. In many cases, invisible cyclists are the constituents of transportation justice organizations, but only insofar as they are poor people of color. As cyclists, they remain invisible.\n“Why is there not more dialogue between these two movements?” we wondered. Surely a more inclusive movement would be more robust, richer in resources, more powerful, and therefore more effective at enhancing bicycle infrastructure for all bicyclists. The mainstream environmental movement missed the boat entirely so that by the time the environmental justice movement matured, the relationship between the two movements was contentious.\nWe hope that by creating space for dialogue between and among activists, advocates, and constituents from a wide range of bicycle advocacy, transportation justice, and other organizations and interests, we can head off a similar divide.\nSo we bring you Invisible Cyclist, which will explore potential linkages between the bicycle culture/advocacy movement and the environmental/transportation justice movements. Through our own posts and those of volunteer and invited guests, we hope to help identify common ground and shared goals around which the two movements can build healthy and mutually beneficial relationships.\nThough both academics, Invisible Cyclist will by no means be an academic exercise nor exercise an academic voice. Steve Zavestoski is a lifelong bicyclist, bicycle commuter, and bicycle advocate, while Julian is a car-free citizen and lifelong advocate for just sustainabilities. We are both passionate about and committed to fashioning a more just and sustainable society that “ensures a better quality of life for all, now and into the future, in a just and equitable manner, while living within the limits of supporting ecosystems.” We believe that we can make a contribution towards such a world through Invisible Cyclist by working to establish dialogue between two movements each working towards just sustainabilities in their own way.\nBut there are caveats. Issues of race and class can easily ignite strong emotions, including defensiveness, anger, and resentment. We will write with honesty and openness–tackling sticky issues of racial and class stereotypes head on–as well as a dash of humor, in order to deftly navigate this minefield. By focusing on promising signs of bridge-building across the two movements, we will aim to generate constructive dialogue while steering clear, where possible, of unproductive debates (e.g., who to assign blame to for past injustices). We hope that you will join us in this dialogue.\n* To check out The Invisible Cyclist Blog, click here.\n# # #\nAbout the authors:\nJulian is a car-free pedestrian, Professor and Chair of the Department of Urban and Environmental Policy and Planning(UEP) at Tufts University, Medford-Boston, MA, and co-founder and co-editor of Local Environment: The International Journal of Justice and Sustainability. My expertise and current research interests critically explore aspects of the complex and embedded relations between humans and the environment, whether mediated by institutions or social movement organizations, and the effects of this on public policy and planning processes and outcomes, particularly in relation to notions of justice and equity.\nAssociate Professor and Chair Sociology and Environmental Studies University of San Francisco Department of Sociology, Stephen received his B.A. from the University of Notre Dame, and his M.A. and Ph.D. from Washington State University. He teaches courses in the area of Environmental Sociology. Dr. Zavestoski’s research areas include environmental sociology, social movements, and sociology of health and illness. His current research focuses on the strategies that disease sufferers take to demonstrate that their conditions are caused by environmental contamination. This work also looks at how citizens engage in the scientific process and policymaking in order to shape research and policy agendas;","Dr Simon Paul James, BSc, MA, PhD\n(email at firstname.lastname@example.org)\nI came to philosophy by a roundabout route, taking a BSc in Biological Sciences, followed by an MA in the History and Philosophy of Science, before obtaining a PhD for a thesis on environmental ethics in 2001. I am currently an Associate Professor (Reader) in the Department of Philosophy.\nMy work engages with a wide range of issues in environmental philosophy, from Buddhist approaches to wildlife conservation to our moral relations with rock formations, and from the (so-called) problem of animal minds to the virtue ethical question of whether a good life must be a green life.\nIn my spare time, I enjoy playing guitar and (with Helen and my daughter Emily) walking in wild (or wildish) places.\nDepartment of Philosophy\n- Environmental philosophy\n- Existential phenomenology\n- Buddhist philosophy\n- James, Simon P. (2015). Environmental Philosophy: An Introduction. Cambridge: Polity Press.\n- James, Simon. (2009). The Presence of Nature: A Study in Phenomenology and Environmental Philosophy. Houndmills, Basingstoke: Palgrave Macmillan.\n- Cooper, David E. & James, Simon P. (2005). Buddhism, Virtue and Environment. Aldershot: Ashgate.\n- James, Simon P. (2004). Zen Buddhism and Environmental Ethics. Aldershot: Ashgate.\n- James, Simon P. & Cooper, David E. (2008). Buddhism and the Environment. Contemporary Buddhism, 8 (2): Taylor and Francis.\nChapter in book\n- James, Simon P. (2016). Phenomenology and the Charge of Anthropocentrism. In Nature and Experience: Phenomenology and the Environment. Bannon, Bryan Rowmann & Littlefield. 43-52.\n- James, Simon P. (2014). Green Managerialism and the Erosion of Meaning. In Old World and New World Perspectives on Environmental Philosophy: Transatlantic Conversations. Drenthen, M. & Keulartz, J. Cham, Switzerland: Springer. 139-150.\n- James, Simon P. (2013). Buddhism and Environmental Ethics. In A Companion to Buddhist Philosophy. Emmanuel, Steven M. Chichester: Wiley-Blackwell. 601-612.\n- James, Simon P. (2012). Conserving Nature's Meanings. In Embodied Values and the Environment. Brady, E. & Phemister, P. Springer.\n- James, Simon P. (2008). Asian Philosophy. In Encyclopedia of Environmental Ethics and Philosophy. Gale.\n- James, Simon P. (2020). Legal Rights and Nature's Contributions to People: Is There a Connection? Biological Conservation 241: 108325.\n- James, Simon P. (2019). Madhyamaka, Metaphysical Realism and the Possibility of an Ancestral World. Philosophy East and West 68(4): 1116-1133.\n- James, Simon P. (2019). Natural Meanings and Cultural Values. Environmental Ethics 41(1): 3-16.\n- James, Simon P. (2019). Nature's Indifference. Environmental Ethics 41(2): 115-128.\n- James, Simon P. (2019). Suffering and the Primacy of Virtue. Analysis 79(4): 605-613.\n- James, Simon P. (2018). Merleau-Ponty and Metaphysical Realism. European Journal of Philosophy 26(4): 1312-1323.\n- James, Simon P. (2016). Ecosystem Services and the Value of Places. Ethical Theory and Moral Practice 19(1): 101-113.\n- James, Simon P. (2016). Protecting Nature for the Sake of Human Beings. Ratio 29(2): 213-227.\n- James, Simon P. (2016). The Trouble with Environmental Values. Environmental Values 25(2): 131-144.\n- James, Simon P. (2015). Cultural Ecosystem Services: A Critical Assessment. Ethics, Policy & Environment 18(3): 338-350.\n- James, Simon P. (2015). Why Old Things Matter. Journal of Moral Philosophy 12(3): 313-329.\n- James, Simon P. (2014). “Nothing Truly Wild is Unclean” Muir, Misanthropy, and the Aesthetics of Dirt. Environmental Ethics 36(3): 357-363.\n- James, Simon P. (2013). Cherished Places and Ecosystem Services. Ethics, Policy & Environment 16(3): 264-266.\n- James, Simon P. (2013). Finding - and Failing to Find - Meaning in Nature. Environmental Values 22(5): 609-625.\n- James, Simon P. (2013). Philistinism and the Preservation of Nature. Philosophy 88(01): 101-114.\n- James, Simon P. (2011). For the Sake of a Stone? Inanimate Things and the Demands of Morality. Inquiry 54(4): 384-397.\n- James, Simon P. (2009). Phenomenology and the Problem of Animal Minds. Environmental Values 18(1): 33-49.\n- James, Simon P. (2007). Against Holism: Rethinking Buddhist Environmental Ethics. Environmental Values 16.\n- James, Simon P. (2007). Merleau-Ponty, Metaphysical Realism and the Natural World.*. International Journal of Philosophical Studies 15(4): 501-519.\n- James Simon P. (2006). ‘Buddhism and the Ethics of Species Conservation’. Environmental Values 15(1): 85-97.\n- James, Simon P. (2006). Human Virtues and Natural Values. Environmental Ethics 28(4): 339-354.\n- James, Simon P. (2005). Awakening to Language in Heidegger and Zen. International Journal of Field Being 2(2).\n- James, S. P. (2015). The New Greenspeak. Earth Island Journal 30(1).\n- James, Simon P. (2017). Conflict and Resolution (editorial for Environmental Values). 26(5): 535-538.\n- James, Simon P. (2016). Letting Nature take its Course (editorial for Environmental Values). Environmental Values 25(4): i-iv.\nAvailable for media contact about:\n- Education & awareness: Environmental ethics\n- Ethics: Environmental ethics\n- Philosophy: Environmental ethics\n- Religion: Environmental ethics"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"format_constrained"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"practical_steps"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:4f4bfa7a-fa16-44ba-bfd3-46647a682692>","<urn:uuid:6cee321e-0591-405e-b453-aa3ea32b95d6>"],"error":null}
{"question":"Could you compare the maneuverability characteristics of the Tempest V and the J2M4 Kai fighters at high speeds?","answer":"Both aircraft had significant maneuverability limitations at high speeds. The J2M4 Kai had poor high-speed performance with the entire aircraft locking up, making it very difficult to pull out of a dive, roll, or turn at high speeds. Similarly, the Tempest V had some handling issues, though less severe - it was noted to have some joint issues under pressure, particularly in the wing leading edges, though it was generally considered a better gun platform than its predecessor the Typhoon and had crisper handling overall.","context":["Eduard 1/48 Tempest V\nThe Tempest was basically a Typhoon gone good: faster, with a more reliable engine and a crisper handling, together to being a better gun platform without any of the vibration problems of the earlier machine. Typhoon pilots usually transitioned to Tempests without inconvenience, this was the intended policy, while Spitfire IX pilots went on to Spit XIVs.\nJN751 was among the first 50 Tempests\nbuilt. It was also the first to score, W/C R.P. Beamont flying it to claim the\nfirst Tempest kill, a 109G claimed on “D+2-Day”. Previous to the invasion, he\nflew it from Castle Camps, Cambridgeshire (adorned with the Typhoon-like ID\nbands) within the ADGB (Air Defense Great Britain) in anti-diver missions. In\nthe last days of September, 1944, 150th Wing (274th, 56th and 80th Sqns) was\nallocated to the 2nd TAF, Beamont leading it to B.60 aerodrome, located at\nThere were two boxings of the Eduard Tempest, a ProfiPack which can be built into a late machine, and a standard one, with two early series machines. The latter is devoid of any resin or PE, but the pieces included in the Profipack are not really worth the expense. The kit has been criticized as being too short and having a too thick fin, and both may be true! In addition to that, it is a typical “short run” product, so expect some cleaning and a pin-free assembly. There are a lot of aftermarket items for the Hasegawa Typhoon, but very few for the Tempest. I added an Eduard PE set (48204), True Details wheels (48036) and in the end Eagle Decal roundels and Carpena code letters decals.\nAfter pondering several ways of furnishing the cockpit, among them using the tube cage structure from a Hasegawa Typhoon or the even the Cutting Edge resin for such a kit, I decided to go with the Eduard PE piece, gluing tube to the flat structure. After much fiddling, it finally went in, with false sidewalls to hide the wingroots and a false floor to hide the tops of the wheel wells. Some scratchbuilt pieces completed both floor and sidewalls. The fit of the windscreen was exemplary. Exhausts came from the Quickboost range.\nThe wheel wells are well thought as inserts, avoiding the shape issues of the Hasegawa Typhoon. They were also furnished with PE and scratchbuilt pieces, following references and the Cutting Edge set for the Typhoon. I added some bulges in the wing roots which are characteristic of early machines.\nI resisted the temptation of depicting the flaps down; with all the add ons, the fit of the wings had been crazed enough. It took several attempts to get the correct diedhral: the central under surface should be perfectly flat, and the model insisted in adopting a slight inverted gull shape. I also dropped the idea of replacing the stabilizers for the Airwaves resin pieces, the ones in the kit (though a cumbersome two piece design) fitted well enough.\nThe crazy idea of the wing inserts for the protruding cannon barrels I dropped very quickly; instead, I cut the barrels, shaped a concave base to them, inserted some rod as a guide and glued them to the muzzle holes trying to keep the alignment. It worked, though the soft nature of the plastic made the leading edge joints pop out under the slightest pressure.\n|COLORS & MARKINGS|\nBuilt for a theme presentation (“From\nD-Day to Bodenplatte”) this model had to have D-Day ID stripes on it. I chose to\npaint them first, together with the remnants of the Sky band, and save camo\npaint and time. I calculated the stripes by establishing the outer limits,\npainting the surface White and then I measured the stripes, masked and painted\nthe Black ones. There were some inevitable issues, compounded by the slightly\ntoo short fuselage, which came out at the time of decalling. The stripes in the\nreal machine were very tidy, applied for the W/C at the Hawker workshop at\nWell, here some problems presented. The Eduard decals are good enough for a normal build, but this I wanted to be a bit over the top, so I started replacing roundels and flashes for Eagle Strike decals. The Eduard ones had a too bright Red centres, something very common. Then, the code letters are in some shade of Grey, when they should be Sky (another difficult one); moreover, they are the standard measure of 36 in, while Beamont used a smaller size. I resorted to some Decal Carpena 1/72nd codes, but the Xtradecals 1/72nd sheet would have been just perfect. I had to adjust the fuselage bands by extending a bit the most forward Black and White stripes, to allow the decals fall exactly where the photo of the original machine showed (the fuselage is a tad too short, and the White band advanced a bit too much on the trailing edge wing root fairing, though to be fair it seems a bit wider than the rest in the picture). Then I realized that the insignia was centered exactly on a Black/White division, and the White ring was translucent. I tore the roundels away and painted some “dent” in White into the Black band, so that the whole inner part of the roundel fell on a White zone. Geez. The upper roundel is shown as a type C, but in the sheet the correct Type B is included (the order to paint the narrow White ring dated from January 1945) The serials were from the original Eduard sheet and performed flawlessly.\nWeathering was very light; this aircraft belonged to the Old Man and clean is the way he liked it. Nevertheless I applied some Burnt Umber washes to the underside, that radiator bath should have exuded oil in quantities, W/C or not. I glued the undercarriage, suitably detailed with some oleo pipelines, then the exhausts and canopy and that was it.\nIt was a quite involved build. It must be\nremembered that those early Eduard kits are nothing like present-day P-39s and\nBf 110s, they are true short run kits. I wanted to get it right, and that made\nthe build a bit tense, but I am quite pleased with the results. Ah, the theme\ncontest was won by a good friend of mine with a Tamiya Mustang\n“Hawker Tornado, Typhoon and Tempest. RAF\n“The Hawker Tempest Mk.!-V”, Francis\nMason, Profile Publications no. 197,\n- “Typhoon and Tempest Aces of WW2”, Chris Thomas, Aircraft of the Aces no. 27, Osprey Publications.\n“Hawker Tempest”, Michail Ovcacik, 4+\n- “2nd TAF vol 1, 2 y 3”, Chris Thomas y Christopher Shores, Classic Publications.\n- Plans drawn by Ian Bentley in SAMI magazine.\nIf you would like your product reviewed fairly and quickly, please contact me or see other details in the Note to Contributors.\nBack to the Main Page\nBack to the Review Index Page","|This page is about the premium Japanese fighter J2M4 Kai. For other versions, see J2M (Family).|\n- 1 Description\n- 2 General info\n- 3 Armaments\n- 4 Usage in battles\n- 5 History\n- 6 Media\n- 7 See also\n- 8 External links\nThe J2M4 Kai Raiden is a premium rank IV Japanese fighter with a battle rating of 5.0 (AB/RB) and 4.3 (SB). It was introduced in Update 1.47 \"Big Guns\" as a premium vehicle purchasable in-game with Golden Eagles , but was removed from in-game sale after the 9th Anniversary Sale. It has been temporarily made available for purchase in-game with Golden Eagles () during the 2022 \"Day of Japan\" mini-event.\nAlthough stubby, the Mitsubishi J2M4, Raiden Model 32 can be considered one of the fastest Japanese fighters in War Thunder, though it is still slower than most of its opponents.\n|Characteristics|| Max Speed\n(km/h at 7,000 m)\n| Max altitude\n| Turn time\n| Rate of climb\n| Take-off run|\n|Combat flaps||Take-off flaps||Landing flaps||Air brakes||Arrestor gear|\n|Wings (km/h)||Gear (km/h)||Flaps (km/h)||Max Static G|\n|Optimal velocities (km/h)|\n|< 390||< 400||< 420||> 324|\nSurvivability and armour\n- 70 mm Bulletproof glass - Armoured windscreen\n- 8.5 mm Steel plate in pilot's headrest\nModifications and economy\nThe J2M4 Kai is armed with:\n- 2 x 20 mm Type 99 Model 1 cannons, wing-mounted (190 rpg = 380 total)\n- 2 x 20 mm Type 99 Model 2 cannons, wing-mounted (150 rpg = 300 total)\nWielding four 20 mm cannons, this aircraft can cripple any enemy it encounters. However, the main advantage the Raiden has over its Allied counterparts is its climb rate. In realistic battles, the J2M4 can climb to altitude very fast, especially when given an air start. Once at a high altitude, this allows the Raiden pilot to pick and choose targets, dictating where and when he or she wants to fight. The J2M4's 20 mm cannons may seem lacklustre at first, but they have a knack for snapshots, or quick bursts of fire when manoeuvring.\nThe J2M4 Kai can be outfitted with the following ordnance:\n- Without load\n- 2 x 60 kg Navy Type 97 Number 6 bombs (120 kg total)\nUsage in battles\nGenerally, the J2M4 performs similarly to the early Fw 190 A variants, having a deadly armament, good roll rate, low top speed, but higher climb rate. Use what the Raiden does best to achieve success - energy fighting. Instead of turn fighting or bleeding all built up energy or speed in turns, attack enemies from a higher altitude and then regain that altitude once the attack has been delivered. The J2M4 excels at Boom & Zoom due to its high rate of climb and deadly armament, even more so than its earlier variants, the J2M2 and J2M3.\nThe Raiden's main downside is its lack of manoeuvrability. Similar to its German counterpart, the Fw 190 A-8, the Raiden struggles to beat enemies in turn fights, especially Spitfires. If caught in a sticky situation, the Raiden pilot may choose to dive away or seek help from teammates. Trying to fight an enemy Spitfire in a turn battle with the J2M is a terrible idea, unless the enemy aircraft is damaged or many teammates are nearby. Moreover, the J2M's high speed manoeuvrability is poor, making the entire aircraft lock up. It can be very difficult to pull out of a dive, roll, or turn when at high speeds with the J2M. The Raiden's manoeuvrability is more or less on par with its enemies in simulator battles, for the most part.\nThe Raiden pilot may also find themselves outrun by high altitude aircraft such as the P-51 D-5 Mustang. All these aircraft have to do to avoid the J2M is dive away and build up speed. Fortunately, the J2M4 has a surprise - a massive ammunition pool totaling 800 rounds. That's 800 rounds of high explosive cannon ammunition that can be dispensed at will towards fleeing enemies. With good aim and practice, it is possible to \"snipe\" enemies from a kilometre away.\nFeaturing four 20 mm cannons, 2 Type 99 Mk 1 and 2 Type 99 Mk 2 cannons with plenty of ammunition, the J2M4 is capable of destroying all kinds of aircraft. Although destroying heavy bombers like the B-29 Superfortress takes a lot of ammunition, the J2M4 can afford to lose some. The \"Stealth\" belt has the best combination of AP/API and HEF to shred enemy aircraft, and are recommended for those who do not need a tracer shell to aim. Alternatively, for those not used to IJN 20 mm cannons, the \"Universal\" belt is your best bet. The \"Tracer\" belt is filled with HEFT shells, but they only contain half of the power of a standard HEF, and can give away your position.\nOverall, the Raiden is best used as a surprise attack, high altitude, high damage output fighter. While it does not excel in the speed or manoeuvrability categories, it makes up for that in armament and rate of climb.\nManual Engine Control\nNot auto controlled\nNot auto controlled\nNot auto controlled\nPros and cons\n- Good top speed\n- Large ammunition pool\n- Climbs very well\n- Has generally good dive characteristics\n- Good energy retention\n- 12 mm armour plate behind windscreen\n- Good roll rate at lower speeds\n- Decent high altitude performance due to the turbocharger\n- Very poor high speed performance\n- Prone to engine and fuel fires\n- Doesn't turn well\n- Elevator doesn't respond well, especially at high speeds\n- Lack of armour around fuel tanks or engine\n- Differing muzzle velocities between the two marks of the Type 99 cannon on the J2M4 will require you to lead much further than normal as an order to utilize the full effectiveness of the J2M4's firepower\nAs the development behind the 14-Shi Interceptor (J2M2 and J2M3) were disappointing in performance and didn't achieve it's projected goal, Mitsubishi set up a new goal with the availability of newer and stronger engines, this would be called under the 14-Shi Kai Interceptor.\nJiro Horikoshi and his team redesigned the nose of the plane to hold the new Kasei 23c engine and with this prototype they achieved the requested goal, this plane would be known as the J2M4, Raiden Model 32. It solved the engine vibrations and the cooling system was more reliable compared to that of the previous models. It would still preserve the same electrical malfunctions to the landing gear which didn't get redesigned as the engine and its performance were a more pressing issue.\nThis progress allowed Mitsubishi to further develop the Raiden and so they would with the Kasei 26a, equipping it in the J2M5, Raiden Model 33.\nLinks to the articles on the War Thunder Wiki that you think will be useful for the reader, for example:\n- reference to the series of the aircraft;\n- links to approximate analogues of other nations and research trees.\n|Mitsubishi Company ()|\n|Fighters||A5M4 · Hagiri's A5M4|\n|A6M2 mod. 11 · A6M2 · A6M3 · A6M3 mod. 22 · A6M3 mod. 22Ko · A6M5 · A6M5 Ko · A6M5 otsu · A6M5 Hei · A6M6c|\n|A7M1 (NK9H) · A7M2|\n|J2M2 · J2M3 · J2M4 Kai · J2M5 · J2M5 (30 mm)|\n|Interceptors||Ki-83 · Ki-109|\n|Ki-21-Ia · Ki-21-I hei · Ki-67-I Ko · Ki-67-I otsu|\n|Captured||▃A6M2 · ␗A6M2|\n|See also||Mitsubishi Heavy Industries (1945+)|\n|A5M||A5M4 · Hagiri's A5M4|\n|A6M||A6M2 mod. 11 · A6M2 · A6M3 · A6M3 mod. 22 · A6M3 mod. 22Ko · A6M5 · A6M5 Ko · A6M5 otsu · A6M5 Hei · A6M6c|\n|A7M||A7M1 (NK9H) · A7M2|\n|J2M||J2M2 · J2M3 · J2M4 Kai · J2M5 · J2M5 (30 mm)|\n|N1K-J||N1K1-Ja · N1K2-J · N1K2-Ja|\n|Ki-10||Ki-10-I · Ki-10-I C · Ki-10-II · Ki-10-II C|\n|Ki-27||Ki-27 otsu · Ki-27 otsu Tachiarai|\n|Ki-43||Ki-43-I · Ki-43-II · Ki-43-III otsu|\n|Ki-44||Ki-44-I · Ki-44-I 34 · Ki-44-II otsu · Ki-44-II hei|\n|Ki-61||Ki-61-I ko · Ki-61-I otsu · Ki-61-I hei · Ki-61-I hei Tada's · Ki-61-I tei · Ki-61-II Otsu Kai|\n|Ki-84||Ki-84 ko · Ki-84 otsu · Ki-84 hei|\n|Ki-100||Ki-100 · Ki-100-II|\n|Other countries||▅F4U-1A · ▅P-51C-11-NT · ▅Bf 109 E-7 · ▅Fw 190 A-5|\n|*Imported designation of the He 112 (A6M was in development - A7M would take A7 designation after the cancelation of the A7He)|\n|Japan premium aircraft|\n|Fighters||Hagiri's A5M4 · A7He1 · Ki-27 otsu Tachiarai|\n|Ki-44-II otsu · ▅Bf 109 E-7 · ▅F4U-1A · Ki-100-II · Ki-44-I 34|\n|▅Fw 190 A-5 · A7M1 (NK9H) · Ki-61-I hei Tada's · ▅P-51C-11-NT|\n|J2M4 Kai · A6M5 Ko · A6M6c · J2M5 · Ki-87 · J6K1|\n|Jet fighters||F-86F-40 JASDF▅|\n|Bombers||Ki-21-I hei · H8K3 · ▅B-17E|"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"answer_length","category_name":"moderate"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"instructional"},{"categorization_name":"user_preferred_response_style","category_name":"structured_comparison"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:1ae6d554-2098-4f3b-afa1-b39eb17e36df>","<urn:uuid:e38eb3e3-dda9-464e-aca3-7862acb06505>"],"error":null}
{"question":"Can both GitHub@RPI and Cisco ASA Firewall be used for remote work scenarios?","answer":"Yes, both systems support remote work. GitHub@RPI can be accessed remotely at github.rpi.edu with valid RCS credentials, while Cisco ASA Firewall provides VPN capabilities that proved valuable during the pandemic when people began working from home, allowing organizations to add more capacity to remote VPN access.","context":["What is GitHub\nGitHub is a web based interface to the version control software GIT. Version control software manages and tracks changes to files over time. It is a critical tool in software development. A great intro to using Git and GitHub can be found at GitHub Hello World Guide.\nHow do I access GitHub @RPI\nRPI's GitHub service is available to all RPI Faculty, Staff, and Students.\nYou may access the service at https://github.rpi.edu/ with a valid RCS username and password.\nCan non-RPI people get accounts\nYes, as long as the project is RPI led and for academic or not-for-profit research then the external user will be permitted access. Guest accounts can be requested at https://webforms.rpi.edu/guest-account-form\nWhy should I use GitHub @RPI vs GitHub.com\nRPI's GitHub service is hosted and managed internally. On premise data storage also allows for use with intellectual property that requires on campus hosting. This makes GitHub enterprise ideal for class usage and research projects.\nWhat documentation is available\nThis page will cover some common topics, particularly related to RPI's GitHub Enterprise service.\nFor topics not specific to RPI, general GitHub documentation is available at:\nWhat are the restrictions for organization names\nGitHub allows the use of groups called Organizations where multiple people can collaborate across many projects at once. Organization names fall into the same namespace as user accounts, which means that someone with an RCS ID that is the same as an existing organization will be denied access to GitHub @RPI. For this reason we currently require all organization requests to be submitted through https://webforms.rpi.edu/request-github-organization\nHow do I request an Organization\nAll requests for a new GitHub Organization should be made by filling out a GitHub Organization Request Form.\nWhat is the address or URL of my repositories\nGitHub uses HTTPS or SSH. The repository address for HTTPS will use the pattern:\nIf you use HTTPS, be aware that the system does not know (or use) your RCS password. You need to create an GitHub access token and use it as your password. See Creating an access token but be aware that you need to create the access token in your RPI GitHub account on github.rpi.edu (and not on github.com).\nThe repository address for SSH will use the pattern:\nIf you use SSH, you need to generate SSH keys and add them to your account. See Generating SSH keys, but be aware that some steps connect to the public GitHub.com site. You will want to adapt those steps, to connect to RPI's github.rpi.edu site.\nCan I store large files in GitHub\nGit is for storing lots of small files that change often, it is not suitable for large files.\nHow much storage am I allowed\nRPI's GitHub enterprise is intended for use with text files such as source code. Binary files are allowed, but attention should be taken with regard to their size. There are no hard limits on file or repository size. However DotCIO does review usage for abnormal situations, and reserves the right to limit excessive use. Contact Us if you have questions about your planned use case.\nSecurity & Privacy\nAs a user of GitHub @RPI, you understand and agree to abide by RPI’s Policy on Electronic Citizenship and acknowledge that you have reviewed this security information.\n- Staff - Activities in support of job responsibilities. Personal use acceptable as long as incidental in nature.\n- Faculty - Academic and not-for-profit research activities. Personal use acceptable as long as incidental in nature.\n- Students - Academic and personal use. Commercial use or any use for the benefit of an unaffiliated third party is prohibited.\nYou should not use your GitHub account to store most institutional data classified as Confidential.\nDo not store private information such as usernames, passwords or security tokens in your GitHub repositories.\nWhat are the RPI GitHub Enterprise host key fingerprints\nRPI GitHub's (github.rpi.edu) public key fingerprints:\n2048 e9:b0:13:9e:d0:cf:09:a5:0e:cb:eb:3b:c2:85:f5:13 (RSA) 2048 SHA256:DPjGmbN5c6wOPTRAPNmu/sVCglz4uq4gszYWuXZ4ZQU github.rpi.edu (RSA) 256 fd:14:12:93:29:ee:a0:1a:50:61:1b:33:f5:07:6c:b8 (ECDSA) 256 SHA256:4a8KbcUgosZPmi7ycux4aOwvqFnc3LPv5HIm3Ls37nA github.rpi.edu (ECDSA)\nYou should be able to use the following command to view which fingerprint is being used when you establish a ssh connection to github.rpi.edu.\nssh -o VisualHostKey=yes email@example.com\nDeleting & Restoring Files and Folders in your GitHub account\n- GitHub is a version control system, most deleted files are end user recoverable inside your repository.\n- Deleting an Organization or Repository is permanent and unrecoverable.\n- Git typically keeps a local copy of the repository on your machine during normal use.\n- DotCIO maintains backups of the servers providing this service for disaster recovery scenarios only.\nWeekly preventive maintenance is scheduled on Wednesdays 8:30am to 9:30am Eastern Time. During this period GitHub @RPI may be down.\n- What is GitHub\n- How do I access GitHub @RPI\n- Can non-RPI people get accounts\n- Why should I use GitHub @RPI vs GitHub.com\n- What documentation is available\n- What are the restrictions for organization names\n- How do I request an Organization\n- What is the address or URL of my repositories\n- Can I store large files in GitHub\n- How much storage am I allowed\n- Security & Privacy\n- What are the RPI GitHub Enterprise host key fingerprints\n- Deleting & Restoring Files and Folders in your GitHub account\n- Schedule Maintenance","\"The features I've found most valuable are the packet captures and packet traces because they help me debug connections. I like the logs because they help me see what's going on.\"\n\"The most valuable feature is stability.\"\n\"I have integrated it for incidence response. If there is a security event, the Cisco firewall will automatically block the traffic, which is valuable.\"\n\"The deep packet inspection is useful, but the most useful feature is application awareness. You can filter on the app rather than on a static TCP port.\"\n\"I like the firewall features, Snort, and the Intrusion Prevention System (IPS).\"\n\"The most valuable feature is the access control list (ACL).\"\n\"A good intrusion prevention system and filtering.\"\n\"The most valuable features of this solution are advanced malware protection, IPS, and IDS.\"\n\"The feature that I have found the most valuable is the control over the network permissions and the network.\"\n\"I like its order management feature. It doesn't have the kind of threat intelligence that Palo Alto has, but the order management makes it much simpler to know the difference.\"\n\"Azure's cost-effectiveness is its major advantage.\"\n\"In terms of the reporting, it's beautiful. It integrates with Azure monitoring and with Azure policies. That piece is a big help. You can set governing policies and you can use the application firewall, as well as the Azure Firewall, to enforce those policies.\"\n\"I can easily configure it.\"\n\"The solution can autoscale.\"\n\"Azure Firewall's feature that I have found most valuable is its scalability.\"\n\"Microsoft's technical support is very good. They're quite knowledgable and responsive.\"\n\"The ASDM (Adaptive Security Device Manager) which is the graphical user interface, works out, and Cisco keeps it current.\"\n\"VPN and firewall are good features.\"\n\"I have not contacted technical support. There is a lot of information on the internet for troubleshooting. All you need to do is use a search engine and you will find the information you are looking for easily.\"\n\"The user interface is easy to navigate.\"\n\"With the pandemic, people began working from home. That was a pretty big move, having all our users working from a home. More capacity needed to be added to our remote VPN. ASA did this very well.\"\n\"It's pretty reliable and allows for isolation capabilities within the network.\"\n\"The return on investment is not going to be restricted to just the box... Now, these genres have been expanded to cyber, to third-party integrations, having integrated logging, having integrated micro and macro segmentations. The scope has been widened, so the ROI, eventually, has multiplied.\"\n\"Cisco offers a great educational series to train users on their devices.\"\n\"The configuration in Firepower Management Center is very slow. Deployment takes two to three minutes. You spend a lot of time on modifications. Whereas, in FortiGate, you press a button, and it takes one second.\"\n\"Report generation is an area that should be improved.\"\n\"I would like to see improvement when you create policies on Snort 3 IPS on Cisco Firepower. On Snort 2, it was more like a UI page where you had some multiple choices where you could tweak your config. On Snort 3, the idea is more to build some rules on the text file or JSON file, then push it. So, I would like to see a lot of improvements here.\"\n\"An area of improvement for this solution is the console visualization.\"\n\"This product is managed using the Firepower Management Center (FMC), but it would be better if it also supported the command-line interface (CLI).\"\n\"The application detection feature of this solution could be improved as well as its integration with other solutions.\"\n\"The Firepower FTD code is missing some old ASA firewalls codes. It's a small thing. But Firepower software isn't missing things that are essential, anymore.\"\n\"The ability to better integrate with other tools would be an improvement.\"\n\"It is a cloud service, but the lending speed for each region is not always the same. For example, in China, the speed is slow. They need to think about how to make sure that the service pace or speed is always the same in all regions. It would be a great improvement if they can provide the same pace worldwide.\"\n\"It would be nice to be able to create groupings for servers and offer groups of IP addresses.\"\n\"The solution lacks artificial intelligence and machine learning. It might be in the roadmap. However, currently, it's not available.\"\n\"It needs a lot of improvement, especially on intruder detection. They are working hard on that.\"\n\"Azure should be able to work better as a balancer also, instead of just being a firewall. It should have a wider mandate.\"\n\"It would be much easier if the on-premises, firewall rules, had some kind of export-import possibility in place, which is not the case right now.\"\n\"An Azure firewall is not a real firewall.\"\n\"The development area and QA area could be improved. With those improvements, we can improve projects and take even less time to implement them.\"\n\"On firewall features, Fortinet is better. Cisco needs to become more competitive and add more features or meet Fortinet's offering.\"\n\"It lacks management. For me, it still doesn't have a proper management tool or GUI for configuration, logging, and visualization. Its management is not that easy. It is also not very flexible and easy to configure. They used to have a product called CSM, but it is no longer being developed. FortiGate is better than this solution in terms of GUI, flexibility, and user-friendliness.\"\n\"I would like it if there was a centralized way to manage policies, then sticking with the network functions on the actual devices. That is probably the thing that frustrates me the most. I want a way that you can manage multiple policies at several different locations, all at one site. You then don't have to worry about the connectivity piece, in case you are troubleshooting because connectivity is down.\"\n\"One thing that we really would have loved to have was policy-based routing. We had a lot of connections, and sometimes, we would have liked to change the routing depending on the policies, but it was lacking this capability. We also wanted application filtering and DNS filtering.\"\n\"They need a user-friendly interface that we could easily configure.\"\n\"I would like to see the inclusion of a protocol that can be used to protect databases.\"\n\"Recently, we have been having an issue with the ASA firewall. We haven't found the root cause yet and are still working on it. We failed over the firewall from active to passive and suddenly that resolved the issue. We are now working to find the root cause.\"\n\"There is huge scope for improvement in URL filtering. The database that they have is not accurate. Their content awareness and categorization for URL filtering are not that great. We faced many challenges with their categorization and content awareness. They should improve these categorization issues.\"\nCisco Firepower Next-Generation Firewall (NGFW) is a firewall that provides capabilities beyond those of a standard firewall and delivers comprehensive, unified policy management of firewall functions, application control, threat prevention, and advanced malware protection from the network to the endpoint.\nCisco NGFW Firewalls include advanced threat defense capabilities to meet diverse needs, from small offices to high-performance data centers and service providers, and are deployed in leading private and public clouds. Available in a wide range of models, Cisco NGFW can be deployed as a physical or virtual appliance. Cisco NGFW firewalls are also available with clustering for increased performance, high availability configurations, and more.\nKey Features of Cisco NGFW Firewalls\nReviews from Real Users\nCisco NGFW stands out among its competitors for a number of reasons. Two major ones are its extensive discovery abilities that enable you to constantly see what is happening on your network and take action when necessary, and the high level of protection it provides.\nMike B., a director of IT security at a wellness & fitness company, writes, \"It is one of the fastest solutions, if not the fastest, in the security technology space. This gives us peace of mind knowing that as soon as a new attack comes online that we will be protected in short order. From that perspective, no one really comes close now to Firepower, which is hugely valuable to us from an upcoming new attack prevention perspective.\"\nZhulien K., the lead network security engineer at TechnoCore LTD, notes, \" The most valuable feature that Cisco Firepower NGFW provides for us is the Intrusion policy. Again, with that being said, I cannot shy away from giving kudos to all of the other features such as AVC (Application Visibility and Control), SSL Decryption, Identity policy, Correlation policy, REST API, and more. All of the features that are incorporated in the Cisco Firepower NGFW are awesome and easy to configure if you know what you are doing. Things almost always work, unless you hit a bug, which is fixed with a simple software update. \"\nAzure Firewall is a user-friendly, intuitive, cloud-native firewall security solution that provides top-of-the-industry threat protection for all your Azure Virtual Network resources. Azure Firewall is constantly and thoroughly analyzing all traffic and data packets, making it a very valuable and secure fully stateful firewall as a service with built-in high availability and unrestricted cloud scalability. Azure Firewall allows users to create virtual IP addresses and provides for secure DDoS protection for the virtual machines on your network. It also provides fast and efficient east-west and north-south traffic security.\nAzure Firewall is a managed, cloud-based network security service built to protect your Azure Virtual Network resources. It is a fully stateful firewall as a service with built-in high availability and unrestricted cloud scalability.\nAzure Firewall has two significant offerings, Standard and Premium.\nAzure Firewall Standard works directly with Microsoft Cyber Security and supplies excellent L3-L7 filtering and threat awareness. The proactive real-time threat awareness will quickly alert you and immediately deny all traffic to and from any known problematic or suspicious domains or IP addresses. Microsoft Cyber Security is updated continually to protect against all new and known potential threats at all times. To learn more about Azure Firewall Standard, click here.\nAzure Firewall Premium provides everything the standard version does, and additionally adds extra levels of data encryption, network intrusion detection, extended URL filtering, and Web category filters. To learn more about the added features of Azure Firewall Premium, click here.\nKey Benefits and Features of Azure Firewall:\nWhat our real users have to say:\nMany IT CEntral Station (soon to be Peerspot) users found Azure Firewall to be very user-friendly and easy to use. They liked that it offers seamless integration to the cloud and were especially pleased with the threat filtering options.\nRegarding integration and threat intelligence, our users wrote:\nCisco ASA Firewall is a security device that combines firewall, intrusion prevention, virtual private network (VPN), and antivirus capabilities. Its main purpose is to provide proactive threat defense to stop attacks before they spread through the network.\nCisco ASA Firewall Features\nCisco ASA Firewall has many valuable key features, including:\nCisco ASA Firewall Benefits\nSome of the benefits of using Cisco ASA Firewall include:\nReviews from Real Users\nBelow are some reviews and helpful feedback written by Cisco ASA Firewall users.\nA Cisco Security Specialist at a tech services company says, “All the features are very valuable. Among them is the integration for remote users, with AnyConnect, to the infrastructure. All the security through that is wonderful and it's very easy. You connect and you are inside your company network via VPN. Everything is encrypted and it's a very good solution.” He goes on to add, “The intrusion prevention system, the intrusion detection, is perfect. But you can also integrate Cisco with an IPS solution from another vendor, and just use the ASA with AnyConnect and as a firewall. Cisco ASA also provides application control. You can block or prevent people from going to certain applications or certain content.”\nJonathan M., Head of Information Communication Technology at National Building Society, comments, \"The benefits we see from the ASA are connected to teleworking as well as, of course, having the basic functionality of a firewall in place and the prevention of attacks. The standard reports allow us to constantly monitor our environment and take corrective steps.”\nEric H., CEO at NPI Technology Management, explains, “The command-line interface is really useful for us. We script basic installations and modifications through the command-line, which is considered sort of old school, and yet it allows us to fully document the changes that we're making due to the fact that we can save the exact script that was applied and say, \"Here are the changes that we made.\"\nAzure Firewall is ranked 19th in Firewalls with 17 reviews while Cisco ASA Firewall is ranked 4th in Firewalls with 90 reviews. Azure Firewall is rated 7.0, while Cisco ASA Firewall is rated 8.4. The top reviewer of Azure Firewall writes \"Good value for your money, good URL filtering, supports intrusion prevention, and is stable\". On the other hand, the top reviewer of Cisco ASA Firewall writes \"Includes multiple tools that help manage and troubleshoot, but needs SD-WAN for load balancing\". Azure Firewall is most compared with Palo Alto Networks NG Firewalls, Fortinet FortiGate-VM, Palo Alto Networks VM-Series, Check Point NGFW and Sophos XG, whereas Cisco ASA Firewall is most compared with Fortinet FortiGate, Palo Alto Networks WildFire, Meraki MX, pfSense and OPNsense. See our Azure Firewall vs. Cisco ASA Firewall report.\nSee our list of best Firewalls vendors.\nWe monitor all Firewalls reviews to prevent fraudulent reviews and keep review quality high. We do not post reviews by company employees or direct competitors. We validate each review for authenticity via cross-reference with LinkedIn, and personal follow-up with the reviewer when necessary."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"search_simple"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"answer_length","category_name":"concise"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"illustrative_examples"},{"categorization_name":"user_profile","category_name":"novice_inquirer"}],"document_ids":["<urn:uuid:3011fa7b-6c5b-4024-93a6-264bdb4519c5>","<urn:uuid:7649a712-492c-4a71-abdf-5fa43b8cac47>"],"error":null}
{"question":"How do honey production and pollination capabilities compare between solitary bees and colony-living bees?","answer":"Colony-living bees like honey bees are major honey producers and pollinators, with a single hive capable of making two pounds of honey per day and honey bees performing about 80% of crop insect pollination. In contrast, while the majority of bee species (over 90%) are solitary bees - including mason bees, carpenter bees, leafcutter bees, and sweat bees - these species live alone and don't produce honey in colonies. However, both types of bees contribute to pollination, with solitary bees like sweat bees being particularly abundant in the Northern Hemisphere.","context":["Yellow Medicine County Bug Camp Beekeeping\nBeekeeping's benefit to agriculture\nThe U.S. Department of Agriculture has estimated that about 3.5 million acres of U.S. fruit, vegetable, oilseed and legume seed crops depend on insect pollination. Another 63 million acres derive some benefit from insect pollination. An estimated 80 percent of crop insect pollination is accomplished by honey bees.\nA 1989 Cornell University study concluded that the direct value of honey bee pollination to U.S. agriculture is $9.7 billion.\nAbout one-third of the total human diet is derived directly or indirectly from insect pollinated plants.\nThe production of most beef and dairy products consumed in the United States is dependent on insect-pollinated legumes (alfalfa, clover, lespedeza, etc.).\nHow many bees does it take?\nTo pollinate California's approximately 360,000 bearing acres of almonds, it is estimated that 250,000 colonies of honey bees must be borrowed from other states to add to the 500,000 colonies already in the state.\nThe practice of renting bees to pollinate crops has expanded rapidly. Most pollination services available to growers in the United States are provided by commercial beekeepers.\nHoney bee facts\nHoney bees are social insects, with a marked division of labor between the various types of bees in the colony. A colony of honey bees includes a queen, drones and workers.\nThe queen is the only sexually developed female in the hive. She is the largest bee in the colony. A two-day old larva is selected by the workers to be reared as the queen. She will emerge from her cell 11 days later to mate in flight with approximately 18 drone (male) bees. During this mating, she receives several million sperm cells, which last her entire life span of nearly two years. The queen bee can lay 9,000 eggs in one day.\nDrones are stout male bees which have no stingers. Drones do not collect food or pollen from flowers. Their sole purpose is to make with the queen. If the colony is short on food, drones are often kicked out of the hive.\nThe buzz about honey\nA hive of bees can make two pounds of honey a day. To create that much honey nectar from 100,000 flowers needs to be gathered. Talk about \"bee-ing\" active!\nA honey bee flies a distance equal to twice around the world in its lifetime!\nIf you want to know where a bee finds its nectar, just watch it dance. Bees explain nectar location to others in the colony with funny dance like performances. Honey bees are social insects. They communicate with each other by dancing. They do this to tell nest mates where pollen and nectar are available. There are two common dances. The round dance tells recruits that food is close by the hive. The waggle dance communicates specific information about the distance and direction of the food.\nBees love honey as much as people do. In fact, the whole process of making honey is a way of storing up food for the bee colony.\nBees may buzz a lot, but you won't hear honey bees complaining. They are totally deaf.\nA busy bee will produce just one-twelfth of a tablespoon of honey in a lifetime.\nAll honey will crystallize (develop sugar-like granules) in time. Honey will crystallize rapidly if placed in the refrigerator. Place one jar of honey in your refrigerator and one jar in a cabinet to compare. Don't worry. You can make the crystals disappear. Carefully place the jar in a pan of warm water. When heated, the honey will re-liquefy. Some honey (called creamed or spun) is finely crystallized. This makes the honey spreadable like butter.\nTalk like a beekeeper\nAnther: The area where pollen is developed and contained in a plant.\nApiarist: A beekeeper\nApiary: Where several bee colonies are kept in one place.\nBee bread: Mixture of pollen and honey fed to bees after they are three days old.\nBeehive: A place where a bee colony dwells. Beekeeping\nBeeswax: Secreted wax from the underside glands of the bee abdomen; bees mold the wax to form honeycomb.\nBrood: A group of bees born at the same time.\nBrood of chamber: Place in the hive where the queen lays her eggs.\nColony: A community of tens of thousands of worker bees, usually containing one queen, with or without drones.\nComb honey: Honey presented in its original wax comb.\nCrystallization: Honey is a supersaturated solution. Crystals will develop in honey when glucose crystallizes out of solution. Crystallization of honey is most rapid at 57 degrees F.\nDrone: A male bee.\nExtracted honey: Honey removed from the comb by a special machine called an extractor and sold in liquid or crystallized form.\nHive tool: A tool the beekeeper uses to pry the frames out of the hives.\nLarvae: A wingless, newly hatched bee.\nNectar: Sweet liquid from flowers that bees use to make honey.\nNurse bee: Bee that is in charge of caring for and feeding the larvae.\nPollination: Fertilization of a flower by a bee. The bee collects pollen from one flower on her legs and transfers it to other flowers when she lands on them.\nPupae: The stage of a bee's life between the larval stage and the adult.\nQueen: The female bee that lays all the eggs in the colony. There is only one queen bee in a colony.\nRoyal jelly: The food the larvae eat for the first three days of their lives.\nSmoker: Tool which sends out small amounts of smoke which calms the bees so the beekeeper can safely look at the hives.\nSuper: Where honey is stored.\nVenom: Poison produced by the bee that is injected into your skin when a bee stings you. This is what makes a bee sting hurt.\nWorker: A sterile female bee that performs special jobs in and around the hive.\nWhy Do Bees Sting?\nBees do not sting for the fun of it. A bee's sting is a way of protecting itself. She will only sting when she feels threatened or to protect her hive if she feels it is being invaded. If you don't bother her or make her feel like she or her hive is in danger, she won't bother (STING!) you.\nWhat does the beekeeper do?\nNot only are the bees hard at work year round (since they do not hibernate), but the beekeeper is \"busy as a bee\" as well. In the summer, he has to make sure there are plenty of flowers around the hive so the bees can collect the nectar to make honey. He also has t collect the honey after the supers fill up. In the fall, he extracts the honey and the supers. He feeds sugar water to the hive and wraps the hive to protect it from the winter cold. During the winger he makes sure the bees have sugar water to eat and that the hive is well insulated. When spring comes, he removes the winter wraps and moves the hive to a spot where spring flowers are blooming.\nNational Honey Board, 390 Lashley Street, Longmont, Co 80501\nPenn State SRUA, 324 Henning Bldg, University Park PA 10802, 814-863-7738","There are many interesting facts about honey bees we love to learn. Bees are wingless insects that are related to wasps and ants. They are renowned for pollination and, in the case of the most well-known bee species, the western honey bee, honey production. Let’s learn more interesting facts about honey bees in this article.\nWithin the superfamily Apoidea, bees are a monophyletic lineage. They are now classified as a clade known as Anthophila. Bees are classified into seven biological groups with approximately 16,000 species.\nSome species, such as honey bees, bumblebees, and stingless bees, live in colonies, but the majority (>90 percent) of species, such as mason bees, carpenter bees, leafcutter bees, and sweat bees, live alone.\nBees can be found in any environment on the globe that includes insect-pollinated blooming plants, with the exception of Antarctica. The Halictidae, or sweat bees, are the most abundant bees in the Northern Hemisphere, yet they are tiny and sometimes mistaken for wasps or flies.\nBees range in size from tiny stingless bee species with workers measuring less than 2 millimeters (0.08 in) long to Megachile pluto, the largest species of leafcutter bee with females measuring up to 39 millimeters in length (1.54 in)\nInteresting facts about honey bees\nThe biodiversity on which we all rely for survival includes bees. They provide premium foods including honey, royal jelly, and pollen as well as other items like beeswax, propolis, and honey bee venom. Honeybees have a top speed of 15 miles per hour. In her lifespan, a honey bee worker only produces 1/12 of a teaspoon on average. A bee could fly across the world on one ounce of honey. A pound of honey is produced by 2 million visits to flowers. More fascinating details about bees will be covered in this post! Find here 25 interesting facts about honey bees!\n1. The sense of smell of a bee is so sensitive that it can distinguish between hundreds of different flowers. It can also determine whether a flower has pollen or nectar from a distance of many feet.\n2. In a specific gland on their stomach, bees produce wax, which they subsequently consume to build honeycomb.\n3. Bees interact with each other in two ways: the waggle dance and the usage of pheromones.\n4. Female bees in the hive (excluding the queen) are termed worker bees\n5. Number of eggs produced by queen: 2,000 per day is the high\n6. When flying to a food source, a worker honey bee may reach speeds of 15–20 mph. When it’s transporting nectar, it’s a little slower on the way back, at 12 mph (19 kph).\n7. Many of our common items, such as furniture polishes, cosmetics, and medications, include beeswax.\n8. Some worker bees are designated as “undertaker bees,” responsible for removing deceased bees from the hive.\n9. Honey bees outnumber London inhabitants 30 to 1 during the summer months, thanks to the growing popularity of urban beekeeping.\n10. Honeycomb is made out of precise hexagons that store the most honey with the least amount of material (wax).\n11. A bee colony has 20,000–60,000 bees and one queen.\n12. While a queen honey bee may live for up to five years, worker honey bees only survive for approximately six weeks and are responsible for all of the labor.\n13. In Napoleonic heraldry, bees were a popular animal to use.\n14. The bee was both a sign of immorality and a symbol of rebirth. It was selected to connect the new monarchy to France’s earliest beginnings.\n15. People in ancient Egypt used honey to pay their taxes.\n16. Bees use the sun as a compass and polarized light to navigate on overcast days.\n17. Honey bees must collect nectar from approximately 2 million blossoms to create one pound of honey.\n18. All of the labor in the hive is done by the females. The primary purpose of the drones is to mate with a queen.\n19. Bees have four stages of development: egg, larval, pupae, and adult.\n20. Honey has antimicrobial qualities and may be used on wounds as a dressing.\n21. Bees have been dying off at a rate of about 30% each year as a result of colony collapse disorder.\n22. Beekeepers in Wisconsin can seek to have their honey certified as pure and use the label “Wisconsin-certified honey” on their products.\n23. Bees despise the smell of human breath.\n24. A hive of bees must travel 55,000 miles to produce a pound of honey.\n25. Honey bees do not take naps. Instead, they sleep immobile at night to save energy for the next day’s activities.\nMore Interesting Articles\n- Thomson Safaris Kilimanjaro – A Guide from Tourists\n- Safari Near Victoria Falls: What Other Travelers Follow\n- Great Migration Serengeti – A Wonder of the Wild\n- Serengeti National Park Facts and Tour\n- Busanga Plains – Camping and Wilderness Safaris\n- Sossusvlei Camping and Trip for Adventure Lovers\n- Namibia Safe Road Trip Guide for the Daredevils\n- 32 Essential Tips on Namibia Guided Tours\n- 11 Memorable Safari Trip Options to South Africa\n- That is Why Travelers Find South Africa Safe to Travel\n- 12 Great Attractions of Zimbabwe Safari Experience\n- Unique Attractions of Mozambique Tours and Travels\n- What to See in the Madagascar Tours and Travels\n- Great Attractions of Thrilling Malawi Safari\n- 11 Great Spots to Spot in Botswana Safari\n- Ultimate Namibia Road Trip Itinerary\n- How Much Does it Cost to Travel to Zambia?\n- Adventurous Kenya Safari Tours for Daredevils\n- Zambia Safari Tips for the Adventure Lovers\n- 13 Best Places For Safari Trip to Zambia"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"multilingual_categorization","category_name":"monolingual"},{"categorization_name":"question_formulation","category_name":"natural_simple"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"answer_length","category_name":"detailed"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_intent","category_name":"information_seeking"},{"categorization_name":"user_preferred_response_style","category_name":"concise_direct"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"}],"document_ids":["<urn:uuid:9729ea3e-985f-4051-9c40-0846b43dbd2d>","<urn:uuid:3479851d-742d-4238-85f4-0e1d3ee01cfc>"],"error":null}