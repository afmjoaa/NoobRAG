{"question":"How effective is cover crop mulch for weed control, and what adjustments to herbicide programs can farmers make when using cover crops?","answer":"Cover crop mulch provides some weed control, with 10 cm (4 inches) of biomass needed for 75% inhibition of weed emergence. However, this may not be sufficient for the whole growing season. Rolling/crimping tends to provide better weed suppression and more uniform residue placement than mowing. When using cover crops, farmers can significantly adjust their herbicide programs - some are able to grow soybeans with just a pre-emergence herbicide application, and if post-emergence treatment is needed, it often requires just one application. Farmers have reported saving $75-80 per acre by cutting out tillage practices associated with conventional weed control.","context":["Rolling or mowing high-residue cover crops like rye and vetch can provide a weed-suppressing and moisture-holding mulch into which vegetable and grain crops can be direct seeded or transplanted. These systems have been successful for tomatoes, pumpkins, broccoli, and other vegetable crops that are later-planted and are not negatively affected by the soil cooling effect of mulch.\nTerminating cover crops in timely manner in spring/summer can be one of the most challenging aspects of these systems. Many growers who use herbicides terminate their cover crops chemically before they can be killed mechanically. Attempting to kill a cover crop mechanically before flowering will result in regrowth. This limits the timing for organic growers, many of whom find they cannot wait until mechanical termination is possible for their first round of some cash crops. Nonetheless, these high-residue systems show a lot of potential for weed suppression, moisture conservation, and erosion reduction.\nIn general, it is believed that rolling/crimping leads to better weed suppression and more uniform residue placement than mowing, resulting in less equipment trouble when planting the following crop. However, some reports have indicated that flail mowing of cover crops is equally effective.\nEven though cover crop mulch provides some weed control, it may not be sufficient for the whole growing season. It has been estimated that to achieve 75% inhibition of weed emergence, 10 cm (4 inches) of biomass is necessary (read more on mulch and weed suppression). Dr. Gerald Brust at University of Maryland looked at using a weed barrier (cloth) for just 1-2 weeks early in the season, and found it increased weed control substantially in organic tomatoes. We recently tried using supplemental tarps to kill rye, vetch and weeds and had some encouraging results in our first trial with black tarps. In Germany, researchers are experimenting with supplemental cut-and-carried mulch for increasing weed suppression.\nFurther Reading and Watching\nThere is a lot of information on rolling/crimping cover crops, but relatively little information on using these cover crop-based systems for vegetable production. The resources listed here cover different parts of the country and we suggest contacting some of the experts in your region for more information.\nWeed ’em and Reap Part II: High residue systems (Videos) featuring Mark Schonbeck, Ron Morse, and others. These videos are incredibly helpful for people considering high-residue systems and have great visuals.\nOrganic Reduced Tillage in the Pacific Northwest eOrganic page of the Washington State University project. Includes regionally important information and cover crop variety trials for the Pacific Northwest.\nReduced Tillage and Cover Cropping Systems for Organic Vegetable Production by Mark Schonbeck and Ron Morse. Project supported by Southern SARE.\nFacilitating Improved Soil Quality on Organic Farms through Research and Training on No-Till Organic Vegetable Production in the Midwest Update on 2010 project at Iowa State University with no-till broccoli and squash.\nWhat is “Organic No-till” and is it Practical? by Mark Schonbeck (from eOrganic)\nRodale Institute has published a report, Beyond Black Plastic, on using cover crop mulches for no-till vegetable production. These systems have come a long way in the last 20 years.\nCover Crops and No-Till Management for Organic Systems, from the Rodale Institute. (includes nice pictures and discussion of equipment needed for high-residue transplanting and cultivation as well as an extensive reference list).","“We let the cover crop get as tall as it can,” says Adam Chappell, a no-till corn, cotton, rice, and soybean farmer at Cotton Plant, Ark. “We’ve learned that the bigger the cover crop gets, the more biomass we get, and the more diverse the cover crop the bigger the benefits.”\nHe plants his commercial crops into the green cover, then kills the cover with herbicides before the crops emerge. But, he says he understands why some growers might be reticent about the practice.\n“I’ve heard growers say that if the cover crop gets that big, you can’t plant into it,” he said at a Cover Crops Conference held by the Arkansas Soil Health Alliance. “But, you can plant into it — you don’t need anything special. The equipment we use is probably the same type of planter you have.”\nChappell says he learned much of what he knows about cover crops by watching YouTube videos done by cover crop enthusiasts in other parts of the country. Here are some tips for growing cover crops that he and other proponents have developed for the Mid-South:\n- Cover crop diversity\nPlant cover crop mixes. Adding a legume to the mix can increase the soil nitrogen level by 80 pounds to 160 pounds, Chappell says. “We’re learning that we can reduce our nitrogen applications by about 30 percent for corn behind a cover crop mixture.”\nCover crop mixtures can be more expensive. Chappell and other members of the ASHA say they spend from $30 to $35 per acre for cover crop seed and planting. “But, the benefits are greater than the costs because of added soil nutrients and improvements in soil health,” says Lonoke, Ark., farmer Robby Bevis, who is president of the ASHA. “Some of these cover crop species can put roots 7 feet to 8 feet in the ground, which helps break up the soil.”\nIf you don’t feel comfortable planting multiple species, start simple with crops like wheat or cereal rye. Once you have a season or two under your belt, you can add more diversity.\n- Drill cover crops\nDrill cover crops when possible. Because of time constraints, some farmers broadcast cover crops into the summer crop or old crop residue, but cover crop specialists advise against it.\n“The broadcast method of seeding is successful about half the time,” says Greg Brann, soil health specialist with the Tennessee Association of Conservation Districts. “We would prefer that people drill it. I know it takes more time, but that’s the best way.”\nFor example, specialists say if growers decide to broadcast, they should try to time seeding of cover crops when soybean leaves are beginning to turn yellow and rain is forecast within a day or two of planting.\n- Use a decision aid to help plan your cover crop program\nUse a decision aid to help plan your cover crop program. Land grant universities and the USDA Natural Resources Conservation Service have developed software programs that can provide checklists for making sure you account for costs before you commit to the approach.\nOne is the Cover Crops Cost Calculator (https://bit.ly/2Mgohlz), developed by Naveen Adusumilli with the Department of Agricultural Economics and Agribusiness at the LSU AgCenter. USDA has a NRCS Cover Crop and Tillage Decision Tool (https://bit.ly/2vvy7Xe) to help growers determine costs and benefits, and to learn if NRCS cost-share assistance is available.\n- Plan for crop termination\nPlan for cover crop termination. Whether you decide to follow university recommendations and kill the winter vegetation three to four weeks before planting in order to eliminate a “green bridge” for insects, or you wait until planting, you need to have a plan.\nMost land-grant universities advise terminating cover crops or winter vegetation ahead of planting, so cutworms, pea leaf weevils, southern corn rootworms, three-cornered alfalfa hoppers, slugs, and other pests cannot simply move to the commercial crop. Killing the covers at that time may also help with planting for those new to cover crops.\n“Some people say they can’t kill the cover crops when they get big,” says Chappell. “But you can, in a multitude of ways. Roundup works pretty well, as does Gramoxone.”\n- Seed treatment for burndown\nIf you decide to terminate at planting, use a seed treatment such as imidacloprid.\n“Where we did our burndown the day of planting, having a seed treatment mattered a lot,” says Dr. Scott Stewart, professor in the University of Tennessee Department of Entomology and Plant Pathology. “Without it, we basically lost the majority of our stand.”\nHe says insects such as pea leaf weevils, southern corn rootworms, three-cornered alfalfa hoppers and slugs will feed on soybeans and cotton when those crops emerge in newly killed cover crops. Finding slugs can be a challenge because they remain in the soil or under residue until late in the day or at night.\n- Adjust herbicide program\nYou may be able to adjust your herbicide program. “We’ve seen great improvements in weed suppression, and in this era of weed resistance, we’re seeing some additions for the management of these weeds with cover crops,” says Dr. Forbes Walker, associate professor in the University of Tennessee Department of Biosystems Engineering and Soil Science.\nIn Arkansas, Chappell and Bevis say they have been able to save $75 to $80 an acre just by cutting out tillage practices associated with conventional weed control. They’re also using fewer chemicals in season.\n“We’re growing some soybeans with just a pre-emergence herbicide application,” says Chappell. “And if we do have to come back postemergence, it’s usually with just one.”\n- Furrow irrigation\nDon’t give up on furrow irrigation. “Farmers look at the dense residue in our middles and when it’s time to irrigate, they say: ‘How do you deal with that?’” says Chappell. “We use a small furrow runner implement built by my brother, Seth, that creates a 4-inch trench, and we send water down that trench. We don’t need as much irrigation because the residue helps hold the moisture in the soil. But we can water.”\n- Adding livestock\nConsider adding livestock to your rotation. Mike Taylor and his son, Michael Taylor, Jr., who farm at Helena, Ark., have been grazing cattle on their cover crops to get more return on their investment. They’ve reported significant weight gains on the cattle while they’ve continued to improve their soils.\n- Yield benefits\nDon’t expect yield increases every year from planting cover crops. “We’re not growing cover crops just to get a yield benefit,” says Forbes Walker, who spoke at the Milan, Tenn., No-Till Field Day. “Don’t expect to get one every year. We are seeing a benefit when things go bad — when we have a dry year or a drought.”"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:9a9efc51-6c6f-4d8e-aa3b-bcd4696dcd63>","<urn:uuid:7cb240b3-6dfd-4463-b4ef-26be0713b8e6>"],"error":null}
{"question":"What are the differences between testimony and settlement in legal proceedings?","answer":"Testimony and settlement are quite different legal concepts. Testimony is what a witness gives at a trial, typically when being examined to establish material facts. Settlement, on the other hand, is an amicable solution reached between two parties to avoid or shorten litigation, typically achieved through mutually agreeable terms.","context":["International Public Law – Key Terms, Part II (Jan. 4, 2021)\nHave a look at these 15 terms related to International Public Law, a key area of Legal English. Would you know the answers? In few cases more than one answer would be acceptable. I will be posting them next week!\n1.what a witness gives at a trial; She gave extensive _______________ as her lawyer examined her to establish the material facts.\na) testimony b) account c) story d) narrative\n2. the legal reasons for filing/bringing of a lawsuit/action/claim against someone; On what ______________ are you thinking of bringing this Class Action?\na) basis b) grounds c) foundation d) motive\n3. a draft of law presented to a legislature for enactment; The government is currently drafting a new ______ on Universal Basic Income and it is expected that it may pass the first vote.\na) legislation b) regulation c) bill d) ordinance\n4. a separate opinion written by one or more justices in a case; this opinion disagrees with the decision of the majority of the court; Justice Roberts wrote the ___________ opinion in this case, disagreeing with the majority’s decision that the Plaintiff’s civil rights were not violated.\na) diverging b) dissenting c) disagreeing d) all of the above\n5. the fixed amount of time that something lasts for; This Treaty has a ___________ of 10 years at which point its terms may have to be renegotiated.\na) period b) validity c) expiry date d) term\n6. to make a decision on a specific point of law; The Judge ______ that, on the specific facts of the case, the Plaintiff was obligated to mitigate his damages.\na) decided b) concluded c) held d) stated\n7. when Court decides which party to the dispute is the “winner”; Given the lack of admissible evidence presented by the Plaintiff, the Court had no choice but to __________ the Defendant.\na) find for b) rule for c) adjudicate for d) a & b\n8. i) to use a law or rule in order to achieve something; ii) to mention law, principle or idea in order to support an argument; The Claimant’s attorneys ______________ the Universal Declaration of Human Rights to support their argument that the Claimant was unfairly discriminated against.\na) invoked b) cited c) relied on d) a & c\n9. having required qualities or fulfilling the required conditions to do, be or get something; In Japan, employees are not _______________ to more than 10 paid vacation days.\na) qualified b) permitted c) eligible d) all of the above\n10. period within which a prosecution or civil action can be initiated against someone; Unfortunately, you have waited too long to bring this action. Due to the operation of the _________________, you are barred from initiating proceedings at this point.\na) lapse period b) limitation period c) statute of limitation d) b & c\n11. the detailed written legal explanation of the court/tribunal/Board for the decision reached in any case; Upon carefully analysing the Board’s _____________ for the decision, the lawyer decided that it was appealable as there were several reviewable errors.\na) reasons b) findings c) rulings d) all of the above\n12. to “appeal” a decision of any governmental body/ to “appeal” an administrative decision; They are going to __________ the EU Council’s designation of the country as a tax heaven.\na) question b) appeal c) challenge d) undermine\n13. when a Court is unable to reach a decision immediately after the conclusion of a trial or hearing; The Court has decided to _______________ its judgment until requested additional evidence is provided by the parties.\na) delay b) postpone c) adjourn d) reserve\n14. an amicable solution to a dispute between two parties to avoid (or to shorten) litigation; Given the costs of potential litigation, they have decided to reach a _____________ on mutually agreeable terms.\na) agreement b) settlement c) resolution d) contract\n15. to consider or judge something in a particular way; The Court ___________ that President Trump’s conduct during the Russia investigation did not amount to obstruction of justice.\na) deem b) interpret c) construed d) all of the above\nInternational Public Law – Key Terms, Part II: ANSWER KEY\n1 a; 2 b; 3 c; 4 b; 5 d; 6 c; 7 d; 8 d; 9 c; 10 d; 11 a; 12 c; 13 d, b & c; 14 b; 15 a"],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"comparison"}],"document_ids":["<urn:uuid:fd72f444-00f1-4a5f-a284-86e483085279>"],"error":null}
{"question":"What's the difference between HTTP GET and POST redirects, and how do they relate to web security?","answer":"HTTP GET and POST redirects differ in their behavior: 301, 302, and 303 response codes will switch POST requests to GET by default, while 307 and 308 maintain the original method. For security, this distinction is crucial as improper input validation (#4 in SANS Top 25) and improper authentication (#14) can be exploited through redirect manipulation. Web applications must carefully validate all redirect targets since they're part of user-controlled inputs that can lead to various security vulnerabilities, including cross-site request forgery (CSRF, ranked #9 in SANS Top 25) and server-side request forgery (SSRF, #24).","context":["I find that many web minded people working client-side or even server-side have neglected to learn the subtle details of the redirects of today. Here’s my attempt at writing another text about it that the ones who should read it still won’t.\nNothing here, go there!\nThe “redirect” is a fundamental part of the HTTP protocol. The concept was present and is documented already in the first spec (RFC 1945), published in 1996, and it has remained well used ever since.\nA redirect is exactly what it sounds like. It is the server sending back an instruction to the client – instead of giving back the contents the client wanted. The server basically says “go look over [here] instead for that thing you asked for“.\nBut not all redirects are alike. How permanent is the redirect? What request method should the client use in the next request?\nAll redirects also need to send back a Location: header with the new URI to ask for, which can be absolute or relative.\nPermanent or Temporary\nIs the redirect meant to last or just remain for now? If you want a GET to resource A permanently redirect users to resource B with another GET, send back a 301. It also means that the user-agent (browser) is meant to cache this and keep going to the new URI from now on when the original URI is requested.\nThe temporary alternative is 302. Right now the server wants the client to send a GET request to B, but it shouldn’t cache this but keep trying the original URI when directed to it.\nNote that both 301 and 302 will make browsers do a GET in the next request, which possibly means changing method if it started with a POST (and only if POST). This changing of the HTTP method to GET for 301 and 302 responses is said to be “for historical reasons”, but that’s still what browsers do so most of the public web will behave this way.\nIn practice, the 303 code is very similar to 302. It will not be cached and it will make the client issue a GET in the next request. The differences between a 302 and 303 are subtle, but 303 seems to be more designed for an “indirect response” to the original request rather than just a redirect.\nThese three codes were the only redirect codes in the HTTP/1.0 spec.\nGET or POST?\nAll three of these response codes, 301 and 302/303, will assume that the client sends a GET to get the new URI, even if the client might’ve sent a POST in the first request. This is very important, at least if you do something that doesn’t use GET.\nIf the server instead wants to redirect the client to a new URI and wants it to send the same method in the second request as it did in the first, like if it first sent POST it’d like it to send POST again in the next request, the server would use different response codes.\nTo tell the client “the URI you sent a POST to, is permanently redirected to B where you should instead send your POST now and in the future”, the server responds with a 308. And to complicate matters, the 308 code is only recently defined (the spec was published in June 2014) so older clients may not treat it correctly! If so, then the only response code left for you is…\nThe (older) response code to tell a client to send a POST also in the next request but temporarily is 307. This redirect will not be cached by the client though so it’ll again post to A if requested to. The 307 code was introduced in HTTP/1.1.\nOh, and redirects work the exact same way in HTTP/2 as they do in HTTP/1.1.\nThe helpful table version\n|Switch to GET||301||302 and 303|\n|Keep original method||308||307|\nIt’s a gap!\nWhat about other HTTP methods?\nThey don’t change methods! This table above is only for changing from POST to GET, other methods will not change.\ncurl and redirects\nI couldn’t write a text like this without spicing it up with some curl details!\nIt turns out that there are web services out there in the world that want a POST sent, are responding with HTTP redirects that use a 301, 302 or 303 response code and still want the HTTP client to send the next request as a POST. As explained above, browsers won’t do that and neither will curl – by default.\nSince these setups exist, and they’re actually not terribly rare, curl offers options to alter its behavior.\nYou can tell curl to not change the POST request method to GET after a 30x response by using the dedicated options for that:\n–post301, –post302 and –post303. If you are instead writing a libcurl based application, you control that behavior with the CURLOPT_POSTREDIR option.\nHere’s how a simple HTTP/1.1 redirect can look like. Note the 301, this is “permanent”:","Differences between the SANS Top 25 and OWASP Top 10\nWhile they both serve as a reference point for software security and are partly based on the same source data, the SANS/MITRE CWE Top 25 and the OWASP Top 10 differ in scope and purpose. The OWASP list groups the most prevalent web application security weaknesses into ten categories corresponding to broader cybersecurity concerns. With each subsequent edition, the categories have been moving away from specific vulnerabilities or even common vulnerability classes and towards a more strategic view – see our post on the 2021 OWASP Top 10 to learn what this means in practice.\nThe SANS/CWE Top 25 lists the most prevalent issues from the Common Weakness Enumeration (CWE). In a way, CWE takes the opposite approach to the OWASP list, focusing on specific weaknesses rather than more abstract classifications. This makes the list more directly useful for developers and security engineers, as each item relates to concrete implementation flaws that can be found and addressed. Interestingly, although the SANS/CWE Top 25 applies to all types of software while the OWASP list is limited to web applications, with each edition there is more and more common ground between web and non-web software security.\nWeaknesses vs. vulnerabilities: Both the SANS Top 25 and the OWASP Top 10 deal solely with CWEs, i.e. security weaknesses that commonly occur during software development. These are different from CVEs, which are confirmed security vulnerabilities in specific products. In simple terms, exploitable weaknesses reported in production become vulnerabilities.\nCommon themes in software security weaknesses in 2021\nThe SANS Top 25 list is based on the prevalence of specific weaknesses in real-life vulnerabilities taken from the NIST NVD. Each CWE that has led to a vulnerability gets a score that reflects its frequency and severity (see here for the actual formula), and this score determines its position on the list. A dry technical list doesn’t seem particularly useful or exciting, but if you read closely, the CWE codes, scores, and trends tell the story of modern software development and security – a tale of trust, deceit, and demons of the past, all set firmly in the cloud. Let’s look at the four common themes running through the Top 25.\nWeb application security is everywhere\nIf you came to the SANS TOP 25 CWEs from the OWASP Top 10, you’d be forgiven for having a sense of deja vu, as eight of the top 25 weaknesses are either web-specific or most commonly found in web applications. It’s no secret that as software development moves to the web, so does application security. Here are the four web-specific weaknesses on the list, along with their official names and overall positions:\n- #2: Cross-site scripting (XSS), officially Improper Neutralization of Input During Web Page Generation [CWE-79]\n- #9: Cross-site request forgery (CSRF) [CWE-352]\n- #23: XXE injection, officially Improper Restriction of XML External Entity Reference [CWE-611]\n- #24: Server-side request forgery (SSRF) [CWE-918]\nApart from these, several other weaknesses in the list usually occur in web security contexts, notably SQL injection, OS command injection, and path traversal (a.k.a. directory traversal). While these can apply to other types of software, they are easiest to exploit in web applications. Again, the position reflects the frequency and severity of vulnerabilities linked to a specific weakness, so having XSS way up at #2 means there is a lot of cross-site scripting going on.\nMemory management issues never go away\nOn the one hand, we see that all the cloudy headlines are true – software development is increasingly web development, and software security is increasingly web application security. However, the #1 weakness (along with five relatives) serves as a stark reminder that a lot of critical software relies on lower-level programming languages that need careful memory management. The top software security weakness of 2021 is essentially buffer overflow, though this specific term is considered too general for CWE. Here are the weaknesses related to low-level memory operations:\n- #1: Out-of-bounds write (code can write to memory that shouldn’t be accessible) [CWE-787]\n- #3: Out-of-bounds read (code can read memory that shouldn’t be accessible) [CWE-125]\n- #7: Use after free (code uses a variable that shouldn’t be used anymore) [CWE-416]\n- #12: Integer overflow or wraparound (mismanagement of large numeric values) [CWE-190]\n- #15: NULL pointer dereference (code attempts to access a non-existent value) [CWE-476]\n- #17: Improper restriction of operations within the bounds of a memory buffer (code can operate on memory that shouldn’t be accessible) [CWE-119]\nTrust no one with your inputs\nThe other overarching theme of this software security tale is trust. It is difficult enough to write software that works correctly with the expected data and users. When every user could be malicious and every input could be an attack attempt, writing even the simplest piece of code is like walking through a minefield. How can you do anything when everyone is suspicious? How can you check every piece of data? And yet this is the reality of application security, as shown by over a quarter of the top 25 being weaknesses related to blindly trusting your inputs:\n- #4: Improper input validation [CWE-20]\n- #5: OS command injection, officially Improper Neutralization of Special Elements used in an OS Command [CWE-78]\n- #6: SQL injection, officially Improper Neutralization of Special Elements used in an SQL Command [CWE-89]\n- #8: Path traversal/directory traversal, officially Improper Limitation of a Pathname to a Restricted Directory [CWE-22]\n- #10: Unrestricted upload of file with dangerous type [CWE-434]\n- #13: Loading saved data without checking, officially Deserialization of Untrusted Data [CWE-502]\n- #25: Code injection, officially Improper Neutralization of Special Elements used in a Command [CWE-77]\nIn all these cases, failure to sanitize user-controlled inputs can have devastating consequences, from software crashes to information exposure or code execution. And as mentioned earlier, many of these are typically found in web application security, where user-controlled inputs make up most of the data your application uses.\nTrust no one with access\nThe threat landscape is easily the biggest change across the history of software security. With threat actors now active at every stage of the application lifecycle, access control should be an integral part of software and data design – except that it’s not. All the remaining weaknesses from the Top 25 are related to implicit trust or failures to protect sensitive data at all times, showing that, all too often, security is still an afterthought during development:\n- #11: Missing authentication for critical function [CWE-306]\n- #14: Improper authentication [CWE-287]\n- #16: Use of hard-coded credentials [CWE-798]\n- #18: Missing authorization [CWE-862]\n- #19: Incorrect default permissions [CWE-276]\n- #20: Exposure of sensitive information to an unauthorized actor [CWE-200]\n- #21: Insufficiently protected credentials [CWE-522]\n- #22: Incorrect permission assignment for critical resource [CWE-732]\nThe importance of such trust-related issues is also reflected in the OWASP Top 10, where the top categories are now Broken Access Control and Cryptographic Failures. Ensuring application security means encrypting sensitive data (or all data, in many cases) at rest and in transit using secure algorithms while also thinking of authentication and authorization when designing user roles and function access.\nTo be effective, security must come first\nWith over half of the SANS Top 25 security weaknesses being related to trust and access control, it’s no coincidence that CISA is calling for organizations to implement zero trust principles in their systems. What’s more, the three fastest risers on the list since 2020 are all trust-related: Incorrect Default Permissions, Missing Authentication for Critical Function, and Deserialization of Untrusted Data. And remember that the list is based on prevalence in real-life vulnerabilities, so these weaknesses are out there and growing in frequency or severity (or both).\nThere are no shortcuts to avoiding software vulnerabilities, only hard work to build a security-first mindset and embed security into every stage of the software development lifecycle (SDLC). Vulnerability testing, mitigation, and remediation all need to be a routine part of the development workflow, built on a solid foundation of education and security awareness.\nOrganizations can no longer afford to compromise on security or accept security risks as the price of rapid development and growth. When anything can be a target and anyone can be an attacker, security must come first."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:6fc085c6-1494-403c-83fd-4f0295c658e4>","<urn:uuid:8aeaf7b5-d75a-4b60-bbba-d0bb596a8aad>"],"error":null}
{"question":"As a mental health professional, I'm curious: what's the key difference between the support offered by The Lighthouse service versus standard NHS GP services for mental health issues?","answer":"The Lighthouse is specifically an informal, out-of-hours mental health service for adults (18+) offering short-term support during difficult times, staffed by people with lived experience of mental health challenges. In contrast, NHS GP services provide primary healthcare during regular office hours (typically 8:30 to 18:30 Monday to Friday) and serve as gatekeepers to specialized mental health services through referrals to specialist doctors when needed.","context":["Safeguarding and Supporting Parents\nWhat is safeguarding?\nSafeguarding is the action that is taken to promote the welfare of children and protect them from harm. All adults in the USH community work together to protect our children. It is our highest priority.\n- protecting children from abuse and maltreatment\n- preventing harm to children’s health or development\n- ensuring children grow up with the provision of safe and effective care\n- taking action to enable all children and young people to have the best outcomes.\nChild protection is part of the safeguarding process. It focuses on protecting individual children identified as suffering or likely to suffer significant harm. This includes child protection (click here then scroll down to see our dedicated Child Protection Policy on our Policies Page) which details how we respond to concerns about a child.\nParents and carers work in partnership with the school and we recognise that from time to time you may need support.\n**If as a parent you are concerned about your own child or another young person you should inform any member of the pastoral team or Designated Safeguarding Lead, Miss Clements via Email** Anneli.Clements@ushschool.org\n**If you are a student who needs to report a concern, please tell any member of staff.**\nUSH isaware of the media attention around the Everyone’s Invited movement. The Government have announced a review into sexual abuse in schools. Ofsted are now undertaking an immediate review of all schools' safeguarding policies which will conclude by end of May 2021. USH would like to assure parents that the senior leadership team review our policies and practices regularly and in conjunction with Hamwic Education Trust.\nA new helpline to support potential victims of sexual harassment and abuse in education settings has opened today. 0800 136 663 The dedicated number, run by the NSPCC, provides both children and adults who are victims of sexual abuse with the appropriate support and advice. This includes how to contact the police and report crimes if they wish. The helpline will also provide support to parents.\nAdditional Support for parents in Southampton:\nThe Lighthouse is an informal, non-judgemental, out-of-hours mental health service for anyone over the age of 18 who requires short-term support in times of great difficulty or is struggling with poor mental health.\nOur team is made up of people who have lived experience of mental health challenges and using services, people who hold a professional registration, and people who fall across both categories.\nVisiting the Lighthouse may be useful if you are:\n· Feeling overwhelmed or hopeless.\n· In need of urgent mental health support\n· Having thoughts to end your life\n· Feeling isolated or alone\n· Confused about where to find support\nThose in mental health crisis or emotional distress can text ‘lighthouse’ and their postcode (for example LIGHTHOUSE SO14 0YG) to the Mind text line number (07451 276010) between 4.30pm and 12am. Our staff will then contact them via telephone, email, webchat or text. To find out more please visit https://www.southernhealth.nhs.uk/locations/the-lighthouse/","Introduction to the National Health Service\nThis fact sheet has been written to explain the role of UK health services, the National Health Service (NHS). It covers issues such as the role of GPs, their function as gatekeepers to the health services, how to register and how to access emergency services.\nNational Health Service (NHS)\nThis leaflet explains how the National Health Service (NHS) works in the UK.\nThe National Health Service provides health care in the UK and is funded by taxation. None of the people who work for the NHS, including doctors, nurses and interpreters, will pass on any information about you to any other person or organisation without your permission.\nHow do I get help with my health?\nIf you are ill or worried about your health or the health of anyone in your family, you should go to see your local doctor, called a General Practitioner (GP). The GP’s clinic is called a Surgery or a Health Centre. You should register with a GP as soon as possible so that you can get medical care if you need it. To register you will need to give your name, date of birth, address and telephone number if you have one. Your support worker, who helped you to move into your accommodation, will know the local arrangements for registering. Some GPs ask all new patients to have a health check. This will usually be carried out by a nurse. It is important that you go to this appointment even if you are well. If a practice will not register you, you can ask the local CCG to assign you to a practice.\nHow do I make an appointment?\nBefore you visit your doctor or one of the nurses at the surgery you will usually need to make an appointment in person or by telephone. You can ask to see a male or female doctor or nurse, although this may not always be possible. You may have to wait a few days for a non-urgent appointment. If you think you need to see the doctor urgently tell the receptionist when you make the appointment, and you will be seen that day if appropriate. If the doctor thinks you are too ill to come to the surgery, he/she may visit you at home. Appointments with the doctor will be for five or ten minutes. You need to make a separate appointment for each member of the family that wishes to see the doctor. Please make sure that you arrive on time for your appointment and if you are unable to attend your appointment please make sure you cancel it.\nWhat if I do not speak English?\nIf you need an interpreter you must tell the receptionist when you make the appointment. Tell the staff which language you speak and they will book an interpreter for you or get an interpreter on the phone. It is important that you and the doctor understand each other so that he/she can make an accurate diagnosis of your problem.\nWho else works with my GP?\n- • Nurses are very highly trained in the UK. They take care of many health needs including vaccinations, contraception advice, chronic illnesses such as diabetes and can give general health advice.\n- • Midwives look after pregnant women and their newborn babies. Care before the birth of the baby is called ‘ante-natal’ and after the birth ‘postnatal’.\n- • Health Visitors are nurses who specialise in the care of children and their families and in helping people to stay healthy. They may come to visit you at your home.\nWhat if I need to see a specialist doctor?\nYour GP will usually provide most of your health care and will decide if you need to see a specialist doctor (a consultant), or if you need to go to hospital. Everyone in the UK has to wait to see these specialist doctors. The hospital will write to you with details of your appointment. You must contact the hospital if you need an interpreter to be present at your appointment. Hospital appointments may sometimes be in hospitals some distance from where you live, although you can get help with costs of travel if you have an HC2.\nPatient Held Records.\nIf you have been given a Patient Held Record (blue book), please take this with you every time you have an appointment with the doctor or nurse. The information in this book is for yourself and NHS staff. No-one else has a right to read this book.\nWho else can help me?\nIf your doctor wants you to take medicines he/she will write you a prescription. Take the prescription to a pharmacy or chemist shop. To get free prescriptions, you need your HC2 form. The pharmacist can give advice on the treatment of minor health problems. Some medicines can be bought from the pharmacist without a prescription, including some pain killers and cough medicines.\nIf you have a problem with your teeth you should see a dentist. To receive NHS dental treatment you need to register with a dentist. If you have trouble registering with a dentist you can contact NHS 111.\nIf you need your eyes testing or need new glasses (spectacles) make an appointment to see an optician. They have shops in most town centres. The HC2 form covers the cost of the eye test and some glasses: ask the optician about this.\nWhen your GP surgery is closed\nGP surgeries are generally open from about 0830 to 1830 Monday to Friday. At all other times – at night, on Saturday or Sunday and on public holidays – medical assistance is available for health problems that cannot wait until the GP surgery is open. To get help you can ring the local out-of-hours service on the number below, and you can receive advice over the telephone. You may be asked to visit a GP surgery, or you may receive a visit from a medical professional at your home.\nYou can also telephone NHS 111 on 111 for health advice or for medical support when your surgery is closed. It will cost much less to use a landline, for example in a telephone kiosk, than a mobile phone. If you do not speak English, NHS 111 and the out-of-hours service can provide an interpreter. All you need to do is say in English the language you would prefer to use at the beginning of your call. If you do not speak any English ask a friend or relative or support worker to make the call for you and wait until an interpreter is on the line before you describe your problem. You will be asked for some details such as your name and address: this information is important and is not shared with anyone else. To contact NHS 111 for health advice, ring: 111 To contact your local out-of-hours service, for medical assistance when the GP surgery is closed, ring: 111\nWhat to do in an Emergency\nIn an emergency, if you or someone with you becomes seriously ill and cannot wait until the GP surgery is open, you can telephone 999 (free of charge) for an ambulance, or go to the Accident and Emergency Department of your local hospital. However, this service is only for emergencies. Do not use the Accident and Emergency Department for minor medical problems.\nQuick Reference Guide to using your Local Health Care Services\nType of Illness/injury\nsore throat/hay fever\ninsect bites /thrush, etc (please see practice brochure for full list)\nMany locations across the city\nSee Hull Coloured Pages under Chemists-Dispensing\nOpening hours vary. Many chemists have extended opening hours\nMinor Injuries Unit\nBransholme Medical Centre\nStory Street Medical Practice & Walk In Centre\nWilberforce Health Centre\n6 – 10 Story Street\nEast Riding Community Hospital\n9.00am - 8.00pm Mon to Fri\n9.00am - 5.00pm Sat and Sun\n9.00am – 5.00pm\nMon to Fri (but not Bank Holidays)\nMore complicated or persistent illnesses (daytime)\n187 Cottingham Road\n8.00am – 6.30pm\nMon to Fri (excluding Bank Holidays)\nMore complicated or persistent illnesses\n(outside normal hours)\nOut of Hours Emergency Doctor\nFor use where there is no possibility of the patient waiting until the surgery re-opens on the next working day\nEvenings, weekends and Bank Holidays\nEmergency Dental Treatment (outside normal hours)\nEvenings, weekends and Bank Holidays\nGenuine Accidents and Emergencies ONLY\nHull Royal Infirmary\nAnlaby Road, Hull\n- Download leaflet in English (PDF, 26K)\n- Download leaflet in Albanian (PDF, 30K)\n- Download leaflet in Amharic (PDF, 66K)\n- Download leaflet in Arabic (PDF, 197K)\n- Download leaflet in Bengali (PDF, 73K)\n- Download leaflet in Bulgarian (PDF, 122K)\n- Download leaflet in Burmese (PDF, 43K)\n- Download leaflet in Chechen (PDF, 144K)\n- Download leaflet in Chinese (Traditional - Cantonese) (PDF, 105K)\n- Download leaflet in Chinese (Simplified - Mandarin) (PDF, 99K)\n- Download leaflet in Croatian (PDF, 113K)\n- Download leaflet in Dari (PDF, 114K)\n- Download leaflet in Farsi (PDF, 142K)\n- Download leaflet in French (PDF, 32K)\n- Download leaflet in Gujerati (PDF, 40K)\n- Download leaflet in Hausa (PDF, 28K)\n- Download leaflet in Hindi (PDF, 50K)\n- Download leaflet in Indonesian (PDF, 29K)\n- Download leaflet in Kinyarwanda (PDF, 30K)\n- Download leaflet in Kirmanji (PDF, 117K)\n- Download leaflet in Korean (PDF, 158K)\n- Download leaflet in Kurdish (PDF, 152K)\n- Download leaflet in Lingala (PDF, 29K)\n- Download leaflet in Lithuanian (PDF, 112K)\n- Download leaflet in Malay (PDF, 30K)\n- Download leaflet in Mongolian (PDF, 125K)\n- Download leaflet in Ndebele (PDF, 25K)\n- Download leaflet in Pashto (PDF, 85K)\n- Download leaflet in Polish (PDF, 140K)\n- Download leaflet in Portuguese (PDF, 31K)\n- Download leaflet in Punjabi (PDF, 40K)\n- Download leaflet in Russian (PDF, 135K)\n- Download leaflet in Serbian (PDF, 112K)\n- Download leaflet in Sinhalese (PDF, 88K)\n- Download leaflet in Somali (PDF, 30K)\n- Download Intro to the NHS - Kinyarwanda (PDF, 151K)\n- Download leaflet in Spanish (PDF, 28K)\n- Download leaflet in Swahili (PDF, 29K)\n- Download leaflet in Tigrinian (PDF, 88K)\n- Download leaflet in Turkish (PDF, 143K)\n- Download leaflet in Urdu (PDF, 241K)\n- Download leaflet in Vietnamese (PDF, 134K)\n- Download leaflet in Yoruba (PDF, 117K)"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:615d0096-5d21-4c86-aa60-f47509b6bdd4>","<urn:uuid:60caf05b-6cee-4617-b7f6-bfe2d908786a>"],"error":null}
{"question":"Can someone explain the relationship between coffee farming and nitrous oxide emissions? This seems crucial for understanding agricultural greenhouse gas impacts.","answer":"Coffee plantations' use of synthetic fertilizer is a significant source of nitrous oxide emissions. According to research published in Nature Geoscience, increased fertilizer use over the past 50 years has led to a dramatic rise in nitrous oxide, which has 300 times the effect of carbon dioxide as a greenhouse gas. Nitrous oxide traps heat at a different wavelength than carbon dioxide, closing a 'window' that allows the Earth to cool off independently of CO2 levels.","context":["What’s in a cup of coffee?\nWhatever the weather, a steaming cup of coffee puts the spark back in our day. For a guilt-free brew, we have all heard of fair trade coffee – which helps secure the rights of coffee workers. But what is the coffee industry doing to combat global warming and how might our daily shot of caffeine be affected by future changes in world climate?\nThe International Trade Centre recently published a paper on the effects of climate change on the coffee industry (and vice-versa). Both coffee quality and yield are expected to be impacted by predicted changes in climate.\nSmallholder producers of coffee are already experiencing the effects of climate change in the form of abnormal rain patterns and an increased frequency of severe weather, but lack the resources to overcome them.\nIn one scenario, by the year 2050, Kenya is expected to have less seasonality in its climate. The mean low and high temperature is predicted to increase by over two degrees Celsius. More rainfall is predicted although its distribution may not be favourable for coffee growing.\nThese changes will shift optimal coffee producing zones 1,000 metres higher than they are today. Changes in rainfall may require coffee to be grown under irrigation in future. Drying of the coffee bean skins may also be affected.\nCurrent suitability of the region for coffee production is as high as 70 per cent but by 2050, Kenya’s suitability for growing coffee beans is predicted to drop to around 45 per cent or lower.\nResearchers are unable to make absolutely precise forecasts about how producer regions and global output will be affected but the general forecast is that climate change will significantly disrupt Arabica and Robusta coffee production in all regions.\nSuperior Arabica coffee beans grown at higher altitudes are delicate, require sunny but cool subtropical climates, lots of moisture, and rich soil. Robusta coffee, grown at lower levels, is generally thought to be the ‘cheaper’ coffee although a quality Robusta is often the secret behind a creamier Italian espresso.\nRising temperatures are expected to render some producing areas unsuitable for coffee cultivation. This would concentrate coffee production in areas where it is still possible but make the output risk more volatile in case of crop failure for other reasons such as pests and plant disease.\nCoffee grew naturally under the leafy canopy of native rainforest trees until monoculture systems were introduced in the 1970s. This led to forest clearing exposing the trees to more sun, and higher yields followed planting of dense rows of coffee bushes doused with agrochemicals.\nForested coffee farms are slowly coming back as certification from the Rainforest Alliance and other bodies helps farmers manage their plantations more sustainably.\nBut many of the mitigation initiatives are small-scale and need to be adopted by the coffee industry as a whole.\nDifferent coffee cultivation systems, such as forest coffee, smallholder plots and commercial plantations, have different levels of greenhouse gas emissions.\nThe advice in the ITC report is that coffee farms have the potential to ‘sequester’ or trap carbon from the atmosphere. Tree cover can be increased through planting of more shade trees or extending total forest cover on farms. Farmers could even be compensated for these initiatives if they generate marketable carbon credits.\nIntercropping, or planting around coffee bushes with plants which absorb greenhouse gases, planting of more shade trees and rehabilitation of degraded lands and hillsides can all count toward carbon credits.\nCertain roasters in consumer countries have launched initiatives to reduce the carbon footprint of a cup of coffee as part of their marketing strategies. Some are even offering zero carbon footprint coffee largely achieved by purchasing carbon offsets.\nThis means that the greenhouse gases emitted during coffee production are offset by investing in carbon emission reduction or sequestration activities elsewhere. It may also be the case that this is done outside the coffee production chain, in other areas of enterprise.\nThe report also warns that the coffee industry must increasingly contribute to control the effect of greenhouse gas emissions and urgently prepare for further adverse changes in the climate.\nProducer organisations must be strengthened before smallholder farmers can have better access to the potential benefits offered by the carbon markets.\nIn Kenya, smallholder coffee growers have used the Cool Farm Tool greenhouse gas calculator for farmers to help them measure the carbon footprint.\nCoffee plantations have been urged to reduce their use of synthetic fertiliser – a big source of nitrous oxide – by maintaining good soil structure.\nIn the journal Nature Geoscience it was reported earlier this year that nitrous oxide traps heat at a different wavelength than carbon dioxide, closing a ‘window’ that allows the Earth to cool off independently of CO2 levels.\nChemists found a ‘fingerprint’ in isotope data, proving that increased fertiliser use over the past 50 years is responsible for a dramatic rise in this major greenhouse gas contributing to global climate change. Nitrous oxide has 300 times the effect of carbon dioxide.\nThere are various small things we can choose to do as individuals toward reducing the carbon footprint of our espresso or capuccino.\nCapsule coffees have a very high carbon footprint due to the emissions involved in the production of the metal capsules. The type and efficiency of the coffee brewing machine also affects the product carbon footprint (PCF). Serving it in a paper cup can easily triple the carbon footprint of your coffee.\nwww.get-neutral.com (select English version)"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:2717a771-3f2e-4fdb-a468-947d8cb34a7d>"],"error":null}
{"question":"Do apraxia and speech disorders from traumatic brain injury share similar rehabilitation methods?","answer":"While both conditions can benefit from speech therapy, they have different rehabilitation approaches. For traumatic brain injuries, Dr. Berry's Wave system can help by converting tongue, lip and jaw movements into real-time speech and using acoustic manipulation to improve articulation. For apraxia of speech, therapy focuses on developing compensations for producing better sounds, and patients may need to rely on alternative communication methods like computers or texting. Apraxia specifically involves problems with speech programming and muscle movement direction despite normal muscle strength, while traumatic brain injury effects can vary more widely.","context":["Every spring DISCOVER: Marquette University Research and Scholarship showcases some of the most interesting research happening on Marquette's campus. Learn more through the links below.\nMarquette Research IN BRIEF SPEAK FOR YOURSELF Speech language pathologists often give clients with severe speech disorders alternative communication tools — in other words, machines that do the talking for them. But Dr. Jeff Berry, a Marquette assistant professor of speech pathology and audiology, thinks we can do better. He wants to help survivors of traumatic brain injuries regain their own voice. “A lot of this arose from working with people who have severe motor speech disorders who were just dissatisfied with the idea of using, for example, a speech-generating device for the rest of their lives,” says Berry, who directs Marquette’s Speech and Swallowing Lab in the College of Health Sciences. Berry thinks the path to better rehabilitation could start with a portable electromagnetic tracking system called the Wave. Last year, he published the first accuracy study with the Wave in the Journal of Speech, Language and Hearing Research and, with help from Marquette engineering students, designed software that makes the commercial device even more useful. “It’s the only software in the world that I’m “By changing how the acoustics are occurring in real time, we can trick you into modifying how you’re articulating.” aware of that takes movements of the tongue, lips and jaw and converts them into real-time speech,” he explains. “We can take somebody who is unable to consistently and reliably produce voicing on their own but can move their mouth and, essentially, when they move their mouth, the system will provide the voice.” Most speech synthesis devices are text-to-speech systems in which the user types what he or she wants to say. But Berry’s innovation is more than just another way to create a robotic voice that speaks for you. “We want to be able to understand and trigger in people with motor disabilities some of the preserved reflexive abilities of the motor system in order to use that reflexive response to modify their speech,” he says. “By changing how the acoustics are occurring in real time, we can trick you into modifying how you’re articulating.” That could mean tricking people into pronouncing a vowel a different way or, in the case of people with severe motor speech disorders, adjusting tongue height to achieve the correct sound. Berry’s speech synthesis software is critical because, until now, researchers could only manipulate acoustics for healthy speakers who could produce a high-quality acoustic signal. Now involuntary adaptations can be studied in survivors of traumatic brain injuries. But first, Berry, who has funding from the American Speech and Hearing Foundation, is refining the technology. After developing a baseline using healthy young adults, he expanded the study to survivors of traumatic brain injury and stroke and presented the results at the Conference of Motor Speech in February. “It’s a technically challenging line of research and a conceptually challenging line of research,” he says, “but we’re making good progress.” — NSE 18 Discover","Apraxia Speech Disorder Can Progress to Neurodegenerative Disease\nAuthor: Mayo Clinic | Contact: www.mayoclinic.org\nSynopsis: It may start with a simple word you can not pronounce, your tongue and lips stumble, and gibberish comes out.\nMayo Clinic researchers to present at American Association for Advancement of Science meeting...\nApraxia of speech (AOS) is defined as a neurologic speech disorder that reflects an impaired capacity to plan or program sensorimotor commands necessary for directing movements that result in phonetically and prosodically normal speech. The messages from the brain to the mouth are disrupted, and the person cannot move his or her lips or tongue to the right place to say sounds correctly, even though the muscles are not weak. AOS can independently occur without issues in areas such as verbal comprehension, reading comprehension, writing, articulation or prosody. AOS occurs in both children (childhood apraxia of speech) and adults (acquired apraxia of speech) who have (prior to the onset of apraxia) acquired some level of speaking ability.\nMisspeaking might draw a chuckle from family and friends. But, then, it keeps happening. Progressively, more and more speech is lost. Some patients eventually become mute from primary progressive apraxia of speech, a disorder related to degenerative neurologic disease.\nTwo Mayo Clinic researchers have spent more than a decade uncovering clues to apraxia of speech. Keith Josephs, M.D., a neurologist, and Joseph R. Duffy, Ph.D., a speech pathologist, will present \"My Words Come Out Wrong: When Thought and Language Are Disconnected from Speech\" on Sunday, Feb. 14, at the American Association for the Advancement of Science annual meeting in Washington, D.C.\nBecause patients and even many medical professionals don't recognize apraxia of speech, treatment typically is sought in later stages of the disease, says Dr. Josephs. As apraxia progresses, it frequently is misdiagnosed as Alzheimer's disease or amyotrophic lateral sclerosis. One patient received vocal cord injections of Botox by a physician who thought the issue was muscle spasms of the larynx. Apraxia of speech even has been diagnosed as mental illness.\n\"Because it first presents as 'just' a speech problem, some people are told, 'This is in your head.' We've seen that. It's very sad,\" Dr. Josephs says.\nWhen it's caused by a stroke, apraxia of speech typically does not worsen and may get better over time. But, apraxia of speech often is ignored as a distinct entity that can evolve into a neurologic disorder, causing difficulty with eye movement, using the limbs, walking and falling that worsens as time passes.\n\"I don't want the take-home message to be that this condition is benign,\" warns Dr. Josephs. \"It is a devastating disease, in some sense worse than Alzheimer's disease, which typically spares balance and walking until very late in the disease course. It may start with the person simply not being able to pronounce a few words. Six years after that, they are in a diaper, can't speak, can't walk and are drooling.\"\nThe benefit to getting an early and correct diagnosis is that people can receive appropriate therapy. \"It would be good if people recognized that changes in speech can be the first signs of neurologic disease,\" Dr. Duffy says. \"An important part of treatment is providing information about the condition.\"\nWhile speech therapy doesn't reverse or halt the progression of apraxia, it can develop compensations for producing better sounds. People with apraxia of speech also can use computers or texting for alternate means of communicating.\nBoth the value and complexities of speech often are underappreciated. \"Speech is what connects us to the world,\" Dr. Duffy says.\nSpeech is a complex brain-body achievement, these researchers note. It first requires selection of appropriate words, organizing them into a coherent message. This message activates 100 muscles between the lungs and lips to produce at least 14 distinct sounds per second that can be comprehended by a listener. A problem with speech programming - directing the muscles and structures that move - is apraxia.\nPeople with apraxia of speech or their loved ones may notice:\n- Slow speech rate\n- Inconsistent mistakes, such as saying a word or sound correctly sometimes and not others\n- Impaired rhythm of speech\n- Groping of the mouth to make sounds\n- Better automatic speech, such as greetings, compared with purposeful speech\nApraxia of speech differs from aphasia, a language disorder that interferes with a patient's ability to understand or use words. Patients, however, can have apraxia of speech and aphasia.\nWhile the cause of primary progressive apraxia of speech has not been determined, an abnormal accumulation of tau protein - a factor also contributing to Alzheimer's disease - has been found in the brains of those with apraxia of speech who have died.\nMayo Clinic has received National Institutes of Health grants, for which Dr. Josephs is the primary investigator, to focus on apraxia of speech in the context of neurodegenerative cognitive and motor disorders.\nDrs. Josephs, Duffy and fellow researchers have published articles about their findings in Brain, the American Journal of Alzheimer's Disease & Other Dementias, Neurology and the Journal of Neurology.\nDisabled World is an independent disability community established in 2004 to provide disability news and information to people with disabilities, seniors, their family and/or carers. See our homepage for informative news, reviews, sports, stories and how-tos. You can also connect with us on Twitter and Facebook or learn more about Disabled World on our about us page.\nDisabled World provides general information only. Materials presented are in no way meant to be a substitute for professional medical care by a qualified practitioner, nor should they be construed as such. Any 3rd party offering or advertising on disabled-world.com does not constitute endorsement by Disabled World.\nCite This Page (APA): Mayo Clinic. (2016, February 14). Apraxia Speech Disorder Can Progress to Neurodegenerative Disease. Disabled World. Retrieved January 27, 2022 from www.disabled-world.com/health/neurology/apraxia.php"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"instructional"}],"document_ids":["<urn:uuid:d6f35262-bf0c-4a49-b293-45b4885333ff>","<urn:uuid:71118600-1ca5-4656-bd77-111400ea51e0>"],"error":null}
{"question":"Hey everyone! As a religious studies enthusiast, I'm curious: how do the pilgrimage traditions compare between the Ganges River and Mount Kailash in terms of their spiritual significance and practices? 🙏","answer":"Both the Ganges River and Mount Kailash are highly significant pilgrimage sites with distinct practices. The Ganges River is particularly sacred to Hindus, who believe bathing in it removes karmic blocks and cleanses past sins. Millions make pilgrimages yearly to its shores, especially in Varanasi, where there are 1,500 temples and numerous bathing ghats. Meanwhile, Mount Kailash is considered sacred by multiple religions including Hinduism, Buddhism, Jainism, and Bön. Pilgrims perform a 52 km circumambulation (kora) around the mountain, with some taking a single day to complete it while others perform body-length prostrations that take four weeks. The mountain is considered so sacred that setting foot on its slopes is forbidden, and no one has ever climbed it. Both sites feature specific ritual practices - while the Ganges focuses on bathing and cremation rituals, Kailash's pilgrimage involves the challenging circular trek around the mountain at high altitudes.","context":["Brad Olsen has been a regular travel columnist for Heartland Healing Magazine for several years. Select PDF versions of “Sacred Destinations by Brad Olsen” are here, along with a sample of World Explorer where Brad Olsen is a Contributing Editor and catalog designer for this magazine.\nHe is also an occasional contributor to Perceptive Travel magazine, including this article, “Discovering Forbidden Archaeology”, another on “The Sexual Draw of the Burning Man Festival”, and “Laotian Prayers on a Sinking Raft” about a trip down a river in Laos.\nBrad Olsen travel articles from Heartland Healing\nClick on each link to read as a PDF:\n- Interview-HH1-1.pdf The first issue of Hearland Healing featured an interview with Brad Olsen. His column “Sacred Destinations” appeared in every issue since!\n- MontStM-HH1-2.pdf Perhaps the most famous island-castle-monastery in Europe! Visiting Mont St Michel is like walking into a fairy tale.\n- Malta-HH1-3.pdf The prehistoric temples of Malta might just be the oldest in the world. Their ancient mysteries are far from being understood.\n- Fiji-HH1-4.pdf Paradise on earth comes with a cost.\n- Tsunami-HH1-5.pdf Only 10 days after the Southeast Asian tsunami hit, Brad Olsen was on location digging through the aftermath — not only the physical destruction, but of people’s lives.\n- Shasta-HH1-6.pdf The Magic Mountain of Northern California.\n- SteAnne-HH2-1.pdf The greatest healing shrine in Canada.\n- DevilsLake-HH2-2.pdf The most famous effigy mound lake in Wisconsin is little known outside the Midwest.\n- Kalalau-HH2-3.pdf Trek along the rugged Kalalau Trail on Kauai to one of the last lawless hippy enclaves in America!\n- Chaco-HH-3.1.pdf This article examines the many mysteries of New Mexico’s Chaco Canyon, once the largest metropolis in North America, then mysteriously abandoned.\n- Philippines.pdf Take a tour to some of the best islands in the Philippine archipelago.\n- Chautauqua-HH-3.4.pdf One of the oldest gatherings of the mind continues in New York state. Come and see how this venerable event has redefined itself in the 21st century.\n- Burning-Man-HH-4.1.pdf This cover article examines the width and bredth of the social experiment that is Burning Man.\n- BVI-HH-4.2.pdf Take a sailing journey around the British Virgin Islands in the eastern Caribbean. Beware of pirates!\n- 5.4BighornWheel.pdf Explore all the astronomical and spiritual of the world’s most famous medicine wheel.\n- 5.5Angkor.pdf Travel to the most famous ruins of Southeast Asia, and climb Cambodia’s most sacred mountain.\nWorld Explorer Articles\nTop Four World Pilgrimage Sites\nBy: Brad Olsen\nPilgrimage is defined as: “1. A Journey to a sacred place or shrine. 2. A long journey or search, especially one of exalted purpose or moral significance.” All pilgrimages to holy places share the same purpose-the search for God and/or the self-a quest for interpersonal communion with a higher force. In some traditions, the destination is left deliberately ambiguous, whether the goal of the journey is actual or merely symbolic. Tibetan tradition relates the mythical Shambahala, or Shangri-La, which may have existed in ancient times, but might also have been an intentional metaphor for a state of consciousness. Throughout history, all world religions and indigenous tribes have encouraged a pilgrimage somewhere. Christians seek miracle cures at Lourdes, France or Chimayo, New Mexico; Muslims trek to Mecca and Medina, Saudi Arabia; Hindus journey to the Ganges River, India; Buddhists and other faiths to Mount Kailas, Tibet; and Jews worship at the Western Wall in Jerusalem, Israel. Early tribes and indigenous people primarily sought the wonders of nature for their spiritual quests, such as Australian aboriginals venturing to Ayers Rock; American Indians to sacred mountains in North America; or prehistoric South Americans to Lake Titicaca.\n1. The River Ganges The River Ganges is Mother Earth to millions of Hindus. She is commonly referred to as “Ganga Ma” or “Mother Ganga.” The Ganges is an extremely sacred river, a highly revered and physically dynamic life force to the Hindu faith. Millions throughout India make a pilgrimage every year. Through the centuries, countless yogis have left countless blessings along her banks. Thousands of temples adorn the shores of the Ganges, and every day bells ring to call the devout to worship and bathe at their nearest Ganga temple. Hindus believe that washing the body in the River Ganges removes karmic blocks and cleanses past sins. To a new disciple, a Hindu would say, “Don’t mind the floating garbage-it is merely an indication of Mother Earth’s presently polluted state-have faith, jump in and let yourself be engulfed by her warm embrace!” Somehow, despite widespread pollution, scientific tests on water purity remain inexplicably high around the Ganges’ many bathing centers. Hundreds of bathing and burial ghats grace the shores of the Ganges, with the highest concentration in the holy city of Varanasi (Benares). Varanasi is India’s holiest, and perhaps oldest, city. The Hindus believe the souls of those who die and are cremated along the shores of the River Ganges will be transported immediately to paradise. Varanasi is a destination to which every devout Hindu attempts to make at least one pilgrimage, especially just prior to death. A slow boat trip on the River Ganges at dawn, past 1,500 temples, shrines, palaces, burning ghats and bathing ghats, where thousands of pilgrims come daily to wash away their sins, is one of the greatest spiritual sights in the world. Rishikesh is a famous town on the Ganges, the name literally translated as “village of seers.” Anyone who goes there knows Rishikesh is blessed with a sacred vibration. For centuries it has attracted saints, sadhus and all those wishing to become rishis, or seers. So significant are the seers that there is even an eye hospital in town for those needing improvement on their physical eyesight! A multitude of Ganges temples grace the east side of the city near dozens of ashrams. Rishikesh is located in the Himalayan foothills, close to where the River Ganges emerges from the mountains. The riverside city of Sarnath is where Buddha preached his first sermon about “the middle way” after having attained enlightenment. Travelers may view ruins of the old city and spiritual sites such as the old Dhamek Stupa (a little Chinese Temple) and the Mulagandhkuti Vihara, which is a magnificent Buddhist temple with murals depicting the life of Buddha. Also in Sarnath is the Asoka Pillar with a lion capital, which has been adapted as the state emblem of the Republic of India. Sarnath is located only six miles north (10 km) of Varanasi.\n2. Mount Kailas The majestic Mount Kailas soars 22,028 feet (6,608 m) above the remote western Tibetan Plateau already high at 15,500 feet (4,650 m) above sea level. The sacred peak is situated far away from any life, in a sort of lunar landscape. Surrounding the lingim-shaped mountain is a pilgrimage route known as the kora, a 32-mile (52 km) path that circles the mountain. Prostrating themselves on the ground along the way, pilgrims have come to Kailas for thousands of years to behold this profoundly spiritual place. Most come to walk the kora route. The biggest challenge of the trek is crossing the 18,300-foot (5,490-m) Dolma La Pass. Stupas, icons and prayer flags from several faiths adorn the kora on the outer slopes of Kailas. Both Hindus and Buddhists consider a pilgrimage to Mount Kailas as the highest point of a spiritual life. Kailas represents Asia’s most sacred mountain to millions of faithful adherents of several religions. Festivals abound year-round at Mount Kailas. Perhaps the most prominent celebration is the spring full-moon festival honoring Buddha’s birthday, enlightenment, and death. Drumming through the night, Khumba monks chant and dance under the silver glow of the moon, joined by those from other religious persuasions. As all faiths merge into one while under the white domed power of Kailas, an ongoing drama of renunciation and revelation continues as it has for thousands of years.\nThe 11th-century Tibetan saint Milarepa spoke of this peak: “The prophecy of the Buddha says, most truly, that this snow mountain is the navel of the world, a place where the snow leopards dance.” Just over the border from India, Mount Kailas is the source of four great rivers: the Karnali (Ganges), the Indus, the Sutlej and the Brahmaputra. All four rivers flow down from the lofty heights of Kailas like a giant mandala extending thousands of miles into the Indian seas. Many spiritual seekers believe that Mount Kailas represents the crown chakra of the earth. At the base of the mountain are two lakes, one shaped like the moon and one like the sun. From the solar lake flow the four rivers in four directions. Mount Kailas is one of the most traveled pilgrimage routes for Hindus, Bon Po, Jains, Buddhists and hearty travelers of all nations. Several well-trodden routes coming from all directions are well known by native Tibetans and relocated Chinese people. The sacred peak is known alternatively as the holy “Mount Sumeru” or “Meru.” Tibetans call the mountain Kang Rimpoche, meaning “precious jewel of the glacial snows.” From afar, the snow formations on the top of the mountain resemble a palace, complete with icy domes and turrets. Pilgrims wishing to walk the kora route around the mountain must travel on foot over high and desolate terrain for five days. Altitude sickness is more of a rule than an exception. Prepare for extremely cold weather and a lack of basic necessities, including shelter, food and fresh water.\n3. Mecca and Medina In the early 600’s CE, when the soon-to-be-prophet Mohammed lived in Mecca as a trader, the city was a small but crowded place of about 3,000 people. Mecca resides in a forbiddingly dry and sandy valley surrounded by a double range of desolate and treeless hills. The only thing that made life possible here was the well of Zamzam in the town square. Also in the middle of town was the Kaba, a boxlike shrine that contains a sacred black meteorite. Mecca and the Kaba would soon become the holiest place in the world to followers of the new Islamic religion. Mohammed moved his ministry to Medina soon after his revelations began in 610 CE. The principle revelations were conveyed to Mohammed through the archangel Gabriel. These visions continued with him up until his death in Medina in 632. By that time, Islam had swept aside all other religions on the Arabian peninsula. Within a century after the Prophet‚Äôs death, the Arabs ruled a vast empire stretching from Spain to India and north into Russia. Medina became the new administrative center for the expanding Muslim empire. As the adopted capital and city where Allah’s word spread through Mohammed, Medina is second only to nearby Mecca as a pilgrimage city. Mecca and Medina are the most visited pilgrimage sites in the world, and the ultimate goal for one billion believers in Islam. According to Mohammed’s command, all Muslim prayers worldwide must be directed toward Mecca. It is estimated that one billion Muslim faithful turn towards the Grand Mosque in prayer five times every day. At the time of the Hajj pilgrimage, which occurs once a year by the lunar calendar, as many as 4 million gather for a period of about six days. The pilgrims circle the Kaba, drink from the miraculous well of Zamzam, pray in white tents on the plain of Mina, then returnto the Kaba for one incredible moment when thousands of devotees touch their forehead to the ground in awe of Allah, then shout “Allah-Hu Akbar”in unison. This chant meaning “Allah is greater than anything” reverberates throughout Mecca and can be heard from miles away. Today the Grand Mosque in Mecca attracts untold millions to behold the sacred Kaba, and be present in the city where Mohammed received his revelations from God. Tourist visas are not available for travel in Saudi Arabia, and visas of other sorts are very difficult to obtain. Pilgrims wishing to visit Saudi Arabia’s holy cities must arrange a visitor’s visa from someone already in the country who can verify the visitor’s faith. The two holiest sites of Islam, Mecca and Medina, are strictly off-limits to non-Muslims. Steep fines are imposed for just turning up at the checkpoints to the sacred cities. All pilgrims coming to the Kingdom must have special visas that declare their religious status in Arabic.\n4. Lourdes The small town of Lourdes was hardly more than a hamlet until 1858, the year a 14-year-old peasant girl named Bernadette Soubirous had the first of 18 visions of the Virgin Mary at a location called Grotte de Massabielle, by the river known as Gave de Pau. Over a period of several months the young girl and many townspeople gathered at the riverside grotto and viewed an apparition of Mother Mary, or the “Immaculate Conception” as she described herself. Once the girl’s visions were recognized by the Catholic Church, the fledgling village at the foot of the Pyrenees Mountains experienced a building boom and is now one of the most visited sites in southern France. Bernadette lived the rest of her life as a nun, was beatified in 1925 and canonized a saint in 1933. The holy city Lourdes attracts more than 5 million Christian faithful every year, making it the largest pilgrimage destination in France. Most of the visitors who come to Lourdes are hoping for a miraculous cure for their pain and suffering. Some 70,000 visitors per year are handicapped or have serious physical ailments and are given preferential treatment at the site. Lourdes has been called the “City of Miracles” and “Capital of Prayer,” which does correspond with a tangible reality. Well over 5,000 cases of spontaneous healing have been reported, and of those, 65 have been declared miraculous by ecclesiastic authorities following long and precise procedures. Such recognized miracles by the Catholic Church have undoubtedly led to the steady increase of pilgrims. Just outside town is the Cite Religieuse, the object of desire for the throngs of faithful flocking to Lourdes. Tucked alongside the riverbank is the candle-blackened grotto where the apparitions of 1858 occurred. Inside the grotto is a Virgin Mary statue and the source of Lourdes‚Äô holy water. The water from the spring has been scientifically classified as “clustered,” meaning it contains structured crystalline molecules more so than regular water, and is used for blessings and healing. Suspended in front of the grotto are rows of rusting crutches offered up by the hopeful. Rising above the grotto cliff is the first church, built here in 1871, and below there is a river-level basilica, which can house nearly 20,000 people for Mass. Because of its famous reputation for rejuvenation and abundant holy water, most modern Christian pilgrim routes in Europe now lead to Lourdes.\nThe Mysterious Effigy Mounds of the Upper Mississippi River Valley","The north face of Mount Kailash\n|Elevation||6,638 m (21,778 ft)|\n|Prominence||1,319 m (4,327 ft)|\n|First ascent||No ascent attempts|\nMount Kailash (also Mount Kailas; (Tibetan: གངས་རི- ་པོ་ཆེ,Kangrinbo- qê or Gang Rinpoche; simp- lified Chinese: 冈仁波齐峰, G- ngrénbōqí fēng) is a peak in the Kailas Range (Gangdisê Mountains), which are part of theTranshimalaya in Tibet. It lies near the source of some of the longest rivers in Asia: the Indus River, the Sutlej River (a major tributary of the Indus River), theBrahmaputra River, and the Karnali River (a tributary of the Ganges River). It is considered a sacred place in four religions: Bön, Buddh- ism, Hinduism andJainism.\n[edi- t]Nomenclature, orthography and etymology\nThe mountain is known as Kailāsa (कैलास- ) in Sanskrit. The word may be derived from the word kēlāsa (केला- ) which means \"crystal\". In his Tibetan-English dictionary, Chandra (1902: p. 32) identifies the entry for 'kai la sha' (Tibetan: ཀཻ་ལ་ཤ,- Wylie: kai la sha) which is a loan word from Sanskrit 'kailāsa' (Devanagari: कैलास).\nThe Tibet- an name for the mountain is Gangs Rin-po-che. Gangs or Kang - is the Tibetan word for snow peak analogous to alp or himal; rinpoche- is an honorific meaning \"precious one\" so the combined term can be translated \"precious jewel of snows\".\n- \"Tibetan Buddhists call it Kangri Rinpoche; 'Precious Snow Mountain'. Bon texts have many names: Water's Flower, Mountain of Sea Water, Nine Stacked Swastika Mountain. For Hindus, it is the home of the mountain godShiva and a symbol of his power symbol om; for Jains it is where their first leader was enlightened; for Buddhists, the navel of the universe; and for adherents of Bon, the abode of the sky goddess Sipaimen.\"\nAnother local name for the mountain is Tisé (Tibetan: ཏི- སེ་) mountain, which derives from ti tse in the Zhang-Zhung language, meaning \"water peak\" or \"river peak\", connoting the mountain's status as the source of the mythical Lion, Horse, Peacock and Elephant Rivers, and in fact the Indus, Yarlung Tsangpo/Dihang/Brahmaputra, K- arnali and Sutlej all begin in the Kailash-Lake Manasarovar region.\nAccording to Hinduism, Lord Shiva, the destroyer of ignorance and illusion, resides at the summit of a legendary mountain named Kailāsa, where he sits in a state of perpetual meditation along with his wife Pārvatī.\nAccording to Charles Allen, one description in the Vishnu Purana of the mountain states that its four faces are made of crystal, ruby, gold, and lapis lazuli. It is a pillar of the world and is located at the heart of six mountain ranges symbolizing a lotus.\nThe ancient Koneswaram temple of Trincomalee is heralded as \"Dakshina Kailasam\"/\"Then Kailasam\" (Kailash of the South) because it lies on exactly the same longitude as Mount Kailash and due to its pre-eminence in Saivite belief. Koneswaram's early black granite rock-cut architectural style shared similarities to famous Kailasanathar Temples of the subcontinent, named after the mountain peak. Koneswaram's traditional history and legends were compiled into the Tamil corpus Tevaram and the Sanskrit treatises Dakshina Kailasa Puranam — Sthala Puranam of Koneswaram, written in 1380 by Jeyaveera Cinkaiariyan, and the Dakshina Kailasa Manmiam — three chapters of the Skanda Puranam of unknown antiquity — manuscripts of which have been discovered and dated from the 5th — 7th century.\nMany of the Kailasanathar temple's sculptures and relics depict episodes relating to Lord Shiva and Maa Parvati, including Ravana's tale. (Ravana was a devotee of Lord Shiva. Ramayana does not document Ravana shaking the mountain.) Ravana's mother had fallen ill. As they were great Lord Shiva devotees, he had attempted to carry the temple on his back to bring it closer to his mother. Shiva, being stunned by his boldness, had blessed him with immortality as Ravana had passed Lord Shiva's test of devotion.\nIn Jainism, Kailash is also known as Meru Parvat or Sumeru. Ashtapada, the mountain next to Mt.Kailash is the site where the first JainTirthankara, Rishabhadeva- , attained Nirvana/moksa (libe- ration). (The authenticity of Mount Kailash being Mount Ashtapada is highly debated.)\nTantric Buddhists believe that Mount Kailash is the home of the Buddha Demchok (also known as Demchog or Chakrasamvara), who represents supreme bliss.\nThere are numerous sites in the region associated with Guru Rinpoche (Padmasambhava), whose tantric practices in holy sites around Tibet are credited with finally establishing Buddhism as the main religion of the country in the 7th–8th century CE.\nIt is said that Milarepa (c. 1052-c. 1135 CE), champion of Tantric Buddhism, arrived in Tibet to challenge Naro Bön-chung, champion of the Bön religion of Tibet. The two magicians engaged in a terrifying sorcerers' battle, but neither was able to gain a decisive advantage. Finally, it was agreed that whoever could reach the summit of Kailash most rapidly would be the victor. While Naro Bön-chung sat on a magic drum and soared up the slope, Milarepa's followers were dumbfounded to see him sitting still and meditating. Yet when Naro Bön-chung was nearly at the top, Milarepa suddenly moved into action and overtook him by riding on the rays of the sun, thus winning the contest. He did, however, fling a handful of snow on to the top of a nearby mountain, since known as Bönri, bequeathing it to the Bönpo and thereby ensuring continued Bönpo connections with the region.\nThe Bön, a religion which predates Buddhism in Tibet, maintain that the entire mystical region and the nine-story Swastika Mountain- are the seat of all spiritual power.\nEvery- year, thousands make a pilgrimage to Kailash, following a tradition going back thousands of years. Pilgrims of several religions believe that circumambulating Mount Kailash on foot is a holy ritual that will bring good fortune. The peregrination is made in a clockwise direction by Hindus and Buddhists. Followers of the Jain and Bönpo religions circumambulate the mountain in a counterclockwise direction. The path around Mount Kailash is 52 km (32 mi) long.\nSome pilgrims believe that the entire walk around Kailash should be made in a single day, which is not considered an easy task. A person in good shape walking fast would take perhaps 15 hours to complete the 52 km trek. Some of the devout do accomplish this feat, little daunted by the uneven terrain,altitude sickness and harsh conditions faced in the process. Indeed, other pilgrims venture a much more demanding regimen, performing body-length prostrationsover the entire length of the circumambulation: The pilgrim bends down, kneels, prostrates full-length, makes a mark with his fingers, rises to his knees, prays, and then crawls forward on hands and knees to the mark made by his/her fingers before repeating the process. It requires at least four weeks of physical endurance to perform the circumambulation while following this regimen. The mountain is located in a particularly remote and inhospitable area of the Tibetan Himalayas. A few modern amenities, such as benches, resting places and refreshment kiosks, exist to aid the pilgrims in their devotions. According to all religions that revere the mountain, setting foot on its slopes is a dire sin. It is claimed that many people who ventured to defy the taboo have died in the process. It is a popular belief that the stairways on Mount Kailash lead to heaven.\nFollowing the political and border disturbances across the Chinese-Indian boundary, pilgrimage to the legendary abode of Lord Shiva was stopped from 1954 to 1978. Thereafter, a limited number of Indian pilgrims have been allowed to visit the place, under the supervision of the Chinese and Indian governments either by a lengthy and hazardous trek over the Himalayan terrain, travel by land from Kathmandu or from Lhasa where flights from Kathmandu are available to Lhasa and thereafter travel over the great Tibetan plateau by car. The journey takes four night stops, finally arriving at Darchen at elevation of 4,600 m (15,100 ft), small outpost that swells with pilgrims at certain times of year. Despite its minimal infrastructure, modest guest houses are available for foreign pilgrims, whereas Tibetan pilgrims generally sleep in their own tents. A small regional medical center serving far-western Tibet and funded by the Swiss Ngari Korsum Foundation was built here in 1997.\nWalking around the holy mountain—a part of its official park—has to be done on foot, pony or yak, taking some three days of trekking starting from a height of around 15,000 ft (4,600 m) past the Tarboche (flagpole) to cross the Drölma pass 18,200 ft (5,500 m), and encamping for two nights en route. First, near the meadow of Dirapuk gompa, some 2 to 3 km (1.2 to 1.9 mi) before the pass and second, after crossing the pass and going downhill as far as possible (viewing Gauri Kund in the distance).\nAlt- hough Mount Kailash has never been climbed, a number of mountaineers have prospected the mountain with a view to climbing it. In 1926, Hugh Ruttledge studied the north face, which he estimated was 6,000 ft (1,800 m) high and \"utterly unclimbable\" and thought about an ascent of the north-east ridge, but he ran out of time. Ruttledge had been exploring the area with Colonel R. C. Wilson, who was on the other side of the mountain with his Sherpa named Satan. According to Wilson, Satan told Wilson, \"'Sahib, we can climb that!' ... as he too saw that this [the SE ridge] represented a feasible route to the summit.\"Further excerpts from Wilson's article in the Alpine Journal (vol. 40, 1928) show that he was utterly serious in his intention to climb Kailash, but, as with Ruttledge, he ran out of time.\nHerbert Tichy was in the area in 1936, attempting to climb Gurla Mandhata. When he asked one of the Garpons of Ngari whether Kailash was climbable, the Garpon replied, \"Only a man entirely free of sin could climb Kailas. And he wouldn't have to actually scale the sheer walls of ice to do it – he'd just turn himself into a bird and fly to the summit.\"\nReinhold Messner was given the opportunity by the Chinese government to climb the mountain in the 1980s but he declined. In 2001 the Chinese gave permission for a Spanish team led by Jesus Martinez Novas to climb the peak, but in the face of international disapproval the Chinese decided to ban all attempts to climb the mountain. Messner, referring to the Spanish plans, said, \"If we conquer this mountain, then we conquer something in people's souls ... I would suggest they go and climb something a little harder. Kailas is not so high and not so hard.\""],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:251d216d-e7f6-418d-a92b-92152c811eab>","<urn:uuid:e35cd24c-f375-4bd7-bfab-8bff9f2fe44a>"],"error":null}
{"question":"¿Cuánto se ahorra al detectar fallas antes que lleguen al usuario final? 💰","answer":"The cost difference between detecting a fault during production versus after reaching the end user is substantial. While repair and debug costs average $7 per unit during production, if a fault is discovered by the end user, the cost increases to approximately $200. This means detecting a fault before the product leaves the factory potentially saves $193 per faulty component.","context":["Despite its standardization as IEEE 1149.1 in 1990 and wide use in the industry, many test engineers and developers still do not fully understand the benefits of boundary scan test. The misconceptions regarding this well-established technology, also known as JTAG test, have led to its relatively slow acceptance or complete rejection by some companies. Here are some reasons why acceptance of boundary scan test has been slow:\n- Cannot thoroughly test a UUT.\n- Limited test applications.\n- Limited number of components supporting the technology.\n- Cost to purchase and use boundary scan components.\nFigure 1. Development of New Technologies\nDespite enormous manufacturing improvements, production problems and component failures do occur. New package types, higher pin-count devices, and denser layouts on PCBs continue to challenge the manufacturing process, as shown in Figure 1.\nThe installation of large, complex chips continues to be an area for recurring faults. However, faulty assemblies must not reach the end user. The goal is to catch any fault as soon as possible in the production cycle by establishing an effective manufacturing test strategy.\nThe production process of a PCB must be analyzed to gain optimal quality at minimal costs. The main issue is failure analysis, with failure classification that helps determine the cause of the problem. Several test techniques can be used to check PCBs for failures. As an example, Table 1 shows common test technologies, their fault coverage, and the fault distribution in a production line of a German OEM.Pros and Cons of Specific Test Techniques\nTable 1 indicates that functional test (FT), in-circuit test (ICT), and flying- probe test (FPT) attain high test coverage of 90.8%. On the other hand, automated optical inspection (AOI) detects all faults except electrically defective components and faults caused by nonvisible solder joints, especially under ball grid arrays (BGAs).\nThe cons of these test techniques are listed in the following:\n- Test-program creation very time-consuming lasting weeks to months; average cost approximately $15k.\n- Very high costs in repair due to limited diagnostics; well-trained personnel required for troubleshooting and fault isolation; average troubleshooting time: 30 min; cost approximately $20 per fault.\n- Test of all functions (coverage of all possible faults) practically impossible.\n|Fault Type||Fault Distribution In Percent||Functional Test||In-Circuit Test||AOI||Flying-Probe Test|\n|SMT Placement Fault||28.5||Yes||Yes||Yes||Yes|\n|THT Placement Fault||7.3||Yes||Yes||Yes||Yes|\n|THT Soldering Defect||4.1||Yes||Yes||Yes||Yes|\n|SMT Reflow Soldering Defect||27.2||Yes||Yes||Partly (13.6)||Yes|\n|SMT Wave Soldering Defect||1.8||Yes||Yes||Yes||Yes|\n|Coverage in Percent||100||90.8||90.8||65.1|\nTable 1. Test Technologies and Test Coverage (Statistic Average Values)\n- High costs in test preparation due to UUT-specific test fixture; average cost $10k to $15k, more for highly complex fixtures.\n- Extra costs when the UUT??s PCB layout changes.\n- Storage and maintenance of test adapters very expensive.\n- Probe placement more complicated due to ever-denser layouts.\n- Impossible to access high lead-count BGAs via nails; unproductive to include in the layout and then probe extra test pads because the advantage of very large-scale integration (VLSI), namely the space savings, would be eliminated.\n- Only visible features verified; fault detection at hidden solder joints not possible.\n- No electrical test.\n- High test execution time due to sequential probing of test points.\n- Maintenance costs for worn probe tips and moving parts.\nBoundary scan is possibly the most resourceful test technique, testing the connectivity on a PCB, similar to ICT, or between PCBs but without the need of physical contact to test pads (Figure 2). With only four lines, it drives and measures thousands of test points simultaneously, detects the failure location, and finds faults even under BGA components. While ICT requires specially constructed adapters, boundary scan testing is possible even if there is only one scanable component on the board.\nEssentially, boundary scan means testing at the boundary of an IC. In addition to the core logic, special test logic is implemented in an IEEE 1149-compliant IC.1,2 Test points, or boundary scan cells, are put between core logic and physical device pins. To provide access to these test points, all boundary scan cells of a device are linked together to the boundary scan register, which is accessible from the outside through the test access port (TAP).\nFigure 2. The Principle of Boundary Scan Test\nBoundary scan test resources are very easily accessible, allowing them to be used throughout the entire product life cycle. Even before PCB layout is completed, boundary scan tests can be developed based on available schematic CAD data. No bed-of-nail fixture is needed so the layout information is not relevant for boundary scan test.\nTest patterns created during the product design phase can be reused for prototype verification and debug as well as manufacturing test, repair, maintenance, and field service. This is an important advantage since, especially during the design of highly complex assemblies, testability throughout the product life cycle must be considered.\nDue to elimination of the time-consuming adapter design, build, and verification process and the reusability of boundary scan tests, the time and effort required for testing and the cost of test itself are dramatically reduced. Only a few days or even hours are required to generate test programs compared with weeks or months for an ICT or FT. Boundary scan tests provide quick pin-level diagnosis while avoiding the high production, storage, and maintenance costs of bed-of-nail adapters.\nIn general, boundary scan detects the same faults as FT, ICT, or FPT (Table 2). Compared to other test techniques, boundary scan has a large financial advantage. In most cases, boundary scan leads to a significant cost reduction including considerably lower up-front investment and cost of ownership.Where to Use Boundary Scan\nFigure 3. Example of PCB Type 1\nFor a better understanding of the following discussions, three different types of UUTs shall be considered:\nType 1—Single PCB, predominantly digital circuits; components with relatively small pin-count, no BGAs; and some components with boundary scan capabilities.\nType 2—Single PCB, predominantly digital circuits; components with high pin-count, a few BGAs; and some components with boundary scan capabilities.\nType 3—Single PCB, predominantly digital circuits; components with high pin-count, many BGAs; and most components with boundary scan capabilities.\nConsidering these three PCB types, boundary scan can achieve a reasonable reduction in the cost of test. The numbers provided in the following examples are average values; the savings can vary upward or downward for a specific UUT.Type 1\nType 1 is well suited for ICT. The cost-saving potential is in the combination of boundary scan with ICT, such as via boundary scan extension modules.\nThis PCB has approximately 1,200 component leads and 200 nets; statistically, the ratio of leads to nets is 6:1 (Figure 3). If there are three boundary scan-compliant components on the board with each connecting to 18 nets, then 54 nets or 27% of all nets are boundary scan accessible.\nAn adapter with 200 nails, each nail for one net, costs about $5,000. Of the total cost, 80% is proportional to the number of nails. By reducing the number of nails needed by 54, the savings achievable are 27% of $4,000 (80% of $5,000) or $1,080.\nTable 2. Test Coverage of Boundary Scan (Statistic Average Values)Type 2\nIn this example, it is assumed that the manufacturer??s product variety is much wider. A flying probe is the most useful solution to test boards in such a low-volume, high-mix environment.\nAn average PCB shall have 560 nets and 3,200 components, with two boundary scan-compliant BGAs: one with 432 pins and the other with 256 pins. There are other high-pin-count components with 956 pins and an additional 230 low pin-count components on the PCB. A total of 5,114 FPT steps must be executed (device tests plus shorts tests on 10% of all nets). Assuming a rate of 13 test steps/s, the test time is 6.5 min.\nThe boundary scan resources in the BGA components offer potential savings. Testing these ICs via boundary scan can eliminate 1,376 FPT steps.\nStatistically, the 688 BGA pins are connected to 115 nets (6:1 pin-to-net ratio) or 20% of all networks on this board. As a result, the number of nets to be tested for shorts, 56 or 10% of all nets, reduces by 20% to 45. The shorts test requires 1,035 steps (45 ?? 46 ?? 2), which results in 561 test steps less than the 1,596 steps necessary for 56 nets. The total reduction of test steps is 1,376 + 561 = 1,937 or 38% of all 5,114 steps, resulting in a cost saving of $2.74 per assembly.\nIn the case of a manufacturing capacity of 50,000 PCBs per year, the savings potential is $137,000, notably with just two boundary scan-compliant ICs on the UUT.Type 3\nIn this case, boundary scan testing is practically a no-brainer. The multitude of BGAs doesn??t allow any physical contacts so no other test technique really is efficient and useful (Figure 4).\nThe only alternative is X-ray inspection; however, the average investment required for an in-line system is about $300,000. Moreover, the test execution time on an X-ray system is greater by far than that of a boundary scan test.\nA 430 mm ?? 380 mm PCB with 50 BGAs can be inspected by an X-ray system in 75 s (average value, test time of 700 ms per BGA plus total traversing time of about 40 s). In contrast, it takes approximately 10 s to test the entire assembly via boundary scan. The average cost for one test minute is calculated as $1. If the production volume were 50,000 PCBs per year, the reduction in test time would result in more than $50,000 in savings.\nThese are only three examples of how boundary scan can reduce the cost of test in electronics manufacturing. There are many other ways that it can be used to improve yield. For example, by combining boundary scan with AOI, the fault coverage can increase to nearly 100%. No other test technologies are required, and the quality of products shipped to the customer is very high.\nFor some applications, FT must be performed after structural testing to identify any dynamic failures that boundary scan and ICT or FPT could not catch. Again, a combination of boundary scan tools with functional test tools often times is very useful.\nLast, but not least, the cost of repair and debug must not be ignored. In the production lines of the German OEM that provided the numbers used in this article, the costs amount to $7 per unit on average. However, if the fault is discovered by the end user, the cost increases dramatically to approximately $200. This means that a fault detected by the\nFigure 4. Example of PCB Type 3\nmanufacturer before the product leaves the factory potentially saves $193 per faulty component.\nIf an assembly line produces 6,500 faults per year, a certain percentage of those faults most likely will not be discovered throughout manufacturing and final test. If there are appropriate test technologies or combinations, such as boundary scan with AOI in place to prevent just 5% of all 6,500 faults from slipping through the manufacturer??s tests, cost savings of more than $60,000 per year could be achieved.Summary\nThese examples demonstrate the enormous potential of boundary scan to decrease costs in the production process of PCBs. The same can be applied to system-level testing.\nBoundary scan software has become faster and more user-friendly, and development in this direction will keep moving. New industries such as automotive electronics embrace boundary scan, and the number of combinations of boundary scan with various test technologies is increasing as well.\nToday, you have a very wide range of test tools and a large number of components to select from, which makes implementing boundary scan easier than in the past, a trend that will last for many years to come. Ultimately, you can argue that not using boundary scan more often than not means losing valuable resources: time, money, and technological leadership.References\n- IEEE Standard Test Access Port and Boundary Scan Architecture—IEEE 1149.1 2001, IEEE Computer Society, 2001.\n- Parker, K.P., The Boundary-Scan Handbook, 3rd Edition, 2003.\nHolger Goepel is the CEO of GOEPEL electronic. He received an M.S.E.E. from the Technical University Dresden in 1973 and began working for Carl Zeiss the same year as a design engineer for electronic test equipment. He was promoted to manage the design group in 1979 and later to chief of the automated test equipment design departments at Carl Zeiss. Mr. Goepel is one of the founders and shareholders of GOEPEL electronic GmbH, established as a spin-off of Carl Zeiss in 1991. GOEPEL electronic GmbH, Goeschwitzer Str. 58/60, 07745 Jena, Germany, 011 49-3641-6896-11, e-mail: [email protected]FOR MORE INFORMATIONwww.rsleads.com/401ee-184Return to EE Home PagePublished by EE-Evaluation Engineering\nAll contents ?? 2003 Nelson Publishing Inc.\nNo reprint, distribution, or reuse in any medium is permitted\nwithout the express written consent of the publisher."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:38736693-730c-43b1-b0d9-82f7644c4d76>"],"error":null}
{"question":"How did the identification processes differ between Edgar Mobbs's remains and other WWI soldiers according to these sources?","answer":"Edgar Mobbs's body was never found and his name appears among the 54,000 on the Menin Gate at Ypres. This identification process was part of a larger effort by the Commonwealth War Graves Commission, which by the end of the war had identified 587,000 graves and registered 559,000 soldiers with no known grave. The Commission continues to help identify names from memorials today, though they may not recognize a deceased member if the war wasn't the immediate cause of death.","context":["Rugby World Cup winner pays tribute to First World War hero from Northampton Edgar Mobbs\nAn England Rugby World Cup winner has paid tribute to Northampton's Edgar Mobbs on the 100th anniversary of the outbreak of the Battle of the Somme.\nJosh Lewsey MBE, a former Royal Atillery officer, joined 99 other sportsmen and woman to pay tribute to those who served during the First World War.\nThe campaign, Sport Remembers the Somme 1916-2016, was launched with the backing of the ECB, the R&A, Professional Golfers’ Association, British Rowing and Team GB.\nMr Lewsey specifically paid tribute to Mr Mobbs, whose contribution to the war effort is legendary.\nHe said: “I am humbled and honoured to help commemorate these players and soldiers by representing rugby in the Royal British Legion Sport Remembers campaign.\n“Many of these players fought and some of them died at the Somme, including the extraordinary Edgar Mobbs who, because of his age, was turned down for commission so joined up as a private and raised a company of rugby fans and players that became known as Mobbs’s Own.\n“I would appeal to anyone who wishes to mark their strivings and their sacrifices to join the Legion’s Sport Remembers campaign.”\nSport Remembers issued the follow synopsis of Mr Mobbs’ life as part of the campaign:\n“Edgar Mobbs was devastated. The charismatic England rugby star had been turned down by the army because, at just 32, he was too old for a commission.\nBut Mobbs, a big, attacking three-quarter who had captained his country and played cricket for his county, had other ideas. He enlisted as a private soldier and after his next game for home club Northampton issued a rallying cry.\nMobbs, in a straw boater, asked the Franklin Gardens crowd to join him at a recruiting office the next Monday. More than 400 men turned up and 264 of them were passed fit for service. Mobbs, a car salesman with no military experience, would rise to lieutenant colonel and become a genuine Boy’s Own hero, giving an interview to the magazine. He was also mentioned in dispatches, won the DSO and was wounded three times before losing his life leading an attack on a machine gun at Passchendaele.\nSon of a car salesman and the third of six children, Edgar Roberts Mobbs was born in Northampton in 1882 and grew up in Olney, Bucks. At Bedford Modern School he excelled at sport and played rugby for Olney, Weston Turks and Northampton Heathens. In 1905 he joined Northampton Football Club, now Northampton Saints of the Premiership. Mobbs was 6ft 1ins, fast and had a famous hand-off; as his wartime fame spread, postcard cartoons portrayed him handing off the Germans.\nHe captained Northampton from 1906 to 1913, scoring 177 tries. In January 1909, on his England debut, he scored the first ever try by an Englishman against Australia. He went on to earn seven caps and played for Toulouse before retiring from rugby in 1913. Mobbs followed his father into car sales and in 1914 was manager of the Pytchley Auto Car Company, Market Harborough.\nThe men of Mobbs Own formed D Company of the 7th Battalion of the Northamptonshire Regiment, with their creator quickly moving up the ranks as sergeant, sergeant major and captain. Arriving in France in September 1915, they saw fierce hand-to-hand bayonet combat with Prussian guards at Loos. Leading his men on several charges, Mobbs escaped unscathed, although his uniform was torn to shreds by shell blasts and wire. The battalion lost nearly half its men, killed or wounded.\nAfter a spell of leave, Mobbs returned to France in early 1916, promoted to major and then lieutenant colonel commanding the 7th battalion. An hour into an afternoon attack at Guillemont on the Somme on August 18, Mobbs was hit in the ribs by a shell splinter and, doubled up in pain, reluctantly retired to a first aid post. More than 350 of his men were killed, missing or wounded. The attacks at Guillemont also claimed the lives of footballers Oscar Linkson, Allen Foster, William Gerrish and George Scott of the 1st Football Battalion, the 17th Middlesex. England rugby stars John King and Lancelot Slocock also died, fighting with the Liverpool Scottish.\nThe next month, a football match was held to mark Mobbs’s return to action. Already mentioned twice in dispatches for his exploits at the Somme, he was awarded the DSO in the New Year’s Honours of 1917.\nMobbs was wounded again at Arras and in June 1917 was sent back to England after being hit yet again at Messines. The war was taking its toll and he was physically weaker and less confident. While convalescing he surprised family by saying that he thought he would not survive the war.\nHis fears were justified. On July 31, Zero Hour 03:50, the 7th attacked Ypres Salient at Zillebeke, Passchendaele. A German machine gun at Lower Star Post was cutting apart 35-year-old Mobbs’s men from the flank, so he decided to take it out.\nBattalion commanders almost never took part in such dangerous missions and fellow officers begged Mobbs not to lead the assault. But he was determined and charged out with his men into withering fire. One of his 2nd Lieutenants shouted: “For God’s sake sir, get down,” but Mobbs was hit and fell wounded into a shell hole.\n2nd Lieutenant Spencer, who had been at school with Mobbs, later wrote: “I was perhaps one of the last to speak to Mobbs and we talked about Bedford. In the tomado of shelling he got ahead and seeing a number of his men cut down charged it to bomb it – and he went down. For a man of his standing and rank it was magnificent... I saw the old three-quarter in his own 25 yards get the ball from a crumpled scrum and get clean through and on. One of England’s finest rugby players, in the greatest game man can play.”\nMobbs’s body was never found and his name is among the 54,000 on the Menin Gate at Ypres. Of more than 400 men who served in the Mobbs Own D Company, only 85 came through the war unscathed.\nThe battalion history says: “The fact that his body could not be recovered and buried, as all ranks would have wished, was perhaps a good thing, as it helped keep alive his memory in the battalion, and inspired in everyone the resolve to avenge his death and to end the war that had already caused so much misery and suffering.”\nMore than £2,000 was raised in an appeal to commemorate Mobbs. His bust is on a memorial in Abington Square, Northampton and from 1921 to 2011 the Barbarians played at Northampton in the Mobbs Memorial Match. In 2006, a new link road to the A45 was named Edgar Mobbs Way.”","Search the Word War One names archive\nWorld War One War Memorial Names\nTwo years of gloom our home has past and still we mourn for him we loved so dear. In an unknown grave somewhere in France our dear boy now sleeps, the memory of that last goodbye and of his boyhood days at home we never can or shall forget. Art Willis died 3/10/1915 age 21.\nWe have been able to identify close to 600 names out of the 711 lost locally in WWI although this is only a fraction, perhaps a third, of the total killed. The primary source has been the Commonwealth War Graves Commission started by Sir Fabian Ware, 1869-1949, commander of a mobile Red Cross unit, that recorded as many war graves as could be found. Recognised by the War office in 1915 and the Prince of Wales in 1917, by the end of the war in 1918 there were 587,000 graves identified and 559,000 registered but with no known grave.\nMemorials to the missing include Ypres Menin Gate, Thiepval on the Somme, Helles at Gallipoli and Tyne Cot in Belgium. Today, google www.cwgc.org to have an excellent chance of identifying a name from the memorial even though the forenames are only represented on it by initials. Occasionally a deceased member of the forces is not recognised by the Commission if it is thought that the war was not the immediate cause of death.\nSometimes the task is impossible without additional information, such as the 53 entries for Field H. The soldiers medals of the National Archives sometimes record names not in the CWGC and just occasionally the spelling may be wrong. Using findmypast or ancestry, the census records for 1911 and 1901 are the next step to confirm that a name found on the cwgc is linked to Beckenham. The BMDs are useful providing forenames and marriages, especially as a widow may have moved away to a family home with no apparent Beckenham connection.\nThe list of private residents in Beckenham, Penge and Anerley from Kelly's Directory for 1914 has assisted identification and occasionally Genes Reunited has solved a problem. Compiled in the War Office, there are 80 volumes of 'Soldiers who died in the Great War 1914-1919,' that commemorate some 635,000 listed alphabetically and we have used part 56 of the Middlesex Regiment supplying rank, birth place, enlistment, date, place and nature of casualty. The Beckenham Journal recorded as many of the local killed and wounded as were notified, first of all by Frank Thornton, and the weekly accounts have listed many who are not on the Beckenham Memorial at all and others where success has come from a vital snippet of local information.\nValuable accounts of shipping lost during the war are found on line too. We have to thank Ellen Barbet for her work in finding those remembered in Beckenham Cemetery, also Peter Wiseman and Irene Palmer and Ian Muir for passing on their research which greatly assisted finding the following alphabetical list. We apologise if some of our identification is wrong and welcome any corrections.\nNot in CWGC or among 90 in National Archives. But could it be Capt Hugh Lionel Allfrey son of Edward Richmond Allfrey of Eden Park Beckenham born abt 1882.\nDied The Buffs 18/9/1918 in Vendhulle?\n29087 Private Duke of Cornwall's Light Infantry 6th Bn formerly 1218, City of London R. Fusiliers.\nBorn Brixton, lived Bermondsey, Killed in action 23 Aug 1917.\nPanel 80 to 82 & 163A. TYNE COT MEMORIAL.\nAlthough no obvious connection with Beckenham he is the only Amner G C in the Nat Arch or CWGC.\nDied long after the echo of guns died away. He enlisted in the Bucks Hussars and transferred to the Fusiliers.\nTwice gassed, he returned to his service with the Post Office but died in Beckenham Cottage Hospital on 20 March 1920.\nA keen cricketer, he was the youngest son of Charles Anderson of Burnhill Rd and husband of Manda Annie Anderson. Reported in the Beckenham Journal on 27.3.1920."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:ad45a947-c239-4402-a422-73e5ef8ea11f>","<urn:uuid:072b1b0e-e285-463f-ac1d-2033bce51b45>"],"error":null}
{"question":"What creative staging elements are employed in both The Golden Cockerel and The Merry Widow productions?","answer":"The Golden Cockerel features an eery, hilled grassland set with a skeleton-like tree designed by Rufus Didwiszus, complemented by Vitoria Benr's creative costuming and Otto Pichler's choreography. The Merry Widow's staging is handled by Max Webster in his ENO debut, incorporating his 'singular sense of the carnivalesque' style, with set design by Ben Stones, costume design by Esther Bialas, and choreography by Lizzi Gee who previously created 'gobsmacking' routines for other productions.","context":["Presented by: Festival D’Aix-En-Provence with Adelaide Festival, Opera National De Lyon and Komische Opera Berlin in association with Adelaide Symphony Orchestra.\nReviewed 6 March 2022\nOscar Wilde said, “Life imitates art far more than art imitates life”. This quote sat at the forefront of my mind throughout the Adelaide Festival’s headlining opera, The Golden Cockerel. With recent events unfolding over in Europe, an opera about a Russian Tsar invading neighbouring countries certainly gave this production a fresh and new take. This production of The Golden Cockerel is an absolute visual and aural feast; the melding of music, clever staging, costume and movement throughout this production is sensational.\nOriginally a poem, The Tale Of The Golden Cockerel, written by Alexander Pushkin in 1834, was the basis of Rimsky-Korsakov’s last opera before his death in 1908. Russian composer Rimsky-Korsakov, along with librettist Vladimir Belsky, wrote the opera in protest of his country’s war against Japan, but due to Government censorship at the time, Rimsky-Korsakov never saw the opera performed. It tells the story of the fictitious Tsar Dodon who thinks that his country is in danger and reaches out for advice from an astrologer, who supplies the Tsar with a magic Golden Cockerel to protect him. The cockerel confirms the Tsar’s fears and the leader pre-emptively attacks a neighbouring country with an army led by his sons.\nThis opera packs as much of a punch today as it undoubtedly did back when it was first performed in 1909. Not only do the themes throughout the opera resonate with truth in regards to the actions happening across the globe between Russia and Ukraine, there is also a strong connection to these themes within the cast. Ukrainian singer Pavlo Hunka, who is playing the Tsar, gives a very deep and emotional performance, as do the other Ukrainian and Russian company members.\nRimsky-Korsakov was a master of orchestration. He had a magical ability to pass the melody around an orchestra to create heavenly orchestral harmonies. His talent for writing for voices is also clearly apparent throughout The Golden Cockerel. There are many aural delights throughout the work where vocal harmonies and orchestral accompaniment blend so perfectly, then transport you to another place. The Golden Cockerel score was played brilliantly by the Adelaide Symphony Orchestra under the ever watchful eye of Maestro Arvo Volmer. As always, the ASO worked seamlessly together and handled Rimsky-Korsakov’s challenging score with ease (or at least made it sound that way). Volmer has a longstanding relationship with the ASO and his emotive connection to the score made it clear why he returns regularly to conduct these challenging works.\nDirection by Barrie Kosky was innovative and fresh. Set in an eery, hilled grassland, with a single skeleton-like tree on which the Golden Cockerel perched, Rufus Didwiszus’s stage design enhanced Kosky’s direction, ably supported through creative costuming by Vitoria Benr and choreography by Otto Pichler. Kosky found great moments of joy, heart-ache, comedy, passion and fear.\nThe principal cast, Pavlo Hunka (Tsar Dodon), Venera Gimadieva (Queen of Chemakha), Andrei Popov (Astrologer), Samuel Dandas (Tsarevich Aphron), Nicholas Jones (Tsarevich Gvidon), Mischa Schelomianski (Polkan), Samantha Clarke (Golden Cockerel’s Voice) and Matthew Whittet (On stage Cockerel), all gave exquisite performances. However, Hunka, Gimadieva and Popov’s performances pushed this opera into a league of its own. Their voices were velvet, both in their solo work and when singing together. Popov’s upper register was incredibly pure and natural, as was Gimadieva.\nThe Adelaide Festival Chorus, under the expert eye of Chorus Master Anthony Hunt was as expected: brilliant. Although often appearing as voices on stage, or hidden under giant horse heads and black shrouds, their vocal work was sublime.\nThroughout this production there were moments of brilliant lighting, designed by Franck Evin. In these moments, the design perfectly accompanied the on stage direction and was very unobtrusive. However, there were a lot of moments where patches of darkness across the stage caused principals to be lost as they moved around. There were also several times where the front wash was so dim that you could barely make out who was singing and where they were singing from. One other little directorial niggle that halted the flow of the show was the use of Astrologer crossing the stage between the acts. It felt unnecessary, and the use of the curtain and house lights to 25% would have been more suitable.\nPutting these minor niggles aside, The Golden Cockerel is two hours (no interval) of pure joy, heart-ache and brilliance. To sit there and listen to this work be performed so expertly was a very moving, emotional experience. Whilst ticket prices are expensive, it’s not every day that a work like this is seen here in Adelaide.\nThe Golden Cockerel has 2 final performances as part of the 2022 Adelaide Festival – Tuesday 8 and Wednesday 9 March at 6pm. Tickets through Adelaide Festival or at https://www.adelaidefestival.com.au/events/the-golden-cockerel/ .\nReviewed by: Ben Stefanoff\nVenue: Festival Theatre, Adelaide Festival Centre\nSeason: Tuesday 8 and Wednesday 9 at 6pm\nDuration: 2 hours, no intermission\nTickets: From $120\nRating out of 5: 5\nPhoto Credit: Andrew Beveridge","Opens Friday 1 March at 7.30pm (12 performances)\nOne of the most successful musical comedies in history returns to the London Coliseum stage in March, in a brand new version fizzing with wit and invention. Old Vic Associate Director Max Webster makes his ENO debut with the company’s first new staging in more than a decade of the beloved 1905 Viennese operetta. The original libretto that has delighted audiences across the world for more than century is given a new English translation by dramatist April de Angelis and lyricist Richard Thomas.\nThis operetta enjoyed unprecedented popularity and was performed an estimated half a million times across the world in its first 60 years. It acted as the bridge that would lead from opera to the rise of 20th century musical theatre. The story of the wealthy widow Hanna Glawari and her pursuit by men trying to keep her wealth in their bankrupt Balkan nation forms a classic romantic comedy, containing some of the most beloved music in opera including the Merry Widow Waltz and the ‘Vilja Song’.\nMax Webster is Associate Director at the Old Vic, where his 2015 production of The Lorax garnered universal acclaim (‘the best family show since Matilda’ – 5*, The Guardian). His theatrical style with its ‘singular sense of the carnivalesque’ (WhatsonStage) is now brought to bear on the ENO comic opera tradition that brought Cal McCrystal’s standing-room-only Iolanthe to the Coliseum in 2018. He comments:\n“I’m delighted to be working with ENO for the first time this season, especially on this wonderful 20th century operetta. The merry widow herself, Hanna Glawari, is one of the most popular creations in operatic history for a very good reason: she is a woman in control of her own destiny.\nA female millionaire from humble origins, in many ways she represents the coming of the new century where women would fight for their freedom and the old, dusty, patriarchal world of the nineteenth century would begin to crumble.\nI want to recreate that excitement of this, one of the forerunners of the modern musical and for many years the best night out across Europe, in the same joyful operetta tradition that has made ENO Gilbert and Sullivan productions so beloved by audiences.”\nHanna is sung by Sarah Tynan, one of the sopranos most associated with ENO, in her second lead role of the season after 2018’s rapturously received Lucia in Lucia di Lammemoor (‘exquisite’ – The Daily Telegraph). In 2017 her Rosina in The Barber of Seville (‘impeccable’– The Independent) and the title role of Partenope (‘dazzling’ – WhatsOnStage) showed her comic abilities to great effect. An alumna of the ENO Harewood Artist programme, she is fast becoming acknowledged as one of the UK’s leading sopranos.\nNathan Gunn makes his ENO debut as Hanna’s former lover Danilo. One of America’s most in-demand baritones, he has ‘everything that today’s opera fans look for in a singer: a beautiful voice, first-class acting and a great sense of humour’ (Bachtrack). He previously sang the role with the Metropolitan Opera, New York in 2014, opposite Renée Fleming.\nENO house favourite Andrew Shore sings the scheming diplomat Baron Zeta, adding another great buffo role to his ENO roster that has included hilarious turns as The Lord Chancellor in 2018’s Iolanthe (‘patter-perfect’ – WhatsonStage), Major-General Stanley in 2015’s The Pirates of Penzance, many Bartolos in The Barber of Seville, and more than thirty other productions.\nThe Baron’s wife Valencienne is sung by former ENO Harewood Artist Rhian Lois, returning after her ‘winning Susanna’ (The Times) in The Marriage of Figaro and her Governess in The Turn of the Screw in the 2017/18 season. Her French admirer Camille is sung by Robert Murray, whose Flute in A Midsummer Night’s Dream in 2018 and Frederic in The Pirates of Penzance in 2015 displayed his abilities as one of ENO’s great comic performers.\nNicholas Lester returns to the ENO stage following a successful run as Marcello in La bohème (‘oozes vocal charm’ - The Guardian) to sing the Vicomte Cascada, while Jamie MacDougall sings Raoul.\nThe other diplomats and their wives are sung by ENO Chorus members Paul Sheehan, Lydia Marchione, Adam Sullivan, Debbie Davison, Trevor Bowes and Natalie Herman. This continues an ENO practice of featuring Chorus members in secondary roles from the Studio Live programme (‘they take on the secondary roles with boundless skill and personality’ – The Stage).\nThe cast is completed by actor Gerard Carey in the non-singing role of Njegus, the Embassy secretary.\nEstonian conductor Kristiina Poska makes her ENO debut with this production, as well as her debut with a UK opera company. She is known on the continent for her distinguished career at the Komische Oper Berlin where she was First Kapellmeister from 2011 to 2016, winning the Deutscher Dirigentenpreis in 2013. From the 2019/20 season she will be the Music Director at Theater Basel.\nThe new translation of the 1905 libretto features dialogue by April de Angelis and lyrics by Richard Thomas. April de Angelis is noted for her many plays centring on the female experience, including Playhouse Creatures, After Electra, Jumpy and The Village. Her libretti include Jonathan Dove’s Flight and The Day After, which was performed by ENO in 2017.\nRichard Thomas garnered huge acclaim for his Jerry Springer: The Opera for which he won the Olivier Award for Best Musical Score in 2004, co-writing the lyrics with Stewart Lee. He wrote the libretto for Mark-Anthony Turnage’s Anna Nicole as well as the lyrics for the musical Made in Dagenham.\nThe ensemble of dancers is choreographed by Lizzi Gee, who previously provided the ‘gobsmacking’ (The New York Times) routines of 2018’s Iolanthe. Her 2018 credits include A Christmas Carol (Old Vic), Twelfth Night (Young Vic) and Little Shop of Horrors (Regent's Park Open Air Theatre).\nSet design is by Ben Stones, who previously designed Max Webster’s Twelfth Night at the Regent’s Park Open Air Theatre in 2014. This marks his operatic debut after designs for productions at the National, Young Vic, Almeida and Bush theatres as well as Burberry fashion shows.\nCostume design is by Esther Bialas, whose designs were last seen at ENO for La traviata in 2018. She is known on the continent for her extensive work at Komische Oper Berlin with Barrie Kosky. Lighting design is by Bruno Poet, whose ENO work includes Akhnaten, Satyagraha and Aida.\nThe Merry Widow opens Friday 1 March at 7.30pm for 12 performances: 1, 6, 8, 9, 13, 15, 22, 27 and 29 March and 1 and 4 April at 7.30pm and 13 April at 3pm"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:6c3509b2-5c81-4df1-b74b-4761522a444d>","<urn:uuid:d27670e5-85e2-4d44-abef-858aa1d4eb41>"],"error":null}
{"question":"I'm researching fluid power systems and would like to know: what are the core operating principles of hydraulic pumps, and how do they differ from pneumatic systems in terms of the substances they use?","answer":"Hydraulic pumps operate by converting mechanical energy into hydraulic energy through two main functions: creating a vacuum at the inlet to draw liquid from a reservoir, and delivering that liquid to an outlet to create flow throughout the system. They use substances like water, mineral oil, water emulsion, or ethylene glycol. Pneumatic systems, on the other hand, operate by compressing gases rather than liquids, typically using compressed air, nitrogen, or carbon dioxide as their working substances. The key distinction is that hydraulics work with relatively incompressible liquids, while pneumatics utilize compressible gases to generate force.","context":["Hydraulic pumps are extremely useful in business applications because they have the ability to convert mechanical power into hydraulic energy, which consists of flow and pressure. The pump itself will generate sufficient flow to overcome any pressure that is induced by a load right at the pump outlet. Most hydraulic systems in operation today require the use of hydraulic pumps so as to accomplish tasks necessary for the machinery that they drive.\nHydraulic pumps – what are they?\nA hydraulic pump is a device that converts mechanical energy from some moving agent (like a truck engine) into hydraulic energy, which can then be used by some kind of system. Hydraulic energy results when pressure and flow are applied by actuators, which can then be harnessed to perform useful tasks. Hydraulic energy is a combination of both flow and pressure, and unless both are present, no work can actually be done. Ordinary flow would have no energy behind it to move fluids, and standalone pressure would just be trapped fluids, so it’s clear that the two must work in tandem in order for any useful work to be accomplished.\nThe function of a hydraulic pump is to push against fluid and cause it to be moved through some type of machinery until it actually moves against actuators so that some kind of load can be driven. A hydraulic pump might be pushing on ball bearings, sand, or any type of solid medium that has the ability to assume the shape of its container so that the net result is force being transmitted.\nThis transmission of force is the essential core of hydraulics, and as any student of hydraulics can tell you, pressure is the force that makes something move, and flow is simply the rate at which pressure is created. Pressure will generally rise as high as it has to in order to overwhelm resistance downstream, but it’s good to keep in mind that if pressure doesn’t start at the pump, the fluid will then move backward.\nAs it relates to hydraulics, pressure is a perfect example of Newton’s Third Law of Motion, which states that every action has an equal and opposite reaction. In this case, the opposing force might be a flow control or possibly some kind of loaded cylinder, and it doesn’t make any difference to the pump as to which it is.\nThe pump will continue to move fluid in accordance with rising pressure so that resistance can be overcome. This is true even if the prime mover ends up being overloaded, or if it causes something to simply blow up. The key point to remember in all of this is that all energy originates from the pump, and once this is understood, everything else about a hydraulic system will begin to make much more sense.\nHow do hydraulic pumps work?\nDuring normal operation, a hydraulic pump has two functions, the first of which is to create a vacuum at the point of the pump inlet, thereby allowing atmospheric pressure to push some type of liquid from a tank or reservoir into the inlet line and up to the pump itself. The second function of a hydraulic pump is to deliver that liquid to an outlet, which then forces it into the entire hydraulic system.\nA hydraulic pump does not generate pressure of any kind; it merely produces flow, or liquid movement. That flow is necessary to create pressure, which functions as a resistance to the flow of fluids throughout the system. This means that the pressure of fluid at the pump outlet itself is zero when the pump is not connected to any kind of load.\nWhen the pump does deliver to a specific system, the pressure will only increase to whatever level is necessary in order to exceed the resistance of the load. All hydraulic pumps will fall into one of two categories: positive-displacement pumps or non-positive-displacement pumps. The vast majority of pumps that are currently used in most hydraulic systems today are of the positive-displacement variety.\nIf one of your hoses develops a leak, a mobile hydraulic hose repair service may be able to help get your machine up and running, quickly, and with minimal downtime. Otherwise, it’s critical to know how to diagnose problems yourself but understanding the components of a hydraulic system.\nHydraulic pump types\nThe most popular types of hydraulic pumps used in most hydraulic systems today are gear pumps, vane pumps, and piston pumps. All of these pumps will either be uni-rotational or bi-rotational in nature, referring to their ability to operate in either a single direction or both directions of produced by shaft rotation.\nGear pumps are commonly used in truck-mounted hydraulic systems. Because they have fewer moving parts, they are easier to maintain, and they’re much more tolerant of contaminants. On top of that, they’re also fairly inexpensive, which makes them appealing to a great many users. Gear pumps are rated in terms of their maximum pressure rating, their maximum input speed rating, or their cubic inch displacement.\nPiston pumps are often used in high operating-pressure systems because they can withstand those higher pressures better than gear pumps. The downside of using piston pumps is that they generally cost more, and they don’t have the same kind of resistance to contamination as gear pumps do. They are often used in applications such as snow and ice removal or on truck-mounted cranes because these are situations where it will often be necessary to modify system flow while maintaining engine speed at a constant. There are more moving parts to piston pumps, and that makes them somewhat more difficult to maintain and service, but they are invaluable when high operating pressures are necessary.\nVane pumps are small displacement pumps that are most commonly used on utility vehicles. However, they are less popular today than they once were, because many applications now use gear pumps in their place. Vane pumps operate by having the input shaft rotate, which causes oil to be picked up between the vanes of the pump, and that oil is then pushed to the outlet side of the pump.\nIt can be somewhat confusing when you try to understand the precise nature of hydraulic pumps in any kind of hydraulic system. However, if you keep in mind that all hydraulic pumps have two functions — create a vacuum and deliver liquid to an outlet — you’ll be well on your way to understanding their operation.\nThere are a wide variety of hydraulic pumps in operation today, only a few of which have been described in this discussion. Because there is such a tremendous range of operating conditions, however, there will always be a need for a diverse number of hydraulic pumps to satisfy those particular business requirements. Be sure to learn about the types most relevant to your business’s needs!","Hydraulic and pneumatic systems are integral to the operation of cars, trucks, buses, aircraft, and other vehicles. These systems power everything from braking and steering to heating and air conditioning. However, there are some essential differences between hydraulics vs. pneumatics.\nHydraulic systems compress liquid, are used for industrial machinery, cost about $10,000, and produce around 6,500 PSI. Pneumatic systems compress gas or air, are used for smaller tools, cost approximately $1,500, and generate about 120 PSI. Overall, hydraulics are better for large jobs, while pneumatics can handle the small ones.\nIn this article, we’ll discuss the ins and outs of hydraulics and pneumatics, what each system is used for, and their pros and cons!\nWhat Is a Hydraulic System?\nThe first type of system we’re going to dive into is hydraulics.\nA hydraulic system, or hydraulic power system, uses pressurized fluid to power the moving parts of a machine. Hydraulics pumps relatively incompressible liquids at extremely high pressures using valves and actuators. The average operating pound-force per square inch of a hydraulic system is 6,500 PSI.\nHydraulic systems are often paired with at least one other kind of power system. For example, some cars use hydraulics to power their steering and braking and use electric motors and gasoline to power the engine. Note that these systems are typically seen on heavy-duty vehicles like construction equipment, aircraft, or elevators.\nHydraulics use engineering and physics principles (think Pascal’s Law) to transfer force from one end to another- effectively, like a seesaw. If one end of the seesaw is pushed down, the other end moves up as a result. This allows for machinery to lift cumbersome pieces of equipment without much effort.\nSubstance Used in a Hydraulic System\nThere are a few different substances that can be used in a hydraulic system to create force or motion.\nThe fluids hydraulics use include water, mineral oil, water emulsion, or ethylene glycol. In order to translate the fluid into power, you need a pump- this is usually a piston pump powered by a motor.\nHydraulics also require a filter to remove particles from the hydraulic fluid before they clog any components of the system.\nParts of a Hydraulic System\nBecause hydraulics involves storing and pressurizing liquid material, hydraulic machines are usually incredibly large and intricate.\nThe main components in a hydraulic system are:\n- Hydraulic pump\n- Reservoir for hydraulic fluid\n- Directional control valve\n- Flow control valve\n- Pressure relief valve\n- Other connecting pipes and wires\nThese parts work like a well-oiled machine (no pun intended) to ensure that your piece of equipment has adequate power.\nWhat Are Hydraulics Used For?\nLike I mentioned above, hydraulic machines are typically big and more complex and are used to power large industrial equipment.\nSome areas where hydraulics are used include:\n- Lifts (fork, elevator, wheelchair, and car)\n- Amusement parks\n- Gasoline pumps\n- Cars (braking and steering systems)\n- Hairdresser/office chairs\n- Boat rudders\n- Other industrial equipment (like on a construction site)\nThese are just a few of the places you might see a hydraulic system at work in your everyday life!\nPros of Hydraulics\nThere are a few advantages a hydraulic system has over a pneumatic one.\nA hydraulic system is usually better at doing the heavy lifting- there are a variety of sizes to accommodate your industrial needs. This has led to hydraulic systems becoming the preferred choice in a wide range of commercial applications.\nOther pros include:\n- Multitasking abilities (they cool, power, and grease a piece of machinery at any given time)\n- More power generated from comparatively smaller actuators\n- Constant torque and force regardless of speed\n- Longer operating time and more reliability due to the design\n- Fewer parts and less maintenance required\nThese are all critical benefits when deciding what system is suitable for your specific needs.\nCons of Hydraulics\nWhile there are many advantages to using hydraulics, they do have some disadvantages.\nA hydraulic system has the potential to leak fluid everywhere, which is why it’s imperative to make sure everything in your machine is adequately sealed and in good working order.\nOther cons include:\n- The expense (the machines can be pricey and more energy is required to operate them).\n- Filtering oils, which can get messy\n- Being prone to leaks, which results in a lack of proper fluids rendering the entire machine nonfunctional\n- Fire hazard (created by oil leaks)\n- Loud operating sounds if air bubbles get into the system\nThe concept of hydraulics is also relatively complex and requires someone with a decent understanding of engineering to set up and use the machine properly. If you don’t know what you’re doing, the pressure in your machine can cause severe damage.\nCost of a Hydraulic System\nThe overall cost of a hydraulic system can get pretty expensive.\nIt’s not uncommon for an industrial-sized hydraulic system to cost upwards of $10,000.\nThe reasons behind this are that the machine needs to be custom-built, with most parts and pieces assembled on site. Additionally, the oil or substance used can get pricey.\nYou must also consider what mammoth machines hydraulic systems are; the energy required to power them is unmatched.\nWhat Is a Pneumatic System?\nThe second type of system is powered by pneumatics.\nPneumatic systems, also called compressed-air systems, use air or gas under pressure to provide mechanical energy for engines or other machines. Pneumatic systems power small, oscillating saws in the OR or medium-sized power tools in your garage. The average operating pound-force per square inch of a pneumatic system is 95 PSI.\nPneumatics utilizes an air compressor to reduce the amount of air to increase its pressure. The compressed air is then pushed through a filter into the tubing. Here it is controlled by valves and an actuator, which converts it into power for your devices.\nOverall, a pneumatic system is easier to operate, less expensive, and smaller in stature than a hydraulic system. That being said, it can’t handle as much weight or pressure. Because this system uses a compressed gas at lower pressures than hydraulics in order to operate, it’s best suited for smaller and lighter projects.\nSubstance Used in a Pneumatic System\nTypically, there are 3 inert gases used in pneumatics.\nThe substances used in a pneumatic system include compressed air, nitrogen, and carbon dioxide.\nCompressed air is usually used in commercial settings; it’s freely available and less combustible than regular oxygen. Nitrogen is the least reactive and most commonly used because it can be easily stored. Lastly, carbon dioxide is less popular because it quickly turns from gas to liquid and can cause suffocation in a closed space.\nParts of a Pneumatic System\nPneumatics is far less complicated than hydraulics; therefore, the parts are smaller and easier to learn.\nThe main components in a pneumatic system are:\n- Air hoses\n- Gauges (or regulators)\n- Check valve\n- Pressure relief valve\nAll of these parts work together to power your tools.\nWhat Are Pneumatics Used For?\nAs described above, pneumatic systems are typically used for small tools and machinery because of their limited pressure capabilities.\nPneumatic systems are great for equipment actions that include gripping, positioning, clamping, or repetitive movements. They are also able to tension or press.\nSome areas where pneumatics are used include:\n- Tire pressure gauges\n- Nail guns\n- Vacuum cleaners\n- The anti-slam feature on doors and drawers\n- Air compressors\n- AC systems\n- Drills and saws utilized by surgeons\nPneumatics can also be used as a direct-acting system on small loads that require exact precision, making them an attractive option across all industries.\nPros of Pneumatics\nWhile pneumatic systems are usually smaller, there are some advantages they have over hydraulics.\nSome pros include:\n- Lower PSIs reached, so safer to use (especially for novices)\n- More cost-effective (the machines and the energy used to power these machines are less expensive)\n- Smaller and can be portable (come in many sizes and pressure capabilities)\n- Utilizing compressed air results in less of a safety hazard\n- The power supply of compressed air or gas is much cleaner than oil (great for sterile environments like surgery)\nOverall, if you’re looking for a reliable energy source that needs fewer than 120 PSI, choose a pneumatic system.\nCons of Pneumatics\nFor the many advantages, there are a few downsides to using pneumatics.\nThe first disadvantage is that a pneumatic system will not be able to supply the high pressure needed to power large machinery. Therefore, it’s unsuitable for heavy loads or large projects because pneumatic systems can’t handle them.\nOther cons include:\n- Limited PSI capabilities\n- Sensitive to temperature change\n- Prone to air leaks if not secure (this can cause energy loss)\n- Hoses can corrode (if they’re not made of stainless steel) if they’re exposed to the outside conditions\nCost of a Pneumatic System\nBecause pneumatic systems are generally tiny in comparison to hydraulic systems, they are much less costly.\nAn average pneumatic system costs around $1,500.\nFor that small cost, you’ll be able to power your garage equipment and small machinery easily!\nThe Main Differences Between Hydraulics and Pneumatics\nWhen you compare hydraulic vs. pneumatic, you’ll notice a few key differences between how they operate and what they’re capable of.\nThe main difference is that pneumatics use compressed air and gas for force, while hydraulics use relatively incompressible liquid. Hydraulic systems are much more substantial and have a capability of over 5,000 PSI, perfect for industrial settings.\nPneumatic systems are used for smaller tools that require 100 PSI or less, ideal for sterile environments.\n- Top Chicago Pneumatic Air Compressors | List & Reviews\n- Central Pneumatic Air Compressor Not Building Pressure?\nWhen considering hydraulic vs. pneumatic, it’s essential to consider the applications and advantages of each.\nIf you’re looking at larger tasks, like construction projects that require heavy-duty tools and equipment, then a hydraulic system may be the best option. Hydraulic systems are more expensive than pneumatics, but they can generate around 6500 PSI of pressure and cost $10,000.\nFor smaller jobs with less demand on power generation capabilities (like saws or drills in home workshops), a pneumatic system might work better. Pneumatics are cheaper and produce less PSI.\nSo, which one is right for your job?"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:7b0b1d56-8d14-4134-88cf-2bab65cc66d6>","<urn:uuid:346c9595-24da-49b2-84f9-4281ab63d3eb>"],"error":null}
{"question":"What are the key differences between free trade and protectionist policies in terms of their economic philosophies and political alignments?","answer":"Free trade and protectionist policies represent opposing economic philosophies. Protectionism involves government policies that restrict international trade to help domestic industries, using tools like tariffs, import quotas, product standards, and subsidies. It is traditionally associated with left-wing politics and economic populism. Proponents argue it creates domestic jobs, increases GDP, and makes domestic economies more competitive. In contrast, free trade emphasizes reducing barriers between countries and eliminating preferential policies. It is typically supported by conservatives and libertarians who favor smaller government and less regulation. Free trade advocates believe businesses should succeed or fail based on market forces without special governmental protections. Critics of protectionism argue it ultimately hurts those it aims to protect by slowing economic growth and increasing inflation.","context":["What Is Protectionism?\nProtectionism refers to government policies that restrict international trade to help domestic industries. Protectionist policies are usually implemented with the goal to improve economic activity within a domestic economy but can also be implemented for safety or quality concerns.\n- Protectionist policies place specific restrictions on international trade for the benefit of a domestic economy.\n- Protectionist policies typically seek to improve economic activity but may also be the result of safety or quality concerns.\n- The value of protectionism is a subject of debate among economists and policymakers.\n- Tariffs, import quotas, product standards, and subsidies are some of the primary policy tools a government can use in enacting protectionist policies.\nProtectionist policies are typically focused on imports but may also involve other aspects of international trade such as product standards and government subsidies. The merits of protectionism are the subject of fierce debate.\nCritics argue that over the long term, protectionism often hurts the people and entities it is intended to protect by slowing economic growth and increasing price inflation, making free trade a better alternative. Proponents of protectionism argue that the policies can help to create domestic jobs, increase gross domestic product (GDP), and make a domestic economy more competitive globally.\nTypes of Protectionist Tools\nImport tariffs are one of the top tools a government uses when seeking to enact protectionist policies. There are three main import tariff concepts that can be theorized for protective measures. In general, all forms of import tariffs are charged to the importing country and documented at government customs. Import tariffs raise the price of imports for a country.\nScientific tariffs are import tariffs imposed on an item-by-item basis, raising the price of goods for the importer and passing on higher prices to the end buyer. Peril point import tariffs are focused on a specific industry.\nThese tariffs involve the calculation of the levels at which point tariff decreases or increases would cause significant harm to an industry overall, potentially leading to the jeopardy of closure due to an inability to compete. Retaliatory tariffs are tariffs enacted primarily as a response to excessive duties being charged by trading partners.\nImport quotas are nontariff barriers that are put in place to limit the number of products that can be imported over a set period of time. The purpose of quotas is to limit the supply of specified products provided by an exporter to an importer. This is typically a less drastic action that has a marginal effect on prices and leads to higher demand for domestic businesses to cover the shortfall.\nQuotas may also be put in place to prevent dumping, which occurs when foreign producers export products at prices lower than production costs. An embargo, in which the importation of designated products is completely prohibited, is the most severe type of quota.\nProduct safety and low-quality products or materials are typically top concerns when enacting product standards. Product standard protectionism can be a barrier that limits imports based on a country’s internal controls.\nSome countries may have lower regulatory standards in the areas of food preparation, intellectual property enforcement, or materials production. This can lead to a product standard requirement or a blockage of certain imports due to regulatory enforcement. Overall, restricting imports through the implementation of product standards can often lead to a higher volume of production domestically.\nFor one example, consider French cheeses made with raw instead of pasteurized milk, which must be aged at least 60 days prior to being imported to the U.S. Because the process for producing many French kinds of cheese often involves aging of 50 days or fewer, some of the most popular French cheeses are banned from the U.S., providing an advantage for U.S. producers.\nGovernment subsidies can come in various forms. Generally, they may be direct or indirect. Direct subsidies provide businesses with cash payments. Indirect subsidies come in the form of special savings such as interest-free loans and tax breaks.\nWhen exploring subsidies, government officials may choose to provide direct or indirect subsidies in the areas of production, employment, tax, property, and more.\nWhen seeking to boost a country’s balance of trade, a country might also choose to offer subsidies to businesses for exports. Export subsidies provide an incentive for domestic businesses to expand globally by increasing their exports internationally.\nWhat Are Examples of Protectionism?\nCommon examples of protectionism, or tools that are used to implement a policy of protectionism include tariffs, quotas, and subsidies. All of these tools are meant to promote domestic companies by making foreign goods more expensive or scarce.\nIs Protectionism Left-Wing or Right-Wing Politics?\nTraditionally, protectionism is a left-wing policy. Right-wing politics generally support free trade, which is the opposite of a protectionist stance. Left-wing politics support economic populism, of which protectionism is a part.\nWhat Are the Arguments for Protectionism?\nLawmakers that favor protectionist trade policies believe that they protect jobs at home, help support and grow small companies and industries, and provide a layer of security to the nation.","Economists and politicians alike debate the relative merits of free trade and fair trade. Although both concepts refer to a comprehensive approach to commercial activity, people who favor one approach over the other are often guided by ideological concerns that affect the political regulation of trade activity. Free trade and fair trade address the same subject but from very different perspectives.\nProponents of free trade emphasize the reduction in barriers between countries and the elimination of preferential policies that favor countries or specific industries. Free traders believe that a business should succeed or fail based on its ability to respond to the free and open market, without needing special governmental protections to protect the industry or its workers. Many free trade advocates advocate for the elimination of tariffs and subsidies, and oppose regulations that force companies to pay extra for doing business in foreign markets.\nFair trade advocates focus on the wages and working conditions of labor in developing markets. For example, a fair trade activist will fight to increase the wage rates of workers and improve their working conditions, especially when a large multinational corporation chooses to pay pennies per hour for labor in one country instead of dozens of dollars per hour elsewhere. Fair traders suggest that companies and governments should regulate trade to ensure that workers receive a just level of compensation and a safe working environment.\n\"Fair trade\" as a term is sometimes used to refer specifically to policies that provide a living wage to farmers for their crops, usually above market prices, because local and small-hold farmers often cannot compete on price with large-scale factory farms.\nAlmost no government takes a purely free trade or fair trade approach to its commercial policy. Instead, countries blend policies in various ways. For example, the United States, Mexico and Canada are members of the North American Free Trade Agreement, which slashed protectionist barriers among the three countries. However, the U.S. also supports certain fair trade policies. For example, the U.S. Trade Representative works with the United Nations to provide preferential access to business resources to women and minorities in markets around the world.\nFree trade advocates are usually conservative or libertarian; their support for smaller government and less regulation, in general, leads them to be skeptical of government programs to redistribute wealth or income. Fair trade advocates, by contrast, tend toward a communitarian outlook that favors equality of outcome, and they are more willing to embrace government action to improve people's quality of life. These differences in political outlook often make trade policy a matter of considerable debate within national legislatures.\nIn general, economists recognize that free trade provides the least amount of overhead during the production of goods and services, so a free trade economist will emphasize the lower end-price for consumers that results from trade policies that do not have government-mandated price minimums. However, some economists believe that fair trade policies help to add more consumers to an economy and that the additional price for \"fair\" labor is outweighed by the net economic benefit that comes from adding more consumers with disposable wages into the marketplace.\n- young girl trading for food image by pcphotos from Fotolia.com"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:9d193cd5-5b59-4f62-a8f7-8949689fb524>","<urn:uuid:c7ee1c80-dc1f-487d-a463-b82bcf66dc10>"],"error":null}
{"question":"How does Section 5 of the Voting Rights Act protect minority voters?","answer":"Section 5 of the Voting Rights Act requires certain jurisdictions to get approval from either the Attorney General or a federal court in Washington, D.C., before implementing any voting changes. This preclearance mechanism ensures proposed changes are not discriminatory. The law has successfully blocked various discriminatory practices, including ID laws, redistricting that reduces minority representation, and changes to election dates. In the 2012 election, Section 5 protected millions of minority voters in areas with a history of discrimination by preventing disenfranchisement efforts.","context":["Shelby County v. Holder\nOn June 25, 2013, the Supreme Court ruled in Shelby County v. Holder that the coverage formula in Section 4(b) of the Voting Rights Act (VRA), which was used to determine the states and political subdivisions subject to Section 5 preclearance, was unconstitutional. Section 5 is the part of the Voting Rights Act that requires certain jurisdictions to demonstrate to either the Attorney General or a federal court in Washington, D.C., that any proposed voting change is not discriminatory, before that change can be implemented. Thus, while the Court did not invalidate the preclearance mechanism in the Voting Rights Act per se, it effectively halted its use by invalidating the formula that determined which places were subject to the preclearance obligation.\nAbout This Case\nIn April 2010, Shelby County, Alabama, a largely White suburb of Birmingham, filed suit in federal court in Washington, D.C., seeking to have Section 5 declared unconstitutional. Shelby County claimed that Congress did not have the required constitutional authority when it reauthorized Section 5 in 2006.\nOn September 21, 2011, the U.S. District Court for the District of Columbia upheld the constitutionality of Section 5, holding that Congress acted appropriately in 2006 when it reauthorized the statute.\nOn May 18, 2012, the U.S. Court of Appeals for the District of Columbia Circuit affirmed the district court ruling by a vote of two to one. The court summarized its decision as follows:\n“Congress drew reasonable conclusions from the extensive evidence it gathered and acted pursuant to the Fourteenth and Fifteenth Amendments, which entrust Congress with ensuring that the right to vote—surely among the most important guarantees of political liberty in the Constitution—is not abridged on account of race. In this context, we owe much deference to the considered judgment of the People's elected representatives.”\n- Supreme Court Rules that Voting Rights Act’s Coverage Formula Is Unconstitutional\n- Civil Rights Groups File Supreme Court Brief in Support of Section 5 of the Voting Rights Act\n- Federal Court Upholds Constitutionality of Key Provision of the Voting Rights Act\n- FACT SHEET: Why the Voting Rights Act Remains Vital—Real Stories (PDF)\n- VOTING RIGHTS ACT: Road to Shelby County v. Holder (PDF)\nCivil Rights Community Shows Support for the Voting Rights Act\nReal Voters Tell Their Stories: “The Voting Rights Act Protected My Vote”\nThe Voting Rights Act continues to play a critical role in preventing and addressing real threats to minorities’ right to vote in our country.\nSadly, voter discrimination based on race is not a thing of the past—it’s a reality of our present. In the 2012 election, efforts to disenfranchise millions of minority voters were only stopped because they were in areas protected by the Voting Rights Act.\nNew videos tell the stories of the people whose right to vote is under threat.\nSee how Section 5 of the Voting Rights Act of 1965 protected voters in Shelby county, Alabama.\nSee how Texas passed a discriminatory law that would have denied Victoria Rose Rodriguez, a college student in San Antonio, the right to vote:\nHear an 82-year old woman tell the story about how the legislators in South Carolina tried to deny her the right to vote because she has never had a birth certificate:\nThese videos show just two attempts to deprive Americans of the right to vote that were stopped because Section 5 of the Voting Rights Act was able to step in and protect voters. And these examples do not stand alone. In just the last few years, a number of towns, cities, and states have tried to change election procedures in a way that takes away the rights of some Americans to vote—because of their race.\nThese practices range from the ID laws in these videos, to packing African-American voters into fewer districts to give them less of a voice, to moving around election dates.\nMany such attempts have also been blocked by Section 5.\nBecause of Section 5 of the Voting Rights Act, Victoria Rodriguez, Hanna White, and millions of other minority voters in South Carolina, Texas and other areas with a continued legacy of discrimination had their right to vote protected in the 2012 election.\nSection 5 is a proven tool to ensure voters are not deprived of this fundamental right – it is flexible, ever evolving, and often helps prevent discrimination from ever taking root.\nAlthough our country has made immense progress over past decades – thanks in large part to the Voting Rights Act – the law has a strong track record and continues to be needed to protect voters from genuine and documented attempts at disenfranchisement. The Voting Rights Act is necessary to ensure that our aspirations for a stronger democracy are a reality for all citizens.\nIf you care about protecting real people’s right to vote, share these videos today and stand up for the Voting Rights Act."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"format_constrained"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"}],"document_ids":["<urn:uuid:d5bff791-284b-421e-b309-d5911a7a9e46>"],"error":null}
{"question":"Both common mullein and emerald green arborvitae have issues with spreading - which one relies more on seed dispersal vs other propagation methods?","answer":"Common mullein relies heavily on seed dispersal, producing 100,000 to 240,000 seeds per plant, though these seeds usually fall within one meter of the parent plant. The seeds can remain viable for 35-100 years when buried. In contrast, emerald green arborvitae spreads through controlled cultivation and planting rather than natural seed dispersal. While it does produce seeds in small cones, these are not significant enough to cause spreading issues, and the plant's spread is primarily managed through intentional spacing during planting, with a recommended minimum of 3 feet between plants.","context":["Source: California Invasive Plant Council\nURL of this page: http://www.cal-ipc.org/ip/management/ipcw/pages/detailreport.cfm@usernumber=87&surveynumber=182.php\nInvasive Plants of California's Wildland\n|Scientific name||Verbascum thapsus|\n|Additional name information:||L.|\n|Common name||common mullein, wooly mullein, great mullein, mullein, Jacob’s staff, flannel leaf, velvet plant, candlewick plant, lung wort, felt wort|\n|Synonymous scientific names||none known|\n|Closely related California natives||0|\n|Closely related California non-natives:||3|\n|Listed||CalEPPC List B,CDFA nl|\nHOW DO I RECOGNIZE IT?\nScrophulariaceae. Biennial or annual herb. Stems: 1.5-6 ft (50-200 cm) tall when mature. Leaves: first-year plant is a rosette of large, woolly, gray-green leaves. Leaves 2-4 times longer than wide, 2-16 in (5-40 cm) long, alternate, the largest leaves at the base of the plant, smallest near the top; leaf pedicle short with leaf base extending a short way down the stalk to form wings. Plants usually bolt in second year and have a single stem covered with overlapping, woolly leaves from base to inflorescence. Inflorescence: a spike extending upward from top of stalk. Usually 1 inflorescence is produced, but occasionally a second or third can form with branches occurring where inflorescences begin. Flowers: densely packed along inflorescence, youngest near top; bracts 0.5-0.7 in (12-18 mm), flower pedicels short, <0.08 in (<2 mm), generally fused to stalk. Calyx deeply 5-lobed; 0.3-0.4 in (7-9 mm) long, several times longer than wide. Corolla (petals) 0.6-1.0 in (15-25 mm) wide, 5-lobed, circular, nearly regular, sulphur-yellow. Seeds: held in a 2-celled capsule 0.24 in (6 mm) diameter, covered with short, branched hairs. Seeds brown, irregular, oblong, 0.02-0.03 in (0.5-0.7 mm) long, with wavy ridges alternating with deep grooves. Each capsule holds numerous seeds. Flowering occurs from June through October (from Munz 1959, Gross and Werner 1978, and Hickman 1993).\n|WHERE WOULD I FIND IT?||\nCommon mullein occurs throughout California, but is particularly abundant in dry valleys on the eastern side of the Sierra Nevada. High population densities have been observed in moist meadows and creek drainages near Mono Lake and Owens Valley. It prefers disturbed habitats with little other vegetation, especially on dry, gravelly soils. It is common along roadsides, rights-of-way, and river banks and in forest cuts, meadows, pastures, and waste areas (Gross and Werner 1978). It is an early colonizer and may be the first plant to colonize bare soil. It is found in all forty-eight contiguous states and in Hawaii. In Canada it is reported to grow abundantly in soils with a pH range of 6.5-7.8 (Gross and Werner 1978). It is found from sea level to 8,000 feet (2,440 m) elevation.\n|WHERE DID IT COME FROM AND HOW IS IT SPREAD?||\nCommon mullein is native to Asia, but it probably was introduced to the United States from Europe. It was valued for its medicinal properties and has been carried with immigrants throughout the world. It has been used as a remedy for coughs and lung diseases, diarrhea, burns, and earaches (Mitich 1989). It probably was introduced several times into North America as a medicinal herb as well as accidentally. The earliest recorded intentional introduction was in the 1700s in the Blue Ridge Mountians of Virginia (Gross and Werner 1978). It apparently naturalized and spread rapidly, for it was erroneously described as a native by Eaton (1818) and was present as far west as Michigan in 1839 (Gross and Werner 1978). It was first recorded in California in 1880 as being widely naturalized in old fields in Siskyou County (Watson 1880). It spreads by prodigious seed production and maintains its presence by long-lived seeds in the soil. Its seeds have no specialized structures for long-distance dispersal by wind or animals. Movement of soil for highway and building construction may have assisted in its dispersal.\n|WHAT PROBLEMS DOES IT CAUSE?||\nCommon mullein is not a weed of agricultural crops, as it cannot tolerate cultivation. It is, however, thought to serve as a host for insects that are themselves economic pests, such as the mullein leaf bug, a pest of apples and pears in the eastern United States and Canada (Maw 1980). Common mullein is not often a significant weed of most wildlands and natural areas, as it is easily crowded out by grasses or other competing vegetation. It is a problem, however, in the sparsely vegetated soils of the eastern Sierra Nevada. In moist meadows and drainages near Mono Lake and Owens Valley, common mullein can become abundant and has invaded pristine meadows with undisturbed soils, displacing native herbs and grasses. It has also been observed to rapidly establish following forest fires in the western Sierra Nevada. High densites of rosettes appear to prevent the reinvasion of native herbs and grasses in burned areas, but eventually these give way to a developing shrub canopy. In this situation, mullein appears to disrupt the normal sequence of ecological succession.\n|HOW DOES IT GROW AND REPRODUCE?||\n(click on photos to view larger image)\nSeeds are contained in a capsule with two cells. Field studies show that single plants produce 200 to 300 capsules with 500 to 800 seeds per capsule. Thus, seed production can be 100,000 to 240,000 seeds per plant. When dry, the capsule splits open and releases the seeds. Seeds are not adapted to dispersal by wind or animals and usually fall to the ground. Field studies report that seeds will disperse as far as eleven meters, but 75 percent fall within one meter of the parent plant (Gross and Werner 1978).\nCommon mullein seeds do not appear to undergo dormancy or require a period of after-ripening. They germinate rapidly under appropriate environmental conditions (Baskin and Baskin 1981). Seed germination can occur in continuous darkness (e.g., when buried) or in light. High germination rates in darkness are restricted to relatively hightemperatures (>30 degrees C). In contrast, high germination rates were observed at 0 degrees C in darkness alternating with 35-40 degrees C in light (Semenza et al. 1978). This indicates that germination is possible on soil surfaces where extreme diurnal fluctuations occur. Despite observations of seed germination in darkness in the laboratory, field studies of buried seeds show low germination rates(<15 percent) suggesting that factors other than darkness may play a role in preventing germination of buried seeds (Baskin and Baskin 1981).\nGenerally, only those seeds at or near the soil surface will germinate (Semenza et al. 1978). Mullein seeds can survive and remain viable for thirty-five to 100 years when buried (Gross and Werner 1978, Baskin and Baskin 1981). The presence of mullein plants immediately following soil disturbance is likely a result of the presence of a seedbank rather than dispersed seeds. In California common mullein seeds usually germinate in spring following snowmelt and in fall with the onset of rains.\nCommon mullein is a usually a biennial, forming a taproot and a rosette in the first year and a flowering stalk in the second year. Rosettes consist of a whorl of leaves from the root crown clustered at the soil surface. In the eastern Sierra Nevada, however, it can grow as a biennial or as a winter annual. If seed germinates in spring, the plant will remain a rosette through the first growing season and the following winter. It will then bolt in spring and flower in summer. If seed germinates in fall, the plant will enter winter as a rosette and bolt the following spring (Semenza et al. 1978). Regardless of its flowering pattern, common mullein spends the first half of its life as a rosette, producing a deep taproot before sending up a three- to six-foot stalk and producing flowers. Flowers may be produced until the first frost or snowfall in late fall.\n|HOW CAN I GET RID OF IT?||\nThe best method for controlling common mullein depends on the size of the infestation, the topography of the site, and the resources available. Timing is critical for efficient control, and follow-up is essential.\nManual/mechanical methods: Perhaps the most effective method of controlling common mullein is to cut plants with a weed hoe. Plants will not resprout if cut through the root crown below the lowest leaves (Gross and Werner 1978). Removing rosettes with a hand hoe can be easily accomplished by workers trained to recognize the plant. Hand hoeing can be selective and effective, and two workers may clear up to twenty acres of mullein in a few hours. Bolted plants can also be removed with a weed hoe. Sometimes bolted plants can be pulled out of sandy soil, especially following heavy rain. If plants have begun to set seed, cut off the flowering racemes with pruning shears just below the lowest seed pods and collect them in a bag to prevent seeds from being released during the hand removal operation. A second or third weeding may be necessary.\nMowing appears to be ineffective, as plants cut above the root crown do not die. Rather, the basal rosette will continue to enlarge, then later bolt and flower. Clipping the terminal flower stalk will not prevent flowering, but will cause increased growth of axillary branches, which will produce flowers later (Gross and Werner 1978).\nPrescribed burning: Burning kills bolted plants and appears to kill rosettes, but creates open areas for reinfestation from seed germination. Individual bolted plants can be killed using a flame thrower, but its use is to be avoided during fire season.\nInsects and fungi: No insects or diseases have been approved for introduction as biological control agents against common mullein in North America. A curculionid weevil, Gymnaetron tetrum Fab., was accidentally introduced into Canada from Europe (Maw 1980). This weevil is specific to common mullein and is considered one of two natural enemies significantly impacting the plant in Europe. The larvae feed on seeds and other tissues in the seed capsules. Larvae are able to destroy all seeds in a capsule when present; however, usually not all seed capsules are infested. Gross and Werner (1978) report that up to 50 percent of seeds may be destroyed by the larval feeding of this weevil. Over time, G. tetrum has spread into California and has been collected from mullein plants throughout northern and eastern California since 1942. While its impact has not been investigated in California, it is unlikely to have much impact on common mullein populations. Despite the rate of seed destruction, too many seeds remain for it to have much effect in controlling common mullein populations.\nGrazing: Grazing animals generally will not eat mullein because of its hairy leaves (Whitson 1992).\nCommon mullein is difficult to control with herbicides because the thick hairs on the leaves prevent the herbicide from reaching and penetrating the leaf surface. A surfactant is recommended for all liquid herbicides used to control this plant.\nZamora (1993) compared the effectiveness of several herbicides to control common mullein along a roadside in Montana. Herbicides were applied with a backpack sprayer calibrated to deliver 20 gal/acre at 42 psi. Treatments were applied to late rosette and bolting plants in late May. Plant height and number of plants surviving to flower were recorded at the end of July. Of the three compounds available in California, 2,4-D provided 66 percent kill at 1.9 lbs/acre; height of standing plants averaged nineteen inches. Glyphosate provided 100 percent kill; height averaged nine inches. Sulfometuron (as Oust®) also provided 100 percent kill; average plant height was six inches. For comparison, in the unsprayed control areas, all plants survived to flowering (zero mortality); average plant height was thirty-eight inches (1 m).\nAnother control method, recently developed by a forest weed manager, is to spray each rosette with glyphosate by putting the spray nozzle into the center of the rosette (DiTomaso, pers. comm.). The applicator touches the plant with the spray nozzle and gives it one good squirt. The key is to ensure that the herbicide penetrates the region of the plant where the growing point is located. If the nozzle is off-center, this method does not work. Only seedlings and rosettes are susceptible using this method. In treating individual plants, it is recommended that a dye be used in the herbicide mixture to mark treated plants and prevent re-treatment.","Key identifying features.. Pyramidal\nevergreen with scale-like miniature leaves.\nCommon name.. Emerald Green Arborvitae\nScientific name.. Thuja occidentalis\n- 'Emerald Green'\nMature height.. 15 feet or more in an\nopen, sunny location\nMature spread.. 4 feet or more, if given\nForm.. Pyramidal, useful as a wind break,\nprivacy screen or hedge. Little, if any, pruning required. (In fact, if the top of the cone is chopped off, the tree's height-potential\nand natural shape will be seriously compromised.)\nFruit/Flower.. Male and female flowers\noccur on the same plant. Male flowers drop off in spring, but the yellowish female ones hang on to become cones, eventually\nturning brown and opening to release the seeds. The tiny cones, which aren't significant enough to cause a messy problem in\nthe yard, often persist throughout much of the winter.\nFoliage.. Evergreen; scale-like miniature\nleaves are soft to the touch, not prickly like many needled evergreens. Deer love to eat arborvitae! (So beware if planting\nwhere deer are near.)\nGrowth rate.. Moderate (one foot per\nyear; grows faster in full sun). See the growth chart for pictures.\nCulture.. Grows best in full sun in moist,\nacidic, well-drained soil. Space at least three feet apart when planting for a privacy screen. This tree needs room to grow\nand plenty of nutrients in the soil; planting them too close together, or too near larger trees, will compromise the health\nof the plants.\nBest time to prune.. Needs no pruning\nfor shape, but prune brown branches back to green any time.\nOf Special Note.. Deer consider this\ntype of arborvitae to be quite a treat. If you live in a deer-prone area, your trees will almost certainly be feasted upon!\n|Deer eat whatever they can reach.\nJulie's Comments.. (June\n2004) We planted several one-foot-tall arborvitae along the back border in 1997, following the advice on the planting card\nto space them four feet apart. It seemed at the time that it would take forever for anything resembling a privacy screen to\ndevelop. So we bought more arborvitae the following year to plant in between the existing ones, that time starting out with\ntrees that were already between four and five feet tall. This resulted in a hedge of conical plants -- one short, one tall\n-- each spaced two feet apart, which is closer than I now recommend. (For a hedge or screen planting, the recommended spacing\nis a minimum of 3 feet.) These trees are so beautiful all year that we have since planted many more of them in other parts\nof the yard as screens and at corners as accent plants. They must like our soil because I have seen so many in other landscapes\nthat turn brown within months of being planted. Perhaps the difference is the water, though, since I make sure that my plants\nget plenty of water for the first two or three years, or until they seem well-established. The chief benefit of this arborvitae\ncultivar is the year-round beauty and pleasant evergreen scent. Bright emerald throughout spring and summer, the green deepens\nin winter adding much needed color to the yard.\n|March 2006: Spoke too soon about no brown arbs in my yard!\nUPDATE: Julie's Comments.. (April\n2006) Two of our arborvitae died, having turned brown during winter, the progression from green to brown taking only a month\nor so. I am not certain what caused the death, but I suspect that all the arbs on the back border will succomb to the maple.\nI planed too many trees here, and somebody had to win. Of course, it would be the mighty maple over the arbs, the maple easily\nreaching for the sun while the arbs sit in her shade hoping for a drink of sunshine. In addition, I now know the difference\nbetween \"good\" arborvitae and \"bad\" arborvitae. You need to carefully choose trees with a single leader because those trees\nare much stronger and better able to shake off snow in winter. Many of my multi-leader trees, purchased at big box stores,\nare mishapen after several winters of heavy snow and me not having the time or energy to get outside and knock the swow off.\nIf I were going to plant arborvitae again, I would spend more money at a quality nursery to buy trees that are shaped properly.\nIt is initially visually misleading because the multi-trunk trees seem fuller, and therefore, they SEEM better as a screen\ntree. But in truth, the single leader trees generally grow taller, live longer and are better able to handle heavy stress\nPlanting date.. Varies.\nThe first ones were planted in 1997 and were one foot tall at the time. Seven years later, those trees were all about five\nfeet tall. The second batch was planted in 1998, each one at least four feet tall at planting time. Seven years later, the\nones that are in full sun locations are seven feet tall. Lessons learned: The smaller trees were far less expensive, easier\nto handle and plant, and have grown at a far faster rate than the taller trees. Just be patient and provide a slow soak with\nthe garden hose now and then. And make sure to buy trees with a single leader! Another set of arborvitae were planted in the\nsideyard in 2002. Those are growing particularly slowly.\nSpecial Note.. As a screen\nor privacy tree, a row of single-leader arborvitae around the corner from my house is the kind to plant, as opposed to the\nmulti-leader ones in my yard. I believe that quality nurseries sell the better-formed trees, while the big box stores sell\nthe ones like mine, with two or more competing leaders. But that's just a theory.\nDO OVER?.. No. Now I need\nevergreen privacy hedge trees or shrubs that can handle being planted in shade. Arborvitae is not that tree."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"}],"document_ids":["<urn:uuid:2446c0f9-4f3b-4bf4-b0e1-1b3a4b1561b6>","<urn:uuid:aeffa0cb-d2eb-4013-941d-d3bc702e944a>"],"error":null}
{"question":"I heard Eilat is doing some major coastal development. What are their plans for future development, and what environmental concerns should they watch out for? 🏗️","answer":"Eilat's coastal development plan emphasizes sustainable development with three main categories: recreational areas (including beaches and tourism), ports (combining military and civilian ports for efficiency), and natural values (coral reefs). The plan focuses on development to the east in the lagoon and salt flats area, while limiting development south of the Coral Beach for conservation. However, coastal development can severely impact coral reefs both directly through land filling, dredging, and coral mining for construction, and indirectly through increased runoff of sediment, sewage, and pollutants. This is particularly concerning given that coastal development linked to human settlements, industry, and infrastructure can significantly affect nearshore ecosystems.","context":["The complexity of issues involved in planning Eilat’s coastline, together with the multitude of factors and interests, has resulted in a prolonged planning process lasting an entire decade. The planners sought to arrive at a plan that will bridge the gap between conflicting interests and create a wide common ground shared by the authorities and various organizations.\nThe central principle guiding the planners was to give preference to land uses requiring proximity to the coast over those for which this is not necessarily essential, with an emphasis on bathing beaches. All this was done in accordance with the overall spirit of NOP 13 and the principles laid out in the instructions of the National Planning Council for the preparation of the plan. In addition to the coastal area, NOP 13 extends 500 m into the waters from the coastline.\nThe plan defines three categories of land use:\n1. Recreational uses for which proximity to the sea constitutes a clear advantage The plan allocates wide areas for bathing beaches, recreational facilities, tourism and hotels, including areas today occupied by the defense forces and the oil port, which it designates to become in the future as open beaches and for other uses suited to their location.\n2. Ports and engineering requiring proximity to the sea Within this category the plan decided upon the relocation of the military port from its present location and its unification with the civilian port, a move which saves space and increases the efficiency of land use along the coastline.\n3. Natural values, coral reefs on the coastline of Eilat.\nThe southern section of the plan emphasizes conservation and extensive development. The plan designates the area to the south of the Coral Beach as a space concentrating principally landscape values and environmental conservation and in which development is limited. In accordance the main development of Eilat will be to the east, in the area of the eastern lagoon and the Eilat salt flats.\nThe plan includes special reference to the city of Eilat and its connection with the sea. The plan determines that the urban areas, principally the new areas to the south of the city, will have open axes and views of the coast, creating a city facing the sea, avoiding physical and visual barriers between the city and the water.\nIn addition the plan emphasizes the need to provide for the recreational and tourism needs of Eilat – a central tourist city in Israel – and to ensure the status and efficiency of the port – the southern gate to Israel. The mutual arrangement of these land uses over short stretches of dense beaches was a central challenge in writing this plan.\nMeeting this challenge requires the correct and controlled use of land resources, ensuring the continued existence of their treasures and values for future generations, and at the same time keeping planning options open. In this sense the plan follows the principles of sustainable development, which promotes moderate and controlled development while conserving the values of the land for future generations.","Beyond threats associated with climate and ocean change, coral reefs are also affected by various local and regional threats. These threats may occur alone or synergistically with climate change adding to the risks to coral reef systems.\nOverfishing and Destructive Fishing\nUnsustainable fishing has been identified as the most pervasive of all local threats to coral reefs. ref Over 55% of the world’s reefs are threatened by overfishing and/or destructive fishing. Overfishing (i.e., catching more fish than the system can support) leads to declines in fish populations, ecosystem-wide impacts, and impacts on dependent human communities. Destructive fishing is associated with some types of fishing methods including dynamite, gill nets, and beach seines. These harm coral reefs not just through physical impacts but also through by-catch and mortality of non-target species including juveniles. Read more about threats and management strategies in the Reef Fisheries Toolkit.\nTraditionally, impacts from wastewater pollution have been associated with human health, but the detrimental effects of wastewater pollution on marine life – and the indirect impacts they have on people – cannot be overlooked. Wastewater transports pathogens, nutrients, contaminants, and solids into the ocean that can cause coral bleaching and disease and mortality for coral, fish, and shellfish. Wastewater pollution can also alter ocean temperature, pH, salinity, and oxygen levels disrupting biological processes and physical environments essential to marine life.\nOther sources of pollution to coral reef waters include land-based pollution associated with human activities such as agriculture, mining and coastal development leading to the discharge or leaching of harmful sediments, pollutants, and nutrients. Marine-based pollution associated with commercial, recreational, and passenger vessels can also threaten reefs by discharging contaminated bilge water, fuel, raw sewage, and solid waste, and by spreading invasive species. Learn more in the Wastewater Pollution Toolkit or in the Wastewater Pollution Online Course.\nMore than 2.5 billion people (40% of the world’s population) live within 100 km of the coast, ref adding increased pressure to coastal ecosystems. Coastal development linked to human settlements, industry, aquaculture, and infrastructure can cause severe impacts on nearshore ecosystems, particularly coral reefs. Coastal development impacts may be direct (e.g., land filling, dredging, and coral and sand mining for construction) or indirect (e.g., increased runoff of sediment, sewage, and pollutants).\nTourism and Recreational Impacts\nRecreational activities can harm coral reefs through:\n- Breakage of coral colonies and tissue damage with direct contact such as walking, touching, kicking, standing, or gear contact that often happen with SCUBA, snorkelling, and trampling\n- Breakage or overturning of coral colonies and tissue damage from negligent boat anchoring\n- Changes in marine life behavior from feeding or harassment by humans\n- Water pollution by tour boats through the discharge of fuel, human waste, and grey water\n- Invasive species which can be spread through transportation of ballast water, hull fouling of cruise ships, and fouling from recreational boating\n- Trash and debris deposited in the marine environment\nCoral disease is a naturally occurring process on reefs, but certain factors can exacerbate disease and cause outbreaks. Coral disease outbreaks can lead to an overall reduction in live coral cover and reduced colony density. In extreme cases, disease outbreaks can initiate community phase-shifts from coral- to algal-dominated communities. Coral diseases can also result in a restructuring of coral populations.\nDisease involves an interaction between the coral host, a pathogen, and the reef environment. Scientists are learning more about the causes of coral disease, especially in terms of identifying the pathogens involved. To date, the most infectious coral diseases are caused by bacteria. Transmission of coral diseases can be facilitated in areas of high coral cover ref as well as through coral predation, as predators can act as vectors by oral or fecal transmission of pathogens. ref\nThe causes of coral disease outbreaks are complex and not well understood, although research suggests that important drivers of coral disease include climate warming, land-based pollution, sedimentation, overfishing, and physical damage from recreational activities. ref\nOn coral reefs, marine invasive species include some algae, invertebrates, and fishes. Invasive species are species that are not native to a region. However, not all non-native species are invasive. Species become invasive if they cause ecological and/or economic harm by colonizing and becoming dominant in an ecosystem, due to the loss of natural controls on their populations (e.g., predators).\nPathways of introduction of marine invasive species include:\n- Ship traffic, such as ballast water and hull fouling\n- Aquaculture operations (shellfish aquaculture is responsible for the spread of marine invasive species through global transport of oyster shells or other shellfish for consumption)\n- Fishing gear and SCUBA gear (through transport when moving from place to place)\n- Accidental discharge from aquaria through pipes or intentional release\nSargassum are a type of brown, fleshy macroalgae that can have detrimental ecological and economic impacts on coral reefs when overabundant.\nIn the Indo-Pacific, high percent cover of Sargassum is common on degraded coral reefs and often represents a phase-shift from a coral to algae-dominated reef system. ref Their reproductive biology and morphology make them excellent colonizers of free space and particularly resilient to disturbances such as tropical storms. ref When overabundant, they can negatively impact the reef by shading, limiting space available for coral larvae to recruit, and transmitting pathogens. ref\nIn the Atlantic, two species of floating sargassum, S. natans and S. fluitans, are responsible for causing large mats of algae blooms which are particularly harmful and prevalent on the Caribbean and West African coastlines. ref Floating algae mats are naturally prevalent in the Northern Atlantic and provide many ecological benefits such as habitat, food, and nursery grounds to many species of fish, crustaceans and even sea turtles. ref However, in the last ten years, a shift in oceanic currents has led to an algae invasion in coral reef areas, causing reduced sunlight required by corals and anoxic and hypoxic conditions on reefs, as well as poor conditions on beaches that are detrimental to the tourism industry. ref\nCoral predators (or 'corallivores') are naturally occurring organisms that feed on corals for their polyps, tissue, mucus, or a combination of the above. Such predators typically include echinoderms (starfish, sea urchins), mollusks (snails), and some fish.\nCorallivory is a common process that, under normal conditions, allows for natural turnover in the ecosystem. However, when these predators are overly abundant (e.g., outbreak conditions), they can cause significant declines in coral cover.\nCommon coral predators include:\n- Crown-of-Thorns starfish (COTS), which are found throughout the Indo-Pacific region, occurring from the Red Sea and coast of East Africa, across the Pacific and Indian Oceans, to the west coast of Central America. COTS can be a major driver of coral loss in the Indo-Pacific, particularly under outbreak conditions.\n- Drupella snails, which are commonly found living on corals in reefs throughout the Indo-Pacific and Western Indian Ocean.\n- Coralliophila snails, which are often more problematic for Caribbean reefs, although some species are prevalent in the Pacific."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:f8c314db-b0ee-4a2f-ab7b-86fb77eb9e8b>","<urn:uuid:6dd87468-19aa-450b-b9cc-46d264a1ee33>"],"error":null}
{"question":"I'm tracking past SpaceX launches - when exactly was the RADARSAT Constellation Mission launched from Vandenberg, and what notable events happened during that PAZ mission launch from the same location?","answer":"The RADARSAT Constellation Mission was launched on Wednesday, June 12 from Space Launch Complex 4E at Vandenberg Air Force Base, with a primary launch window opening at 7:17 a.m. PDT. As for the PAZ mission, it launched from the same location (SLC-4E at Vandenberg) on Thursday at 14:17 UTC, 6:17 a.m. local time. The PAZ launch was notable for providing a spectacular show to morning commuters across Southern California, with observers witnessing expanding clouds of gas emanating from the rocket. The launch featured a re-used Block 3 Falcon 9 first stage from a 2017 mission and debuted SpaceX's Payload Fairing 2.0.","context":["VANDENBERG AIR FORCE BASE, Calif. (SpaceX PR) — SpaceX is targeting Wednesday, June 12 for launch of RADARSAT Constellation Mission from Space Launch Complex 4E (SLC-4E) at Vandenberg Air Force Base in California.\nThe primary launch window opens at 7:17a.m. PDT, or 14:17UTC, and closes at 7:30 a.m. PDT, or 14:30 UTC. The satellites will begin deployment approximately 54 minutes after launch. A backup launch window opens on Thursday, June13 at 7:17a.m. PDT, or 14:17 UTC,and closes at 7:30 a.m. PDT, or 14:30 UTC.\nFalcon 9’s first stage for launch of RADARSAT Constellation Mission previously supported Crew Dragon’s first demonstration mission in March 2019. Following stage separation, Falcon 9’s first stage will return to land on SpaceX’s Landing Zone 4 (LZ-4) at Vandenberg Air Force Base.\nThe RADARSAT Constellation Mission (RCM) is the evolution of the RADARSAT Program and builds on Canada’s expertise and leadership in Earth observation from space. It consists of three identical C-band Synthetic Aperture Radar (SAR) Earth observation satellites.\nBuilt by MDA, a Maxar company, the three-satellite configuration of the RCM will provide daily revisits of Canada’s vast territory and maritime approaches, including the Arctic up to 4 times a day, as well as daily access to any point of 90% of the world’s surface.\nThe RCM will support the Government of Canada in delivering responsive and cost-effective services to meet Canadian needs in areas like maritime surveillance, ecosystem and climate change monitoring, and helping disaster relief efforts. For example:\n- The RCM will help create precise sea ice maps of Canada’s oceans and the Great Lakes to facilitate navigation and commercial maritime transportation. Each satellite also carries an Automatic Identification System receiver, allowing improved detection and tracking of vessels of interest.\n- The highly accurate data collected by RCM will enable farmers to maximize crop yields while reducing energy consumption and the use of potential pollutants.\n- Like RADARSAT-2, the RCM will support relief efforts by providing images of areas affected by disasters to help organize emergency response efforts and protect the local population.\n(all times approximate)\n-00:38:00 SpaceX Launch Director verifies go for propellant load\n-00:35:00 RP-1 (rocket grade kerosene) loading underway\n-00:35:00 1st stage LOX (liquid oxygen) loading underway\n-00:16:00 2nd stage LOX loading underway\n-00:07:00 Falcon 9 begins engine chill prior to launch\n-00:01:00 Command flight computer to begin final prelaunch checks\n-00:01:00 Propellant tank pressurization to flight pressure begins\n-00:00:45 SpaceX Launch Director verifies go for launch\n-00:00:03 Engine controller commands engine ignition sequence to start\n-00:00:00 Falcon 9 liftoff\nLaunch, Landing and Satellite Deployments\n00:01:03 Max Q (moment of peak mechanical stress on the rocket)\n00:02:13 1st stage main engine cutoff (MECO)\n00:02:17 1st and 2nd stages separate\n00:02:24 2nd stage engine starts\n00:02:49 Fairing deployment\n00:03:18 Boostback burn complete\n00:06:04 1st stage entry burn begin\n00:07:53 1ststage landing\n00:08:28 2nd stage engine cutoff (SECO-1)\n00:50:08 2nd stage engine restarts\n00:50:12 2nd stage engine cutoff (SECO-2)\n00:54:43 RCM-1 deployment\n00:58:24 RCM-2 deployment\n01:02:13 RCM-3 deployment\nSpace Launch Complex 4E\nSpace X’s Space Launch Complex 4E at Vandenberg Air Force Base has a long history dating back to the early 1960s. Originally an Atlas launch pad activated in 1962, SLC-4E was in active use until its last Titan IV launch in 2005. SpaceX’s groundbreaking was in July 2011, and extensive modifications and reconstruction of the launch pad were completed just 17 months later. SLC-4E consists of a concrete launch pad/apron and a flame exhaust duct. Surrounding the pad are RP-1 and liquid oxygen storage tanks and an integration hangar. Before launch, Falcon 9’s stages, fairing and the mission payload are housed inside the hangar.A crane/lift system moves Falcon 9 into a transporter erector system and the fairing and its payload are mated to the rocket. The vehicle is rolled from the hangar to the launch pad shortly before launch to minimize exposure to the elements.","A SpaceX Falcon 9 rocket provided a spectacular show to morning commuters across Southern California on Thursday after taking off from Vandenberg Air Force Base with Spain’s PAZ radar satellite and a pair of SpaceX prototype broadband satellites. Falcon 9 streaked into the morning sun as it climbed skyward while observers on the ground remained in the dark and were stunned by the expanding clouds of gas emanating from the rocket and the various components it shed on its way into orbit.\nThursday’s launch marked SpaceX’s fourth mission of the year and the 20th orbital space launch of 2018, involving a re-used Falcon 9 first stage from a 2017 VAFB mission and debuting SpaceX’s “Payload Fairing 2.0” designed for operational recovery and re-flight missions as the company continues its push toward making more and more elements of their launch system re-usable to slash costs for accessing space.\nBlasting off from SLC-4E at Vandenberg at 14:17 UTC, 6:17 a.m. local time, the 70-meter tall Falcon 9 fired its first stage for the first two and a half minutes of the mission before the MVac-powered second stage took over for a direct boost into a 514-Kilometer Sun Synchronous Orbit. The twice-used Booster was not planned to be recovered and, like a number of recent expendable missions, went through a series of flight tests after separation before finding a watery grave in the Pacific Ocean. These post-separation maneuvers contributed to be powerful display painted into the outer atmosphere by Falcon 9 and visible across most of California.\nThe launch of PAZ, coming after years of delays and a launch vehicle switch, was initially expected on Saturday but slipped into this week as SpaceX took additional time to review what it called “an upgraded payload fairing.” Sources have since confirmed that this indeed referred to the long-awaited “Fairing 2.0” that SpaceX hopes will lead to considerable progress in the area of fairing re-use by the end of the year.\nInstalled atop the rocket’s second stage, the Payload Fairing is tasked with protecting the vehicle’s payload while out in the elements waiting for launch and during the extreme aerodynamic environments encountered during atmospheric ascent. Falcon 9 flies with one of the largest payload fairings currently in operation under a “one size fits all” architecture as opposed to other launchers that can use differently sized fairings to accommodate payloads of various sizes.\nThe 13-meter long, 5.2-meter diameter payload fairing maintains the rocket’s aerodynamic profile while flying through the dense atmospheric layers before splitting open and separating in two halves roughly three to four minutes into the mission when its protection is no-longer needed in order to discard unnecessary weight.\nSpaceX earmarked the fairing as a desired re-use item early on because of two major factors: a) its cost being around 10% of the total cost for a Falcon 9 and b) its all-composite construction being a time-intensive process creating a potential bottleneck in the company’s plans for a rapid mission cadence.\nThe survivability of SpaceX’s baseline fairing design was proven in 2015 when large chunks of a fairing half washed up in South Carolina after floating for one month in the Atlantic. Video obtained from cameras installed on that fairing delivered a stunning look at its journey back to Earth and also confirmed SpaceX was actively pursuing fairing re-use. An initial controlled landing attempt on the April 2017 Falcon 9 mission with SES-10 returned one fairing half mostly in one piece; however, SpaceX CEO Elon Musk recently characterized the re-usable fairing development as “surprisingly complex.”\nThe step-up to Fairing 2.0 was incremental with several of the previous generation fairings introducing some of the recovery systems with all eventually coming together in the upgraded fairing design that consists of fewer parts, is lighter in mass and allows for faster manufacture. From an external appearance, Fairing 2.0 seems to be slightly larger than its predecessor, growing around 0.1 meter in diameter and length based on imagery of the PAZ vehicle, but what differentiates it from the baseline Falcon fairing resides on the inside and at the fairing base in the form of an upgraded structural interface.\nEach fairing half has its own avionics system, pressure vessels holding Nitrogen gas, a manifold of lines transporting propellant to a series of cold gas thrusters and a compartment for an auto-steering parachute. One particular area improved on Fairing 2.0 was the chute attachment since the baseline fairing introduced a turbulent airflow that made the chutes only partially effective, resulting in trouble on the way back to Earth, especially in the accuracy department.\nAs the fairings separate from the ascending rocket, they are to employ their thrusters to stabilize from their initial tumble and enter a pre-determined orientation for atmospheric re-entry. The auto-steering chute will then be tasked with guiding each fairing half toward a recovery boat positioned to ‘catch’ it.\nA vessel going by the name of “Mr. Steven” made a first appearance last year, featuring a four-armed contraption to support the fairing recovery, described by Musk as a “giant catcher’s mitt.” Recent photos of Mr. Steven have shown a net was added in between the four metal arms and the ship departed the Port of Los Angeles before noon on Tuesday to be ready to catch a fairing half.\nThe launch of PAZ and the two MicroSats was handled by the first “Sooty” Falcon 9 booster to launch from the West Coast, having flown back in August 2017 with the FormoSat-5 satellite for Taiwan. Still sporting the sooty attire from its first voyage to space, Booster 1038 was only outfitted with grid fins on Thursday to enable some post-separation flight testing toward a splashdown in the Pacific Ocean as a means of disposal since the Block 3 booster was not deemed suitable for anything beyond two missions.\nB1038 was the final Block 3 booster to roll off SpaceX’s production line and may very well be the last Block 3 vehicle to fly. Following last-year’s debut of the slightly improved Block 4, SpaceX now plans to roll out the Falcon 9 Block 5 – the final iteration of the workhorse launcher – in April for a Geotransfer Mission out of Cape Canaveral.\nThe primary passenger for Thursday’s mission was PAZ, an X-Band Synthetic Aperture Radar Satellite commissioned by Hisdesat and the Spanish Government for multi-mission use in the defence and security sectors, for Earth observation and commercial exploitation of high-quality radar imagery at a ground resolution exceeding one meter. PAZ, Spanish for ‘peace,’ is the first member in the country’s Program for Earth Observation by Satellite (PNOTS) that is to include PAZ as radar component and the upcoming Ingenio optical-imaging spacecraft for multi-band imagery collection.\nAstrium (now operating under Airbus) was awarded the contract for PAZ in 2008 with an initial goal of launching in 2012. However, the satellite was forced to remain on the ground when its Dnepr rocket fell victim to the conflict between Russia and the Ukraine; eventually prompting Hisdesat to switch launch providers to a 2017 launch slot on SpaceX’s manifest.\nThe 1,350-Kilogram PAZ satellite employs a hexagonal satellite platform with a diameter of 2.4 meters and a length of five meters, hosting a large XSAR antenna on one of its side panels operating at a center frequency of 9.65 GHz and a peak transmit power of 2,260 Watts, capable of operation in various imaging modes including high-resolution spotlight and wide-area ScanSAR to deliver a multitude of data products. Auxiliary payloads include an AIS ship-tracking terminal and GNSS occultation instrument for atmospheric profiling.\nAmong the services provided by the PAZ mission is geo-information intended to enhance surveillance of the Spanish territory and other parts of the globe, improve the security of the Spanish borders, support operations of the Spanish armed forces, provide data for natural disaster assessment and mitigation, and support risk and crisis management. Data from the satellite will also be used to support operations against piracy in the waters off Somalia and to control the illegal traffic of immigrants into and through Spanish waters.\nPAZ has a planned service life of seven years, but Hisdesat is confident the spacecraft will last for at least ten – in part because of the performance of its predecessors, the German TerraSAR-X and TanDEM-X that have been in operation since 2007 and 2010 and will be set for a coordinated extended mission with PAZ co-located in their orbital plane to maximize coverage.\nRiding shotgun alongside PAZ were SpaceX’s MicroSat-2a and 2b, the first prototypes from the company’s satellite venture operating out of Redmond, Washington to develop the “Starlink” Internet constellation. The two 400-Kilogram satellites are the first of over 11,000 Starlink satellites to be launched by SpaceX to establish a global Fixed Satellite Services architecture capable of bringing Internet access to all corners of the Earth.\nSpaceX announced the Starlink venture in 2015 but has since been extremely tight-lipped about it, only noting that it is still in its development phase. However, filings made with the Federal Communications Commission indicate SpaceX is planning to launch a series of prototypes in 2018 to fully characterize signal and transmission capabilities before pressing into the deployment of the operational constellation as early as next year.\nAccording to 2017 documentation, Starlink is to consist of two constellation segments: 4,425 satellites in 83 orbital planes at an altitude of 1,200 Kilometers operating at the Ku/Ka/V-Band frequencies and 7,518 satellites in a Very Low Earth Orbit at 340 Kilometers operating solely in the seldom-used V-Band spectrum. The MicroSat-2a and 2b satellites are identical and only host Ku-Band links to test the data throughput capabilities, pointing of broadband arrays, and ground station handoffs. They will complete one communications demonstration every day for six to 12 months from an orbit of 1,125 Kilometers, according to FCC documentation.\nFalcon 9 was wheeled out to the launch pad at SLC-4E on Tuesday with less than 24 hours to go until Wednesday’s instantaneous launch slot. Upper level winds just 1.8% above allowable limits thwarted plans for launching on Wednesday and SpaceX went into a 24-hour recycle.\nCountdown operations picked up again in the late hours on Wednesday and ran like clockwork as Falcon 9 checked off a series of tests before being handed over to computers to orchestrate the complex tanking sequence picking up at T-70 minutes to load the two-stage rocket with around 155 metric tons of chilled Rocket Propellant 1 and some 360 metric tons of sub-cooled Liquid Oxygen.\nFalcon 9 was venting gaseous oxygen as it headed into the fast-paced events of its final countdown sequence to chill down its nine Merlin 1D engines, switch to battery power, retract the Strongback structure and achieve flight levels on its fuel and oxidizer tanks with close-out of LOX load right at the T-2-minute mark. A final GO was voiced from the Autonomous Flight Termination System as Falcon 9 assumed control at the one-minute mark and the Launch Director gave his final approval with half a minute on the clock.\nThe bright green flash of Falcon’s igniter mix lit up the rocket’s business end at T-3 seconds as all nine engines soared up to a cumulative launch thrust near 700 metric-ton-force under close watch by computers. Hold-downs released the rocket at precisely 14:17:00 UTC, right at first light and still 21 minutes before sunrise – creating the right ingredients for another spectacular display in the SoCal skies similar to that of December’s Iridium-4 mission that occurred at evening twilight.\nRising from its launch pad, Falcon 9 climbed vertically before pitching and rolling onto its flight trajectory to the south-south-west, headed toward a 97.44° orbit. As the vehicle went through the sound barrier, thrust on the nine Merlin engines was reduced for Maximum Dynamic Pressure before Falcon 9 went back into full thrust mode for another minute of first stage flight – ascending into sunlight as it rapidly gained altitude.\nThe first stage shut down two minutes and 29 seconds into the flight after boosting the vehicle to a speed of 1.87 Kilometers per second, departing the stack via four pneumatic pushers that sent the stages on their opposite ways three seconds after MECO. Immediately after staging, the MVac-powered second stage went into start-up mode and ignited its 95,000-Kilogram-force engine on a planned burn of 6 minutes and 18 seconds to directly inject the stack into its target orbit – flying an initial lofted trajectory to climb to the target altitude before pitching down to accelerate to orbital velocity.\nFairing 2.0 had its big moment two minutes and 59 seconds into the flight when it dropped away from the climbing rocket and began its trip back toward Earth. At least one half of the fairing featured recovery hardware and was headed for an attempt to maneuver toward the fairing recovery vessel deployed underneath the rocket’s flight path around 510 Kilometers from the launch pad.\nThe fairing half pegged for recovery successfully managed to descend from space and deploy its parafoil, but missed Mr. Steven “by a few hundred meters,” according to Elon Musk. Apparently the half splashed down intact and future plans of increasing the size of the chutes may make the feat of catching it easier.\nFor the first stage, separation marked the start of a data-gathering exercise on its return regime. December’s Iridium-4 mission and the GovSat flight in January both disposed their boosters via soft splashdown landings after collecting data on flight environments not possible for operational returns to deliver valuable information for the continued refinement of the booster return sequence.\nStage 2 was lightly loaded on Thursday, carrying a total payload upmass of around 2,200 Kilograms whereas the vehicle’s theoretical capacity to the target orbit was 8,600kg with RTLS landing of the first stage and 11,700kg with ASDS recovery. Real time calls made by the launch team indicated Stage 2 performed admirably throughout its burn, spending the last 15 seconds in terminal guidance to ensure an on-target injection of the PAZ satellite and its two companions.\nShutdown of the second stage was called right at the T+9-minute mark and the guidance engineers confirmed a good orbit was achieved. The PAZ satellite was sent on its way just after clocks hit T+11 minutes, starting a decade-long mission to deliver high-quality radar imagery and ship-tracking data to the Spanish Government and commercial customers. SpaceX did not cover the separation of the two MicroSats and details on their mission are unlikely to be coming forward given the secrecy with which the project reached the launch pad."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:e2ac016f-91d1-4bfa-bb57-39f974a1bba1>","<urn:uuid:4366b5ca-d134-41d9-a334-7ad5231b7d84>"],"error":null}
{"question":"I'm studying environmental protection: what are the economic incentives that drive both overfishing and deforestation?","answer":"Both overfishing and deforestation are driven by similar economic incentives. For overfishing, these include market availability, consumer demands, and government subsidies that allow unprofitable fishing entities to survive, resulting in fishing fleets that are 250% larger than needed. Additionally, the lack of property rights in open access fisheries removes motivation to conserve fish stocks. For deforestation, the economic drivers include international factors such as development pressures, government subsidies to attract corporations into developing countries, trade agreements, and economic uncertainty related to international loans from The World Bank and International Monetary Fund.","context":["What is Overfishing?\nOverfishing is yet another environmental issue which means consumption of a species of fish from a body of water at a rate which is outpacing its natural reproduction.\nAccording to World Wildlife Fund (WWF), “overfishing occurs when more fish are caught than the population can replenish through natural reproduction.”\nWhile overfishing sounds like a lucrative practice, it is a detrimental environmental issue with wide-ranging impacts on aquatic life and land dwellers.\nOverfishing, for example, has stripped many fisheries across the globe of their fish stocks. About 85% of the world’s fisheries could be over-exploited, totally depleted, or recovering from exploitation.\nFor this article, the purpose is to explore the major causes and effects of overfishing. Shall we start with the causes first?\nCauses of Overfishing\nThere are numerous reasons for overfishing. The major ones include:\n1. Poor Fisheries Management\nThe fishing industry has long been weighed down by a lack of management oversight and proper government regulations. Traceability of fishing activities has been a great challenge as well.\nThe rules and regulations we have today have proven to be ineffective when it comes to limiting fishing capacity to sustainable levels. And the high seas are the most affected.\nNamely, there are insufficient fishing regulations in the high seas. And the existing regulations are normally not enforced. Most fisheries management organs lack the capacity to adequately apply scientific advice of fish quotas.\nMoreover, customs agencies and fish retailers can’t always ascertain the fish coming into their country is caught through proper channels.\n2. Unsustainable Fishing\nUnsustainable fishing encompasses the use of nets, fishing methods and other fishing gear that catch so much fish to a level that they are endangered.\nIt may also involve catching other sea creatures other than fish in the process. The unwanted animals are called By-catch. And they are normally destroyed and discarded into the sea, hence the name Discards.\nDiscards may include turtles, cetaceans, young fish, sharks, corals, and seabirds. Invertebrates such as crabs, starfish, brittle stars, sea urchins, sponges, mollusks, and warms could also be caught, destroyed, and thrown back into the sea.\nSome fishermen also catch tiny fishes, depriving them of the opportunity to grow and reproduce.\n3. Illegal and Unregulated Fishing Activities\nIllegal fishing activities include poaching, taking more than the allowed amount of catch, and fishing out of season. According to WWF, illegal fishing accounts for about 20 percent of the world’s catch and up to 50 percent in some fisheries.\nUnregulated fishing practices that result in grave harm include by-catch (as explained in the previous point) and Trawling. Trawling involves scraping along the bottom of the sea to gather fish. This practice is one of the major causes of destruction to marine habitats.\n4. Economic and Food Needs\nMarket availability and consumer demands are the major factors that determine the amount of fish that fishing companies bring ashore.\nIn the last 100 years, human population has increased in many folds. This has, in turn, pushed the need for food and fish up significantly. Coupled with economic aspirations of fishing industries, these factors have compelled fishers to catch more fish than the seas can replace.\n5. Government Subsidies\nMany governments around the world continue to subsidize their fishing equipment. This allows unprofitable fishing entities to survive, eventually leading to overfishing. Today, fishing fleet across the globe is estimated to be up to 250 percent of the actual capacity needed to catch what the world needs.\n6. Open Access Fisheries\nThe ‘open access’ nature of fisheries is another major problem of overfishing. In light of the fact that there are no or limited property rights, fishermen lack the motivation to leave fish in the water.\nMoreover, only about 1.5 percent of water bodies have been declared protected areas. And most of those areas still remain accessible to fishermen, exposing them to destruction and depletion.\nNow, let’s let quickly look at some of the effects of overfishing.\nEffects of Overfishing on the Environment\nAt the beginning of this article, we pointed out that overfishing has impacted at least 85 percent of the world’s fish resources. The fact that most fisheries are harvested far beyond their sustainable capacity is poised to have wide-ranging effects on marine life and the socio-economic well-being of humans.\nThat said, here are some of the major effects of overfishing:\n1. Marine Ecosystem Imbalance\nTargeted catching of essential predators such as sharks, tuna, and billfish disrupts marine ecosystem in the long run. This results in increased numbers of smaller marine animals below the food chain.\nThis ends up affecting the rest of the ecosystem, with issues such as the increased growth of algae. Coral health becomes compromised as well. Overfishing is also associated with bycatch, one of the major threats to marine life as it causes unnecessary loss of massive fish population along with other marine animals like turtles.\n2. Dwindling Harvests of Targeted Fish\nThe population of fish that is worth consuming is increasingly reducing, thanks to overfishing. Overfishing has led to a decrease in the population of productive fish, resulting in lesser stocking of the fish.\nThere is urgent need to curb overfishing in a bid to restore the dwindling marine population in a couple of years. Limiting fishery activities will allow fish to breed and reproduce, and well will eventually have a great supply of fish available again.\n3. Fishing of Untargeted/Endangered Marine Species\nBycatch leads to the capturing of marine animals that are not used or required. The animals may include protected or endangered species or species that are of little or no economic value. If caught, they are normally destroyed and discarded either in the water or ashore.\n4. Unsustainable Aquaculture\nFish farming requires feed for reared fish. For example, you will need between four and eleven pounds of prey fish to raise just one pound of farmed salmon.\nWith the rapid expansion of the aquaculture industry, prey fish population is reducing at alarming and untenable rates. According to some researchers, if this trend continues, fish farming will have outstripped the supply of fishmeal by 2020.\n5. Socio-economic Impact\nMillions of people around the world have pegged their livelihood and nutritional needs on fishing. Oceans have supplied us with sufficient seafood for years, but that is no longer the case.\nOverfishing and untenable fishing practices over the last couple of decades have stripped the oceans of their fish supply. And this has affected many people’s everyday way of life and source of income. With no valuable fish left in the waters to fish, the fishing industry is on the verge of collapse.\nFishing boats, trawlers, and vessels hurt marine life not only through overfishing but also through oil and liquid, and chemical spills.\nYou may think that oceans are so expansive that these are not significant threats. However, a slight pollution by thousands of fishing vessels every day results in a massive disturbance. And water pollution has grave consequences to both aquatic and terrestrial lifeforms.\nWe may dismiss overfishing as a harmless practice oblivious to the fact that it is causing untold harm to the world’s ocean and marine life. Overfishing depletes the population of adult fish and doesn’t leave enough fish to reproduce and replenish their dwindling numbers. This can be attributed to poor fisheries management, unsustainable fishing, economic needs, as well as illegal and unregulated fishing. And its effects include marine life imbalance, loss of income, and harvesting of endangered marine species.\nPhoto by: pixabay\nLatest posts by Sonia Madaan (see all)\n- Raised Floor System: The Need for Adaptive Whole Building Design - January 13, 2020\n- Sustainability Matters to Long Term Guests - December 5, 2019\n- 25+ Disturbing Facts About Water Wastage That Will Leave You Highly Disturbed - December 1, 2019","What is Deforestation?\nDeforestation refers to the cutting, clearing, and removal of rainforest or related ecosystems into less bio-diverse ecosystems such as pasture, cropland, or plantations (Kricher, 1997).\nWhat are the causes of deforestation?\nIII. Oil and gas extraction\nIV. Cattle ranching\nV. Agriculture: Cash crops\nVI. Local, National, and International factors: development, land titles, government subsidies to attract corporations into developing countries, trade agreements (NAFTA, CAFTA), civil wars, debt, lack of resources, and lack of law enforcement.\nLargest rainforests worldwide listed in descending order (from largest to smallest).\n- Amazon basin of South America\n- Congo river basin of Central Africa\n- S.E. Asia\n- New Guinea\n- Did you know that tropical rainforests, which cover 6-7% of the earth's surface, contain over half of all the plant and animal species in the world!\n- Did you know that 57% of all rainforests remaining are located in the Neotropics, with 30% located in Brazil.\nOverview of deforestation around the world:\nBetween 1960 and 1990, most of the deforestation occurred globally, with an increasing trend every decade.\n- Brazil has the highest annual rate of deforestation today.\n- Atlantic coast of Brazil has lost 90-95% of its rainforest.\n- Central America has 50% of its rainforests.\n- South America has 70% of its rainforests.\n- Philipines have lost 90% of its rainforests!\n- Madagascar has lost 95% of its rainforests!\n- El Salvador has lost 70-85% of its rainforest due to heavy bombing during the civil war 1984-1985.\n- Sumatra has 15% of its rainforests left.\n- Only 6% of Central Africa's forests are protected by law.\nStatistics on Global Rates of Rainforest Destruction:\n2.4 acres (1 hectare) per second: equivalent to two U.S. football fields\n149 acres (60 hectares) per minute\n214,000 acres (86,000 hectares) per day: an area larger than New York City\n78 million acres (31 million hectares) per year: an area larger than Poland\nOn average, 137 species become extinct everyday; or 50,000 each year!\n*If the current rate of deforestation continues, the world's rain forests will vanish within 100 years- causing unknown effects on global climate and eliminating the majority of plant and animal species on the planet*\nWhat are the consequences of deforestation?\n- Extinctions (loss of biodiversity of microbes (bacteria), plants, insects, animals, indigenous peoples, etc.\n- Habitat fragmentation. This disturbes the animals' habitat and may force them to enter habitats which are already occupied. This can pose many problems such as territorial conflicts, homelessness (loss of habitat), lack of food availability, migration disturbances, etc.\n- Soil erosion occurs when trees and plants are removed; the rain water washes the nutrients in the top soil away.\n- Changes in watershed geomorphology.\n- Desertification (dry, hot, arid conditions).\n- Edge effects can change microclimates (small climates) which affect endemic species (native species which can only live in specific environmental and habitat conditions).\n- Climate change (more carbon dioxide is released into the atmosphere, thus increasing the effects of global warming).\n- Pollution (ground, water and air pollution from oil extraction and mining chemicals).\n- Loss of culture (indigenous peoples subsistence living in the rainforest). People who live in the rainforest depend on the natural environment for food, shelter, materials for cooking, clothing, etc. If the forest is cut down or if their environment becomes polluted from oil extraction and mining, they are forced to move or risk starvation and sickness.\n- Displacement of people (loss of farmland, forest resources, etc).\n- Social conflicts and struggles over land and natural resources.\n- Conflicts over racial and ethnic rights.\n- Poisoning from oil and mining waste.\n- Economic uncertainty (price fluctuations and high interest rates on outstanding international loans with The World Bank and International Monetary Fund.\nWhat can we do to STOP or at least lessen the amount of deforestation and conserve our own use of natural resources such as wood, oil and gas, electricity, minerals and elements, and water? Brainstorm...here's a start:\n- Always use both sides of paper when writing, drawing, photo-copying, faxing, etc.\n- Recycle paper, cans, glass, and plastic.\n- Read the newspaper on-line.\n- Buy paper products made from recycled paper: notebook paper, paper towels, toilet paper, books, etc.\n- Use pencils until they are stubs! Think of pencils as gold (you'll never lose them if you do).\n- Encourage your parents, relatives, and friends to buy furniture and wood that is Certified. That means the wood was legally cut-down.\n- If you buy a product and you notice they use wood chips to package it, write to the company and suggest they use another packaging material.\n- Trees get cut down for cattle to graze. Instead of eating meat, think of eating other sources of protein such as fish, soy, beans, whole-wheat, and nuts.\n- Buy organic fruits and vegetables. That means there are no insecticides or pesticides (poisonous chemicals) sprayed on the food. If these chemicals kill insects and pests that try and eat the vegetables, think about how harmful they can be to you and the environment.\n- Instead of buying gold or diamonds, which are mined and cause environmental damage, consider jewelry that is made from materials that are not mined...such as glass.\n- Encourage your parents, relatives, and friends to drive fuel efficient cars that get good gas mileage. Hybrid and bio-diesel cars get great mileage and use less or no gasoline.\n- Even better, whenever possible, walk, bike, carpool or use mass transit (bus or train).\n- Save electricity by turning off lights, t.v., radio, computer, etc when you are not using them.\n- Save water by NOT taking baths; instead take quick showers (turning off the water while you soap up) and then turning it back on to rinse quickly.\n- While washing your hands and brushing your teeth, turn off the water. You'll save gallons if you do.\n- When washing the dishes or your parent's car, turn off the water while washing it with soap. Rinse quickly after washing.\n- Hmmm, can you think of other ways to conserve wood, oil and gas, electricity, minerals and elements, and water, etc...? Brainstorm with your pen pal or a family member.\nOkay, now show YOURSELF what you have LEARNED by answering the following questions:\n- What does deforestation mean? (Hint: The prefix de- means to remove or reduce).\n2. Why does deforestation happen? For what purpose(s)?\n3. The largest rainforest in the world is located in:\na.) The Philipines\nb.) The Congo Basin in Central Africa\nd.) The Amazon Basin of South America\n4. If 2 U.S. football fields are destroyed every second, how many football fields are destroyed in 5 seconds?\n5. If 50,000 species become extinct every year, how many will become extinct in half a year?\n6. T or F: Rainforests contain over half of all plant and animal species in the world?\n7. Fill in the blank: One environmental consequence of deforestation is __________. This occurs when heavy rains wash nutrients from the soil.\n8. Name two things you can do as a global citizen to decrease deforestation.\n9. Biodiversity refers to:\na.) The loss of animals and plants\nb.) A variety, or many different kinds of living things\nc.) When animals lose their living space or habitat\nd.) An increase in the earth's temperature\n10. Fill in the blank: Indigenous people _______ in the rainforest. They depend on the forest for their food, clothing, medicine, cooking and building materials.\nAnswers are located after the references (please don't look until you have completed all 10 questions).\nPen Pal Letter: Imagine you're in class and your teacher reads an article about a U.S. company which is deforesting a rainforest in Brazil. Your teacher encourages you and your classmates to write letters to the company. Using the information you have learned in this lesson, write your letter to convince the company to STOP the deforestation. Use the facts you have learned to support and provide evidence for your position. Write your letter in the Comments Section after this lesson. You and your Pen Pal will read each other's letters and provide positive feedback to each other. Please don't forget to type your name in the Comments Section.\nKricher, J. (1997). A Neotropical Companion: An introduction to the animals, plants, & ecosystems of the New World Tropics. New Jersey: Princeton University Press.\nRainforest Action Network web-site: http://ran.org/info_center/factsheets/04b.html\nNASA web-site: http://eospso.gsfc.nasa.gov/ftp_docs/Deforestation.pdf\nWRM Briefing: This is an excellent site on deforestation! http://www.wrm.org.uy/publications/briefings/underlying.html\nAnswers to questions:\n1. Deforestation refers to the cutting, clearing, and removal of rainforest or related ecosystems into less bio-diverse ecosystems such as pasture, cropland, or plantations.\n2. Logging, mining, oil and gas extraction, cattle ranching, agriculture, and International, National, and Local reasons.\n3. d.) The Amazon Basin in South America\n4. 2 U.S. football field= 1 second, then\n? U.S. football fields= 5 seconds\nYou can set it up as a proportion: 2/1= n/5, n=10\n5. 1/2 of 50,000 or 1/2 x 50,000 or 50,000/2= 25,000 species\n8. Buy paper products made from recycled paper and become a vegetarian\n9. b.) A variety, or many different kinds of living things\nHow did you do? I bet you did great!\nNote: This integrated lesson is designed for 3rd grade students. The following California standards are addressed in this lesson:\nReading: Vocabulary and Concept Development (1.6): Use sentence and word context to find the meaning of unknown words.\nReading Comprehension: Comprehension and Analysis of Grade-Level-Appropriate Text (2.6): Extract appropriate and significant information from the text, including problems and solutions.\nWriting applications: Write personal and formal letters , thank-you notes, and invitations (2.3): Show awareness of the knowledge and interests of the audience and establish a purpose and context.\nLife Science: Students know when the environment changes, some plants and animals survive and reproduce; others die or move to new locations.\nSocial Studies: Students understand the role of rules and laws in our daily lives and the basic structure of the U.S. government (3.42): Discuss the importance of public virtue and the role of citizens, including how to participate in a classroom, in the community, and in civic life.\nAlgebra and Functions: Students select appropriate symbols, operations, and properties to represent, describe, simplify, and solve simple number relationships: (1.1): Represent relationships of quantities in the form of mathematical expressions, equations, or inequalities."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:14da101e-6008-4330-b50e-0e7c2b52be04>","<urn:uuid:d21a9d6b-9350-49d2-9a97-a8473ebad5dd>"],"error":null}
{"question":"Looking into climate activism in South America - how do grassroots movements in Bolivia compare to legal environmental actions in Colombia?","answer":"In Colombia, environmental activism has taken a primarily legal route, with 25 children bringing a landmark lawsuit to the supreme court to stop deforestation in the Amazon, resulting in the court declaring the rainforest a 'subject of rights.' In contrast, Bolivia's grassroots movement focuses on community-level adaptation and women's organization. The Bartolina Sisa Confederation of Campesino, Indigenous and Native Women in Bolivia leads union organization for peasant women, helping them adapt to climate change through agricultural diversification, economic independence, and collective action. While Colombia's approach emphasizes legal protection through the courts, Bolivia's movement centers on practical community-based solutions and women's empowerment in response to environmental challenges.","context":["“Today, environmental laws regulate the human use and destruction of nature……….As daily headlines tell us how we are tearing holes in the very fabric of life on earth, it is time to make a fundamental shift in how we govern ourselves towards nature …….”\nFor decades our laws have been a death sentence for the environment. Now, from the Amazon to Australia, the tide is turning\nThe Amazon rainforest is often called the earth’s lungs, and generates 20% of the world’s oxygen. Yet in the past half-century nearly a fifth of it has been cut down. The felling and burning of millions of trees is releasing massive amounts of carbon, in turn depleting the Amazon’s capacity to be one of the world’s largest carbon sinks – the natural systems that suck up and store carbon dioxide from the atmosphere.\nRecently, 25 children brought a lawsuit to end the deforestation and its devastating impacts on the environment and their own wellbeing. The case made its way to Colombia’s supreme court, which issued its decision last month. While deforestation is hardly a new issue in this region, the court’s response to the lawsuit certainly was. Commenting that environmental degradation – not only in the Amazon but worldwide – is so significant that it threatens “human existence”, the court declared the Colombian Amazon a “subject of rights”.\nIn 1972 the law professor Christopher Stone published a seminal article, Should Trees Have Standing?, that explored the possibility of recognising the legal rights of nature. He described how women and slaves had long been treated as rightless in law, and suggested that just as they had eventually attained rights, so trees and other nonhuman living things should also do so.\nToday, environmental laws regulate the human use and destruction of nature. They legalise fracking, drilling, and even dynamiting the tops off mountains to mine coal. The consequences are proving catastrophic: the die-off crisis of the world’s coral reefs, accelerating species extinction, climate change. Finally, though, this is changing. In 2006 the first law recognising the legal rights of nature was enacted in the borough of Tamaqua, Pennsylvania, in the United States. The community sought to prevent dredging sludge laden with PCBs (polychlorinated biphenyl) being dumped in an abandoned coalmine. The organisation I work for, the Community Environmental Legal Defense Fund, helped the council draft the law, transforming nature from being rightless to possessing rights to exist and flourish. It was the first such law in the world. Communities across more than 10 US states have now followed suit, including New Hampshire, Colorado and Pittsburgh.\nThe poisoned landscape left left by an illegal goldmine in the Amazon forest. After the decision to grant legal rights to nature in Pennsylvania, representatives of my organisation met Ecuador’s constituent assembly in 2008, which was elected to draft a new constitution. We discussed the rights of nature, and why communities all over the world find themselves unable to protect nature under laws that authorise its exploitation. The assembly’s president, Alberto Acosta, told us: “Nature is a slave.”\nHowever, that year Ecuador enshrined the rights of nature – or Pachamama (Mother Earth) – in its constitution, the first country to do so. Since then Bolivia has put in place a Law of Mother Earth. Courts in India and Colombia have similarly ruled that ecosystems possess rights. In Mexico, Pakistan, Australia and other countries, rights-of-nature frameworks are being proposed and enacted.\nColombia’s supreme court was asked to consider the climate-change impacts of Amazon deforestation in the lawsuit that led to its groundbreaking ruling. Similarly, in Nepal the Center for Economic and Social Development is working to advance rights to protect against climate change. The Himalayas – known as the world’s third pole – are experiencing warming faster than any other mountain range on earth. With the melting of ice and snow, a Sherpa told us, “the mountains are turning black”. But now a constitutional amendment has been developed that would, if adopted, recognise the rights of the Himalayas to a climate system free from global-warming pollution. It would for the first time provide a platform for Nepal to hold major climate polluters accountable for violating the rights of the mountains.\nLaw today divides the world into two categories: persons, capable of having rights; and property, unable to possess rights. While there is no universally agreed upon definition of “legal person”, it is generally understood to mean an entity capable of bearing rights and duties. The problem that the rights-of-nature movement is now encountering is that this definition is predictably problematic when it comes to rivers, forests or nature more broadly.\nIn 2017, for example, the state high court in Uttarakhand, India, ruled that in order to protect the Ganges and Yamuna rivers, they should be considered legal persons with “all corresponding rights, duties and liabilities of a living person”. In a subsequent appeal to India’s supreme court, the state government asked whether, if the rivers flood, leading to the death of a human being, a lawsuit could be filed for damages. Could the Uttarakhand chief secretary of state, named by the court as one of several officials in loco parentis, be held liable on the river’s behalf? In this case, the supreme court decided not.\nCan we hold a river accountable for flooding, or a forest for burning? Of course not. Yet existing legal systems force us to think of nature in terms of human concerns rather than what concerns nature. With the past three years the warmest in recorded history, and as we face what has been called the sixth great extinction, lawmakers and judges appear increasingly to agree that it is time to secure the highest form of legal protection for nature, through the recognition of rights.\nTo make progress in this area, we must break away from legal strictures that were never intended to apply to nature, such as legal personhood, and establish a new structure that addresses what nature needs. Perhaps we can call this framework legal naturehood. A recent symposium at Tulane Law School, in New Orleans, brought together academics, lawyers and activists to develop a set of guidelines for recognizing and enforcing legal rights of nature, known as the rights-of-nature principles.\nAs daily headlines tell us how we are tearing holes in the very fabric of life on earth, it is time to make a fundamental shift in how we govern ourselves towards nature – before, as Colombia’s constitutional court wrote, it’s too late.\n• Mari Margil is associate director of the US-based Community Environmental Legal Defense Fund\n- This article was corrected on 24 May 2017. The Center for Economic and Social Development is based in Nepal, not the US. And the warning referred to in the final paragraph is now correctly attributed to the Colombian constitutional court, not the supreme court","‘Climate change is making us stronger’ — Resilient Bolivian women adapt to global warming\nIn rural Bolivia, making a sustainable living is becoming difficult for smallholders. But the country’s women, who are traditionally responsible of farming, are demonstrating resilience to the effects of climate change.\nNestled in Bolivia’s Cochabamba valley is the village of Tiraque. One of dozens of indigenous farming communities in the traditionally fertile local region, it sits at an altitude of 3,300 meters (10,800 feet). There, families live as they have for generations: from what they can cultivate. That has traditionally been potatoes, but changing weather patterns bring a need to adapt and think beyond habit. Particularly for women.\nThe consequences of climate change are not evenly distributed — the poor are hit harder than the rich. Furthermore, gender plays a role: women are more vulnerable, as they are the ones responsible for production and preparation of food. This is especially the case in rural areas, where making a sustainable living is depends directly on agricultural production.\nTeresa Hosse is representative of the Bolivian Platform against Climate Change. She says the South American country’s unique composition of highland (Altiplano), valley and Amazon makes it among those worst-affected by the consequences of global warming.\nJuanita Terrazas (pictured above), who is now 23 years old, remembers a time when it was “so cold that only potatoes could grow here.” Carrying a plastic container of ecological herbicides on her back, she sprays the cauliflowers she has now been growing for the last three years.\n“The sun is coming closer, so it is much warmer than before, and that brings new plagues to our fields,” she says in reference to the tiny red spiders and aphids that wreak havoc.\nAlthough they may not understand the exact mechanics of global warming, women in Tiraque are well aware of how the climate is changing. The average temperature, they say, is rising; the rainy season has shortened from four to two months; communities are being hit by drought; and the weather is less predictable, bringing more extremes such as floods and hailstorms.\nThey have different explanations for these shifting weather patterns. One woman says Pachamama, or Mother Earth, is tired of producing; another believes the sun coming through the hole in the ozone layer is so strong that it vaporizes the rain before it can hit the earth. Other women hold cars, asphalt and factories outside Bolivia responsible.\nAs it is no longer possible to produce the same quantity and quality of potatoes as before, farmers need to try out other crops such as onions and beans. Luckily, water is still available in wells on the mountains with irrigation canals either dug by hand, or more effectively using plastic tubes leading to their fields.\nAlthough learning about food diversification has the advantage of giving the women the chance to grow, sell and eat a wider range of vegetables, Juanita’s neighbor Nicola Montaña (pictured above planting) says they did not make this choice freely. Rather, they were forced to take action now that their potatoes no longer grow to a decent size.\n“We learn by trial and error. And it is much more work because we have to sow all the onions by hand instead of using bulls,” as is the case with potatoes. “I am 64, and my back is hurting.”\nThe Bolivian Institute for Empowerment of Farmer Communities (INCCA) is teaching the communities to use ecological fertilizers to help in the fight against climate change and secure a decent yield.\nLivestock is also a feature of life in the Cochabamba valley. Cows provide milk, chicken lay eggs and sheep are kept for their wool. Occasionally an animal is slaughtered so the family has meat to eat or sell. The women are the ones who take care of the animals, and it is also their role to slaughter or sell them.\nPrimavera Besara’s granddaughter stands with a calf she bought in a neighboring village. “We will feed it the clover from our fields,” Primavera says. “In half a year, during the dry season, I will sell the cow for six times the price.” She describes the animal as her “personal investment.”\nTrinidad Cossío (pictured above) also has a cow. This was given to her when she became a member of a native women’s farming syndicate, the Bartolina Sisa Confederation of Campesino, Indigenous and Native Women in Bolivia, which is the leading union organization for peasant women in the country.\n“If it delivers a calf, I have to donate it to another Bartolina, so everyone will benefit.”\nWomen involved in the union have greater economic independence through funding targeted at improving their situation, and have become more organized.\nTrinidad, who became a Bartolina some eight years ago, says her main reason for doing so was because she heard there was funding available. But she was also motivated by a desire to speak in public, to learn how to make decisions and to value women’s voices.\nIn traditional gender roles, men are responsible for providing an income while women take care of the children. Nowadays, women also run their own businesses, such as chicherias, where they brew and sell chicha, an alcoholic beverage brewed from fermented maize. Or they make an additional income by slaughtering chickens and preparing food to sell at the local market on fridays.\nTeresa Hosse, of the Bolivian Platform against Climate Change, says women are more affected by climate change. “Men migrate to the cities for other work, while the women stay behind with the double burden of taking care of their children, and their fields and their livestock.”\nUnder Bolivia’s President Evo Morales, several steps have been taken for greater gender equality, including passage of a 2005 law that calls for at least 50 percent female representation in local government.\nBut more money has also been made available for organizations and projects such as the INCAA leadership training program that empowers women to make their own decisions and become more independent from men.\nINCCA also runs a program on gender education in the communities around Tiraque village. Municipal Councilor Miriam Cossío (pictured above, left) says INCCA taught her that her voice counts, and how to discuss her opinions with men. “It is not only the women that have to change,” she says “Men are also learning to respect and listen to us. The mentality in the communities is slowly changing.”\nIt might be a plodding process, but Juanita — who remembers fields of potatoes from her earlier years — says life in the community has evolved. “We are becoming more independent and we are in a process of empowerment. Climate change is making us stronger.”\nAuthor: Sanne Derks\nDate03.05.2018 | 11:08\nTagsagriculture, Bolivia, climate change, Cochabamba, farming, global warming, INCAA, women, women's rights"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_formulation","category_name":"search_synthesis"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:db2d1628-7588-4cc2-8024-7971d0721955>","<urn:uuid:f1c025db-1cd2-4c0e-b493-959b480d2757>"],"error":null}
{"question":"I'm working on a research paper about modern teaching methods. Could you explain how Chinese language education is evolving in schools, and how does this compare to the evolution of traditional medicine in modern times?","answer":"Chinese language education has evolved from traditional language studies to an integrated approach across multiple subjects. In Kentucky, for example, schools have implemented innovative programs combining Chinese with arts, physics, and social studies, with teachers receiving specialized training through summer academies. Similarly, traditional medicine, particularly herbal medicine, has evolved from its historical roots to become increasingly mainstream. While it was temporarily overshadowed by modern pharmaceuticals in the 20th century, herbal medicine has experienced a recent resurgence and is now supported by scientific investigation. Modern practices combine traditional knowledge with standardized manufacturing processes and quality control measures, much like how modern Chinese education combines traditional elements with contemporary teaching methods.","context":["Chinese language and culture classes have become a popular offering in schools. But what happens when China breaks free from language and area studies? Teachers find that it can complement the arts and English, sway through dance and music, trek across social studies, and even trifle with physics. Surprising subject area pairings revitalizes teaching as educators try fresh approaches, learn from one another, and see their own areas of specialty in a new light.\nA case study of an innovative pairing of arts and language teachers spearheaded by policy-makers in Kentucky reveals strategies and benefits for integrating subject areas. “When you integrate, you double achievement,” says Jacque Bott Van Houten, world language and international education consultant for the Kentucky Department of Education. The Kentucky legislature originally awarded money so schools themselves could establish integrated programs, but administrators and teachers were unsure how to do so, and their efforts floundered. The Department of Education then decided to organize summer academies and directly train teachers to engender ongoing collaboration.\nDesigned by the Kentucky Department of Education, the Confucius Institute at the University of Kentucky, and the Kentucky Center for the Performing Arts, the weeklong summer academies were free to elementary and middle school teachers in the arts, and the Spanish or Chinese language teachers with whom they were paired. A flamenco dancer, guitarist, pipa player, brush painter, storyteller, and fan dancer taught the arts and language teachers in the target language. “The Chinese teachers were very surprised, I think, to see that it was possible to teach someone in the target language all the way through the content,” observes Bott Van Houten. Participants learned how to assess performance and language. After the academy, outcomes were measured upon observations of teaching, a review of lesson plans, and interviews.\nBott Van Houten advises teachers wishing to integrate programs to garner administrative support and respect new pedagogical approaches. They should become familiar with content areas, and ensure that goals, if not common, are at least mutually supportive.\nIntegrated programs, she says, are compelling to student participants and parent audiences. Sometimes they garner media interest, further raising program visibility. According to Robert Duncan, arts and humanities consultant for the Kentucky Department of Education, “Teachers thought it had a strong, positive impact on their teaching.”\nTeachers need not wait for a state initiative to embark on integration. The National Consortium for Teaching about Asia (NCTA) provides professional development so teachers across subject areas can infuse their courses with China-related materials.\nJacqueline Fludd, a social studies teacher at Paint Branch High School in Maryland, was inspired by her NCTA seminar and study tour. She incorporates art exhibitions at nearby museums as well as film festivals and international culinary fairs to engage her students in learning about China. She also leveraged the resources she purchased with a mini-grant to introduce colleagues to China and pique their interest in pursuing China-related professional development.\nThe doyen of combining subject areas is B.J. McElderry, chair of the art department at the Upper School at Garrison Forest School in Maryland. “I wanted to see China across the curriculum,” she explains, and began by approaching the school’s headmaster and various teachers, encouraging them to attend NCTA conferences.\nBecause of her endeavors, students at her school today analyze Du Fu in English, dabble in the “three perfections” in a joint art and literature session, and investigate China’s “floating population” of migrant laborers. Music classes integrate Chinese folk songs and hulu flutes have replaced recorders. P.E. classes feature Tang ribbon dances and tai chi.\nUndaunted by seemingly random pairings, McElderry convinced a physics teacher to co-design a unit on modular construction featuring courtyard houses and hutong alleyways, and another on trusses based on the Bird’s Nest Olympic stadium.\nMcElderry, who acknowledges that she has been weaving China into her school’s curriculum since 1993, recommends persistence. “For every teacher I was able to pull on board, at least two were resistant.” Next year, students at her school will encounter China in a biology unit on Chinese medicine. If you are a colleague of McElderry, resistance appears futile. Resistance would also seem misguided, according to the many educators who testify that unleashing China animates teaching throughout the curriculum.\nNational Consortium for Teaching About Asia (NCTA)\nCollege Board Chinese Language and Culture Initiatives\nGeorgetown University National Resource Center for East Asia\nAsia in the Curriculum Bulletin\nThe U.S.-China Institute","Herbalism is probably the oldest, most tried and tested form of medicine in the world. The use of plants for medicinal purposes is an integral element of all cultures and has played a significant role in healing since prehistoric times.\nAlso known as phytomedicine or botanical medicine, herbalism refers to the use of a plant’s seeds, berries, roots, leaves, bark, fruits or flowers for therapeutic purposes. Not only is herbal medicine the science of using plants for treating the sick and managing various conditions from minor health complaints to serious illnesses, it is also the art of utilising nature’s medicine to protect and augment health and prolong life. Herbal lore is like a priceless treasure chest and knowledge of the healing power inherent in plants has been passed down by word of mouth from generation to generation.\nHerbs have a long and illustrious history. They were used extensively for healing by the ancient Greeks, Chinese, Indians, and Egyptians. There is some evidence of the Chinese use of herbs during the Shang dynasty circa 1 600 BC and the first known written record of herbal medicines was also found in China, dating back to 2 700 BC. Furthermore, ancient Egyptian papyrus writings described medicinal uses for plants, the Assyrian and Babylonian scribes wrote herbal recipes on clay tablets and indigenous African and Native American cultures have always been renowned for their herbal wisdom.\nWestern herbal medicine has its roots in the homespun practices of the British, Greek, and Roman traditions and can be traced back to the prominent physicians Hippocrates and Galen. The former, who lived 469 -377 BC in ancient Greece, is regarded as the Father of Modern Medicine. He wrote about 70 books on herbs, healing and holistic health, including a list of 400 herbs for common use and a book of 600 herbs that became the basis for many later books on this subject.\nIn the first century AD the Greek physician Dioscorides wrote the first comprehensive, illustrated book on herbal medicine – De Materia Medica – which included information on the preparation, properties and testing of herbs and became the basis for pharmaceutical and herbal writings until the 16th century. Herbal medicine spread rapidly throughout the Roman Empire and in 200 AD the herbal practitioner and surgeon, Galen, created a system for classifying illnesses and remedies. In the following centuries herbal medicine became largely the domain of monks who took on the task of translating Arabic and Roman herbal scripts and cultivating medicinal herb-gardens. In 1500 AD herbal medicine began to go mainstream when it was promoted by Henry VII, who initiated the introduction of Acts of Parliament that allowed herbalists to practise. One of the most famous herbalists of the time was Nicholas Culpepper, who wrote the herbal book for the layperson, The English Physician. He later wrote Complete Herbal – a highly popular, informative and comprehensive book that is still available and quoted today.\nA PARTIAL ECLIPSE\nIn the 19th century chemical analysis evolved, and scientists began extracting and modifying ingredients found in plants and identifying individual active constituents. This heralded the transition from raw herbs to synthetic pharmaceuticals. The discovery of penicillin by Alexander Fleming in the 1930s ushered in the dawn of the antibiotic age. As developments in chemistry and fast-acting orthodox drugs increased in popularity, interest in herbs began to wane and herbal medicine faded into the background.\nThe pharmaceutical industry got under way in earnest from the 1950s. Pharmaceutical companies identified the active therapeutic principles of many plants, synthesised commercial analogues and patented new drugs. Many well-known pharmaceutical medications were originally derived from plants: for example, morphine comes from poppies, aspirin from willow bark and digoxin from foxglove. Today, approximately 25 percent of modern pharmaceuticals are derived from plants.\nHerbal medicine may have been temporarily eclipsed by the advent of modern pharmaceuticals, but it has recently experienced a resurgence in popularity and is again one of the fastest-growing health trends. The World Health Organisation estimates that 80 percent of the global population uses herbal medicine for some aspect of primary health care. While herbal medicine has always been widespread in developing countries, its popularity is now increasing in the West.\nAlthough the active ingredients of many plants have been isolated, imitated, refined and marketed as drugs, it is often the whole plant, not just the active ingredient, which has the beneficial action. This is because the plant’s constituents work synergistically to stimulate the body’s natural healing capacity.\nThe whole plant is often better than an isolated extract as the delicate balance of compounds within the plant is needed for best effect, as well as to reduce potential side-effects. Herbs work with the body instead of against the disease. Plants act in a variety of ways. They can be used for cleansing, eliminating and detoxifying, as well as for stimulating the body’s self-healing capacity and to boost immunity and resistance to disease.\nHerbal medicine involves the preparation of specific parts of various plants and the individual actions of these herbs range from mild to potent. Mild herbs have subtle effects and may have to be taken for weeks before their full effects are achieved. More potent herbs will have an immediate and powerful effect. The form and dose play important roles in action and safety.\nHerbs are available in many forms – as fresh or dried products, liquid or solid extracts, tablets, capsules, powders and tea bags. They are prepared either for consumption or for use on the skin in the form of creams, salves, oils, balms and ointments. Common preparations include teas, decoctions and tinctures. A tea, also known as an infusion, is made by adding boiling water to fresh or dried herbs and steeping them. Some roots, barks and berries need more forceful treatment to extract their ingredients and must be simmered into a decoction in boiling water for longer periods than teas. Tinctures are made by soaking a botanical in a solution of alcohol and water for some weeks and are used for concentrating and preserving plants.\nThe different forms have different strengths and different preparations vary in the relative amounts and concentrations of chemical extracted from the plant. For example, peppermint tea is safe to drink but peppermint oil is far more concentrated and can be toxic if used incorrectly. Whole herbs contain many ingredients that work together to produce a beneficial effect.\nHerbal medicine has been practised for healing. Many medicinal plants have highly beneficial therapeutic properties and can be used to treat a wide range of symptoms and diseases. While some people consult a trained medical herbalist or phytotherapist, most use herbal medicines to self-medicate for prevention or treatment of common ailments. A variety of herbal preparations is available over-the-counter in health shops, pharmacies and supermarkets.\nHerbs are ideal as a simple system of homecare for first aid, everyday ailments, the management of chronic conditions, strengthening the body and preventive treatment. There are many possible methods of using herbs for health. They can be taken internally as tablets, teas and tinctures or used externally in hand-baths, footbaths, skin washes, rubs, massage oils, eyebaths, compresses and fomentations. Local treatments allow the herb to act exactly where it is needed. Be aware that results from a particular plant will not necessarily be the same for everyone, as different herbs work for different people.\nNot all herbs are created equal and efficacy is based on quality. Quality depends on numerous factors, starting with the environment in which the plant is grown; climate, soil, rainfall, genetics, insects and the time of day and season of harvesting all play a part. Everything that happens to the plant after it is harvested – extraction, preparation, storage, processing, manufacture and packaging – will also affect the quality and therapeutic activity of the final product. If the herbal product contains specific chemical components it will work; if these essential constituents are absent or are present in insufficient amounts, it will not work as effectively.\nThere are good- and bad-quality herbal preparations available on the market. Some products are standardised – i.e. tested for certain chemicals to ensure the herbs are sufficiently potent. This process is not compulsory across the global industry, however, but pressure is mounting for all products to be compliant with Good Manufacturing Practises (GMPs) for dietary supplements. These are a set of requirements by which dietary supplements must be manufactured, prepared and stored to ensure quality. Manufacturers are expected to guarantee the identity, purity, strength and composition of their dietary supplements. For example, GMPs aim to prevent the inclusion of the wrong ingredients, the addition of too much or too little of a dietary ingredient or an illegal substance, the possibility of contamination (by pesticides, heavy metals, bacteria, etc.) and the improper packaging and labelling of a product.\nIt is difficult to determine the quality of a herbal product from its label, but it is a good rule of thumb to favour reputable brands. As herbal medicine becomes more mainstream, improvements in analysis and quality control – along with advances in clinical research – show the value of herbal medicine in the treatment and prevention of disease.\nHerbs must be recommended and taken with knowledge and responsibility. They are classified as dietary supplements and can be sold without being tested to prove that they are safe and effective. Many people believe that products labelled “natural” are safe, but this is not necessarily true because the safety of a herb depends on many things including its chemical makeup, how it works in the body, how it is prepared and the dose. The bioactivity of herbs is often underestimated.\nAlthough generally considered safe, it is important to be aware that herbal medicines contain active ingredients which can be toxic if taken in excess and can also interact with prescription medications. With the growing popularity of herbal products, more research is currently being conducted into their safety and efficacy. It is always important to follow the manufacturer’s suggested directions for using a herbal product and not exceed the recommended dose without the advice of a healthcare provider. It is important to talk to your doctor or an expert in herbal medicine about the recommended doses of any herbal products.\nConsumers need to be aware of the indications and contraindications of use for herbal products and specifically the interactions between herbal products and pharmaceutical medicines. However, herbs can be taken safely as long as a few simple rules are followed:\n- Consult a doctor or other healthcare provider if you have a disease or medical condition, take any medications, are pregnant or nursing, or are planning to have an operation.\n- Consult with a doctor or other healthcare provider before treating a child with herbal preparations.\n- Like drugs, herbal or botanical preparations have chemical and biological activity. They may have side-effects. They may interact with certain medications. These interactions can cause problems and can even be dangerous.\n- If you have any unexpected reactions to a herbal or botanical preparation, inform your doctor or other healthcare provider.\nUsed correctly, herbs can help treat a variety of conditions and in some cases may have fewer side-effects than some conventional medications.\nINTO THE FUTURE\nA worldwide renaissance in natural therapeutic systems is taking place and modern science is validating traditional practices. Renewed interest in herbs is being supported by a surge of scientific investigation into the use of plant-based medicines. These investigations are giving a greater understanding of how herbs work and greater credence to the ancient practise of herbal medicine."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:9bc5837c-3522-45b0-a0bb-704419ee75cb>","<urn:uuid:0523e373-587b-46f1-b9dd-b0647d934a0f>"],"error":null}
{"question":"How to properly secure RSA private keys for web encryption?","answer":"The biggest priority is to only store private keys on trusted systems - never use them on public computers or infected machines. Create and securely store a revocation certificate and backup in case the key is compromised. For most users, following the default settings when generating a key with GPG is sufficient. If using the key for email, it's recommended to use a local mail client like Thunderbird with Enigmail that connects to your email provider.","context":["While it is a nice idea, I do not see any practical applications.\nIt requires a receiver who is a) knowledgeable enough to decrypt it using something like openssl and b) have access to the actual private key.\nIf that's the case it is highly likely that this person is either capable of using something like PGP or facilitate a file upload form on the apparently available website. Both of which are at least as secure and a whole lot more convenient.\nSo it appears that this site has the perceived advantage of turning a web developer's SSL cert into key for encryption, which at first sounds like a good idea.\nIf on the other hand you don't exclusively communicate with SSL-using web developers, you're better off using a PGP implementation. Unfortunately Symantec bought PGP Corporation, but GPG4Win is free, as are GPG-based PGP implementations for almost every other platform.\nWorried about it being hard? It really isn't. In fact it's easy to get up and running with encrypting your Gmail in Firefox even if you have a Mac or something else.\nIt's not for communicating with web developers. It's for publicly and provably, but responsibly exposing vulnerabilities in software. The people/entities who write such software are likely to have a public website with SSL. If they don't, it's unlikely to be very important or widely used software. In that context, PGP makes no sense.\nCan you point me to a site that discusses the best practices for generating and securing my keypair? I don't have enough faith in an Instructable to get all the details right. How would I go about becoming part of this \"web of trust\" that I keep hearing about in relation to PGP.\nThe biggest thing to worry about is that you only want the private key on systems you trust. If you put your private key on a USB stick, and use the local library or computer lab, you've already lost the battle. If you're running a totally infected Win95 machine, you've already lost the battle.\nSecond biggest thing is to make sure you properly generate a revocation certificate, and a backup, and store them in a location you consider secure. (And maybe that secure location is just a shoebox in your bedroom closet unless you're worried about the NSA or something.) Then if you realize you've done something stupid, you can just revoke the key and create a new one.\nOther than that, there's not much to screw up if you follow the default settings when creating a key with gpg.\nFor email, I would also highly recommend using a local MUA that connects to gmail. Most people use Thunderbird + Enigmail, but there are other options. Enigmail also has a pretty good manual that covers both the how and why.\nWhile there are Internet services that purport to realize an actual \"web of trust\", the \"web of trust\" concept is really notional. It's more an idea than a thing. The idea is, instead of having a central authority that vouches for every key, you get your keys directly from your acquaintances, verify them directly with your acquaintances, and in turn vouch for those keys with your peers.\nIt's not the RSA key size that prevents you from using RSA for arbitrary message lengths. Notice that block ciphers used for bulk encryption are similarly constrained by their block length (which are far shorter than an RSA key). In both RSA and AES, you can use a chaining construction to encrypt arbitrary-length messages.\nThe things that keep you from doing this in the real world with RSA are security and speed.\nIt's first of all much slower to perform a single RSA operation than it is to perform the AES block transform. AES involves no bignum math at all, let alone bignum modular multiplication.\nSecondly and more importantly, RSA encryption is fundamentally volatile and dangerous. As an exercise, go implement it in Python or Ruby (you're going to find it's remarkably easy, since both those languages automatically promote to bignums). RSA is just a simple formula. As a result, there are a variety of pitfalls to using it safely. Among the important ones is the fact that you can't safely encrypt related messages, and that messages require a certain proportion of random padding.\nWhy don't you use the standard openssl RSA encryption function to encrypt the entire file, rather then encrypt a plaintext passphrase?\nI don't know of an implementation that uses RSA encryption that doesn't use RSA to encrypt a (heavily padded, very random) key which they then use to encrypt the final payload using say AES or IDEA (in the original PGP).\nSpeed, because cryptanalysis via cipher-text only attacks becomes easier as you get more and more ciphertext associated with a given key, and because if someone attempts to analyse a memory core dump or the memory space of your computer hopefully the only data available is the session key, rather than the full decrypted RSA private key.\nYou got downvoted, and maybe I've misinterpreted the thread, but my perception was:\n* Parent commenter thinks messages should just use RSA, and not RSA+AES.\n* You try to explain why he should use RSA+AES instead of RSA.\n* He tries to post an analysis of why to use RSA-only.\nCan I just step in to say: (a) using RSA only is way slower, like you said, and (b) it is significantly harder to make bulk RSA encryption secure than it is to make bulk AES encryption secure, just like you said?\nThat's a neat hack. I once had call to send banking details to a client. It was very annoying - eventually settled on encrypting an emailed zip file and sending password out of band.\nThis, on the other hand, turns any web developer's SSL cert into their PGP key without their advance cooperation. (They don't have to have one, understand why they need one, or create one and publish the public key. They just have to have an https site, like all my clients already do.) Limited utility, since decrypting is impossible for regular people and larger corps would have that private key locked down like crazy, but a very neat hack. I could actually see myself using it, too, for secure geek-2-geek transmissions.\nGreat I think that got most of it (validation!) but revocation checking worries me and a skim of the OpenSSL (0.9.8o) sources doesn't leave me with the warm'n'fuzzies.\ns_client.c calls SSL_CTX_set_verify() (the default verifier). Results from that can be obtained from SSL_get_verify_result() and are documented in verify(1).\nAll of the CRL/revocation-related return codes there are marked \"unused\". There is no mention of OCSP.\nI found found a \"crl_check/crl_check_all\" option for verify(1). Command line help mentions an \"ocsphelper\". OpenSSL does have a separate OCSP client. But I don't think any of this machinery is activated by default.\nIt goes without saying that you shouldn't do a simple \"rm\" on the password file. I'm not going to put on my tin-foil hat and start gibbering about magnetic alignment and electron tunnel microscopy but this is just \"one of those things\" that everyone knows to avoid.\nUsing /dev/urandom as a password source is fine. It's a CSPRNG. It theoretically degrades if you exhaust entropy, but there's no current attack I know of based on that property. Also, RNG attacks are usually \"online\", meaning an attacker gets to continually interact with the RNG. This is a one-off offline use. In this scenario, you could probably survive with rand().\nAgreed. /dev/urandom should be mixed with other sources of entropy (system statistics, epoch, low-level counters, cryptographic PRNGs like Yarrow) and then \"combined\" using a cryptographic hash. Such a principle is used in e.g. Fortuna.\nBlocking /dev/random when entropy is low is the correct behaviour, but it is a system-dependent behaviour. Darwin (Mac OSX) has the two sources behave identically.\nThe Darwin man page justifies this behaviour saying:\n/dev/urandom is a compatibility nod to Linux. On Linux, /dev/urandom will produce lower quality output if the\nentropy pool drains, while /dev/random will prefer to block and wait for additional entropy to be collected. With\nYarrow, this choice and distinction is not necessary, and the two devices behave identically. You may use either.\nand then contradicts itself later by saying:\nYarrow is a fairly resilient algorithm, and is believed to be resistant to non-root. The quality of its output is\nhowever dependent on regular addition of appropriate entropy.\nA counterpart to /dev/random is /dev/urandom (\"unlocked\"/non-blocking random source) which reuses the internal pool to produce more pseudo-random bits. This means that the call will not block, but the output may contain less entropy than the corresponding read from /dev/random. While it is still intended as a pseudorandom number generator suitable for most cryptographic purposes, it is not recommended for the generation of long-term cryptographic keys.\nThis is a drastic oversimplification. Both urandom and random (on Linux; there's no difference between the two on BSD) are seeded from hard entropy sources. Both urandom and random extract entropy by updating pools with SHA1. The difference is that random has an estimator and will demand more hard entropy when it has serviced too many requests. But it's not as if urandom goes from producing \"101010100101000101010100111001\" to \"111011011110111101111111110111\" when entropy is depleted.\nIn any case, this is entirely irrelevant to the discussion at hand. You can absolutely use /dev/urandom to make a one-shot crypto key. You shouldn't wire /dev/urandom up into an online cryptosystem (don't use it to produce DH parameters, for instance), but even then, urandom isn't going to be how your system really gets broken.\nIn your case, experimenting with encrypting whole files with RSA instead of using RSA to exchange keys is what's really going to break your system. This is almost a decent example of how people obsess over the wrong things in cryptosystem design, and why perhaps generalist programmers should stay far, far away from this stuff.\n\"and why perhaps generalist programmers should stay far, far away from this stuff.\"\nCould I adjust that to say \"generalist programmers should stay at least enough in touch with this stuff to know how badly they'll screw it up on their own\"?\nI've had _many_ heated discussions with inexperienced devs who don't understand just how much you need to know (and how much you need to know that you don't know) before you can start ignoring the simple advice \"SSL for data on the move, GPG for data at rest\".\nVirtual machines receive very little entropy from their environment, which is a real problem when entropy is required for the generation of cryptographic keys.\nThere have been many attacks based upon vulnerabilities which exist due to misunderstandings entropy, and the need for a secure random number generator, for example the mozilla ssl vulnerability and the debian ssh key vulnerability.\nI would agree with you that /dev/urandom can be used for one shot passwords, however I would disagree with you that getting in to the habit of using a non secure random number generator as a source of secure entropy is a bad idea and should be discouraged.\nI'd also like to point out that \"the standard openssl RSA encryption function\" last time I checked worked to spec, and does in fact encrypt a symetric key used for AES (By default), using RSA, including proper cryptographic padding of the key using PKCS#1.\nI'm not exactly sure why you thought otherwise.\nI do agree with your final assertion, though. Unless you know what you're doing, it's very easy to make a mistake."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"content_constrained"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"instructional"}],"document_ids":["<urn:uuid:5fa6942f-b352-4862-ae00-900a647343a3>"],"error":null}
{"question":"How to improve content marketing measurement effectiveness?","answer":"To improve content marketing measurement effectiveness: 1) Set clear goals for your content strategy and assign core metrics to them, ensuring individual metrics align with overall strategy. 2) Make measurement a real priority by determining metrics, responsible parties, tools, budget, and resources before starting campaigns. 3) Define brand-level goals clearly and identify appropriate metrics for them, maintaining consistent tracking over time for metrics like sentiment and brand associations.","context":["In the Content Marketing Institute’s annual study of B2C content marketers, respondents were asked about ten key content marketing challenges like “producing engaging content,” “finding trained content marketing professionals,” “lack of budget,” or “gaps in knowledge and skill.” The highest percentage of marketers (51%) rated “measuring content effectiveness” as very challenging.\nIt’s no surprise—more and more businesses are creating tons of different types of content, and there are so many possible channels of distribution. Video, photos, text, downloads, and more can be distributed on social media, owned websites, apps, a nearly infinite variety of paid channels, custom or programmatic, and they can be shared, engaged with, or repurposed across and between any of these spaces.\nEverything is tracked differently, and people across teams are responsible for doing so for many brands. It makes sense that measurement is a challenge.\nA lot of brands really want to do better, but aren’t sure where they’re going wrong.\nWe’ve identified three of the core ways in which companies aren’t getting measurement right, and what they can do to fix them and measure better.\n#1 – Measurement is missing focus\nCompanies that don’t know how successful their content strategy is might be measuring plenty. The issue is that whatever’s measured isn’t able to tell them if their content is doing what they want it to do.\nYou can measure a dozen metrics for a single piece of content. For a Facebook video, you can see total views, you can get a breakdown of autoplay vs click to play views, of how many people watched through different time intervals—if it’s an ad, cost metrics come in to play too.\nWhen teams are considering how and what to measure, content marketing metrics on this level get a major amount of attention. Metrics for specific channels, specific pieces of content, or other micro-level concerns are hugely important for optimising individual elements of your content strategy.\nBut they won’t necessarily allow you to understand how successful you are overall.\nHow to solve it:\nThe best way to gain a real perspective on how well your content is doing is to set clear goals for your content strategy and assign a few core metrics to them.\nIndividual teams, and the people responsible for measurement and reporting on them, should determine more specific goals and metrics for their efforts, but there needs to be a crystal-clear line between those objectives and measurements and those for your overall content strategy.\nIf it is obvious where individual metrics fit into the bigger picture of your content strategy’s success, not only measuring, but evaluating success and improving outcomes become much easier.\n#2 – Measurement’s a priority on paper\nMaking content a priority requires dedicating time, resources and money to producing content. This makes sense, logically. You can’t create something from nothing. Measurement, on the other hand, especially for people who don’t come from a data background, can seem like something that takes care of itself. That approach doesn’t lead to the most effective content measurement.\nHow to solve it:\nBefore kicking off a content campaign, it’s critical to determine what the goals are, who will be involved, the timeline, the budget, and what tools and outside resources will be necessary for success.\nIt’s no less important to figure out what the metrics are for determining success, who will be responsible for tracking those metrics, what tools and budget are available to do so, and what other resources can be made use of in order to track performance.\nWhen measurement is focused, and made a priority across a department, teams and individuals have a better understanding of their role and how to perform their best in it.\n#3 – Brand-level goals are different\nMany companies can still find it a challenge to measure content’s effectiveness around what could be called brand-level goals.\nGoals like increasing brand awareness and recall and improving positive customer sentiment can be measured, but it can be harder to agree on exactly how than it is for say, revenue.\nIt’s clear that these elements are critical to the health of a brand: The number of people aware of your brand and how positively they feel about it can impact sales immensely. And your content can have a huge effect on these things. But knowing the exact effect means determining the best measures for them.\nHow to solve it:\nWebsite traffic, mention volume, press coverage—there are lots of content marketing metrics to go by, and a lot of different ways of looking at them.\nBy defining your brand-level goals clearly, and taking the time to figure out exactly which metrics are the most appropriate for them, you can set up a strong brand-level measurement base.\nFor brand-level goals especially, consistency is key—by tracking positive brand associations through sentiment, for example, having a baseline that you continue to monitor from over time gives you a strong idea of how well you’re doing.\nMaking it stick\nMeasuring performance accurately can make or break a marketing department. In a complicated content landscape, measurement could continue to be a challenge. But the benefits to defining and aligning goals and measurement across teams are huge: you can see what’s working, what needs to be reevaluated and where your biggest opportunities lie. For the companies that are able to get it right, and stick to it, content can do even more to drive success as strategies and channels evolve."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:777267e8-f439-4d4d-af15-658090fca5e9>"],"error":null}
{"question":"Were Jimmy Reed and Heavy D alive at the same time?","answer":"No, Jimmy Reed and Heavy D were not alive at the same time. Jimmy Reed passed away on August 29, 1976 at age 50, while Heavy D was born later and passed away on November 8, 2011 at age 44 due to a pulmonary embolism caused by deep leg vein thrombosis.","context":["November 8: This Day in Black History\nFEATURED: Heavy D\n1898: In 2 days of racial violence, a mob of whites, led by some of Wilmington’s most respected and influential citizens, destroyed the state’s only daily African American newspaper.\n1920: Ester Rolle was born. She was an Emmy Award winning actress, singer, and dancer. She passed in 1998, aged 78.\n1932: The Spingarn Medal was awarded to Robert R. Moton, president of Tuskegee Institute, for his “thoughtful leadership in conservative opinion and action.”\n1938: Crystal Bird Fauset became the 1st black woman legislator of Philadelphia elected to PA legislature.\n1947: Singer, Songwriter Minnie Riperton was born. She died of breast cancer in 1979, aged 31.\n1952: B.B. King and his legendary guitar, Lucille, had their second #1 R&B in a row with “Darling, You Know I Love You,” also his second chart single.\n1952: Happy Birthday to Alfre Woodard who turns 61 today. She is an actress, producer and the recipient of numerous awards.\n1966: John H. Johnson, publisher of Ebony and Jet magazines, awarded Spingarn Medal “for his productive imagination…in the perilous field of publishing” and “for his contributions to the enhancement of the Negro’s self-image through his publications.”\n1966: Edward Brooke became the 1st African American U.S. senator since reconstruction.\n1966: Jazz trumpeter Harold ‘Shorty’ Baker passed away at age 52.\n1969: The Supremes’ swan song as an entity including Diana Ross, “Someday, We’ll Be Together” was the last of the group’s twelve #1s.\n1970: The Four Tops performed on The Ed Sullivan Show on CBS-TV.\n1970: Diana King turns 43 today. She is a Reggae fusion singer & songwriter.\n1974: Ivory Joe Hunter passed away, aged 60. He was an R&B, blues, country singer, songwriter & pianist.\n1991: Barry White was a guest on The Arsenio Hall Show.\n1975: ‘Low Rider’ by War was the #1 song this day.\n1978: Rapper Jamal Barrow aka Shyne turns 35 today.\n1984: Singer, songwriter and Broadway actress Tasha Thomas died of cancer at age 33.\n1988: The 1st African American Dr. Lenora Fulani officially qualified to run for President of the United States.\n1997: The O’Jays’ “Baby You Know” charted.\n1999: Songwriter & composer Gwen Gordy Fuqua, who had convinced her family to stake brother Berry Gordy Jr. the $800 he needed to start Motown Records, passed away. She was 71.\n1999: Lester Bowie passed away, aged 58. He was a jazz trumpeter, composer &co-founder of the Art Ensemble of Chicago.\n2006: Massachusetts elected the 1st black person (Deval Patrick) to win the state’s highest office in its 218-year history.\n2006: America elected the nation’s 1st Muslim member of Congress, Keith Ellison.\n2008: Cleve Duncan passed away, aged 78. He was the lead singer for the Penguins whose tenor voice helped to propel the 1954 doo-wop ballad “Earth Angel (Will You Be Mine)” to rock ’n’ roll immortality.\n2008: Virgil Starks died of a heart attack, aged 46. He was Auburn University’s associate athletic director and played a big role in helping Auburn student athletes to get their degrees and cared for Auburn athletes as if they were his own children.\n2010: Quintin Dailey, aged 49, died of hypertensive cardiovascular disease. He was a former All-American basketball player who also played 10 seasons in the NBA and made the 1982-83 All-Rookie teams.\n2011: Heavy D (Dwight Arrington Myers) passed away at age 44. He was the self-proclaimed “overweight lover” of hip-hop who became one of rap’s top hit-makers with wit, humor, and a positive vibe. His death was due to a pulmonary embolism caused by deep leg vein thrombosis.\n2011: Jimmy Norman passed away, aged 74. He was a rhythm-and-blues singer and songwriter who worked with Bob Marley and Jimi Hendrix early in their careers.\n2012: Lt. Col. Herbert Eugene Carter passed away, aged 95. He was one of the original Tuskegee Airmen who broke color barriers in World War II as the 1st black aviators in the US military.","|Birth name||Mathis James Reed|\n|Born||September 6 1925\n|Died||August 29 1976 (aged 50)\n|Instrument(s)||Vocals, Harmonica, Guitar|\nMathis James \"Jimmy\" Reed (September 6, 1925 – August 2, 1976) was an American blues singer, guitarist, and harmonica player. He was the best-selling Chicago blues artist of the later 1950s and early 1960s, with classic blues hits such as \"Big Boss Man,\" \"Bright Lights, Big City,\" \"Baby What You Want Me To Do,\" and \"Aint That Lovin' You Baby.\"\nReed was a major player in the early days of electric blues, whose unpretentious style proved highly popular with R&B fans. His lazy, slack-jawed singing, piercing harmonica, and hypnotic guitar patterns were one of the blues' most easily identifiable sounds in the 1950s and ‘60s. He also had a major influence on rock and roll players, most notably the Rolling Stones, among many others.\nDespite outselling his Chicago contemporaries during his heyday, Reed's battles with alcoholism led to his early decline and caused him to be unable to take advantage of the blues revival of the late 1960s and early ‘70s to resurrect his career. He died in 1976 at the age of 50. He was inducted into the Rock and Roll Hall of Fame in 1991.\nReed was born on a plantation near Dunleith, Mississippi in 1925, where he lived until the age of 15. He learned the basics of harmonica and guitar from local semi-professional player Eddie Taylor, who became a close friend.\nAfter spending several years performing in clubs and playing for tips in the area, Reed moved to Chicago, Illinois in 1943 before being drafted into the United States Navy during World War II. In 1945, he was discharged and moved briefly back to Mississippi, marrying his girlfriend, Mary Reed, before moving to Gary, Indiana to work at an Armour & Co. meat packing plant.\nReed soon began to break into the growing blues scene in Gary and nearby Chicago. By the early 1950s, he had established himself as a popular musician known for his ability to play guitar and harmonica simultaneously by using a neck-brace harmonica-holder. He joined the \"Gary Kings,\" playing harmonica and guitar with John Brim, with whom he also recorded. However, when Reed attempted to gain a recording contract with Chess Records, the premier record company for Chicago-based blues artists, he was rebuffed. With the help of Brim's drummer and future guitar legend Albert King, he then signed with Vee-Jay Records. At Vee-Jay, Reed began playing again with his old mentor, Eddie Taylor. His third single, \"You Don't Have to Go,\" was his first hit record, reaching number three on the Billboard R&B chart in 1956.\nA string of blues hits soon followed. Reed's simple, straightforward style was easy for fans to relate to and was also highly danceable. He was soon outselling even the great Chess blues stars like Muddy Waters, Howlin' Wolf, and Little Walter. In New York, he not only played Harlem's famous Apollo Theater but also performed across town in the prestigious Carnegie Hall, although his Live at Carnegie Hall album (1961) was actually a studio reproduction of his performance there.\nLike some other successful bluesmen, Reed suffered from alcoholism. However, unlike some of them, did not hold is liquor well. He became notorious for being drunk on stage, slurring and forgetting his words, and losing the beat. His wife often had to help him remember the lyrics to his songs and stay on beat while performing. Reed's bouts with delirium tremens were so common that when he was stricken with epilepsy in 1957, the disease went undiagnosed for months.\nDespite these problems, reed continued to succeed as a recording artist. He reached his peak in 1961 with the classic \"Big Boss Man,\" followed by \"Bright Lights, Big City,\" which reached number three on the R & B charts.\nAlthough he had more hit songs than many of his peers, Reed's personal problems prevented him from achieving the same level of respect and long-term fame as other popular blues artists of the time. When Vee-Jay Records temporarily ceased operations in the second half of 1963, Reed's manager signed a contract with the fledgling ABC-Bluesway label, but Reed was never able to score another hit. He made a minor comeback as a performer in the days of the blues revival of the late 1960s and early ‘70s, but continued to prove unable to rise above his problems with alcohol, often proving a disappointment to his new live audiences.\nReed lived a reclusive life in his final years before finally getting proper medical treatment and attempting a comeback, playing at the blues festivals that had achieved popularity in the mid-70s. He died in Oakland, California on August 29, 1976, a few days short of his 51st birthday. He is interred in the Lincoln Cemetery in Worth, Illinois.\nAlthough not the most skillful, passionate, or powerful of the Chicago bluesmen, Reed is arguably one of the most influential. In addition to his numerous R & B hits, Reed produced 11 records that made the Billboard Hot 100 pop chart, a figure unmatched even by the most successful bluesman of all time, B.B. King.\nReed's simple style was easily imitated, and he became a major influence on other performers from Chuck Berry to Elvis Presley, Hank Williams, Jr., and the Rolling Stones. His guitar style found its way into numerous rock and roll songs, while his harmonica riffs were often copied by players like the Rolling Stones' Mick Jagger.\nIndeed, The Rolling Stones have cited Reed as a major influence on their sound, and their early set lists comprised many of Reed's songs. In their early years Stones recorded Reed songs like \"Ain't That Lovin' You Baby,\" \"The Sun is Shining,,\" \"Close Together,\" \"Bright Lights, Big City,\" and \"Shame, Shame, Shame\" as demos to offer to record labels. Their February 1964 hit single \"Not Fade Away\" was backed by \"Little by Little,\" an obvious remake of Reed's \"Shame, Shame, Shame.\" Their first album, The Rolling Stones, released in April 1964, featured their cover of Reed's \"Honest I Do.\"\nElvis Presley also covered several of Reed's songs, scoring a 1967 hit with \"Big Boss Man\" and performing \"Baby, What You Want Me to Do\" for his 1968 Comeback TV Special. \"Big Boss Man\" was performed regularly by Grateful Dead, sung by the band's Ron \"Pigpen\" McKernan, from their inception in the mid-1960s through the early 1970s. The song appears on the live album known as Skull and Roses.\nFew blues bands omit Jimmy Reed songs from their set lists. In 2007, Austin Texas-based bluesmen Omar Kent Dykes and Jimmie Vaughan released a tribute album to Reed entitled On the Jimmy Reed Highway featuring guest performances by Kim Wilson, Delbert McClinton, James Cotton, Lou Ann Barton, and Gary Clark Junior.\nIn 1991 Reed was posthumously inducted into the Rock and Roll Hall of Fame. He became a member of the Blues Hall of Fame in 1980. His recordings of \"Big Boss Man\" and \"Bright Lights, Big City\" were both voted onto the list of The Rock and Roll Hall of Fame's 500 Songs that Shaped Rock and Roll.\n|Year||Single||R&B Singles||U.S. Pop Singles|\n|1956||\"Ain't That Lovin' You Baby\"||#3||-|\n|1956||\"Can't Stand to See You Go\"||#10||-|\n|1956||\"I Don't Go for That\"||#12||-|\n|1956||\"I Love You Baby\"||#13||-|\n|1957||\"Honest I Do\"||#4||#32|\n|1957||\"Honey, Where You Going?\"||#10||-|\n|1957||\"The Sun is Shining\"||#12||#65|\n|1958||\"Down in Virginia\"||-||#93|\n|1959||\"I Told You Baby\"||#19||-|\n|1960||\"Baby, What You Want Me to Do\"||#10||#37|\n|1961||\"Big Boss Man\"||#13||#78|\n|1961||\"Bright Lights, Big City\"||#3||#58|\n|1962||\"Aw Shucks, Hush Your Mouth\"||-||#93|\n|1963||\"Shame, Shame, Shame\"||-||#52|\n|1958||I'm Jimmy Reed|\n|1959||Rockin' With Reed (Collectables)|\n|1961||Jimmy Reed at Carnegie Hall|\n|1962||Just Jimmy Reed|\n|1963||Jimmy Reed Plays 12 String Guitar Blues|\n|1963||Jimmy Reed Sings The Best Of The Blues|\n|1963||T'Ain't No Big Thing But He Is...Jimmy Reed|\n|1964||Jimmy Reed At Soul City|\n|1965||The Legend: The Man|\n|1967||The New Jimmy Reed Album/Soulin'|\n|1968||Big Boss Man/Down In Virginia|\n|1974||Best Of Jimmy Reed|\n|1976||Blues Is My Business|\nAll Links Retrieved February 5, 2009.\nNew World Encyclopedia writers and editors rewrote and completed the Wikipedia article in accordance with New World Encyclopedia standards. This article abides by terms of the Creative Commons CC-by-sa 3.0 License (CC-by-sa), which may be used and disseminated with proper attribution. Credit is due under the terms of this license that can reference both the New World Encyclopedia contributors and the selfless volunteer contributors of the Wikimedia Foundation. To cite this article click here for a list of acceptable citing formats.The history of earlier contributions by wikipedians is accessible to researchers here:\nNote: Some restrictions may apply to use of individual images which are separately licensed."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:920b51fb-bffa-4c4d-9c2e-d317195edd56>","<urn:uuid:d9144aaa-c03d-4b51-8254-2231c8848c1c>"],"error":null}
{"question":"How to ensure effective food safety training in the food industry?","answer":"Effective food safety training can be achieved through e-learning, which offers several key advantages: 1) It provides accessibility through mobile devices and multiple languages, allowing employees to access training at their convenience. 2) It enables quick updates of rules and regulations, with better completion rates through short microlearning modules. 3) It promotes higher retention through interactive content and scenario-based learning. 4) It allows better tracking and reporting of training completion through LMS. 5) It facilitates recurrent training and performance support, making it easy to schedule refresher courses and provide point-of-need access to training materials.","context":["Food safety has assumed significance in recent times. Businesses involved with food such as food processing units, manufacturers of food products, hotels, or even a thriving restaurant business have to pay attention to food safety. Food safety involves a set of practices, procedures and processes that need to be followed to ensure safety and hygiene. These steps are crucial at every step from production, procurement, and storage to preparation and presentation.\nFood safety is a complex process and if it has to be followed meticulously, employees have to be trained in the right way so that there are no lapses. Failing to follow food safety procedures can lead to serious consequences for organizations and their reputation. Food safety training is necessary to avoid such repercussions.\nFood safety training can be provided in the classroom for employees; however, it might not be a one-time event because updates have to be provided for which subsequent training sessions have to be organized. Classroom training can work for small restaurants and hotel chains where employees are at one place but what about large hotel chains or food manufactures whose employees are at diverse locations? Holding training sessions every time new employees join or getting employees together whenever there is an update might be impractical.\nThe food industry is fast-paced, and employees need to be highly skilled and well-trained to keep pace with the changes. Classroom training might be impractical and expensive in such circumstances. E-learning is a better alternative. The advantages offered by e-learning are compelling many companies in the industry to adopt this mode of training. Let us explore the reasons for this.\n1. Provides Accessibility\nEmployees in the food industry usually work in shifts and e-learning provides the convenience of accessing safety training any time they want, as per their convenience. This is useful for employees at companies having operations at diverse locations. Moreover e-learning modules can now be accessed through mobile devices and can be made available in multiple languages to cater to a wide variety of learning needs. The courses being self-paced can cater to various skill levels of learners from sanitation workers to food safety inspectors.\n2. Ensures Quick Updates and Better Completion Rates\nAny changes in rules and regulations or updates that employees need to know can be quickly updated in e-learning courses and delivered to employees. Emergency refresher training is easy and can be deployed when required.\nCompletion rates are better when they are delivered as short, microlearning modules because these short and crisp courses can be completed at the learner’s convenience unlike classroom sessions which can be long and tedious.\n3. Promotes Higher Retention\nE-learning results in higher retention of knowledge. The courses are engaging and interactive and require learner participation. Food safety training becomes effective if there are elements that invite their active participation.\nTraining is more effective when learners are not just given the information about a process but are given demonstrations on how to do it. Learners should be given activities that enable virtual practice so that they can apply what they have learned. For this, the best option would be scenario-based learning.\nScenario-based learning helps the learner to examine and explore a particular situation and make choices on the actions to be taken or precautions to be followed. It also allows the learner to make mistakes without any real-world consequences and learn from them. Tools such as Articulate Storyline make it easy to create scenarios for such course. View a sample module we created for a course on food safety.\n4. Helps in Better Tracking and Reporting\nThe food industry is heavily regulated, and organizations need to regularly submit proof of training and certification of their staff on food safety regulations. When you host your course on an LMS, you have better chances of tracking who has taken the course, those who need a refresher course, or employees who need training from scratch. This will help you plan your training schedule. The LMS will help you create reports which will show how many employees have completed the training.\n5. Facilitates Recurrent Training and Performance Support\nFood safety training is a continuous process; it is not a one-time issue. Changes in production processes or the introduction of new products or upgraded storage facilities may call for new training programs or refresher courses. In some countries, laws require that food safety training be repeated every few years. E-learning makes it easy to schedule such training based on employees’ convenience as well as rollout updates in short time. Performance support in the form of mobile learning modules that can be accessed by employees at the point of need is possible with online learning.\nFood safety is a crucial issue in the food industry and e-learning provides the best options to ensure your employees are well-trained and updated on latest requirements while your business stays compliant."],"question_categories":[{"categorization_name":"answer_type","category_name":"procedural"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"format_constrained"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:c8f1c768-6901-41bc-93e7-94c8162d27e5>"],"error":null}
{"question":"How do the EU's competition law exemptions compare to the Māori Trade and Cooperation chapter's special provisions?","answer":"The EU's competition law exemptions under Article 101(3) allow restrictions that have beneficial effects on production, distribution, or technical progress, provided they benefit consumers and don't eliminate competition. In contrast, the Māori Trade and Cooperation chapter provides special provisions that acknowledge Te Tiriti as a constitutional document and includes specific protections for Māori interests, such as defining and protecting 'mānuka' as a Māori word, and establishing cooperation areas to enhance Māori enterprise opportunities. While both systems provide exceptions to general rules, the EU focuses on economic benefits while the Māori provisions emphasize cultural protection and economic development for Indigenous peoples.","context":["Treaty of Waitangi\nAs in all of New Zealand’s free trade agreements since 2001, the NZ-EU FTA contains a clause that preserves the unique status of Te Tiriti o Waitangi (Treaty of Waitangi), ensuring the Government’s ability to meet its obligations to Māori. The Te Tiriti o Waitangi exception protects the New Zealand government’s ability to adopt policies it considers necessary to fulfil its obligations to Māori.\nMāori Trade and Cooperation – a new modality for New Zealand-EU engagement\nNew Zealand and the European Union have agreed a “Māori Trade and Cooperation” chapter in the FTA that will provide a valuable new platform to advance Māori economic aspirations in the EU.\nThe chapter acknowledges Te Tiriti/The Treaty as a foundational document of constitutional importance to Aotearoa New Zealand, and references Māori concepts including Te Ao Māori, Mātauranga Māori, Tikanga Māori, Kaupapa Māori, Tāonga and Wāhine Māori to achieve wellbeing.\nIt provides a definition for ‘mānuka’ as the Māori word used exclusively for the Leptospermum scoparium tree grown in Aotearoa New Zealand and derivative products such as honey and oil. It describes ‘mānuka’ as culturally important to Māori as a tāonga and traditional medicine.\nThe cooperation areas in the chapter include collaborating to enhance the ability for Māori enterprises to benefit from the Agreement’s trade and investment opportunities, strengthen links between EU and Māori enterprises (with a particular emphasis on SMEs), supporting science, research and innovation links, and cooperating on geographical indications.\nMāori exporters and businesses\nProtecting and promoting Māori interests in this FTA is a priority for New Zealand, reflecting New Zealand’s Trade for All agenda and commitments under Te Tiriti o Waitangi.\nThe FTA includes outcomes in each of these areas:\n- Trade in goods – There are significant outcomes in this FTA for Māori exporters in a range of sectors including kiwifruit and other horticultural products, meat, dairy, fish and seafood, wine and honey. Ninety-seven percent of New Zealand’s current goods trade will enter the EU tariff-free under the FTA, with ninety-one percent from day one (including kiwifruit, apples, wine, fish and seafood products, forestry products and Mānuka honey). New Zealand has increased beef, butter, cheese and milk powder quota access into the EU.\n- Digital, services and investment – The FTA includes new cross-cutting language that is aligned with the Te Tiriti o Waitangi exception, which makes it clear that New Zealand has reserved the right to adopt or maintain measures to protect Māori rights, interests and duties, and responsibilities.\n- Intellectual property – The FTA’s outcome on geographical indications provides an opportunity for Māori food and beverage producers to develop and leverage their own GIs for quality New Zealand products for export to the EU.\n- Sustainable food systems – The sustainable food systems chapter includes cooperation on “Indigenous knowledge, participation, and leadership in food systems”. This reflects the value that Aotearoa New Zealand places on traditional knowledge and approaches, and the vital role that Indigenous peoples can play in achieving sustainable food systems globally.\n- Trade and sustainable development – this chapter includes strong new commitments on climate action, including the Paris Agreement, and on labour rights and gender equality including making these commitments legally binding and enforceable in the FTA. The FTA has disciplines on fisheries subsidies and commitments to work together on fossil fuel subsidy reform, the most ambitious FTA outcome in these areas by the European Union. There’s strong commitments on trade and gender, including a specific cooperative focus on wahine Māori.\nEngagement with Māori\nThroughout the FTA negotiations, officials engaged with Māori to ensure that interests and priorities were understood and advocated for in the FTA negotiations. This included regular engagement with Te Taumata, Ngā Toki Whakaruruanga, National Iwi Chairs Forum and the Federation of Māori Authorities, as well as a range of broad public engagements, updates and opportunities for comment.\nThis improved engagement lead to new practices such as sharing and engaging on live negotiating texts.\nWe will continue to engage with Māori groups throughout the implementation process to ensure that Māori interests are promoted and protected.\nThe FTA includes new mechanisms for public consultation and engagement on matters related to the implementation of the agreement, including the creation of a Domestic Advisory Group and a Civil Society Forum. Both of these mechanisms provide specifically for Māori representation.\nReport on Māori interests in the EU\nIn 2019, the Ministry of Foreign Affairs and Trade together with Te Puni Kōkiri commissioned BERL to put together a report on Māori interests in the NZ-EU FTA in order to better understand the priorities and challenges for Māori exporters in accessing the EU market.\nThe report highlighted the value of the EU market to Maori businesses but noted the need for greater support to help SMEs. Māori interest in intellectual property protections and treatment for taonga works, taonga species, and matauranga Māori also featured prominently.\nGet in contact\nIf you have any questions about upcoming Māori consultation or Māori interests in relation to New Zealand trade policy, you can contact us at firstname.lastname@example.org.","Homewood: EU Law Concentrate 5e\n'Because of its wide scope, Article 101(1) TFEU is an effective tool for the achievement of the fundamental aims of EU competition law. At the same time, the exemption provisions in Article 101(3) allow sufficient room for restrictions which, on balance, have beneficial effects.'\nCritically assess the accuracy of this statement, with reference to relevant cases.\nIntroduction: context and aims of EU competition law\nThe internal market concept – including the free movement of goods and services.\n- The free movement of goods rules target actions by Member States – the competition rules target business behaviour.\n- Anti-competitive business behaviour has other harmful consequences – harm to consumers, to small- and medium-sized businesses, and to business efficiency.\n- Articles 101 and 102 TFEU prohibit restrictive business practices because of these harmful effects.\n- Article 101 concerns restrictive arrangements between businesses.\nWide scope of Article 101(1): a tool to achieve the fundamental aims of EU competition law\n- Article 101(1) is wide as to the kinds of arrangements covered – agreements between undertakings, decisions by associations of undertakings, and concerted practices. Discuss the scope of each, with authorities (ie case law).\n- Article 101 is wide in scope as to object or effect. Either is sufficient (STM). Note a deemed object: market sharing and price fixing.\n- Also wide as to scope of 'restriction, prevention, distortion', including an increase in trade (Consten).\n- Covers both horizontal and vertical agreements (Consten).\n- An 'effect on trade between Member States' is interpreted broadly to include direct or indirect, actual or potential effect (STM, Commission notice: guidelines on the effect on trade concept contained in Articles 81 and 82 of the Treaty, 2004) – can include agreements between undertakings operating solely within one Member State (Vacuum Interrupters) – agreements are considered in their market context, so may be caught even if, considered in isolation, they would not affect trade between Member States (Brasserie de Haecht).\n- Butde minimis agreements outside scope – an appreciable effect on competition required (Volk, Commission notice on agreements of minor importance, 2014) – so wide scope is not unlimited. Note matter of anticompetitive objective under the new notice.\n- List of restrictions in Article 101 (1)(a)–(e) is non-exhaustive, leaving it open to Commission/Court of Justice to make decisions on case-by-case basis, having regard to the underlying aims of competition policy.\n- The Court of Justice may balance the anti- and pro-competitive effects of an agreement (Pronuptia, Metro), but a rule of reason not expressly recognized and has been denied by the Court of First Instance (now called the General Court) (Métropole Television).\n- Article 101(2) provides that restrictive agreements are 'automatically void' but the Court of Justice has introduced the possibility of severance (STM, Consten).\n- Achieving competition law aims, for example: internal market – no absolute territorial protection (Consten); harm to consumers and to business efficiency – no price-fixing (ICI, Henessy/Henkell); harm to small- and medium-sized undertakings – no disproportionate non-compete clauses (Henessy/Henkell).\nExemption provisions in Article 101(3): sufficient room for restrictions which, on balance, have beneficial effects?\n- Context – restrictions falling within Article 101(1) that are nevertheless permitted because of the overall beneficial effects of an agreement – distribution, production, technical and economic progress, provided proportionality, and no substantial elimination of competition.\n- Application of Article 101(3) conditions both to individual agreements and categories of agreements – individual and block exemption.\n- Article 101(3) conditions require a balancing of pro- and anti-competitive effects.\n- Individual exemption, for example: improving the production or distribution of goods or to promoting technical or economic progress (ACEC/Berliet, Prym-Werke).\n- Provided they allow consumers a fair share of the resulting benefit, there are no unnecessary restrictions (CECED) and no elimination of competition (CECED, ACEC/Berliet).\n- The block exemptions, for instance Regulation 330/2010 on vertical restraints, cover categories of agreement that are regarded as normally satisfying the Article 101(3) conditions, thus having overall beneficial effects.\nEU competition law aims to root out business practices that threaten market integration, reduce efficiency, and harm consumers. Article 101(1) is interpreted broadly, to catch all arrangements between businesses with these harmful effects. At the same time, the framework of Article 101, specifically the provisions in Article 101(3), provides for the assessment of the pro- and anti-competitive effects of agreements and allows exemption for agreements which, despite being restrictive, have overall beneficial effects. In order to further ensure the achievement of EU aims, exemption only applies where consumers derive a benefit, where restrictions are proportionate, and where there is no substantial elimination of competition."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:fdad324a-88f4-4a82-9e36-05122d8230f9>","<urn:uuid:9e7c35fc-bb95-4d35-9523-b6ff100418be>"],"error":null}
{"question":"What types of event spaces for hosting are available at Mosaic Stadium compared to the documentation formats recommended for describing art installations?","answer":"While art installation documentation is recommended to follow a structured format with sections like Introduction, Context, Concept, Technical Issues, and Conclusion, Mosaic Stadium offers various structured hosting spaces each with distinct specifications. The stadium features premium spaces including the two-level AGT Lounge (with capacities of 89 and 251 people), Harvard's Studio 620 Lounge (capacity 192-500), and Capital Auto Suites (with sizes of 3,390 and 4,305 sq ft). Each space requires specific documentation of its features and capabilities, similar to how art installation documentation must detail both conceptual and technical aspects of the work. Both systems emphasize clear organization of information, whether it's describing an art piece's context and choices or detailing a venue's specifications and amenities.","context":["Documenting your Art Installation\nMaarten Lamers | Media Technology MSc program | Leiden University\nThis workshop is offered as part of the Media Technology MSc and ArtScience programs. It deals with the question of how art installations (in the broadest sense of the word) can be documented in a structured manner. Such documentation can serve to promote the resulting work, explain it, get financing, or to describe the process by which it came about for a broader audience.\nThe method of documenting one's work that we discuss uses many elements from scientific writing. Central in this are:\n- a compact structured description\n- logically explaining the choices you made that resulted in the final work,\n- describing the context of your work: how does it relate to work by others, to your own works, to existing knowledge, and what is its place in time?\nThe page that you are reading now is in support of the workshop. Part of the workshop is spent on documenting the works that students created. The results of this exercise are discussed within the group and feedback is given. This should kickstart the possible describing of these works for future use.\nWho am I?\nMaarten Lamers of the Media Technology MSc program at Leiden University. Follow these links if you want to know more.\nWhat can you document?\nWhat works did you create?\nWhy document your work?\n- Who of you have described their art installations in writing? How?\n- With the web it seems more common. See for example the Information Aesthetics website.\n- There seems to be very little history or conformity in describing art installations.\n- Why would you want to describe your work?\nScientists have been writing down the results of their thinking and research for ages, in a highly structured and focussed way. In fact, writing is usually the only output of scientific labour. The method that I propose for documenting your work uses elements from academic writing:\n\"But my art speaks for itself!\"\n- It is intended for a critical and informed audience, people who understand what you are talking about. In the case of art installations, such people may be fellow artists, exhibition curators or knowledgeable viewers.\n- It places the work in its proper context, demonstrating its relevance within current and past ideas, happenings, trends, and theories.\n- It explains your choices in a rational manner.\n- It gives others the possibility to react to your work.\nThat's very true (I hope). However, reading your writing may be very different from experiencing your work. Reading about an artwork may enhance its experiencing or even kill it. But here's the thing: your writing is usually meant for another audience (curators and fellow artists, for example), and to add to the experiencing of the work itself. It is intended for people who want to go beyond experiencing your work.\nDescribe the context\nThe context of your work is what gives it meaning. It is the collection of knowledge, other works, human behaviour, current events, your own experiences, trends, whatever, that your work relates to.\nDescribe your choices\n- By making this context explicit, you establish the meaning of your work, and its relevance.\n- For artworks especially, the context includes works by other people that can somehow be compared to your own work, and its place within \"history\" or current trends. This doesn't imply that the other works must be similar to yours. It just means that they are interesting to compare.\n- If you use certain theoretical foundations, for example about how people react to color, then this is also context.\nWhat about technical stuff?\n- To get from the context of your work to the concept that it expresses, you had to make a series of choices. Making these choices was the most important thing you did! Think about what these choices were, and motivate how you made them.\n- Why you did not do certain things may be equally important to motivate.\n- Make a difference between conceptual choices (why do you express something in color and not in sound? why did you choose a certain user interaction? what should it trigger in the viewer? why did you use a specific medium?) and implementation choices (why do you use MIDI instead of RS232, Mac or PC, Processing or Max/MSP?).\nRule-of-thumb: everything that happens \"underwater\" and is not part of the viewer's experience is technical.\nReflect on your own work\n- Before you start writing down al the technical details, think about how important they are to mention!\n- Usually, it's enough to just mention them briefly. But this really depends on who your intended audience is.\n- Rule-of-thumb: mention just enough technical details to satisfy immediate curiosity. If you want to go into technical details fully, consider doing this in another document, a \"Design Document\" for example, or a \"Technical Report\".\nIt is wise (and good practice) to include a short reflection on your own work at the end of your documentation. Perhaps you can draw some conclusions from your work or mention area's of improvement. Certainly when it comes to possible improvements, it is better to mention them yourself than to have someone else point them out to you afterwards.\nStart your document with an appealing title. If you named your product or installation, you can include that name. However, most often it is wise to give your documentation a more descriptive title, so that people can decide from the title if they want to read it. And don't forget to mention your name(s). Some examples:\nReally useful: an abstract\n- If your artwork is called \"Life24\", then a title for its documentation might sound like \"Life24: An Affective Visualization of Global Events\".\n- For an installation such as the Digital Pin Display, you could consider the title \"Digital Pin Display: Greyscale versus Physical Depth\".\n- If your product is named \"Furby\", then your documentation may be titled \"On the Boundary Between Pets and Robots: Furby\".\nAn abstract is a short summary of your document (approx 100-150 words). Every scientific article starts with one, and they are a good thing to have.\n- A good abstract is very useful for the reader, but also for communicating your work. It can be used for exhibition invitations, for example.\n- It's always better that you write a good summary of your work than have someone do it who does not really understand what your work is about.\nWhere to start?\n- The Khronos Projector by Alvaro Cassinelli. A very complete description of the project. Good title: it captures your interest. Good division between conceptual and technical choices. Has \"Experiments\" and \"Conclusion and Remarks\" sections. Very complete project documentation.\n- String Thing by Ben Dove. A fairly good project description. Nicely structured. Somewhat short text for the important parts, and a very oversized process description.\n- Flight Patterns by Aaron Koblin. An example of a nice project, but minimal description of his work. In terms of describing your work, this is not what I mean...\n- Vizster by Jeffrey Heer and Danah Boyd. Their 'research paper' contains a very scientific explanation of the project. But see how they separated the truly technical information in another document, what they call the 'early design document'.\n- Have-a-Seat by Media Technology students Michiel Stade, Sylvain Vriens and Mika Igarashi. The draft paper that goes with the sofa describes the context of this work very extensively. Note how only Section 5 (one page!) discusses the work itself.\n- A Tactile Closed-Loop Device for Musical Interaction by Media Technology student Staas de Jong. Excellent length (only 2 pages). The context is described rather shortly in the \"Introduction\" section (too shortly, I think). Note how he reflects on his own work in the \"Conclusion and Future Work\" section. By describing his project in this way, it was accepted for presentation at the International Conference on New Interfaces for Musical Expression, 2006 in Paris.\n- Globe4D, time-traveling with an interactive four-dimensional globe by Media Technology students Rick Companje, Nico van Dijk, Hanco Hogenbirk, and Danica Mast. In only 2 pages the paper gives a very good description of the project's aims and results. The \"Introduction\" section makes clear the context of this work. Note how the paper nicely separates the conceptual and technical choices into sections 2 and 3. Also a video was made to explain the project. The paper and video were presented at the famous ACM Multimedia Conference, 2006 in California and won the Best Video Presentation Award there.\nGetting started is the difficult part. Most importantly, try to keep it simple at first! If you know a good project description that you like, use it as an example. Here is a suggestion for the steps that you can take:\nThis is just a suggestion of how you can describe your work. Go ahead and rename the sections if you want, or split up your writing into more sections.\n- Think about the context of your work. How does it relate to other works? What theory does it use? Why is your work relevant at this time? Make a short list with some context issues. If necessary, find information about these issues on the web or elsewhere.\n- What are the most important (conceptual) design choices that you made? Make a short list of a few, and make sure that they are conceptual choices, not technical ones.\n- Make a structure for your document. Suggestion: 1. Introduction, 2. Context, 3. Your Concept (with design choices), 4. Technical Issues, 5. Conclusion and Remarks.\n- Start by writing the Context section. After that, describe your concept and design choices. Then the Technical Issues (keep it short!).\n- Shortly discuss your own work in the Conclusion and Remarks section.\n- If you then still need it, you can write a short Introduction section (sometimes this gets merged into the Context section).\n- Come up with a descriptive and catchy title.\n- Finally, write the abstract that shortly summarizes what you wrote.\nDescribe the work that you created for this course. Start with the structure that I proposed (1. Introduction, 2. Context, 3. Concept, 4. Technical, 5. Conclusion). Try to get as far as you can, and don't worry about the writing style. Present your writing before the group.","About Mosaic Stadium\nMosaic Stadium has a standard capacity of 33,000 and can be expandable to 40,000. The stadium delivers an incredible event experience with wider individual seats, a sunken bowl to ease spectator access, expansive concourses, and a wide range of concessions and hospitality offerings, including a general admission lounge and premium options that include 38 suites for corporate partners.\nMosaic Stadium, located at Evraz Place, is home of the Saskatchewan Roughriders Football Club.\nMosaic Stadium Visitor Guide\nEverything you need to know before attending an event at Mosaic Stadium!\nThe information provided applies to majority of events held at Mosaic Stadium. For event-specific information, please visit evrazplace.com or follow Evraz Place social channels for updates leading up to the event.\nHost your next event at Saskatchewan's iconic new stadium!\nMosaic Stadium is much more than a sporting facility. This new centerpiece of the Regina horizon offers several premium service lounges and suites for hosting corporate meetings, receptions, luncheons and galas. These modern spaces can accommodate a range of event types in a unique and comfortable setting.\nEnjoy premium, culinary services in stunning lounge and reception spaces that boast exceptional views of the CFL's premier football stadium.\nOur passion for delectable cuisine shines through in every culinary experience. Chef Jaimeet Kathuria prepares each menu item with pride using the freshest ingredients catered to your event needs. Whatever your guests' tastes may be, our team will deliver the experience you are looking for.\nWe know what it takes behind the scenes to host a flawless, unforgettable event. Our team's dedication and attention to detail ensure your event will leave a lasting impression on your guests. Let us help you bring your event vision to life at Mosaic Stadium.\nLocated on suite and club level, west side.\nEnjoy this two-level premium lounge with warm decor, views of the football field and access to an exterior balcony overlooking beautiful Confederation Park and its historic fountain. The lower level has quartz-topped tables, leather chairs and a Starbucks beverage station to please your most discerning guests. The upper level has modern, comfortable furniture, a cozy fireplace and a birds-eye view of the lounge below. The modern aurora borealis lighting feature adds to the atmosphere in this unique event space.\nAGT Lounge Upper Level\nSize: 3,831 sq. ft\nCapacity: 89 (reception style)\nAGT Lounge Lower Level\nSize: 7,728 sq. ft\nCapacity: 251 (reception style)\nHarvard's Studio 620 Lounge\nLocated on the main concourse level, west side.\nThis contemporary sports lounge setting is perfect for more casual events. True football fans will enjoy the decor that features benches from historic Mosaic Stadium at Taylor Field. Our team can also transform the lounge into a more a formal event space to meet your needs.\nSize: 10,739 sq. ft\nCapacity: 500 (Rider game days) 192 (reception style)\nLocated on the 300 and 400 levels.\nMosaic Stadium offers suites for smaller gatherings. With stunning views of the football field, these suites are perfect for more intimate events. These areas offer views of the football field, premium Starbucks coffee service stations and everything you need to make your event a success.\nCapacity: 20 - 100 (reception style)\nCapital Auto Suites\nLocated on the club level, east side.\nTwo Capital Auto Suites offer an intimate setting for your next event. Modern, upscale decor make this area the perfect setting for smaller gatherings and celebrations.\nUpper level size: 3,390 sq. ft\nLower level size: 4,305 sq. ft\nBook an Event at Mosaic Stadium\nTo book Mosaic Stadium for your next event, complete the request form below. A member of our team will be in touch to complete your request and discuss your event needs.\nMosaic Stadium Public Tours\nHave you ever wondered what Mosaic Stadium looks like behind the scenes? Or just how big the Maxtron really is? Join us to experience a behind-the-scenes peek at some of the inner workings of Mosaic Stadium while having some of your most burning questions answered.\n- Your excursion begins at the Rider Store and follows the main concourse to the Maxtron with highlights along the way.\n- We want you to get the most out of tour as possible so please bring a camera and your questions.\n- We keep the groups small so that you won’t miss any of the sights, facts or trivia that our guides share.\n- There is a nominal charge of $10.00 per person 12 years of age and older.\n- You can book your spot(s) online or through the Rider Ticket Office at 1-888-4-RIDERS (474-3377)\nField of Play Bookings\nFor rental information on the field of play for Mosaic Stadium, call the City of Regina Central Scheduling office at 306-777-PLAY (7529) or fill out a request form on the City of Regina website.\nFor any questions, please contact Evraz Place at 306-781-9200.\nDirections and Parking\nMosaic Stadium is located at Evraz Place in Regina, Saskatchewan.\nMosaic Stadium Accessibiltiy Features\nMosaic Stadium is a public, community facility, and it is important that all guests are able to visit the facility for any type of event and have a positive experience. Improving the accessibility of the stadium is an ongoing effort and ensuring it is inclusive for all guests is a top priority.\nAccessible Media Inc. (AMI) published a video in September 2017 to speak to the accessible features of Mosaic Stadium\nThe City of Regina and architect team worked closely with the following community groups to ensure the building process met the accessibility needs of the citizens of Regina:\n- Accessibility Advisory Committee\n- Office of Disability Issues for Saskatchewan\n- Saskatchewan Human Rights Commission\n- Saskatchewan Deaf and Hard of Hearing Services\n- The Big Sky Centre for Learning and Being Astonished Inc.\n- Paratransit, a convenient way of getting to the stadium is given priority access on game days and during major events\n- Guests with accessible needs are able to be dropped off right outside the stadium gates\n- Approximately 200 accessible parking spots are available close to the stadium (located west of Confederation Park and south of the Sportplex). Paid parking spaces was a recommendation from the community to guarantee a parking spot for those with accessible needs\n- There is free accessible parking along 10th Avenue, east of the stadium\n- Braille is available on all room signage\n- Each stadium level is identified with signage of a different bright colour, so a person that experiences visual impairment will know what level they are in based on the colour. The stadium team has started to implement signage with white logo/pictogram and dark background, giving the proper contrast for individuals that experience visual impairment.\n- The wide concourse makes it easier for guests to make their way around the stadium easier and more comfortably\n- Tactile wayfinding strips are in place at all main entrance gates and three elevator lobbies\n- Tactile panels are installed at all PED ramps\n- Twenty three accessible seating pods are located on every level with 271 accessible/ companion seats (157 and 114 respectively)\n- Power stations were included in the majority of the accessible seating pods to allow users to charge their chairs or other devices (e.g. breathing apparatus)\n- Guests with accessible needs can watch a game or event from anywhere in the stadium and have their family there with them\n- Each of the 38 suites and the AGT Lounge have dedicated accessible viewing spaces Guests with accessible needs have access to a variety of seating options\n- Historic Mosaic Stadium had limited seating options and guests were limited to a small number of friends and family members. The current Mosaic Stadium has an open-seating format with comfortable folding chairs available for use by friends and family members\n- 14 of the accessible seating pods are located on the main concourse level as you enter Mosaic Stadium, so guests do not have to go up the elevators, stairs or ramps to get to their seats\n- Accessible seating areas are gated so those in those areas can sit comfortably without getting congested by the crowd. This also allowed the front rail to be dropped 250 mm, or 10” to provide a clear view of the playing field\n- Accessible drink counter tops have been installed in all of the accessible pods following feedback from the community\n- Nine, voice-equipped elevators are located around the stadium\n- Nine large, universal-inclusive, accessible washrooms\n- One of the washrooms has an overhead lift for transfers and adult plinth for personal care needs\n- Only one other lift in Regina is available to the public (U of R)\n- The City of Regina consulted with Being Astonished on this design\n- All standard public washrooms (53 in total) have at least one accessible stall\n- Four guest services booths are conveniently located on the main concourse for guests to go to if they require additional assistance of any kind\n- 300 hearing assist devices using Listen Technologies Corporation are available from the guest services booths\n- The fire alarm system is equipped with strobe lights\n- All hallways and rooms have strobe lights attached to their alarm systems\n- All concession stands counters are set at standard accessible heights\n- Every door in the stadium has lever handle instead of door knobs\n- 40 power-assisted doors are in place throughout the stadium\n- Over 20 of the doors were added outside of code requirements"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"format_constrained"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:26588515-7ca1-47fd-9528-3f2d87678488>","<urn:uuid:ee2dac80-2c75-4e26-928d-3a36b5ce6c39>"],"error":null}
{"question":"What's the maximum output power and sensitivity of the nRF51422 radio frequency transceiver? 🤔","answer":"The nRF51422's software programmable output power ranges from -20dBm minimum to +4dBm maximum. Its sensitivity in Bluetooth low power mode is -92.5dB RX.","context":["Nordic Semiconductor nRF51422 It is a single chip solution supporting multi-protocol，Widely used to include PC periphery、Internet TV Remote Controller、motion/Bodybuilding/Health sensor、Toys and Automation Applications.\nOverview of performance\n1）Cortex-M0 kernel，Single instruction32Bit multiplier，Three-stage pipeline，On chip256KB FLASH，16KB RAM，NVM（classEEPROM），32 individual GPIO.\n2）Multi-protocol 2.4GHz Radio Frequency Transceiver. Support BLE,ANT、 Gazell™ And user-defined protocols。By setting registers, you can work with Nordic Existing nRF24L series IC Fully compatible in the air.\n3）Sensitivity in Bluetooth low power mode is-92.5dB RX.\n4）Software programmable output power,minimum-20dBm-，Maximum accessibility +4dBm Output power.\n5）When inLDO-1.8VPower supply mode，output+4dBmPower Time，Operating current is only16mA（MCU+RADIO），When inDC-DC3VPattern，output+4dBmPower Time，Operating current is only10.5mA. Low power consumption，It fits perfectly.3V Application of Button Battery Power Supply. See the comparison below.\n6)sleep mode2uAElectric current.\n7）Compliance with Bluetooth Low Power Consumption（Bluetooth 4.0 ）standard.\n8）field strength RSSI\n9）Maximum data rate 2Mbps\n10）64Bit Device ID. BLE Can be used for identification\n11）Powerful and low-power 32 position ARM Cortex-M0 processor，Start-up time is 2μs，and 8/16 Bit Processor Comparisons，Greatly reduced activity time and increased code density.\n12）Refinement of Power Supply Management，Individual system can switch independently，It can control clock autonomously based on activity level.\n13）Programmable peripheral interconnection (PPI) system. Through Event Task Mechanism，Peripheral devices such as radio frequency transceivers、Timer and 、ADC、I/OThe interaction between the processor and the other is completely free from the involvement of the processor.，Improving system efficiency greatly，More energy-saving.\n14)EfficientEasyDMARadio Frequency Transceiver Interface is Flexible RAM mapping FIFO.\n15)Highly flexibleGPIO mapping. Most of the figures IO Users can customize pin location. Simplification PCB Design，Help to reduce the number of layers of wiring.\n16）custom 2 Internal Storage Protection Device (MPU) Low power consumption for user programs and precompiled protocol stacks such as Bluetooth and Gazell™Runtime protection。 nRF51 Series software architecture has a unique and powerful partition between protocol stack and user application，Provide maximum flexibility for application developers、Developing Simplicity and Code Security.\n17）The stack is 100% Asynchronous and event-driven，And provide thread security management program calls to the application layer (SVC) Application Program Interface (API)，User-friendly understanding and Application.\n18）Simple programming model，No dedicated application framework or scheduler/RTOS Dependency，YesCLanguage foundations can be developed quickly.\n19）Protocol stack and application code have no link time dependency，It can be compiled and updated independently./programming；Stack Runtime Protected，Ensure interoperability and reduce the risk of application errors affecting the stack.\n20）nRF51 series IC Code and pin compatibility，Allow a basic code，Reuse in different projects. The benefits of pin compatibility are not only in development、Re-use of hardware design for different projects in prototyping and production processes，It can also be easily transferred to another sibling. IC.\n21）OriginalTASKwithEVENTconcept，Operating chip peripherals are very convenient and concise，You only need to configure a fairly small number of registers.，It's easy to use all kinds of peripherals.\n1)256kB Flash memory and 16kB RAM\n2)Digital and Mixed Signal Periphery，Include On-chip temperature sensor、RNG（Random Number Generator）、10-bit ADC Orthogonal decoder\n3)32 individual GPIO，Arbitrary pin has trigger interrupt function，16 individualPPIpassageway\n4)128-bit AES ECB/CCM/AARCoprocessor\n5)3individual 32Bit timing/ Counter 2 individua l24 position RTC，2The highest achievable 400Kbps OfTWI，2The most arrived8MbpsOfSPI，A maximum achievabl e1Mbps OfUART\n6)On chip LDO、DC-DC，Wide power supply range 1.8-3.6V\n7)On chip+/- 250 ppm 32kHZ RC oscillator，In Bluetooth Low Power Applications，No external need 32kHz crystal，Cost savings and board space savings，And32KHZClock source can be from16MHZSystem clock frequency division acquisition\n8)6x6mm 48 foot QFN ，WCSPencapsulation，Provide maximum accessibility 32 individual GPIO"],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"content_constrained"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:0df106b6-6b5c-42e1-90e2-4a8265ed4882>"],"error":null}
{"question":"I've noticed swelling in my horse's legs after being stalled overnight. What causes this condition, and what protective gear can help prevent it?","answer":"The swelling is likely 'stocking up,' which occurs when the body fails to pump fluid efficiently back to the heart due to gravitational forces and impaired lymphatic system. It's generally painless and tends to subside with normal activity like riding and turnout. To address this, standing wraps can help push the swelling out of the lower leg when the horse is stabled. These wraps consist of padding wrapped around the horse's legs using polo wraps and are beneficial for horses that tend to stock up while in a stall. When applying standing wraps, always use proper padding and ensure they stretch from the bottom of the knee or hock to below the fetlock.","context":["Q: My horse’s hind legs above his fetlocks swell up when he’s in a stall overnight. The swelling goes down when I turn him out or ride him. He doesn’t seem lame or sore. Should I do anything to treat the swelling?\nGINA TRANQUILLO, VMD\nA: This is a very common condition, especially in older sporthorses. Although it is likely benign, double-check that there is no heat or pain associated with your horse’s leg swelling. Slowly run your hands over the swollen areas to feel for heat and gently palpate the region to identify any tenderness. If he flinches in response to your touch or his skin feels warmer in these areas than elsewhere on his legs, he may be experiencing an acute inflammatory reaction to a tendon or ligament injury. Consult your veterinarian for a definitive diagnosis. Should he or she pinpoint a problem (most likely via ultrasound), the treatment may include stall rest.\nIf neither heat nor pain accompanies your horse’s swelling, he probably has a non-acute condition, such as windpuffs or stocking up. Windpuffs, also called windgalls, are residual inflammations from old tendon and ligament injuries. They usually occur on the back of the leg, at or just above ankle level, and are symmetrically shaped with the same amount of swelling on the medial side (inside) of the leg as the lateral side (outside). Windpuffs normally occur on both hind legs, although they occasionally appear on just one leg and sometimes can also be found in the front legs.\nPeople often discover windpuffs without having known about the past injury because it never caused obvious lameness. Many times the initial condition is subclinical (showing no obvious symptoms), so when the resultant chronic inflammation is noticed later in the horse’s life in the form of a windpuff, no one is able to put a finger on the exact time of injury or trauma.\nThe original source of a windpuff can be any previous damage done to a soft-tissue structure in the ankle area, such as the superficial digital flexor tendon, the deep digital flexor tendon, the suspensory ligament or the sesamoidean ligaments. A windpuff can also result from a compromised tendon sheath (the protective tissue surrounding the tendons). Even though the injury may have healed a long time ago, the lining of the tendon sheath may continue to produce excess synovial fluid, which leaks into nearby structures. Noticeable in both acute and chronic conditions, excess synovial fluid is what provides the visual appearance of the windpuff. This fluid is usually removed by the lymphatic system, which pumps the body’s waste products and unused nutrients back up to the heart. However, gravity is always working against the horse. Especially in inactive and/or older horses whose lymphatic systems may be impaired, fluids naturally tend to accumulate in the lower hind legs.\nThe same gravitational forces and general impairment of the lymphatic system lead to stocking up, which is also characterized by excess fluid accumulation. Unlike windpuffs, stocking up may not be caused originally by an old injury. It is simply the body’s failure to pump fluid efficiently back to the heart, similar to a pregnant woman’s tendency to retain fluid in her ankles. Stocking up can occur in both hind legs, both front legs or all four limbs. The swelling is more generalized around the entire circumference of the lower leg compared to windpuffs’ relatively localized swelling.\nBoth stocking up and windpuffs occur in horses of all disciplines. Although aesthetically unpleasing, they are generally painless and tend not to interfere with a horse’s soundness or athletic ability. Depending on their severity, they usually subside with normal activity—riding and turnout. People often first notice the swelling at shows because their horses are confined to stalls and deprived of the regular turnout they enjoy at home.\nThe best way to treat chronic windpuffs and stocking up is with daily activity. At home, include plenty of turnout and exercise in your horse’s routine. When you are at a horse show, hand-walk him frequently or ask the organizers if a roundpen or paddock might be available for rent. Supportive standing bandages can also help to push the swelling out of the lower leg when your horse is stabled. Be careful, however, not to wrap the bandage unevenly or too tightly, which can damage tendons. Always apply at least a 1-inch-thick layer of quilting underneath the wrap. If you are unsure of your bandaging skills, ask an experienced horseperson for guidance.\nIf the appearance of your horse’s legs continues to bother you, consider trying acupuncture on him. I have found that performing acupuncture on horses with this type of benign swelling successfully reduces the aesthetically unpleasing appearance while also improving the horse’s overall health. Acupuncture can help to remove stagnation (blockages) in the various meridians of the body and increase movement of fluid, energy and blood. Placing an acupuncture needle into an acupoint releases an array of hormones in the body, triggering cells to aid in repair and producing a small inflammatory reaction (which contributes to the healing process) and pain relief as well as improvement in lymphatics.\nWhen selecting an acupuncturist, be sure to use a vet who has been certified in acupuncture. Depending on the severity of the case and how long the condition has been going on, owners generally see improvement after just one treatment, although a horse may require maintenance treatments at different intervals, based on the individual.\nGina Tranquillo, VMD, grew up in Reading, Pennsylvania, showing Arabians. She then attended Wilson College, where she joined the intercollegiate hunt-seat team. After graduating from college, she worked as first a field reproductive assistant and then a technician for the Hagyard Equine Medical Institute in Lexington, Kentucky. She went on to complete her veterinary degree at the University of Pennsylvania before returning to Hagyard for her field-care internship. She joined Hagyard’s team as a field-care associate in 2011. Her current areas of interest include reproduction, field neonatology, preventive medicine, emergency services and sports medicine.\nRiding took a back seat in Dr. Tranquillo’s life as she pursued her veterinary career and started a family—she and her husband, Jason, are expecting their second child—although she still enjoys spending time with horses through her work.\nThis article originally appeared in the July 2015 issue of Practical Horseman.","Keeping Horse Legs Safe: Bandages, Boots, and Wraps\nBy Sarah Evers Conrad\nWhether a horse is being used for jumping, eventing, dressage, reining, cattle work, trail riding, riding lessons, camp programs, or just as a pleasure horse, one thing is certain – they work hard, and so do their legs. The legs of a horse are certainly amazing. They take on extreme amounts of stress, bear a lot of weight, can move quickly so that the horse can change directions on a dime or jump over an obstacle, and they are one of the most important parts of the horse. Protecting a horse’s legs is imperative in certain situations, especially if the horse is young and still growing.\nHorses that are faced with poor footing, uneven ground, a competition environment, transportation, or have a tendency to stock up (or have their legs swell) while in a stall, can benefit from leg wraps, boots, or bandages. It is important to know when and how to use each kind so that the horse’s legs are protected properly. Using leg wraps and boots incorrectly can cause problems for the horse and could accidentally put more strain on the horse’s legs and cause damage, such as inflammation of the flexor tendon and the flexor tendon sheath, which is sometimes known as the “bandage bow.”\nSkid Boots: Skid boots are for use on the hind legs during work, especially if a horse has a tendency to catch one leg with another leg or hoof. They are popular in western events, such as cutting, reining, and cattle work. Skid boots protect the lower legs, fetlock joint, and pasterns.\nBell Boots: Bell boots fit around and underneath the fetlock and Velcro in place. Some can even be pulled on, and these may be used if the ones with Velcro cause chafing or do not fit the horse well. Proper fit means that the rider can put two fingers between the bell boot and the pastern at the top opening, and they should cover the heel bulbs. Bell boots are used when a horse has a tendency of overstepping/overreaching, which could then cause him to catch the back of his front hoof or coronet and cut or bruise himself. In addition, the horse could pull off a shoe, along with part of the hoof. Horses that have studs on their shoes also benefit from the use of bell boots so that the studs do not injure the horse if he catches himself. Bell boots can also be used during turnout or shipping or when being ridden.\nTendon Boots: These boots have elastic straps across the front and hook closures while padding protects the tendons and ligaments on the sides and backs of the leg from a strike from the back hooves. They are popular among jumpers since the open front helps the horse feel a pole if he strikes it with his foreleg. In addition, the open design allows additional air flow. They are only used on the front legs.\nFetlock Boots: These boots are used to protect the fetlocks on the hind legs and may be used with tendon boots. They are also open in the front.\nSports Medicine Boots: These boots can be used during exercise to protect the muscles and tendons, as well as the pastern and fetlock. Sports medicine boots are most commonly used to protect the horse from muscle and tendon strains and sprains, suspensory injuries, and splints. Many riders tend to only put boots on the front legs. However, the hind legs can also be susceptible to injury. In addition, by booting all four legs, support is even on each leg, and it may help the horse bear weight more evenly.\nSplint Boots or Brushing Boots: Splint boots or brushing boots help prevent injury during exercise, especially if one hoof strikes an opposite leg, and are easier to put on than wraps. They come in handy with horses that are less coordinated or in training for faster events. They can also be used in turnout, especially if a horse is extra exuberant when playing. They sit right on top of the fetlock joint. Fit and proper placement is important to prevent injury. To learn how to put on bell boots, sports medicine boots, and splint boots, check out CHA's Safety Short Video titled \"Fitting Horse Boots\" on YouTube.\nPolo Wraps: Polo wraps are stretchy, available in various colors and lengths, and help protect the horse’s legs from scrapes, bruises, and irritation from dirt, sand, and other types of arena footing. However, polos, also called track wraps, should not be used during trail riding since burrs and small sticks and debris can become attached to them and then cause the horse irritation as they dig into his skin. They are not recommended for use when putting the horse in a stall for a while or in turnout since they can easily become unraveled and torn if the horse steps on them. Many choose polo wraps over boots since they conform to the leg, however, if they become wet, they become really heavy for the horse. This can place additional strain on tendons and ligaments. Applying polo wraps incorrectly can also damage the horse’s leg. Polo wraps should be washed often since a dirty polo wrap can irritate a horse’s legs. For proper placement, check out CHA’s video called “How to Put Polo Wraps and Standing Wraps on Horses.”\nStanding Wraps: Standing wraps, also called stable bandages, consist of padding that is wrapped around the horse’s legs using polo wraps. They help protect the horse’s legs, tendons, and ligaments, while the horse is in a stall. Standing wraps can be beneficial if a horse has a tendency to be restless in the stall, or if the horse’s legs tends to stock up (swell) after exercise or while in a stall. They can also be used in shipping, although shipping boots provide better protection. In addition, they can be used for certain injuries, but this should be at the discretion of a veterinarian. Using a wrap can help keep cuts, wounds, and other injuries clean while they heal. In addition, standing wraps are beneficial when poultices or liniments need to be used, again at the discretion of a veterinarian. A veterinarian should advise on the use of standing wraps with any product, since some products can produce excessive heat, thus causing the horse discomfort or pain if used under a wrap. Standing wraps stretch from the bottom of the knee or hock to below the fetlock and are always used with padding.\nShipping Bandages, Boots, or Wraps: Shipping boots, bandages, and wraps are used when trailering and flying to prevent injuries to the legs. Shipping boots and wraps go from the knee or hock down to the hoof. Shipping boots can provide more protection than shipping wraps since they cover the hock and some even have hoof guards. They protect the cannon bones, tendons, fetlocks, pasterns, coronets, and heels. As with other boots, bandages, and wraps, make sure to clean the horse's legs and the boot and wrap so that the horse does not become irritated from trapped dirt, shavings, or other obstructions. Poorly applied shipping bandages and wraps have the possibility of coming loose and falling off. In addition, they could strain the horse’s legs. Wraps are best for long trips, while boots are great for short trips or for those who do not know how to properly put on a shipping wrap.\nIt is possible to go on and on about wraps, boots, and bandages. There is a plethora of options on the market, and each company may have a unique take on the design. In addition, the names of boots may vary from discipline to discipline and also differ by country.\nThe most important thing about using wraps, boots, and bandages is to apply them properly and to use them in the right situations. Proper fit is important as well. It may take trial and error to find the right options for a particular horse, but the benefits are worth the effort. After all, no rider wants to hear that their horse has turned up lame."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"}],"document_ids":["<urn:uuid:1420ed56-96c0-43f0-93e1-b567c366bbbf>","<urn:uuid:8a82d24c-8475-49bd-bbb3-a04ad31e5b2e>"],"error":null}
{"question":"How do kitchen sponges and dishcloths relate to food safety risks, and what implications does this have for preparing complex dishes like Beef Wellington that involve multiple preparation stages?","answer":"Kitchen sponges and dishcloths pose significant food safety risks, with about 10% containing salmonella and harboring the most E. coli and fecal-based bacteria in the average home due to their moist conditions that promote bacterial growth. This is particularly relevant when preparing complex dishes like Beef Wellington, which involves multiple stages including mushroom duxelles preparation, pâté making, and meat handling. The recipe's recommendation for advance preparation helps minimize cross-contamination risks, as different components can be prepared separately and stored properly, rather than rushing all preparations simultaneously with the same cleaning tools.","context":["Beef Wellington is a classic, rich dish, also known in France as boeuf en croûte. Venison is the perfect meat to use in place of beef fillet, especially for a smaller group of diners (beef fillets can be a hefty weight, not to mention price!). It's definitely a special occasion meal, but don't be put off if you have never done a 'welly' before – they really aren't hard to put together. The key to success is in the advance preparation.\nThe pâté and the mushroom duxelles are best made the day before to set properly. Then the actual assembly takes about 20 minutes. This is a seriously rich dish, so your accompaniment should, ideally, be light. Steamed spring greens or a watercress salad would both be perfect.\n1 length of boned loin or saddle meat of venison, weighing around 1kg, trimmed of any fat or sinew\nSalt and freshly ground black pepper\nFor the duxelles\n600g large black field mushrooms\n2 round shallots\n2 tablespoons of unsalted butter\nSalt and freshly ground black pepper\nA small bunch of tarragon\nFor the pâté\n2 1/2 tablespoons duck fat or soft butter\n2 shallots, finely diced\n1 clove of garlic, crushed\nSea salt and freshly ground black pepper\n100ml Madeira wine\n1kg free-range chicken livers\n2 tablespoons brandy\n1 egg yolk\n150g cold unsalted butter, chopped into 1cm pieces\n500g good butter puff pastry\n1 egg, beaten\nSlice the mushrooms as finely as possible, then turn your knife and chop them until you have a fine dice. Dice the shallots as finely as possible, too. Warm the butter in a wide pan. Add the mushrooms and shallots with a good pinch of salt and sauté over a high-ish heat until the mushrooms give off their liquid. Finely chop the tarragon and stir it into the pan.\nReduce the heat to a low flame and continue to cook, stirring occasionally, until all of the moisture from the mushrooms has evaporated. This should take around 20 minutes. Cool the mixture to room temperature, then pop it into a container, covering the mix with clingfilm and then into the fridge to set.\nChicken liver pâté\nMelt a tablespoon of the fat in a small pan. Add the shallots and garlic with a pinch of sea salt. Sauté until they have become soft and translucent, about 3 minutes, then pour over the Madeira. Simmer until the liquid has reduced by half. Tip the mixture into the bowl of a food processor.\nTrim the livers of any sinew and season them with a good pinch of sea salt and pepper. You will probably need to cook the livers in two batches so melt half of the fat or butter in a wide pan over a high heat and, when it starts to bubble, add half of the livers. Fry the livers for 1 minute on either side until they are sealed, and tip them from the pan into the food processor. Repeat with the remaining livers but, after you've cooked the second lot of livers, add them to the food processor and deglaze the pan with the brandy. Let it bubble and then pour the juices into the food processor with the livers. Add the egg yolk, then give everything a good blitz. Feed the butter into the processor one piece at a time while the motor is running and keep going until the mixture is smooth.\nCheck the seasoning: you might want a touch more salt. Then, scrape the pâté into a container, cover and refrigerate.\nThis needs to be done a good couple of hours or so before you put the dish together. Rub the venison all over with the olive oil and season with salt and pepper. Heat a heavy-based pan over a high heat and when it is smoking, add the meat. Sear it on all sides for no more than a minute each side. Place the meat onto a cooling rack and let it get completely cold.\nPreheat the oven to 200°C / Gas Mark 6.\nCut a piece of baking parchment to fit the tray you'll be baking the Wellington on. Halve the pastry and roll out both pieces into rectangles, a good 3cm longer and wider than the venison fillet. Keep all of the trimmings. Place one of the pastry sheets onto the parchment, then brush the edges with some of the beaten egg.\nNow spread a third of the pâté onto the middle of the pastry and top that with a third of the mushroom mixture. Sit the venison on the middle of the pastry and smear the top and sides of the fillet with the pâté. Finally, press the mushroom duxelles onto the pâté. Drape the second piece of pastry over the top and crimp the edges, trimming again if necessary.\nRoll out the pastry trimmings to create a lattice over the top of the Wellington, like an old-fashioned pie, and brush the pastry with the remaining egg wash.\nBake the Wellington for about 20 minutes, turning the tray 180 degrees half way. It's ready when the pastry is golden and crisp – if not, it might need 5–10 minutes more in the oven. Allow the Wellington to rest for 10 minutes before carving (at the table, of course, where it will wow everyone).\n• This recipe is taken from Game by Trish Hilferty and Tom Norrington Davies (Absolute Press, £25)","“In most cases, it’s safer to make a salad on a toilet seat than it is to make one on a cutting board,” says Dr. Charles Gerba (a.k.a. Dr. Germ), a microbiologist and professor at the University of Arizona in Tucson. “People disinfect their toilet seats all the time, but they don’t realize that they really need to pay attention in the kitchen too.” Since 1973, he’s been studying the hidden bacteria lurking in American homes, and his findings should influence your behavior when it comes to storing a toothbrush (in the medicine cabinet) and how to flush a toilet (lid down). Here, Dr. Germ identifies the top five dirtiest spots in the kitchen and gives advice on how to banish nasty germs.\n1. Sponges and dishcloths\n“We did a survey collecting 1,000 sponges and dishcloths in kitchens, and about 10 percent had salmonella. They get wet and stay moist, so bacteria grow like crazy. The most E. coli and other fecal-based bacteria in the average home are on a sponge or cleaning cloth.”\nDr. Germ's advice: “Replace dishcloths every week and throw the sponge into the dishwasher or microwave it on high for 30 seconds.”\n“There’s more E. coli in a kitchen sink than in a toilet after you flush it. The sink is a great place for E. coli to live and grow since it’s wet and moist. Bacteria feed on the food that people put down the drain and what’s left on dishes in the sink. That’s probably why dogs drink out of the toilet—because there’s less E. coli in it,” says Dr. Germ.\nDr. Germ's advice: “Clean the sink basin with a disinfectant product made for the kitchen. Vinegar and lemon juice can clean some bacteria, but they can’t clean really bad pathogens, so the Environmental Protection Agency doesn’t recommend using them as an alternative.”\n3. Cutting board\n“In most cases, it’s safer to make a salad on a toilet seat than it is to make one on a cutting board. There’re 200 times more fecal bacteria from raw meaton the average cutting board in a home than a toilet seat. Most people just rinse their cutting board, but poultry and raw meat can leave behind salmonella and campylobacter.” The latter bacteria, which can come from eating raw meat, is one of the most common causes of food-borne illness, according the FDA.\nDr. Germ's advice: “Use one cutting board for meats and another one for vegetables, so you don’t get cross-contamination. Boards can be cleaned with a kitchen disinfectant or put it in a dishwasher.” As to whether you should buy a wood or plastic cutting board: “We used to always recommend using plastic cutting boards, but wood seems to have antimicrobial resins, so it’s a toss-up.”\n4. Bottom shelf of the refrigerator\n“When we looked at refrigerators, the bottom shelf tends to have the most bacteria, because moisture and condensation drip down from the upper shelves. People often put produce on a bottom shelf and defrost a meat product above it.”\nDr. Germ's advice: “Wipe down the bottom shelf every two or three weeks with a disinfectant cleaner that’s made for the kitchen. To avoid cross-contamination, put raw meat on the bottom shelf and tuck raw produce into a drawer away from everything else.”\n5. Kitchen countertops\n“Kitchen countertops tend to be the dirtiestnear the sink area because people wipe them down with sponges and cleaning cloths that have E. coli and other bacteria. The sponges and cloths just spread the germs all over the countertops.”\nDr. Germ's advice: “Use a disinfectant kitchen cleaner and finish off by drying the countertop with a disposable paper towel. Paper towels are great because they absorb a lot of the moisture and bacteria and you can just throw them away.”\nMore from Food & Wine\n- Sleek Kitchen Makeovers\n- Best Pizza Places in the U.S.\n- Best Burgers in the U.S.\n- America's Best Bars\n- Kitchen Secrets from Celebrity Chefs\n- Healthy Grilling Recipes\nYuck! More stories about germs:"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:c10c3873-dbda-466b-a179-7ece4f3de8ab>","<urn:uuid:183a6a0f-f72a-4dbf-9f32-2501baeb5ef8>"],"error":null}
{"question":"What are the key differences between wine stabilization through pasteurization and ultrasonic preservation techniques when it comes to their effects on microorganisms?","answer":"Wine pasteurization and ultrasonic preservation differ significantly in their antimicrobial mechanisms. Pasteurization relies purely on heat, typically heating wine to 185°F (85°C) for a minute before cooling to 122°F (50°C) for up to three days to kill all yeast and bacteria. This thermal process can affect wine flavor and aging potential. In contrast, ultrasonic preservation combines multiple mechanisms - it creates localized high temperatures and pressures through cavitation, while also generating mechanical shear forces that can physically disrupt microorganisms. Ultrasound is particularly effective when combined with other antimicrobial methods like heat (thermo-sonication) or pressure (mano-sonication). Unlike pasteurization, ultrasound offers a non-thermal alternative that can help preserve sensory attributes like texture, flavor, and color while still effectively inactivating problematic microorganisms like E.coli, Salmonellae, and various pathogens.","context":["Clarification and stabilization of wine\nIn winemaking, clarification and stabilization are the processes by which insoluble matter suspended in the wine is removed before bottling. This matter may include dead yeast cells (lees), bacteria, tartrates, proteins, pectins, various tannins and other phenolic compounds, as well as pieces of grape skin, pulp, stems and gums. Clarification and stabilization may involve fining, filtration, centrifugation, flotation, refrigeration, pasteurization, and/or barrel maturation and racking.\nIn wine tasting, a wine is considered \"clear\" when there are no visible particles suspended in the liquid and, especially in the case of white wines, when there is some degree of transparency. A wine with too much suspended matter will appear cloudy and dull, even if its aroma and flavor are unaffected; wines therefore generally undergo some kind of clarification.\nBefore fermentation, pectin-splitting enzymes and, for white wine, fining agents such as bentonite may be added to the must in order to promote the agglomeration and settling of colloids later. Pectins are structural molecules in the cell walls of fruits which have the important function of 'gumming' plant cells together. The pectin content of grapes increases steadily throughout ripening, reaching levels of about 1 g/l, although it varies by varietal and pre-fermentation handling processes. Large pectin molecules can affect the amount of juice yielded at pressing, ease of filtration and clarification, and extraction of tannins. Grapes contain natural pectolytic enzymes responsible for softening the grape berries during ripeneing, but these are not active under wine-making conditions (due to pH level, SO2, and alcohol.) Therefore, fungal pectolytic enzymes are often added to white must to break up pectins, decrease the viscosity of the juice, and speed up settling. In red musts, this increases colour and tannin extraction.\nAfter fermentation, the force of gravity may eventually cause the wine to \"fall bright\" or clarify naturally, as the larger suspended particles gradually settle to the bottom of the storage vessel. The wine can then be siphoned or \"racked\" off the compact solids into a new container. But this process may take many months, or even years, as well as several rackings, in order to produce a perfectly clear wine. Producers can accelerate the process by using fining agents, filtration and/or flotation.\nIn winemaking, fining is the process where a substance (fining agent) is added to the wine to create an adsorbent, enzymatic or ionic bond with the suspended particles, producing larger molecules and larger particles that will precipitate out of the wine more readily and rapidly. Unlike filtration, which can only remove particulates (such as dead yeast cells and grape fragments), fining can remove soluble substances such as polymerized tannins, coloring phenols and proteins; some of these proteins can cause haziness in wines exposed to high temperatures after bottling. The reduction of tannin can reduce astringency in red wines intended for early drinking. Many substances have historically been used as fining agents, including dried blood powder, but today there are two general types of fining agents — organic compounds and solid/mineral materials.\nOrganic compounds used as fining agents are generally animal based, a possible cause of concern to vegans. The most common organic compounds used include egg whites, casein derived from milk, gelatin and isinglass obtained from the bladders of fish. Pulverized minerals and solid materials can also be used, with bentonite clay being one of the most common, thanks to its effectiveness in absorbing proteins and some bacteria. Activated carbon from charcoal is used to remove some phenols that contribute to browning as well as some particles that produce \"off-odors\" in the wine. In a process known as blue fining, potassium ferrocyanide is sometimes used to remove any copper and iron particles that have entered the wine from bentonite, metal winery and vineyard equipment, or vineyard sprays such as Bordeaux mixture. Because potassium ferrocyanide may form hydrogen cyanide its use is highly regulated and, in many wine producing countries, illegal. Silica and kaolin are also sometimes used.\nSome countries, such as Australia and New Zealand, have wine labeling laws that require the use of fining agents that may be an allergenic substance to appear on the wine label. A study conducted by the University of California, Davis Department of Viticulture and Enology, however, found that no detectable amount of inorganic fining agents, and only trace quantities of proteinaceous agents, are left in the wine.\nThere is the risk of valuable aromatic molecules being precipitated out along with the less desirable matter. Some producers of premium wine avoid fining, or delay it in order to leach more flavor and aroma from the phenols before they are removed.\nWhile fining clarifies wine by binding to suspended particles and precipitating out as larger particles, filtration works by passing the wine through a filter medium that captures particles larger than the medium's holes. Complete filtration may require a series of filtering through progressively finer filters. Many white wines require the removal of all potentially active yeast and/or lactic acid bacteria if they are to remain reliably stable in bottle, and this is usually now achieved by fine filtration.\nMost filtration in a winery can be classified as either the coarser depth filtration or the finer surface filtration. In depth filtration, often done after fermentation, the wine is pushed through a thick layer of pads made from cellulose fibers, diatomaceous earth or perlite. In surface filtration the wine passes through a thin membrane. Running the wine parallel to the filter surface, known as cross-flow filtration, will minimize the filter clogging. The finest surface filtration, microfiltration, can sterilize the wine by trapping all yeast and, optionally, bacteria, and so is often done immediately prior to bottling. An absolute rated filter of 0.45 µm is generally considered to result in a microbially stable wine and is accomplished by the use of membrane cartridges, most commonly polyvinylidene fluoride (PVDF). Certain red wines may be filtered to 0.65 µm, to remove yeast, or to 1.0 µm to remove viable brettanomyces only.\nThe winemaking technique of flotation was adapted from the froth flotation process used in the mining industry for ore refining. In this process, small bubbles of air (or compressed nitrogen) are injected into the bottom of a tank. As the bubbles rise through the must, grape solids, including phenolic compounds prone to oxidation and browning, will tend to cling to the bubbles, creating a froth that can be removed from the wine. This must be done prior to fermentation, since yeast will inhibit the flocculation involved.\nAs a complex chemical mixture dependent on the activity of microorganisms, wine can be unstable and reactive to changes in its environment. Once bottled, a wine may be exposed to extremes of temperature and humidity, as well as violent movement during transportation and storage. These may cause cloudiness, sedimentation and/or the formation of tartrate crystals; more seriously, they may also cause spoilage or the production of carbonic gas.\nTartaric acid is the most prominent acid in wine with the majority of the concentration present as potassium bitartrate. During fermentation, these tartrates bind with the lees, pulp debris and precipitated tannins and pigments. While there is some variation according to grape variety and climate, usually about half of the deposits are soluble in the wine, but on exposure to low temperature they may crystallize out unpredictably. The crystals, though harmless, may be mistaken for broken glass, or simply reckoned unattractive by consumers. To prevent this the wine may undergo \"cold stabilization\", in which it is cooled to near its freezing point to provoke crystallization before bottling. In some white wines there are significant quantities of proteins that, being \"heat-unstable\", will coagulate if exposed to excessively fluctuating heat; the use of fining agents such as bentonite can prevent the haze this causes.\nA wine that has not been sterilized by filtration might well still contain live yeast cells and bacteria. If both alcoholic and malolactic fermentation have run to completion, and neither excessive oxygen nor Brettanomyces yeast are present, this ought to cause no problems; modern hygiene has largely eliminated spoilage by bacteria such as acetobacter, which turns wine into vinegar. If there is residual sugar, however, it may undergo secondary fermentation, creating dissolved carbon dioxide as a by-product. When the wine is opened, it will be spritzy or \"sparkling\". In a wine intended to be still this is regarded as a serious fault; it can even cause the bottle to explode. Similarly, a wine that has not been put through complete malolactic fermentation may undergo it in bottle, reducing its acidity, generating carbon dioxide, and adding a diacetyl butterscotch aroma. Brettanomyces yeasts add 4-ethylphenol, 4-ethylguaiacol and isovaleric acid horse-sweat aromas. These phenomena may be prevented by sterile filtration, by the addition of relatively large quantities of sulfur dioxide and sometimes sorbic acid, by mixing in alcoholic spirit to give a fortified wine of sufficient strength to kill all yeast and bacteria, or by pasteurization.\nPasteurization gives a kosher wine of the type called mevushal, literally \"cooked\" or \"boiled\", that can be handled by non-Jews and non-observant Jews without losing its kosher status. Typically, the wine is heated to 185°F (85°C) for a minute, then cooled to 122°F (50°C), at which temperature it remains for up to three days, killing all yeast and bacteria. It may then be allowed to cool, or be bottled \"hot\" and cooled by water sprays. Since pasteurization affects a wine's flavor and aging potential it is not used for premium wines. A gentler procedure known as flash pasteurization involves heating to 205°F (95°C) for a few seconds, followed by rapid cooling.\nOther methods of stabilization\nClarification tends to stabilize wine, since it removes some of the same particles that promote instability. The gradual oxidation that occurs during barrel aging also has a naturally stabilizing effect.\nPremium wine production\nSome producers prefer not to thoroughly clarify and stabilize their wines, believing that the processes involved may diminish a wine's aroma, flavor, texture, color or aging potential. Wine experts such as Tom Stevenson note that they may improve wine quality when used with moderation and care, or diminish it when used to excess. Winemakers deliberately leave more tartrates and phenolics in wines designed for long aging in bottle so that they are able to develop the aromatic compounds that constitute bouquet. The consumers of some wines, such as red Bordeaux and Port, may expect to see tartrates and sediment after aging in bottle.\n- J. Robinson (ed) \"The Oxford Companion to Wine\" Third Edition, pp. 173, 661–62. Oxford University Press 2006 ISBN 0-19-860990-6.\n- Robinson, Janis (2006). Oxford Companion To Wine. Oxford University Press. ISBN 0198609906.\n- T. Stevenson \"The Sotheby's Wine Encyclopedia\" pp. 26–7 Dorling Kindersley 2005 ISBN 0-7566-1324-8.\n- J. Robinson (ed) \"The Oxford Companion to Wine\" Third Edition pp. 271–72 Oxford University Press 2006 ISBN 0-19-860990-6\n- J. MacQuitty \"Vegan wines\", The Times, August 20th 2008\n- C. Pyevich \"Why is Wine so Fined?\" Vegetarian Journal, January/February 1997, Volume XVI, Number 1.\n- J. Robinson (ed) \"The Oxford Companion to Wine\" Third Edition, p. 83 Oxford University Press 2006 ISBN 0-19-860990-6.\n- K. MacNeil The Wine Bible pp. 35–40 Workman Publishing 2001 ISBN 1-56305-434-5.\n- \"Wine Filtration\". Gusmer Enterprises. Retrieved 3 August 2012.\n- J. Robinson (ed) \"The Oxford Companion to Wine\" Third Edition, p. 681 Oxford University Press 2006 ISBN 0-19-860990-6.\n- S. Retsky \"Kosher, Mevushal and Israeli Wines? Not What You Think\" American Thinker, December 17th 2005.\n- J. Robinson (ed) \"The Oxford Companion to Wine\" Third Edition p. 508 Oxford University Press 2006 ISBN 0-19-860990-6","Ultrasonic Extraction and Preservation\nThe disintegration of cell structures (lysis) by means of ultrasound is used for the extraction of intra-cellular compounds or for the microbial inactivation.\nIn microbiology, ultrasound is primarily associated with cell disruption (lysis) or disintegration (Allinger 1975). When sonicating liquids at high intensities, the sound waves that propagate into the liquid media result in alternating high-pressure (compression) and low-pressure (rarefaction) cycles, with rates depending on the frequency.\nDuring the low-pressure cycle, high-intensity ultrasonic waves create small vacuum bubbles or voids in the liquid. When the bubbles attain a volume at which they can no longer absorb energy, they collapse violently during a high-pressure cycle. This phenomenon is termed cavitation. During the implosion very high temperatures (approx. 5,000K) and pressures (approx. 2,000atm) are reached locally. The implosion of the cavitation bubble also results in liquid jets of up to 280m/s velocity The resulting shear forces break the cell envelope mechanically and improve material transfer. Ultrasound can have either destructive or constructive effects to cells depending on the sonication parameters employed.\nUnder intense sonication enzymes or proteins can be released from cells or subcellular organelles as a result of cell disintegration. In this case, the compound to be dissolved into a solvent is enclosed in an insoluble structure. In order to extract it, the cell membrane must be destructed. Cell disruption is a sensitive process, because the cell wall’s capability to withstand high osmotic pressure inside. Good control of the cell disruption is required, to avoid an unhindered release of all intracellular products including cell debris and nucleic acids, or product denaturation.\nUltrasonication serves as a well-controllable means for cell disintegration. For this, the mechanical effects of ultrasound provide faster and more complete penetration of solvent into cellular materials and improve mass transfer. Ultrasound achieves greater penetration of a solvent into a plant tissue and improves the mass transfer. Ultrasonic waves generating cavitation disrupt cell walls and facilitate the release of matrix components.\nIn general, ultrasound can lead to a permeabilization of cell membranes to ions (Mummery 1978), and it can reduce the selectivity of the cell membranes significantly. The mechanical activity of the ultrasound supports the diffusion of solvents into the tissue. As ultrasound breaks the cell wall mechanically by the cavitation shear forces, it facilitates the transfer from the cell into the solvent. The particle size reduction by the ultrasonic cavitation increases the surface area in contact between the solid and the liquid phase.\nIn particular the extraction of enzymes and proteins stored in cells and subcellular particles is a unique and effective application of high-intensity ultrasound (Kim 1989), as the extraction of organic compounds contained within the body of plants and seeds by a solvent can be significantly improved. Therefore ultrasound has a potential benefit in the extraction and isolation of novel potentially bioactive components, e.g. from non-utilized by-product streams formed in current processes. Ultrasound can also help to intensify the effects of enzyme treatment, and by this reduce the amount of enzyme needed or increase the yield of extractable relevant compounds.\nUltrasonication is often used to improve the extraction of lipids and proteins from plant seeds, such as soybeans (e.g. flour or defatted soybeans) or other oil seeds. In this case, the destruction of the cell walls facilitates the pressing (cold or hot) and thereby reduces the residual oil or fat in the pressing cake.\nThe influence of continuous ultrasonic extraction to the yield of dispersed protein was demonstrated by Moulton et al. The sonication increased the recovery of dispersed protein progressively as the flake/solvent ratio changed from 1:10 to 1:30. It showed that ultrasound is capable to peptize soy protein at almost any commercial throughput and that the sonication energy required was the lowest, when thicker slurries were used. (Moulton et al. 1982)\nApplicable to: Citrus oil from fruits, oil extraction from ground mustard, peanut, rape, herb oil (echinacea), canola, soy, corn\nEnzymes, such as pectinases, cellulases and hemicellulases are widely used in juice processing in order to degrade cell walls and improve the the juice extractability. The disruption of the cell wall matrix also releases components, such as phenolic compounds into the juice. Ultrasound improves the extraction process and therefore can lead to an increase in the phenolic compound, alkaloids and juice yield, commonly left in the press cake.\nThe beneficial effects of ultrasonic treatment on the liberation of phenolic compounds and anthocyanins from grape and berry matrix, in particular from bilberries (Vaccinium myrtillus) and black currants (Ribes nigrum) into juice, was investigated by VTT Biotechnology, Finland (MAXFUN EU-Project) using an ultrasonic processor UIP2000hd after thawing, mashing and enzyme incubation. The disruption of the cell walls by enzymatic treatment (Pectinex BE-3L for bilberries and Biopectinase CCM for black currants) was improved when combined with ultrasound. “US treatment increase the concentration of phenolic compounds of bilberry juice by more than 15%. […] The influence of US (ultrasound) was more significant with black currants, which are more challenging berries in juice processing than bilberries due to their high content of pectin and different cell wall architecture. […] the concentration of phenolic compounds in the juice increased by 15-25% by using US (ultrasound) treatment after enzyme incubation.” (Mokkila et al. 2004)\nMicrobial and enzyme inactivation (preservation), e.g. in fruit juices and sauces is another application of ultrasound in the food processing. Today, preservation by elevation of temperature for short periods of time (Pasteurization) is still the most common processing method for microbial or enzyme inactivation that leads to longer shelf-life (preservation). Because of the exposure to high temperature, this thermal method has often disadvantages for many food products.\nThe production of new substances from heat-catalyzed reactions and the modification of macromolecules as well as the deformation of plant and animal structures may reduce in a loss of quality. Therefore, thermal treatment can cause undesirable alterations of sensory attributes, i.e. texture, flavor, color, smell, and nutritional qualities, i.e. vitamins and proteins. Ultrasound is an efficient non-thermal (minimal) processing alternative.\nHeat generated locally by the cavitation and the created radicals can lead to an inactivation of enzymes by sonication (El’piner 1964). At sufficiently low levels of sonication structural and metabolic changes can occur in cells without their destruction. The activity of Peroxidase, which is found in most raw and unblanched fruits and vegetables and can be particularly associated with the development of off-flavors and browning pigments can be reduced substantially by the use of ultrasound. Thermoresistant enzymes, such as lipase and protease that withstand ultra-high-temperature treatment and which can reduce the quality and shelf-life of heat-treated milk and other diary products can be inactivated more effectively by the simultaneous application of ultrasound, heat and pressure (MTS).\nUltrasound has demonstrated its potential in the destruction of food-borne pathogens, like E.coli, Salmonellae, Ascaris, Giardia, Cryptosporidium cysts, and Poliovirus.\nApplicable to: preservation of jam, marmalade or toppings, e.g. for icecream, fruit juices and sauces, meat products, dairy\nUltrasonication is often more effective when combined with other anti-microbial methods, such as:\n- thermo-sonication, i.e. heat and ultrasound\n- mano-sonication, i.e. pressure and ultrasound\n- mano-thermo-sonication, i.e. pressure, heat and ultrasound\nThe combined application of ultrasound with heat and/or pressure is recommended for Bacillus subtilis, Bacillus coagulans, Bacillus cereus, Bacillus sterothermophilus, Saccharomyces cerevisiae, and Aeromonas hydrophila.\nUnlike other non-thermal processes, such as high hydrostatic pressure (HP), compressed carbon dioxide (cCO2) and supercritical carbon dioxide (ScCO2) and high electric field pulses (HELP), ultrasound can be easily tested in lab or bench-top scale – generating reproducible results for scale-up. The intensity and the cavitation characteristics can be easily adapted to the specific extraction process to target specific objectives. Amplitude and pressure can be varied in a wide range, e.g. to identify the most energy efficient extraction setup. Tough tissues should undergo maceration, grinding or pulverization prior to ultrasonication.\nTo produce small amounts of recombinant proteins for the study and characterization of their biological properties, E.coli is the bacterium of choice. Purification tags, e.g. polyhistidine tail, beta-galactosidase, or maltose-binding\nproteins, are commonly joined to recombinant proteins in order to make them separable from cell extracts with a purity sufficient for most analytical purposes. Ultrasonication allows to maximize the protein release, in particular when the production yield is low and to preserve the structure and activity of the recombinant protein.\nThe disruption of E.coli cells in order to extract the total Chymosin protein was studied by Kim and Zayas.\nSaffron is known as most expensive spice on the world market and is distinguished by its delicate flavour, bitter taste and attractive yellow colour. The saffron spice is obtained from the red stigma of the flower of saffron crocus. After drying, these parts are used as a seasoning in cuisine or as colouring agent. The intensive characteristic flavor of saffron results especially from three compounds: crocins, picrocrocin and safranal.\nKadkhodaee and Hemmati-Kakhki have showed in a study that ultrasonication increased the extraction yield significantly and reduced the processing time considerably. In fact, results by ultrasound extraction were conspicuously better than by traditional cold water extraction, which is proposed by ISO. For their research, Kadkhodaee and Hemmati-Kakhki have used Hielscher’s ultrasonic device UP50H. Best results have been achieved with pulsed sonication. This means that short pulse intervals were more effective than a continuous ultrasonic treatment.\nAt controlled intensities, the application of ultrasound to biotransformation and fermentation may well result in an enhanced bioprocessing, due to induced biological effects and due to facilitated cellular mass-transfer. The influence of the controlled application of ultrasound (20kHz) on the oxidation of cholesterol to cholestenone by resting cells of Rhodococcus erythropolis ATCC 25544 (formerly Nocardia erythropolis) was investigated by Bar.\nCholesterol + O2 = cholest-4-en-3-one + H2O2\nThis system is typical of microbial transformations of sterols and steroids in that the substrate and the products are water insoluble solids. Therefore, this system is rather unique in that both the cells and the solids may be subject to the effect of ultrasound (Bar, 1987). At a sufficiently low ultrasonic intensity which preserved the structural integrity of the cells and maintained their metabolic activity, Bar observed a significant enhancement in the kinetic rates of the biotransformation in microbial slurries of 1.0 and 2.5 g/L cholesterol when sonicated for 5s every 10mn with a power output of 0.2W/cm². Ultrasound showed no effect on the enzymatic oxidation of cholesterol (2.5g/L) by cholesterol oxidase.\nThe utilization of ultrasonic cavitation for extraction and food preservation is a new powerful processing technology that can not only be applied safely and environmentally friendly but also efficiently and economically. The homogenizing and preserving effect can be easily used for fruit juices and purees (e.g. orange, apple, grapefruit, mango, grape, plum) as well as for vegetable sauces and soups, like tomato sauce or asparagus soup.\nBar, R. (1987): Ultrasound Enhanced Bioprocesses, in: Biotechnology and Engineering, Vol. 32, Pp. 655-663 (1987).\nMokkila, M., Mustranta, A., Buchert, J., Poutanen, K (2004): Combining power ultrasound with enzymes in berry juice processing, at: 2nd Int. Conf. Biocatalysis of Food and Drinks, 19-22.9.2004, Stuttgart, Germany."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:457863c8-023e-46be-9a36-0e0a359106df>","<urn:uuid:307fac4c-60ed-4191-b48c-579e9fc497d3>"],"error":null}
{"question":"Looking for soil management methods - can you compare labor requirements between conservation agriculture and cover crop farming?","answer":"Conservation agriculture is notably more labor intensive, requiring increased weeding and more work to prepare the ground and sow crops. Additionally, farmers must manage crop residues like maize stalks, which can attract pests if left on the surface. For cover crops, the main labor requirements involve the establishment costs (approximately $15 per acre) for aerial distribution of seed and eventually killing the plants at season's end, plus the initial seed costs of about $25 per acre. Cover crop management requires careful decision-making about which species to use and timing of planting, but doesn't necessarily increase regular farming labor like conservation agriculture does.","context":["Can conservation agriculture (CA) help farmers in sub-Saharan Africa build resilience to the problem of climate change? Professor Andy Dougill believes it is possible, but that more coordinated planning and coherent policy support across sectors nationally, on a district level, and to a range of local farmer groups and community leaders is needed.\nFor over a decade now, most development organisations have been advocating conservation agriculture as a ‘climate-smart agriculture’ approach. The idea behind conservation agriculture is that farmers maximise organic matter in their soil and reduce CO2 release by limiting or eliminating tillage, using crop rotations and by keeping a permanent organic coverage on the fields. In return, the argument goes, they get improved soils that are able to hold water for longer and sustain yields in dry years, making maize harvests more resilient to the impacts of climate change.\nThere is growing evidence globally to suggest that no-till farming works when good crop residue management practices are followed, but that local context remains critical, and further research insights, such as those being provided by the GCRF-AFRICAP project, are essential. Why is the evidence base still so poor, given that conservation agriculture – sometimes billed as ‘farming God’s way’ – has been promoted to farmers for so long?\nWebinar on 23 Feb: Improving soil health through climate-smart agriculture\nA threefold problem\nPart of the problem is the patchy take up of conservation agriculture across countries such as Malawi, Zambia and Zimbabwe. Many farmers are reluctant to change to this method of farming or, once started, fail to maintain it after a donor-supported project leaves. The reasons for this are threefold: practical, cultural and institutional.\nOn the practical side, good conservation agriculture can be more labour intensive at certain times of the year, requiring more weeding and more work to prepare the ground and sow a crop. Leaving organic matter on the surface, such as maize stalks, can encourage pests such as mice, which are deterred when the stalks are burned. Because the benefits take a while to be seen and are largely evident only in drought years, farmers can easily be put off by more immediate changes in their farming practices.\nCulturally, many farmers hold the view that conventional ploughing of land and creation of ridges and furrows is what epitomises good, modern farming. It is imperative that such views are questioned and that locally appropriate land management practices are discussed and supported by farmers, groups, community leaders and government extension services.\nAt an institutional level, take up of conservation agriculture is often incentivised through provision of additional fertiliser and new seed, which makes it hard to identify the impact of the change in farming method alone. Malawian studies have shown that when the incentives end, for the reasons above, farmers often revert to their former methods.\nAlthough conservation agriculture has been promoted for many years, this has been done by many different organisations – governmental and non-governmental – in various ways and for diverse reasons, resulting in confused messages as to why farmers should take up the practice and sometimes even what the practice should consist of.\nRecent studies – conducted under auspices of the GCRF-AFRICAP project – looking at how policy on conservation agriculture is implemented in Malawi highlight the need for better communication and collaboration between all relevant parties within a country: government departments, local government and NGOs. Effective implementation of conservation agriculture requires government departments responsible for agriculture to move outside their traditional responsibilities and link with departments working on climate change adaptation, meteorology, health, and water distribution.\nGiven these limitations, what reliable evidence do we have of the benefits that conservation agriculture can bring, particularly in relation to climate resilience? A recent paper has shown that conservation agriculture improves soil structure and can increase organic carbon levels in soil aggregates leading to improved maize yields in drought years. However, most of this work has been undertaken on government research stations rather than in the ‘real world’ of smallholder farming systems. Furthermore, there is a lack of robust findings to determine whether these benefits will hold up in the face of climate change.\nWe’ve been working with farmers in Malawi for the last 10 years and know many of those who have taken up conservation agriculture – currently around 2–3%. Those connections are helped us to run a fast-turnaround study, comparing how the crops of conservation agriculture farmers in Malawi survived the 2015/16 drought compared to those using conventional methods.\nThis work, funded by the UK government through the National Environment Research Council (NERC), can help us understand just how ‘climate-smart’ conservation agriculture can be. This research also looked at the impact of El Niño in Kenya, to assess whether conservation agriculture helped farmers retain yields in the face of the floods there. Interim results from Malawi indicate that, where the drought was most severe, all farmers lost their crops; however, in more marginal areas, conservation agriculture did provide benefits where household labour was available (linked to the effectiveness of village health services) and crop residue management had been possible for the last 5 years.\nResearch is starting to provide a much-needed evidence base to show farmers when it is in their interest to move to conservation agriculture. Farmers need a clear message to help them understand which practices will work best for them, so that they can make an informed decision. We need both the evidence and better collaborative working amongst key organisations at both a national and district level to make that happen. Ongoing studies in the GCRF-AFRICAP project and the future work of the Food Systems Research Network for Africa (FSNet-Africa) offer scope to provide further empirical insights on how land management can build climate resilience in African Agricultural Systems.\nWebinar on 23 Feb\nLearn more about AFRICAP’s research on Conservation Agriculture and soils science at our webinar on 23 February, ‘Improving soil health through climate-smart agriculture’. Visit the event page for full details and to register.\nThis blog and associated vlog is part of a joint campaign for World Food Day led by the ARUA-UKRI GCRF Food Systems Research Network for Africa (FSNet-Africa) in partnership with the Food, Agriculture, and Natural Resources Policy Analysis Network (FANRPAN), the University of Leeds’ Global Food and Environment Institute (GFEI), and the GCRF AFRICAP programme. Follow the campaign on Twitter @gcrfafricap, or visit our partners’ websites over the next two weeks – University of Pretoria, FANRPAN, and GFEI.","|Credit: vovan | Shutterstock|\nMargaret Mellon is a senior scientist for food and the environment at the Union of Concerned Scientists (UCS). An expert on sustainable agriculture and the potential environmental risks of biotechnology, Mellon holds a doctorate in molecular biology and a law degree. This article was adapted from a post on the UCS blog The Equation. Mellon contributed this article to LiveScience's Expert Voices: Op-Ed & Insights.\nFarmers planting crops that can't be sold doesn't sound like a sensible proposition, does it? After all, seeds cost money, and so does the equipment to get them in the ground. Why grow 'em if you can't sell 'em?\nBut it turns out that an increasing number of farmers are doing just that: buying, planting and tending to so-called cover crops. No, farmers can't sell cover crops, but they do reap benefits from them, including increased yields of cash crops like corn and soybeans. Use of cover crops can also help farms survive the droughts expected to become more common in the era of climate change.\nCover crops — which can be many species of grains, grasses and legumes — are usually planted in the interval between the harvesting and planting of cash crops. Sending their roots down into bare soil, cover crops can increase soil carbon, provide slow-release nitrogen and prevent erosion. But a cover-crop/cash-crop system is complex. If not managed properly, cover crops can deprive cash crops of water or even reduce yields. Although they make sense in theory, many have wondered how cover crops would work in the real world.\nNow, a new survey of commercial farmers has confirmed that cover crops increase yields in corn and soybeans, the most common crops in the U.S. Moreover, cover crops were especially effective under drought conditions.\nThe North Central Sustainable Agriculture Research and Education (SARE) program and the Conservation Technology Information Center conducted the survey of more than 759 commercial farmers from winter 2012 through spring 2013. Farmers who responded reported average increases of 11.1 bushels of corn per acre and 4.9 bushels of soybeans per acre over prior harvests. In percentage terms, the extra bushels represent an average 9.6-percent-greater yield in corn planted after the planting of cover crops compared with crops not preceded by cover crops. The increase in soybeans was 11.6 percent. That's pretty impressive.\nThe growers reported yield information from fields comparable in conditions and rotation — except for the cover crops. And, the advantages for cash crops planted after cover crops were even greater in states hit hard by drought.\nThe states most affected by the severe 2012 drought were Illinois, Indiana, Iowa, Kansas, Missouri, Nebraska and South Dakota. The 141 respondents from those states reported an average corn yield of 11.3 bushels per acre, which represented an 11 percent increase in crops grown after cover crops compared with those grown without them. Respondents from the drought-affected states reported even greater benefits in soybeans: an average increase of 5.7 bushels per acre, or 14.3 percent higher yields after cover crops.\nThe farmers responding to the survey grew cover crops on an estimated 218,000 acres in 36 states, mostly in the Mississippi River basin. Not surprisingly, drought-related impacts varied across the country. But the results were solid: Farmers enjoyed better corn yields after cover crops in all but one of the states hardest hit by the drought.\nFarmers expected to pay for the ecosystem services provided by cover crops, and were willing to pay median costs of $25 an acre to purchase seeds and $15 an acre for cover-crop establishment (aerial distribution of seed and the eventual killing of the plants at the end of the growing season).\nFarmers interested in cover crops need to decide which species to use, how and when to plant them, and whether to plant single or multispecies mixes. If the wrong decisions are made, cover crops might not deliver on their potential benefits, or may even be detrimental. The survey respondents reported a long list of challenges, including cover-crop seed availability, increased insect potential and the risk of cover crops using too much soil moisture.\nDespite the challenges, the surveyed farmers had steadily increased their use of cover crops over the last decade. Last winter, they reported planting cover crops on an average of 42 percent of their acreage and planned to increase their cover-crop acreage this coming winter.\nThe complexity of the system may explain the correlation between yield increases and experience using cover crops. Growers with more than three years of experience working with cover crops saw a 9.6 percent increase in corn yields, whereas growers with one to three years of experience reported a still respectable, but lower, 6.1 percent boost in corn.\nA complete, drought-tolerant package would include appropriate crop choices and specially bred varieties of crops, as well as a drought-tolerant system. The crop-centered approach to drought was discussed by my colleague, Doug Gurian-Sherman, in hisrecent report \"High and Dry.\" In addition to highlighting the availability of crops like sorghum and alfalfa that are inherently more drought-tolerant and might be used more often in U.S. agriculture, Doug also discussed the success of conventional corn breeders who have increased drought tolerance at a steady pace of 1 percent per year over decades.\nGenetic engineering has yet to play an important role in drought tolerance. Only this year did agricultural biotech company Monsanto introduce its first drought-tolerant seed variety, DroughtGard. According to the Monsanto website, the variety has produced a five-bushel (or about 4 percent) yield advantage in field tests against competitor hybrids.\nHowever successful crop genetics might be, new plant varieties cannot compensate for the deficiencies in systems. The fundamental requirement for combating drought is to keep moisture in the soil. Cover crops can do that — and so much more.\nThis article was adapted from \"Cover Crops Dramatically Increase Corn Yields –Especially In Drought Conditions\"on the UCS blog The Equation. The views expressed are those of the author and do not necessarily reflect the views of the publisher. This article was originally published on LiveScience.com."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"non_native_learner"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_intent","category_name":"instructional"}],"document_ids":["<urn:uuid:155d6dc0-5127-42b9-938c-416288b657bc>","<urn:uuid:b7394d30-ae4f-49a6-8228-49eeccf2b121>"],"error":null}
{"question":"I'm worried about my cat's health. What are the different kneading styles that might indicate stress, and what other signs should prompt an immediate vet visit?","answer":"There are several kneading styles that cats display: gentle petal (soft, soothing motions), drooler (forgets to swallow), porcupine (aggressive with claws), suckler (nibbles blankets), and hypnosis guru (enters a trance-like state). While kneading itself is normal, you should seek immediate veterinary attention if you notice signs like frequent coughing/sneezing, runny eyes/nose, repeated vomiting/diarrhea, trouble breathing, yellowing of gums or skin, unusual thirst with increased urination, or if your cat becomes dirty and stops using the litter box properly.","context":["Why Do Cats Knead?\nThis article is written by Pet Circle Veterinarian, Dr Carla Paszkowski BVSc.\nIf you're a cat parent, you may have witnessed your fur baby taking part in an unusual behaviour known as 'kneading'. This weird - and downright adorable - behaviour is one of the least understood behaviours elicited by the domestic cat.\nSkip to a section:\n1. What is kneading?\nA compilation of cats kneading. Credit: Best Meow via Youtube\nThe term 'kneading' refers to the massage-like pressing of each paw into a soft surface, alternating between left and right paw in a smooth, soothing rhythm. The action closely resembles a baker kneading dough, which is why many people call it 'kneading dough' or 'baking biscuits'. (other fun names for it are 'making paddycakes' and a 'shi-cat-su massage')\nEvery kitty has their own style of kneading. Some cats will bite or suckle on a blanket while deep in the massage zone, and some will purr intensely. Some cats like to be quite gentle with their kneading, pushing mostly with their squishy little toe beans, but others like to dig their claws in and get a nice deep nail-shedding scritch-scratch. Unfortunately, for many cats, the more 'into' the knead, the deeper and more intense their scratching\nWhich kneader is your kitty?\n- The Gentle Petal: This sweet little angel kneads with soft, soothing motions, using only the squishiest most precious little toe beans. The Gentle Petal wants you to feel loved and is practically saying 'how's the pressure? Would you like some aromatherapy too?'\n- The drooler: A bit of a special little pumpkin, The Drooler will get so into their kneading they'll forget to swallow their own saliva. They may also be reminded of their mama's milk and the thought invokes some serious droolage. Who knows? Try not to embarass The Drooler by pointing or laughing - he is still a proud feline afterall and will clean himself up once his intense knead sesh is over.\n- The Porcupine: This spiky little kneader is anything but gentle. The Porcupine will dig her claws right in, and rip them out with gusto. It's as if she's saying 'you are nothing but a scratching post, peasant'. You may be left nursing some serious scratches, so be sure to keep a nice thick blanket around to shield your precious human skin.\n- The Suckler: This special petal thinks he's still a kitten, and will suckle on bits of blanket as he kneads. He may need a mother figure in his life, he may need years of therapy - either way, always treat with lots of love and attention.\n- The Hypnosis Guru: Nothing will distract the Hypnosis Guru from her extra-worldly kneading trance. A deeply spiritual being, The Hypnosis Guru will get so lost in the Knead Universe that her eyes may become fixed and intensely glazed over. Interrupting this psychic phenomenon can result in total universal implosion - so always treat with caution.\n2. Why Do Cats Knead?\nAs yet, we aren't exactly sure why cats knead. But there are a few theories. Keep in mind that the feline psyche is a complex thing - one cat's reason for kneading could be different to another's.\n1. Are you Mummy?\nYour kitty may be kneading due to a leftover instinct from kittenhood. Young kittens will knead on their mother's teats in order to stimulate milk production. Suckling kittens are often obsered giving their mum a mini massage while they drink.\nThis doesn't necessarily mean that your adult cat sees you as their 'mother'. Nor does it mean that your cat expects to express milk from you (or your blanket)! What is more likely is that your cat learned to associate the act of kneading with comfort, safety, and a tasty milk reward. Therefore when they feel comfortable and cosy, they knead as a means of association.\n2. Staking their Claim\nCats have scent glands on their paws which release scent and pheronomes when they knead or scratch a surface. Leaving their scent on objects is one way that cats mark their territory. This means that kneading might be your kitty marking you as 'their own'. Try to take it as a compliment - clearly your fur baby sees you as a commodity that they want other cats to keep their 'paws off'!\n3. An expression of love\nKneading is often associated with feelings of comfort and relaxation, so it makes sense that cats will only knead on their 'favourite' people. If you are lucky enough to receive a kneading massage from a cat, it means they are relaxed and comfortable with you.\nTherefore, kneading is generally interpreted as one way that your cat 'shows love'. There are many ways that felines show humans love, and kneading may just be the most adorble of them all.\n4. Making the Bed\nAnother theory is that cats like to knead as a leftover instinct from their wild cat days. Wild cats will press their paws down into soft grass before settling in for a snooze. So if your kitty is doing this on your lap it might be a sign they think your lap looks nap-worthy!\n5. Stretchy Stretch Stretch!\nAs any cat parent knows, cats are yoga pros and love pushing the boundaries of their innate flexibilities. Kneading is one of the many ways cats keep themselves loose and flexible. Think about it — if your back is stiff, it feels good to grab onto a surface and pull against it.\n6. Release that extra stress\nThe fact that our feline friends can experience stress might seem a bit weird, as their 'daily grind' involves around 70% sleeping on soft surfaces, with food and litter provided for, and zero responsibilities. I mean, who wouldn't want the carefree life of a pet cat?\nBut despite their somewhat envious lifestyle, pet cats can still experience stress in response to many situations such as house visitors, new pets, children, new furniture, or neighbouring cats.\nKneading may be one way your kitty releases stress, partly because it helps release scent from the marking glands in their feet, and partly because it usually accompanies purring, which releases positive endorphins.\nUltimately, the bond between cats and (their) humans is a special one, and kneading is just one part of the relationship that makes it ever more unique.\n3. Further Reading\nWant to read more? Check out our other articles:","Did you recently get a new little friend and are constantly worrying about his well being? Let me tell you, we have been there! Is he eating too much? Too little? Does he have a drinking problem? A good way to answer all the questions you might ask yourself is to regularly complete a professional check up and make sure everything is in order with your beast. It is very hard to detect a potential disease in your cat on your own, however, a regular visit to his favorite doctor could greatly simplify the task.\nFrequency of vet consultations\nEvery cat is different so know that if your cat is more fragile or suffers from a specific problem, the frequency of consultation might be more important. Our suggestion is designed for the average healthy cat.\nKitten: from 0 to 1 year\n- Once a month for the first 4 months\n- One more time at 6 months\nAdult: from 1 to 7 years old\n- Once to twice a year\nSenior: from 7 to 10 years old\n- Twice a year\nOlder cats: >10\n- 4 times a year (once every 3 month)\nTry to keep a notebook or folder with your beast’s records. This is what we do for our Yoda, it enables to keep track of everything while making sure we can provide relevant information for future examinations.\nVet consultations in detail\nIn this section we go into more details about why a check up should be encouraged and what happens during those check ups. You can start with this introductory video.\nIt is important for very young cat to get a very regular check up: once every month during the first four months. The reason behind this is quite simple. At this early stage of his life your kitty needs his first vaccinations and first illness controls (he will normally be tested for feline leukemia and feline immunodeficiency virus).\nAt this stage your cat will also need to start heartworm and flea/tick prevention medications.\nAt 6 months, another check up will occur combined with the necessary chop chop (spayed/neutered)*.\n*If you are adopting from a shelter, it’s necessary for the kitten to be spayed/neutered before you can take it home. Yoda needed this procedure before we were allowed to take him home, for example. We adopted him at around 10 weeks of age, so the age can vary 2-6 months but first check with the local shelter and/or your veterinarian to be sure.\nFor every check up, even if it is for a specific vaccination, your vet should proceed to a control of normal growth and that your little buddy is showing no signs of diseases.\nThe American Association of Feline Practitioners (AAFP) and the American Animal Hospital Association (AAHA) recommend a check up every 6 months as a best practice. Although it is acceptable to only go once a year, they advise to go to the vet more often: anticipation is key in the treatment of any disease. God knows that cats are good at hiding their problems, sometimes.\nThe vet will also proceed with the necessary vaccinations for your cat’s health.\nSenior (7-10) and older cats (>10)\nAs your cat ages, it is important to increase the frequency of the visits (from twice a year up to four times a year) as problems may occur on a more regular basis. It is essential to be proactive if you want to increase your cat’s chances to live a longer and healthier life. Your cat will get a thorough physical examination and new vaccines if needed.\nA check up can also consist in blood, urine and stool tests if necessary in order to identify your little friend’s kidney health, thyroid hormone levels, and much more.\nWhat is a cat “check up” anyways?\nHere is the list of things your vet will check to make sure your cat is well:\n- Vaccination status\n- Weight and general body condition (ears, eyes, nose, mouth and dental care, skin, coat, nails)\n- Good digestion\n- Heart and respiratory rate\n- Parasite control\n- Behavior and personality\nThis checklist will be supplemented with your answers to the vet’s question. Be ready to answer the following:\n- What other animals does your cat come in contact with?\n- What type of food do you feed your cat?\n- How often do you feed your cat?\n- Have any of your cat’s habits changed recently? (eating, playing, grooming, sleeping…)\nBeing aware of your companion’s life is a must as you can be more accurate in the way you will describe his habits to his doctor.\nWhich vaccinations ?\nCore vaccines are recommended for all cats. The disease they prevent have a significant morbidity and mortality rate and are widely distributed. Addressing those diseases with the appropriate vaccines will give your cat a good protection for a healthy life.\n- feline herpesvirus 1 (FHV1)\n- feline calicivirus (FCV)\n- feline panleukopenia virus (FPV)\nNon-core vaccines are optional vaccines that should be considered in light of the exposure risk of the animal, ie. based on geographic distribution and the lifestyle of the pet.\n- feline leukemia virus (FeLV)\n- feline immunodeficiency virus\n- virulent FCV\n- chlamydia felis\n- bordetella bronchiseptica.\nFor more information check out the feline vaccination guidelines of the William R. Pritchard Veterinary Medical Teaching Hospital at the University of California, Davis.\nCheck out your beast yoself\nEvery so often, you can do a little examination of your cat on your own if you know what to look for. Although it does not prevent you from consulting a professional, it helps you regularly monitor the status of your cat’s health. How to proceed ? Check out this pawesome video for additional info.\nHow much does a cat check up cost ?\nWhat we can tell you is that a trip to the vets can vary a great deal in the prices they charge for office visits. For a regular check up it is safe to expect something between 35 to 70 dollars. However, because it varies depending on your location, it is best to call and ask. In any case, vets rarely accept walk ins so it’s always best to call beforehand.\nJust know that the check up cost is just a starting point! Depending on what your vet will recommend (vaccination, further tests…) the bill could be much higher. You should always go prepared and ask in advance the detail for a consultation for your Kitty.\nObvious signs of needed veterinary attention\nBasically anything obvious that changes in his behavior should signal a red flag. Here are some good examples:\n- Cough or sneeze (frequent)\n- Runny eyes or nose\n- Your cat drools and stops grooming\n- Repeated vomiting and diarrhea\n- Trouble breathing with accentuated chest movements\n- Yellow mucosal and skin: gums, conjunctiva, ear flap\n- Abnormal lump or wart on his skin and specifically near breasts\n- Any vaginal discharge: puss or blood\n- Any unusual thirst accompanied by a large urine production\n- Your cat becomes dirty and does his business out of the litter box\n- A cat that constantly returns to his litter box and does nothing or a few drops (risk of urinary stones)\n- Your senior cat suddenly bumps into the furniture\nHow often should I take my cat to the vet for a check up: Final thoughts\nPreventive veterinary care can improve the quality of life of your cat. By respecting these simple guidelines of regular check ups, you will ensure that your fluffy friend is healthy and well. Thanks for reading! Do not forget to follow us on Twitter and Facebook where you will find all our latest news and articles. 🙂"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:55cd2320-fc24-4776-88e1-27e9fc9ea71c>","<urn:uuid:ff0ca5bf-cca4-42d6-903b-8fcb8f16aa6c>"],"error":null}
{"question":"What are the key aspects of dreams during sleep, and how can psychotherapy help process these experiences?","answer":"Dreams are mental phenomena occurring during REM sleep where images, emotions, and thoughts are experienced with a sense of reality. They typically occur 4-5 times per night for about 90 minutes total. According to psychoanalytic theory, dreams have both manifest content (the dream as remembered) and latent content (underlying meaning). Through psychotherapy, particularly psychodynamic therapy, individuals can explore these unconscious motivations and repressed content that drive behavior. Psychotherapy provides a safe environment to gain insight into these dream experiences and learn how they affect waking life, helping to improve mental health and develop better coping skills.","context":["a mental phenomenon occurring during sleep\nin which images, emotions, and thoughts are experienced with a sense of reality.\nThe interpretation of dream material is an important part of psychoanalysis\n. According to psychoanalytic theory, dreams have both manifest content\nand latent content\n(see under content\n). The patient's free associations\nare used to discover the latent content\nand to discover how that affects waking life.\n2. to experience such a phenomenon. Dreaming occurs during REM sleep; typically there are four or five such periods a night, with a total duration of about 90 minutes. The psychological interpretation of dreams was originated by Freud, who theorized that dreams enable the conscious expression of repressed unconscious impulses and wishes. Such wishes and impulses (latent dream content) are distorted and disguised so as to be acceptable to the conscious mind by the defensive processes of condensation, displacement, and symbolization and are then worked into a coherent story by secondary elaboration; this entire process (dream work) results in the dream as remembered by the dreamer (manifest dream content).\nMental activity during sleep in which events, thought, emotions, and images are experienced as real.\n1. a mental phenomenon occurring during REM sleep in which images, emotions, and thoughts are experienced with a sense of reality.\n2. to experience such a phenomenon.\nday dream wishful, purposeless reveries, without regard to reality.\n1. A series of images, ideas, emotions, and sensations occurring involuntarily in the mind during certain stages of sleep.\n2. A daydream; a reverie.\n3. A state of abstraction; a trance: wandering around in a dream.\n4. A condition or achievement that is longed for; an aspiration: a dream of owning their own business.\nv. dreamed or dreamt (drĕmt), dreaming, dreams\n1. To experience a dream in sleep: dreamed of meeting an old friend.\n2. To have a deep aspiration or hope: dreaming of a world at peace.\n1. To experience a dream of while asleep: Did it storm last night, or did I dream it?\n2. To have as an aspiration or hope: She dreams that she will become a pilot.\nEtymology: ME, dreem, joyful noise\nDiabetes Reduction Assessment with Ramipril and Rosiglitazone Medication. A study designed to determine if ramipril and/or rosiglitazone prevent the onset of type 2 diabetes\n1 a sequence of ideas, thoughts, emotions, or images that pass through the mind during the rapid-eye-movement stage of sleep.\n2 the sleeping state in which this process occurs.\n3 a visionary creation of the imagination experienced during wakefulness.\n4 (in psychoanalysis) the expression of thoughts, emotions, memories, or impulses repressed from the consciousness.\n(in analytic psychology) the wishes, emotions, and impulses that reflect the personal unconscious and the archetypes that originate in the collective unconscious. See also dream analysis, dream state\nConclusion Among persons with impaired fasting glucose levels or impaired glucose tolerance, the use of ramipril for 3 years does not significantly reduce the incidence of diabetes or death but does significantly increase regression to normoglycemia; 10.6% of people receiving rosiglitazone progressed to type 2 diabetes vs. 25% of people treated with placebo\ndream Neurology A series of images and thought processes that occur during sleep which, in the framework of psychoanalysis, are believed to have latent and manifest content; eyelid movement and REM sleep coincide during dreams; dreaming is more common during REM sleep. See Wet dream.\nMental activity during sleep in which events, thoughts, emotions, and images are experienced as real.\nPatient discussion about dream\nQ. Hi! I am Kennedy.From my childhood I have always been dreaming of slim body. Hi! I am Kennedy. From my childhood I have always been dreaming of slim body and in fact I was slim before my wedding. But after my pregnancy and delivery, I lost my shape and I am desperate to regain my shape. I tried with post-pregnancy exercises, but they didn’t help me. I am open to any kind of treatment to get shape. I hate to hang out with my hubby as I feel inferior with my shape. I feel my muscles are not tight for my age. I just want to feel good for which I need to get shape. So what kind of fitness classes shall I join? I am not comfortable with body pumping…….Please let me know?\nA. You can join Aerobic classes where they will have spinning and other exercises to make your body toned up and as well will control on your weight and blown tummy. Even though you don’t like on body pumping you must do them for some time till you find some control on your tummy. One other way is to start on running or sit-ups. Eat healthy diet esp. balanced diet and cut down on junk food, fried food and include whole-grain and fiber in your diet. Add more fruits and vegetables in your daily diet. Drink 8-10 glasses of water every day. I think your activity is not matching your calorie intake otherwise with simple post-pregnancy exercise you could lose extra fat.\nQ. I also fear that if my case is diagnosed as Breast Cancer how can I achieve my dreams? I am a Mechanical Student currently in my second year. It is very rare to find a girl pursuing this course. In fact, all my friends and well wishers too have advised me that it may be tough for a girl pursuing this course of study. I am a very stubborn girl very much firm in my opinion. For the recent past months, I fear that I may be having a breast cancer. I have lethal classes which I always found to be difficult. Of late, I could see a lump in the under arm area which is painful when touched. I fear that this may be due to the heavy workout which I had to do as per my curriculum. I have got so many dreams to be achieved in the near future and this worry is causing me greater concern that I am not able to concentrate in my studies and my performance in the college has also declined to the significant level. I feel that this needs to be diagnosed without any further delay. I also fear that if my case is diagnosed as Breast Cancer how can I achieve my dreams and lead a full-fledged life? Please advise me suitably….\nA. as jenniferLinda said -there's little to worry about. a lump under the arm can be from many things...there are lymph nodes over there and every viral infection can cause swelling. More discussions about dream","What Is Psychotherapy?\nPsychotherapy is a form of treatment that involves talking about your thoughts, feelings, and experiences with a trained professional. It’s a way to improve mental health, gain insight into your behavior, and learn how to cope with difficult situations. In psychotherapy, you can explore your feelings, beliefs, and behaviors in a safe, supportive environment.\nPsychotherapy can help with a variety of issues, including depression, anxiety, relationship issues, eating disorders, trauma, substance abuse, and much more. Through psychotherapy, you can gain insight into your emotions, thoughts, and behavior patterns, and learn how to make changes to improve your life.\nWhat Happens During Psychotherapy?\nThe specifics of what happens during psychotherapy vary depending on the type of therapy being used and the individual’s needs. Generally, psychotherapy involves talking about your experiences and feelings with a therapist. The therapist will listen to you and ask questions to help you gain insight into your behavior and thoughts.\nIn psychotherapy, you will learn about your condition and how it affects your moods, feelings, thoughts, and behaviors. You’ll learn about the causes of your condition, how to recognize triggers, and how to manage your symptoms. The therapist may also offer advice and provide guidance on how to navigate challenging situations and make meaningful changes in your life.\nBenefits of Psychotherapy\nPsychotherapy can provide a number of benefits, including:\n- Reduced symptoms: The goal of psychotherapy is to reduce or eliminate symptoms of mental health conditions. Through regular psychotherapy sessions, you can learn how to manage your symptoms and improve your overall mental health.\n- Improved relationships: Psychotherapy can help you build better, healthier relationships with yourself and with the people around you. You can learn how to communicate more effectively, develop empathy, and set healthy boundaries.\n- A greater sense of control: Psychotherapy can help you gain a greater sense of control over your life. You can learn how to identify triggers, manage your symptoms, and take charge of your own mental health.\n- Better coping skills: Psychotherapy can help you develop better coping skills for dealing with difficult situations. You can learn how to recognize and manage your emotions, think more clearly, and make healthier decisions.\n- Increased self-esteem: Through psychotherapy, you can gain a better understanding of yourself and your needs. This can help you build self-esteem and gain a greater sense of self-worth.\nTypes of Psychotherapy\nPsychotherapy can take many forms, depending on the individual’s needs and the therapist’s approach. Some of the most common types of psychotherapy include:\n- Cognitive-Behavioral Therapy (CBT): CBT is a type of psychotherapy that focuses on identifying and changing negative thoughts, behaviors, and emotions. It can help you recognize patterns of behavior and learn how to change them.\n- Interpersonal Therapy (IPT): IPT is a type of psychotherapy that focuses on relationships. It can help you identify and resolve conflict in relationships, understand how your relationships affect your mental health, and learn how to build healthier relationships.\n- Dialectical Behavior Therapy (DBT): DBT is a type of psychotherapy that helps you identify and manage emotions. It can help you learn how to regulate your emotions and cope with difficult situations in a healthy way.\n- Psychodynamic Therapy: Psychodynamic therapy is a type of psychotherapy that focuses on understanding the unconscious motivations that drive behavior. It can help you gain insight into your thoughts, feelings, and behavior patterns.\n- Family Therapy: Family therapy is a type of psychotherapy that focuses on improving relationships within the family. It can help families address issues, resolve conflicts, and improve communication.\nFinding the Right Psychotherapist\nWhen you’re looking for a psychotherapist, it’s important to find someone who is the right fit for you. You want to make sure that they have the experience and qualifications to provide the type of therapy you need. It’s also important to find someone you feel comfortable talking to and who you can trust.\nYou can start your search by asking your primary care doctor for a referral. You can also search online or ask friends and family for recommendations. Once you’ve narrowed down your list, you can call each therapist and ask questions about their experience and approach to psychotherapy.\nPsychotherapy is a form of treatment that can help you learn about your mental health condition, gain insight into your behavior, and learn how to manage your symptoms. It can also help you develop better coping skills, build healthier relationships, and increase your self-esteem. There are many different types of psychotherapy, and it’s important to find a therapist who is the right fit for you. With the right psychotherapist, you can learn how to take control of your life and manage your mental health in a healthy, productive way."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"sensitive"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:6f228744-5d66-4183-a51d-aeb4354b0dde>","<urn:uuid:260f9b08-b193-41ae-a561-31adcb125a8a>"],"error":null}
{"question":"How do modern power plants integrate preventive maintenance with operational cost management, and what are the key operating cost considerations across different generation technologies?","answer":"Modern power plants integrate preventive maintenance through consolidated technologies like oil analysis, vibration analysis, and thermography programs, which together enable early fault detection and long-term maintenance planning. The maintenance strategy includes proactive measures such as testing new oil deliveries for additive levels, viscosity, and contaminants before acceptance. Regarding operating costs, these vary significantly by generation technology: fossil-fuel plants are dominated by fuel costs, while nuclear plants have low fuel costs but higher labor and maintenance expenses. Renewable energy sources like wind and solar have operating costs less than $0.01/kWh, while coal and natural gas plants range from $0.02-$0.10/kWh. These operating costs must be managed alongside maintenance requirements to optimize overall plant performance.","context":["The PdM team of Palo Verde Nuclear Power Generation Station has a recipe for oil analysis success. Over the past several years they have documented several “saves” that could have potentially costed over $200,000.\nMuch of the success can be attributed to a consolidation of maintenance technologies. Early on, maintenance related technologies such as oil analysis, vibration analysis and thermography programs were isolated, each concentrating on maintaining and improving their individual programs. A company-wide re-engineering effort brought the three together into one predictive maintenance program, under one leader. The move resulted in better communication, synergy, and support between disciplines. Strong support from management helped the effort. This integration has led to improved fault detection, each technology picking up where the others leave off, with some overlapping.\nPrior to introduction of a Palo Verde lubricant test lab, the lubrication program used off-site services for all of its oil testing. The off site services testing effectiveness was limited by the nature of the very basic test package used and the limited understanding of the meaning of the data provided. The lubrication program was not able to function as effectively as the vibration program. That began to change with the decision to implement an on-site lubrication testing strategy.\nA comprehensive testing strategy was developed and instrumentation was purchased that allowed equipment condition monitoring well beyond the level previously supplied by the outside service. Microscopic evaluation techniques became routinely performed tests. Oil chemical condition monitoring was dramatically improved with test methods appropriately targeted to additive effects and depletion. With the enhanced technical capability and the use of a highly skilled and dedicated lab staff, the lubrication and vibration program obtained equal footing. With two independently strong programs available, true integration began.\nAn important monitored condition is in bearing failure forecasting. The vibration technology is seen as a better forecaster of late stage bearing failure while the lubrication program is better at identifying early stage bearing conditions. Wear begins at the micron size level and deposits itself in the lubricant. The defects are too small to cause a flaw that can be monitored with vibration techniques. Together, the programs are able to monitor a failure in excess of a year to failure. The long term planning has advantages in pre-planning and scheduling maintenance.\nWatching a failure progress over time has the added advantage of allowing ‘root cause’ evaluations in this power generation station. Wear debris in oil can be evaluated microscopically to establish probable failure mechanism such as fatigue, abrasion or lube failure. This information can often be correlated to a cause such as misalignment, unbalance or mechanical looseness. Data points from both technologies can help narrow the root cause of the condition.\nThe final step in completing the root cause is an examination of the parts after they have been removed. Severely degraded and worn parts are difficult to evaluate. Advanced wear often removes the evidence of the initial failure mechanism. If root cause evaluation is treated as an important part of a program, attempts should be made to remove machinery from service prior to advanced failure stages.\nThe on-site oil analysis program was expanded. The PdM team uses Rotrode Filter Spectroscopy to detect wear metals in the oil. If high ferrous content is detected, a ferrogram is made to help determine the source of the problem. If high non-ferrous content is detected, a filtergram is made using an eight micron membrane.\nA proactive strategy was initiated for all aspects of lubricants. Whenever an order of oil is delivered it is isolated and then tested before acceptance. Each oil is tested for additive level, viscosity and then a 100-ml sample of the oil is filtered through a 3-micron filter paper for less viscous oils and an 8-micron filter paper for more viscous oils to check for contaminants.\nEducation is a big part of the success at Palo Verde Power Generation. All mechanics have gone through continuing lubrication, vibration and thermography training.\nIn one year, the predictive maintenance department documented approximately $3.7 million in savings. Johnson points out that for every $1 dollar spent, at least $6.50 in maintenance costs has been saved over the last 3 years.\nRef: Johnson, Bryan, Maxwell, Howard, “Integration of Lubrication and Vibration Analysis Technologies”","Basic economics of power generation, transmission and distribution\nIn most industrialized countries, electric power is provided by generating facilities that serve a large number of customers. These generating facilities, known as central station generators, are often located in remote areas, far from the point of consumption. The economics of central station generation is largely a matter of costing. As with any other production technology, central station generation entails fixed and variable costs. The fixed costs are relatively straightforward, but the variable cost of power generation is remarkably complex. We will examine each of these in turn.\nThe fixed costs of power generation are essentially capital costs and land. The capital cost of building central station generators vary from region to region, largely as a function of labor costs and \"regulatory costs,\" which include things like obtaining siting permits, environmental approvals, and so on. It is important to realize that building central station generation takes an enormous amount of time. In a state such as Texas (where building power plants is relatively easy), the time-to-build can be as short as two years. In California, where bringing new energy infrastructure to fruition is much more difficult (due to higher regulatory costs), the time-to-build can exceed ten years. Table 5.1 shows capital cost ranges for several central-station technologies. Although the ranges in Table 5.1 are quite wide, they still mask quite a bit of uncertainty in the final cost of erecting power plants.\nOperating costs for power plants include fuel, labor and maintenance costs. Unlike capital costs which are \"fixed\" (don't vary with the level of output), a plant's total operating cost depends on how much electricity the plant produces. The operating cost required to produce each MWh of electric energy is referred to as the \"marginal cost.\" Fuel costs dominate the total cost of operation for fossil-fired power plants. For renewables, fuel is generally free (perhaps with the exception of biomass power plants in some scenarios); and the fuel costs for nuclear power plants are actually very low. For these types of power plants, labor and maintenance costs dominate total operating costs.\nIn general, central station generators face a tradeoff between capital and operating costs. Those types of plants that have higher capital costs tend to have lower operating costs. Further, generators which run on fossil fuels tend to have operating costs that are extremely sensitive to changes in the underlying fuel price. The right-most column of Table 5.1 shows typical ranges for operating costs for various types of power plants.\n|Technology||Capital Cost ($/kW)||Operating Cost ($/kWh)|\n|Coal-fired combustion turbine||$500 — $1,000||0.02 — 0.04|\n|Natural gas combustion turbine||$400 — $800||0.04 — 0.10|\n|Coal gasification combined-cycle (IGCC)||$1,000 — $1,500||0.04 — 0.08|\n|Natural gas combined-cycle||$600 — $1,200||0.04 — 0.10|\n|Wind turbine (includes offshore wind)||$1,200 — $5,000||Less than 0.01|\n|Nuclear||$1,200 — $5,000||0.02 — 0.05|\n|Photovoltaic Solar||$4,500 and up||Less than 0.01|\n|Hydroelectric||$1,200 — $5,000||Less than 0.01|\nBecause of the apparent tradeoff between capital and operating cost, comparing the overall costs of different power plant technologies is not always straightforward. Often times, you will see power plants compared using a measure called the \"Levelized Cost of Energy\" (LCOE), which is the average price per unit of output needed for the plant to break even over its operating lifetime. We will discuss LCOE in more detail in a future lesson - it is an extremely important (and often-used) cost metric for power plants, but it has its own problems that you will need to keep in the back of your head.\nIrrespective of technology, all generators share the following characteristics which influence the plant's operations:\n- Ramp rate\nThis variable influences how quickly the plant can increase or decrease power output, in [MW/h] or in [% of capacity per unit time]\n- Ramp time\nThe amount of time it takes from the moment a generator is turned on to the moment it can start providing energy to the grid at its lower operating limit (see below), in [h]\nThe maximum output of a plant, in [MW]\n- Lower Operating Limit (LOL)\nThe minimum amount of power a plant can generate once it is turned on, in [MW]\n- Minimum Run Time\nThe shortest amount of time a plant can operate once it is turned on, in [h].\n- No-Load Cost\nThe cost of turning the plant on, but keeping it \"spinning,\" ready to increase power output, in [$/MWh]. Another way of looking at the no-load cost is the fixed cost of operation; i.e., the cost incurred by the generator that is independent of the amount of energy generated.\n- Start-up and Shut-down Costs\nThese are the costs involved in turning the plant on and off, in [$/MWh].\n|Technology||Ramp Time||Min. Run Time|\n|Simple-cycle combustion turbine||minutes to hours||minutes|\n|Combined-cycle combustion turbine||hours||hours to days|\n|Nuclear||days||weeks to months|\n|Wind Turbine (includes offshore wind)||minutes||none|\n|Hydroelectric (includes pumped storage)||minutes||none|\nThe minimum run time and ramp times determine how flexible the generation source is; these vary greatly among types of plants and are a function of regulations, type of fuel, and technology. Generally speaking, plants that are less flexible (longer minimum run times and slower ramp times) serve base load energy, while plants that are more flexible (shorter minimum run times and quicker ramp times) are better-suited to filling peak demand. Table 5.2 and Figure 5.3 show approximate (order-of-magnitude) minimum run times and ramp times for several generation technologies. It is important to realize that, in some sense, these are \"soft\" constraints. It is possible, for example, to run a nuclear plant for five hours and then shut it down. Doing this, however, imposes a large cost in the form of wear and tear on the plant's components.\nThe cost structure for transmission and distribution is different than for power generation, since there is basically no fuel cost involved with operating transmission and distribution wires (and their associated balance-of-systems, like substations). At the margin, the cost of loading a given transmission line with additional electricity is basically zero (unless the line is operating at its rated capacity limit). Capital cost thus dominates the economics of transmission and distribution."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:22ab4828-7f36-4334-88f0-d576f53c2e40>","<urn:uuid:f0adad7d-89e2-4843-84d4-1efb3fae8547>"],"error":null}
{"question":"What are the respective guidelines for women's attire when comparing cocktail dress code versus black tie and white tie events?","answer":"For cocktail attire, women typically wear knee-length dresses, though they can also opt for elegant pantsuits, jumpsuits, or a skirt and blouse combination. The dress should not be too short, too long, scant, or translucent. In contrast, for black-tie and white-tie events, women are expected to wear floor-length evening gowns. While black-tie asks for traditional and refined clothing, white-tie events for women follow similar guidelines to black-tie, with the option to add long gloves, particularly when arriving at the event or exchanging handshakes. The key difference is that cocktail attire allows more flexibility in length and style, while both black-tie and white-tie require full-length gowns.","context":["Cocktail attire is a type of clothing that is suited for wearing to parties and other semi-formal events such as weddings. For women, this often entails wearing dresses and high heels, however this is not required in any way.\nWhat do you wear to a cocktail party?\n- Cocktail attire in the traditional sense. Generally speaking, cocktail clothing is regarded as being less formal than formal wear, but not too casual. This type of costume is similar to but usually somewhat less formal than semi-formal wear. For males, it normally means a dark suit or trousers and sport coat\n- for ladies, it typically means a cocktail dress or a lovely shirt and skirt.\n- 1 What is women’s cocktail attire 2020?\n- 2 What is an example of cocktail attire?\n- 3 What should a woman wear to a cocktail bar?\n- 4 Why is it called cocktail attire?\n- 5 Are pants OK for cocktail attire?\n- 6 Is a pencil skirt cocktail attire?\n- 7 What should you not wear to a cocktail party?\n- 8 What is after 5 attire for a woman?\n- 9 What length is a cocktail dress?\n- 10 Can I wear a long dress to a cocktail party?\n- 11 What is beach cocktail attire?\n- 12 Is a black suit OK for cocktail attire?\n- 13 Is cocktail attire the same as semi-formal?\n- 14 What is black-tie attire for a woman?\nWhat is women’s cocktail attire 2020?\nCocktail dresses are normally knee-length, while certain more formal occasions may necessitate a longer piece, albeit not necessarily one that is floor-length. As an alternative, a classic little black dress or a shirt and skirt/pants ensemble can be worn to a cocktail party.\nWhat is an example of cocktail attire?\nCocktail clothing is defined as a suit in a dark color, ideally navy or charcoal, with a white shirt, a pair of black leather dress shoes, and a tie, to name a few essential elements. You may deviate from this form only if the invitation specifically requests that you do so.\nWhat should a woman wear to a cocktail bar?\nWhat Should a Woman Wear to a Cocktail Party? As a basic rule of thumb, a cocktail dress cannot be too short or too long; it also cannot be scant, translucent, or too short. A-line, strapless, embroidered, lace, or long-sleeved midi dresses are also good choices, as are traditional little black dresses (LBD).\nWhy is it called cocktail attire?\nCocktail wear strikes a balance between being formal and informal, as well as being stylish and comfy. When attending an event with this dress code, such as a wedding, males often wear a suit and tie, and women typically wear a cocktail dress. Wedding consultant LauraLee Baird argues that “cocktail attire” is intended to bridge the gap between day and nighttime wear.\nAre pants OK for cocktail attire?\nWomen may, in fact, dress appropriately for a cocktail attire event by wearing the appropriate trousers. Wear an exquisite pantsuit with high-heeled shoes and a formal women’s top to elevate your pantsuit from the office to the cocktail hour. Wearing wide-legged or cropped ankle dress pants with a dressy shirt is another option you might consider.\nIs a pencil skirt cocktail attire?\nIt is true that a pencil skirt is not acceptable for all cocktail parties, but it is appropriate for the great majority of them.\nWhat should you not wear to a cocktail party?\nAs a general guideline, avoid wearing both maxi and short dresses and instead choose something in the middle of the spectrum. While a cocktail dress is appropriate for the occasion, jumpsuits, pantsuits, blazers, and blouses made of high-quality fabrics are all suitable options for the occasion.\nWhat is after 5 attire for a woman?\nWomen’s After-Five Attire might be casual, semi-formal, or formal. If the occasion is in the evening, opt for a cocktail dress or a set of beautiful pieces. If it’s a midday semi-formal affair, opt for a knee-length dress, a dress suit, or fancy pieces to spice up the occasion.\nWhat length is a cocktail dress?\nIf you question different people about the right length for a cocktail dress, you will get different answers. For the most part, these dresses are knee-length or somewhat shorter, with longer gowns for more formal parties and shorter cocktail dresses for formal or semi-formal occasions.\nCan I wear a long dress to a cocktail party?\nIn most cases, cocktail wear consists of knee-length skirts with stylish heels and a basic suit. When dressed properly, a maxi dress may easily pass for suitable cocktail wear, regardless of the color and fabric of the dress, as well as the haircut and accessories you choose to go with it.\nWhat is beach cocktail attire?\nSemi-formal/cocktail party on the beach Dresses, suits, dressy rompers, and jumpsuits are all appropriate for semi-formal occasions. Feel free to incorporate prints, but avoid anything that is too loud. Consider wearing a beachy dress that is either tea-length or maxi-length in order to prevent seeming too casual.\nIs a black suit OK for cocktail attire?\n4) Cocktail Dress Code It is still formal, but it allows you a bit more flexibility in terms of design. You may dress up your tie with a stylish design, and in rare circumstances, you can wear colorful socks. Suits and ties, on the other hand, should always be in dark colors, never black (unless you’re a priest, of course).\nIs cocktail attire the same as semi-formal?\nCocktail. This is a step up from semiformal, yet it is not as formal as black-tie. Cocktail clothing, whether optional or formal, is a common choice for dress codes. Instead of wearing a floor-length dress, women could go for a tea-length, knee-length, or midi-length gown instead. Regardless of where the wedding will take place, men are expected to dress in a suit and tie.\nWhat is black-tie attire for a woman?\nA black-tie dress code is formal and asks you to dress in clothes that is both traditional and refined. Women should wear an evening gown or a floor-length dress for this occasion. You should avoid wearing anything that is too short, too exposing, or too loud and vivid in color.","Fashion is all about expressing yourself and sending a powerful message without uttering a single word. The choice of attire for an event speaks volumes about its nature and significance. For a formal event, two styles fit the occasion perfectly well. We have the distinguished black tie and the prestigious emblem of elegance, the white tie. Both dress codes have deep-rooted traditions and are reserved for exclusive formal events.\nBefore going to any event, you must find out what it is about so you can dress well for it. Most invitations will give you the dress code, but you can ask the organizers if you need to know. So to understand these two styles better, this article takes you through black tie vs white tie and all you need to know, plus how to dress up for the occasion.\nBlack Tie Attire\nThe rules for wearing black tie attire for a formal event are the same. Always keep it simple and fantastic. Unlike white tie attire, which has specific dress code requirements that must be strictly adhered to, black tie attire for men does not follow a rigid pattern.\nWhile still trying to keep your appearance simple, you should also look formal. This includes pants, shoes, and blazers. You can choose from various footwear, such as leather shoes, loafers, derbies, and oxfords to pair with. A great way to wear your black tie white shirt is with a tuxedo shirt, bow tie, and formal black shiny shoes. With a combination of a black tuxedo, a white shirt, and a pair of black shoes, you will look incredibly handsome and ready for the occasion.\nWhite Tie Attire\nThe white tie dress code speaks of a highly formal event. On occasions like galas, balls, Uber-formal weddings, state banquets, etc., where white tie attire is applicable, black tie attire is rarely seen. To dress well with white tie attire, you must know how to pair the tie correctly with the right outfits.\nFor example, the white tie dress code that can serve as inspiration includes white waistcoat, white tux shirt, black tux pants, and black tailcoat. You can add accessories to enhance your looks, like a black belt, black leather shoes, and a white tie. Other accessories accompanying this dress pattern are a top hat, gloves, wristwatch, and black belt.\nThe Origin of Black Tie and White Tie Attire\nBoth attires became a fashion item in vogue in the 19th century. The white tie attire also referred to as the Full Evening Dress, was a popular dress code worn in the Victorian Era. It was used by elites, royals, and highly placed individuals in society for important events.\nBlack tie attire, which is often called a \"Tuxedo or Dinner jacket,\" is a style that started in the US. It is a more relaxed version of the white tie but still retains its sophistication and formality. By wearing a black tie attire, you bypass the formal tailcoat associated with the white tie dress code and tone it down with a more relaxing look.\nWhen black tie attire became a fashion item, it was a common clothing attire men wore to semi-formal and social events. But since then, black and white tie attire has been a part of the formal culture and dress sense. They have crossed times, seasons, and social boundaries to be a part of our everyday style. In modern times both black and white tie attires exude a timeless appeal together with refined style and an expression of formal fashion.\nBlack Tie Vs White Tie Attire\nA white tie attire is a prestigious clothing used for special formal events. Both white and black tie are considered formal attire for men, but white tie attire is ahead of black tie attire in formality. While you may wear any of these outfits, there are some things to note regarding the white tie vs black tie event dress code.\nOne thing to remember when considering white tie vs black tie attire is their specifics in outfitting. For instance, the classic all-black suit ensemble exudes sophistication and elegance. Another option is pairing a black suit with a white tie, creating a refined and formal look. Conversely, the white tie on white shirt, along with black suit showcases a timeless and distinguished appearance.\nWhen comparing black tie and white tie attire, there are various style options to explore. The black tie tuxedo is a classic formal attire that exudes elegance and sophistication. It typically consists of a black dinner jacket, black trousers, a crisp white dress shirt, a black bow tie, and polished black shoes. On the other hand, the white tie tuxedo, also known as \"full dress,\" is the epitome of formalwear. It features a black tailcoat, matching trousers with satin stripes, a stiff white wing-collar shirt, a white bow tie, and patent leather shoes. It is the most formal and traditional option, reserved for prestigious events and high-level occasions.\nWhite tie attire exudes an aura of elegance and astute formality reserved for high-profile events in a state and exclusive functions. Black tie attire allows for more flexibility and comfort in formal settings and occasions.\nWhite Tie Events\nWhen it comes to highly formal events, the first attire that likely comes to mind is formal black tie attire. However, it's worth noting that the white tie event surpasses it as the epitome of formality. Did you know that attending a white tie event is considered the utmost level of formal elegance?\nIn most Western societies, a white tie event is the most prestigious event ever, and a white tie is used to show its uniqueness. Nowadays, white tie attire is dedicated to special occasions like royal ceremonies, exclusive banquets, or state events.\nIf an event is tagged as white tie, it is used to show the caliber of the guests invited and how formal the occasion will be. The dress attire for a white tie event is unique and traditional. Here is an idea of how to dress up for the event:\n- A white tie or bow tie\n- An evening tailcoat with more pronounced lines than the usual morning tailcoat.\n- High-waisted tailored trousers with a double-lined braid\n- A Crisp evening white shirt with being collars\n- An evening waistcoat\n- Black leather shoes and black socks\n- Additionally, a cane, hat, white gloves, wristwatch\nBlack Tie Events\nA black tie event is a typical formal event in modern society, encompassing events such as weddings, awards nights, galas, and more. Attending these events requires men to don a formal attire known as \"black tie for men.\" This attire typically includes a blazer, shirt, bow tie, and appropriate shoes.\nTo add more embellishments to your attire for black tie event , accessories like pocket squares, cufflinks, and wristwatches can be worn. Despite the name \"black tie,\" it's important to note that the attire doesn't have to be entirely black. Colors like brown, gray, blue, and others are acceptable, but the tie itself must be black.\nBlack Tie Optional\nUnderstanding the meaning of \"black tie optional\" is essential when decoding formal dress codes. Events referred to as black tie optional have their formality toned slightly less than what you have in black tie events. Occasions like weddings are described as black tie optional events. Simple dressing like a pair of jacket on trousers with a tie instead of a regular tie will suffice.\nSometimes, the tie is unnecessary, and you can lose it entirely. Ensure that your color combinations are simple and blend when combined. Colors like Navy blue or black pants and a white or light blue shirt will be a perfect fit for a black tie optional. Wearing accessories like cufflinks are often optional as most men leave the accessories to differentiate between themselves and the groom.\nFrequently Asked Questions\nWhat is the Best Occasion to Wear a Black Tie Attire?\nA black tie attire is a straightforward fashion dress code with different formal and semi-formal events. Their versatility makes them the perfect attire for formal events like dinners, weddings, galas, etc. Even though they are worn to formal events, they are still relaxed and comfortable to the wearer without appearing too formal.\nCan I substitute a White Tie Attire for a Black Tie Attire?\nWhile both white tie and black tie attire are formal, they are distinct and should not be substituted for one another. Wearing a black tie attire in place of a white tie attire is not suitable because they have different dress codes and are intended for different settings. White tie attire adheres to strict rules of formality, and wearing black tie attire instead would be inappropriate for the occasion. Similarly, wearing white tie attire to a black tie event would appear overly formal and out of place. It's important to respect and adhere to the specific dress code requirements for each type of event.\nWhat is the Best Way to Wear a Black Tie and White Tie Attire?\nThe best way to wear a black tie attire is to opt for a well-tailored black tuxedo, a crisp white dress shirt, a black bow tie, and polished black dress shoes. Ensure that the jacket fits properly, the bow tie is neatly tied, and the trousers are tailored to the correct length. When it comes to white tie attire, the key is precision and attention to detail. Wear a perfectly tailored black tailcoat with matching trousers featuring satin stripes, a stiff white wing-collar shirt, a white bow tie, and patent leather shoes.\nWhat Accessories are Best Suited for a Black Tie and White Tie Attire?\nBoth attires look great with accessories, but each has the dress code accessories that fit each attire. You can use a pocket square, cufflinks, belt, or wristwatch to accessorize your outfit in black tie attire. White tie attire does not require many accessories like black tie attire. For white tie attire, accessories like white bow tie, a white waistcoat, and a top hat can enhance your look.\nWhat is White Tie Attire for Women?\nWomen's white tie dress code is not as rigid as men's. For women, it's almost the same as black tie attire. For a white tie attire for women, the ladies can wear a full-length ball gown with a fitted bodice. Sometimes, women wear long gloves for white tie balls, but it's not compulsory. The gloves are usually worn when guests arrive or for exchanging handshakes during the event.\nWhat is White Tie Wedding Attire?\nWhite tie wedding attire is probably the highest display of a formal wedding ceremony. This tradition was a common practice over two decades. It originated from Western evening wear and is used mainly in royal weddings."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:9944af2b-979b-4632-b4f1-9c87a5c7d42d>","<urn:uuid:c7e9bb37-fb32-4105-91f0-91b391588eb5>"],"error":null}
{"question":"How do Automatic Identification System (AIS) and Sentinel-1 radar systems differ in their ability to track ships, particularly considering that ships can disable AIS?","answer":"AIS and Sentinel-1 radar systems have distinct capabilities in ship tracking. AIS works through transponders on ships that automatically transmit vessel information including position, identity, and other data. However, AIS trackers can be switched off by the crew. In contrast, Sentinel-1's C-band SAR radar detection cannot be disabled since it operates from 693 km above sea level, detecting ships by capturing the strong radar signals that bounce back from vessel surfaces compared to the darker sea surface. While AIS provides more comprehensive tracking of all types of ships (including smaller vessels) at all times rather than just at specific satellite pass times, Sentinel-1 offers the advantage of unavoidable detection regardless of crew cooperation.","context":["ARIS: Automatic Reporting and Identification System (1987 – 2000)\nIn 1956, Rotterdam was the first port with a radar system for the guidance of shipping, the ‘walradarketen’. This (then modern) but rather simple system was less and less capable of keeping up with the intensification of shipping. Moreover, the system could not support the operators in determining the identity of the vessels better and more clearly for safety reasons and to link them to the radar echoes. When it was decided to replace the system at the beginning of the 1970s, the identity question came up for discussion. Philips Netherlands conducted a trial with a secondary radar system. Transmission pulses from that system were received by a special receiver on the target (vessel). This receiver is triggered and sends back a (secret) code that is captured by the secondary radar antenna. The test itself was successful, but the consequences of introducing such a system would mean that all ships that would call at the port of Rotterdam would have to have a (then quite large) box on-board to respond to the secondary radar signals. At that time, the system could be implemented. Another major disadvantage was that it would work to identify vessels from shore, but not from ships because radar systems on board did not lend themselves to the installation of an extra antenna for the secondary radar. The shore radar system in Rotterdam was therefore equipped with automatic radar extractors. A radar extractor makes it possible to determine the position, dimensions, etc of a ship can be digitally determined from the radar signal and linked to identity information that is automatically entered from a computer or manually by an operator. This did quite well for isolated targets. In practice, however, it turned out to have a number of limitations when targets are close to each other or cross at a short distance. Identity change or even loss of identity (label) is then the result. This problem not only occurred in Rotterdam but in all comparable vessel traffic control systems that had been built in the meantime.\nOn board of ships, radar was meanwhile good to get a traffic picture on the bridge, even in bad weather conditions and on the open sea. Here too, the question arose as to the identity of the vessels in the vicinity to come to traffic safety arrangements. In addition, the position of one’s own ship became increasingly available through systems such as Decca, Loran-C and the emerging GPS.\nAutomatic Reporting and Identification System (ARIS)\nIn 1985, the International Maritime Organization (IMO) resolution A.578, ‘Guidelines for Vessel Traffic Services‘ stated that ship identification may be supported by technical means; in other words, the legal basis for a form of transponder technology was laid. At the end of 1987, this was a reason for the then Directorate-General for Shipping and Maritime Affairs (DGSM) of the Ministry of Transport, Public Works and Water Management (V&W) to ask TNO-FEL for researching the feasibility of an identification system for shipping based on VHF or UHF radio communication. The system should be a support for operators in a traffic control system. The system should also be suitable for the mutual identification of vessels.\nTNO-FEL then designed the Automatic Reporting and Identification System (ARIS) in accordance with the WG3 requirements of the IALA-VTS commission. The ARIS concept consists of a relatively simple transponder on board each ship and a shore station that has radar coverage.\nThe operation of ARIS can be explained easily. When entering the VTS area, the position of the ship can automatically be detected by radar and used as input for the ARIS shore equipment to initiate an identification request via the VHF radio connection. Periodically, the coastal system of ARIS will interrogate the ‘approach area’ of the VTS to identify ships that have not yet been detected by the radar system. In this way, new ships will automatically be taken over in the traffic image without any manual actions from the operator. But, if an operator wants to identify a target in a Vessel Traffic Services (VTS) centre (ship traffic coordination centre), he/she will point the target to a radar screen (using a mouse or light pen). Because radar knows the position of the ship, the position of the target is transmitted in an ARIS message. All ships with an ARIS transponder receive this message. Only the ship that is at that position with a certain tolerance will send a message back with the identity (name, call sign) as the most important information. However, this mechanism can also be used to transfer other additional information such as course, speed, draft, destination, etc.\nThe onshore equipment translates the response to computer data that can be presented as readable text and/or in graphical form on the ARIS monitor. Displaying ships equipped with ARIS on an electronic chart or ECDIS is also possible. When ARIS is integrated with the VTS system, the position data can be used to construct the ship traffic chart; the additional data can be used in an information processing system. The system is particularly valuable in busy harbour lanes and can even be used in areas with a radar breakdown or in coastal waters where no advanced VTS system is available.\nThe ARIS demonstration system developed by TNO consisted of a VHF transmitter at the VTC and several ship transponders. A number of operational tests were carried out in IJmuiden, Hoek van Holland and later Vlissingen. This made ARIS the first maritime radio transponder system in the world. The aim of the tests was to demonstrate the added value of the transponder technology in a maritime traffic environment.\nDuring the trials, a number of presentations were given to the international maritime community. With this, DGSM has opened international discussions within IMO and other organisations about the introduction of maritime transponders for shipping. However, discussions within IMO about the (mandatory) introduction of a new system always take a long time because an agreement has to be reached with all member states.\nSystem configurations: The ARIS shore-based equipment can be implemented in a variety of configurations:\n- ARIS in combination with, and completely integrated in a VTS system (for operational actions and the presentation of ARIS data).\n- ARIS combined with a standard radar system (in a simple VTS environment). A target position marker is shown on the radar screen.\n- ARIS as a stand-alone system (for logistics and planning). The ARIS monitor shows the data of the replies of the identified vessels received.\nARIS was developed with an idea, a vision, but without a preconceived position. There was nothing, no free frequency for the broadcast of ARIS messages, no communication protocol, no standard and a limited technical package of requirements. Everything was developed by TNO-FEL using the then state-of-the-art technologies.\nARIS could, with some limitations, also be used in a ship-ship mode. This means that ships can also question each other’s identity. However, at the moment most ships still have insufficient possibilities on their radar to designate another ship and to offer the position in digital form to the ARIS transponder.\nBut there was more going on in IMO. For the “Global Maritime Distress and Safety System” (GMDSS) a new digital communication protocol was introduced that works with analogue modem technology: “Digital Selective Calling” (DSC), based on the CCIR (currently UN / ITU) recommendation 825. DSC is designed to exchange information from ship to country and from ship to ship. For the exchange between ship and shore, three different types of information are distinguished:\n- Static information: call sign, type of ship, etc. and will normally be programmed into the shipborne ARIS equipment.\n- Variable information: this includes load, actual draught, and destination. It will be determined per voyage and will often be available via the ship’s computer system.\n- Dynamic information: for example position and course. Dynamic information has to be constantly adjusted and can be accessed through the navigation equipment such as Global Positioning System (GPS).\nAll three information types can be used simultaneously in order to obtain clear identification.\nThe maritime community thought it desirable to introduce the future transponder system using the DSC protocol as a basis. That was not a problem, it did not affect the functional functioning of the transponder. That is why an international standard was drawn up for the new transponder technology based on DSC. Then negotiations between the member states about the global introduction started; a process that easily could take ten years. In Scandinavia, very busy with the introduction of GSM, one got the idea that the underlying technology was very attractive for transponder technology, but without a network, without a service provider. And so the idea is born for the “Self Organized Time Domain Multiple Access” (SOTDMA) technique as a communication standard.\nIn parallel to these developments, TNO-FEL created the technical specifications for the harbour approach system (HAvenNAderingsSysteem or HANAS) for the pilots of the Rotterdam harbour in 1994/95. HANAS which became operational in 1997 and was based on differential GPS (DGPS). HANAS was the successor of the Decca-based Brown Box system.\nAutomatic Identification System\nThus the idea of the “Automatic Identification System” (AIS) is suggested, which. after years of discussion, was also accepted by IMO in 2000. The objective was to make AIS mandatory from 2002 onwards, in phases, until 2008. But that meant that the idea had to be further developed from a global description to a specification. An international standard had to be set up, agreements had to be made to free up frequencies within the International Telecommunication Union (ITU), guidelines had to be put on the use and installation on board and much more.\nThe Ministry again relied on TNO-FEL because TNO had developed ARIS and had the technical knowledge. They asked TNO to be present in international working groups of the International Association of Maritime Aids to Navigation and Lighthouse Authorities (IALA), the International Electrotechnical Commission (IEC), and ITU. On behalf of V&W, TNO had to actively cooperate with the further development and operationalisation of AIS. Naturally, Dutch interests had to be taken care of. IALA would ultimately play the leading role in this development, also because it links the shipping industry and the world of traffic management.\nThen 9/11/2001 happened, after which the identification of ships was given a dominant place in society. Everything has to be speeded up. As of January 1, 2005, every seagoing merchant ship must have AIS on board. AIS is no longer just a contribution to safety but has also become a ‘security’ obligation.\nAIS is a success: see www.marinetraffic.com or the AIS web page of Scannernet. Those pages show the current positions and movements of sea vessels around the world. Moreover, after the transponders for seagoing vessels and shore stations, special AIS versions have been developed for recreational shipping and inland navigation. We also see transponders for use on lighthouses, buoys and other maritime objects (such as marking wrecks, oil platforms and wind farms at sea). Special transponders for Search And Rescue (SAR) planes, transponders for satellite observation, for lifesaving and man-over-board transponders, in short AIS plays a role in the maritime community that can not be disregarded.\nTNO’s role with AIS has ended, but TNO has been at the basis of this development, laid the foundation stone, and made an important contribution to this successful development internationally.","When a (big) ship is illuminated by Sentinel-1 C-band SAR, it returns a strong signal back to the antenna and therefore a bright spot is captured. In contrast, the sea surface causes a smaller coherent scattering: the radar waves bounce off the water surface in many directions and thus only a small fraction of the energy return to the antenna, which explains why the sea looks much darker.\nIn Google Earth Engine it's straightforward to generate such a max composite using the function ee.ImageCollection.max(). Here the max composite was done after filtering the Sentinel-1 GRD collection to get images from a similar look angles (in this case ascending node). Hence it provides a snapshot of ships density at the overpass time of Sentinel-1 at 6 pm local time (England). We can compare to the same composite made with descending orbits only i.e. 6 am.\nThe differences in the area near Calais and Dover may be due to the fact that there's a P&O ferry leaving Calais at 5:45 which is still near the French coast at 6am, while a ferry leaves Dover at 5:30 which is already farther off the English coast in the 6 am image. On the other hand, a ferry leaves Calais at 5:55 pm, therefore it is still very close to the port of Calais at Sentinel-1 overpass time. It's fun too look at other straits with the same method...\nSea of Marmara\nIn the Sea of Marmara the traffic is dense between the Bosphorus and Dardanelles straits. However, there is an intriguing dark area around İmralı island. This is because there is a military base and a maximum-security prison on the island...\nA nice one spotted by Michel Le Page: the southern entrance of the Suez canal, one of the world's most heavily used shipping lanes:\nThe bright areas beside the main stream of ships are anchorage areas for ships waiting to enter the canal...\nMississippi River delta\n- Ship detection using SAR imagery can be a bit more complex. In particular a challenge is to deal with interferences from ground sources and SAR ambiguities which create \"ghost ships\" [1,2,3]. However, mass processing of Sentinel-1 data accounting for this effect has been done for maritime surveillance in the Mediterranean sea.\n- If you are a GEE user and would like to play with these composites here is a quick-start script: https://code.earthengine.google.com/522465700ba56fadc5814ac457219d85).\n- The shipping lanes can also be visualized using Automatic Identification System (AIS) data (an automatic tracking system on ships) as done by Marine Traffic. AIS data are emitted by all kind of ships (even small ships that may not be detected by Sentinel-1) and not only at 6am or 6pm. However, an AIS tracker can be switched off, whereas the Sentinel-1 radar at 693 km above sea level is out of reach... It seems that a Greek startup SatShipAI is building a tool to automatically identify ships using Sentinel-1 data. A new challenge for the yellow vests?\n- Wikipedia article on Environmental impact of shipping: \"The International Maritime Organization estimates that carbon dioxide emissions from shipping were equal to 2.2% of the global human-made emissions in 2012 and expects them to rise 50 to 250 percent by 2050 if no action is taken\""],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:12595362-190d-4af1-b6ad-d61cec737b5d>","<urn:uuid:4cdf665c-1222-4c72-8b08-e2e06cb35a85>"],"error":null}
{"question":"How does the compression behavior of Ultra High Performance Concrete compare to regular concrete, and what practical architectural applications showcase its structural advantages?","answer":"UHPC demonstrates superior compression behavior under high strain rates of 101 s-1 to 103 s-1, with testing showing significant strength increases quantified by dynamic increase factors between 1.85 and 2.09. These enhanced properties are being practically applied in innovative architectural projects, such as the Dutch observation tower where UHPC's high density and steel fiber reinforcement allow for impressive cantilevered structures. The material is specifically used in areas with high compressive stresses, while steel is employed where tensile stresses are predominant.","context":["Off-campus Michigan Tech users: To download campus access theses or dissertations, please use the following button to log in with your Michigan Tech ID and password: log in to proxy server\nNon-Michigan Tech users: Please talk to your librarian about requesting this thesis or dissertation through interlibrary loan.\nDate of Award\nMaster of Science in Civil Engineering (MS)\nCollege, School or Department Name\nDepartment of Civil and Environmental Engineering\nTheresa M. Ahlborn\nThe need for a stronger and more durable building material is becoming more important as the structural engineering field expands and challenges the behavioral limits of current materials. One of the demands for stronger material is rooted in the effects that dynamic loading has on a structure. High strain rates on the order of 101 s-1 to 103 s-1, though a small part of the overall types of loading that occur anywhere between 10-8 s-1 to 104 s-1 and at any point in a structures life, have very important effects when considering dynamic loading on a structure. High strain rates such as these can cause the material and structure to behave differently than at slower strain rates, which necessitates the need for the testing of materials under such loading to understand its behavior.\nUltra high performance concrete (UHPC), a relatively new material in the U.S. construction industry, exhibits many enhanced strength and durability properties compared to the standard normal strength concrete. However, the use of this material for high strain rate applications requires an understanding of UHPC’s dynamic properties under corresponding loads. One such dynamic property is the increase in compressive strength under high strain rate load conditions, quantified as the dynamic increase factor (DIF). This factor allows a designer to relate the dynamic compressive strength back to the static compressive strength, which generally is a well-established property. Previous research establishes the relationships for the concept of DIF in design. The generally accepted methodology for obtaining high strain rates to study the enhanced behavior of compressive material strength is the split Hopkinson pressure bar (SHPB).\nIn this research, 83 Cor-Tuf UHPC specimens were tested in dynamic compression using a SHPB at Michigan Technological University. The specimens were separated into two categories: ambient cured and thermally treated, with aspect ratios of 0.5:1, 1:1, and 2:1 within each category. There was statistically no significant difference in mean DIF for the aspect ratios and cure regimes that were considered in this study. DIF’s ranged from 1.85 to 2.09. Failure modes were observed to be mostly Type 2, Type 4, or combinations thereof for all specimen aspect ratios when classified according to ASTM C39 fracture pattern guidelines. The Comite Euro-International du Beton (CEB) model for DIF versus strain rate does not accurately predict the DIF for UHPC data gathered in this study. Additionally, a measurement system analysis was conducted to observe variance within the measurement system and a general linear model analysis was performed to examine the interaction and main effects that aspect ratio, cannon pressure, and cure method have on the maximum dynamic stress.\nVanSlembrouck, Daniel J., \"COMPRESSION BEHAVIOR AT HIGH STRAIN RATE FOR AN ULTRA HIGH PERFORMANCE CONCRETE\", Master's report, Michigan Technological University, 2015.","Dutch architects UNStudio have designed a concrete observation tower to cantilever into the sky above a nature reserve in the Netherlands.\nThe 25 metre-high tower will be primarily constructed from a high-performance concrete that the studio has been researching alongside engineers ABT, developer BAM Utiliteitsbouw and concrete manufacturer Haitsma Beton.\nThis dense concrete strengthened by steel fibres will enable the impressive cantilever, while embedded steel members will provide additional stability.\nVisitors will climb 134 steps to reach the highest of the tower’s three viewing platforms, which will be positioned five metres above the surrounding forest canopy.\nClick above for larger image\nA steel mesh parapet will create a balustrade for the staircase and platforms.\nHere's a project description from UNStudio:\nUNStudio’s design for an Observation Tower for ‘De Onlanden’ presented to Natuurmonumenten\nOn September 22nd the design for an observation tower for the nature reserve ‘De Onlanden’, situated to the South-West of the City of Groningen, was presented to Natuurmonumenten (the Dutch Society for the Preservation of Natural Heritage) during the mini-symposium ‘Experience Nature with innovative concrete’ in Peize. The observation tower is the result of a study into the optimal application of Ultra High Performance Concrete by a case study team comprising of UNStudio, ABT, BAM Utiliteitsbouw en Haitsma Beton. Natuurmonumenten received the design as a gift from the case study team.\nCase Study Observation Tower Ultra High performance Concrete\nThe design for the observation tower is the result of a case study which aimed to apply the characteristics of Ultra High Performance Concrete in a functional, operative design. The case study team consisted of designers, engineers and builders who together sought a solution through which architecture and construction could reinforce one another. According to Ben van Berkel, “The observation tower afforded our Inventive Materials Research Platform the opportunity to investigate the properties of Ultra High Performance Concrete and to truly test out the full potential of this new material in a real structure.” Ultra High performance Concrete differs from normal concrete as it has a very high density, contains steel fibres and has an extremely fine grain structure. These properties facilitate the application of large compressive stresses in structures of narrow dimensions. UNStudio’s Inventive Materials Platform is one of four in-house research platforms and aims to investigate custom-made material applications and to facilitate inspired and imaginative collaborations with other experts and with manufacturers in the construction industry.\nThe Observation Tower\nThe 25 metre high observation tower will be realised on the forested boundary of ‘De Onlanden’ nature reserve on the outskirts of Groningen. Once built, the tower will extend 5 metres above the trees and will offer views over the 3,000 hectares of natural landscape which form the largest water storage area in the Netherlands.\nThe design for the observation tower guides visitors in a fluid ascent up the 134 steps to the highest viewing point. Visitors are lead via the first set of steps to the lower viewing platform which stands at a height of 10 metres. Following this, the second set of steps provides a turn in direction, allowing for an alternative view of the surrounding forested pastures. These steps lead visitors through the tree tops to the second viewing platform which stands at a height of 20 metres and offers views over the nature reserve around the city of Groningen. The highest viewing platform, at a height of 24 metres, is reached via the final set of steps and offers visitors a wide open vista of ‘De Onlanden’ nature reserve.\nBy means of changes in direction in the structure of the observation tower, visitors can experience views of the surrounding natural landscape from different perspectives, whereby the height of each viewing platform offers a different experience of the vistas over the surrounding landscape. From the highest viewing platform views are afforded of the Groningen skyline, which includes the Education Executive Agency & Tax office building which was also designed by UNStudio.\nBen van Berkel: “The Netherlands enjoys a rich and textured natural landscape, but unfortunately the Dutch topography is not very varied; we don’t have mountain ranges, or many hilly areas from which to enjoy a panoramic overview of our natural surroundings. The viewing tower for ‘De Onlanden’ was designed to provide the opportunity to create a new awareness and different perspectives of the landscape we move through, but may otherwise never experience in all its scope.”\nThe fine lines and the form of the tower bring to mind the silhouette of a deer. UNStudio’s design has therefore been given the (provisional) name ‘Het Hoge Hert’ (The Tall Stag).\nThe observation Tower is a hybrid construction, consisting of a combination of steel and Ultra High Performance Concrete. Steel is employed where the tensile stresses are foremost, whereas Ultra High Performance Concrete manifests excellent performance properties where the compressive stresses are highest. The parapet around the stairs and platforms is constructed from stainless steel mesh, enabling the combination of both maximum transparency and necessary safety levels.\nBen van Berkel: “The strength of Ultra High Performance Concrete is conceptually expressed in the cantilever of the structure, which combines UHPC with steel to enable a substantial protraction in the form of the viewing tower.”\nLocation: Outskirts of Drenthe (near City of Groningen, Eelde and Peize)\nHeight: 25 m\nNo. of steps: 134\nProgramme: Observation Tower\nUNStudio: Ben van Berkel with Arjan Dingsté and Marianthi Tatari, Marc Hoppermann, Kristoph Nowak, Tomas Mokry, Dorus Faber\nCase Study partners: UNStudio, ABT, Haitsma Beton, BAM Utiliteitsbouw"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:b0a7d81a-fd9c-469b-8b6d-68e19e54f77a>","<urn:uuid:08bb185d-9169-4314-8967-be8eff6f9769>"],"error":null}
{"question":"What's the main difference between Windows Defender quarantine and SmartScreen Filter?","answer":"Windows Defender quarantine isolates potentially harmful files that are detected during system scans, storing them in a secure environment to prevent execution and spread of malware, while SmartScreen Filter focuses on real-time protection against malicious websites, downloads, and applications by checking their reputation against a constantly updated database before allowing access or execution.","context":["Having dependable antivirus software is essential in today’s digital environment, where cyber threats continue to change and present risks to both individuals and organizations. Malicious software, also known as malware, must be found and eliminat by antivirus programs before it can do any damage. The ability to quarantine suspicious files is a crucial component of antivirus software. We will examine the idea of antivirus quarantine, its function, and how it helps to safeguard your system in this article.\nWhat is Antivirus Quarantine?\nAntivirus software uses quarantine as a safety measure to separate potentially harmful files that have been found during a system scan. When an antivirus program determines a file to be suspect or malicious, it quarantines it in a safe, secure environment. The quarantine serves as a short-term storage space, keeping the file separate from the rest of the system and preventing it from running or infecting other files.\nPurpose of Antivirus Quarantine:\nAntivirus quarantine’s main objective is to stop malware from being execut and from spreading throughout a computer system. Antivirus software isolates suspicious files in an effort to stop potential threats while lowering the possibility of unintentional execution by users or other programs. Before making any further decisions, like deleting or restoring the file, quarantining enables users to review and confirm the file’s security.\nBenefits of Antivirus Quarantine:\nProtection from zero-day threats: An extra layer of protection against recently discover or unidentified malware is offered by antivirus quarantine. Quarantining suspicious files ensures that potential threats are contained until the antivirus vendor can analyze and provide the necessary updates or instructions, as antivirus programs may not have immediate knowledge of the latest threats.\nEnhanc system stability: Antivirus quarantine separates potentially harmful files to stop malware from interfering with crucial system operations or corrupting crucial files. The stability and overall performance of your computer system are maintain by this isolation.\nQuarantining gives users control and peace of mind by allowing them to review files before performing any irreversible actions. Users have the option to check the file’s nature, get professional advice, or have the file restor if it was mistakenly identifd as malicious. Users feel confident and at ease with this level of control, which reduces the possibility of accidentally deleting valid files.\nManaging Quarantin Files:\nThe user interface of antivirus software typically enables users to access and manage quarantin files. Users can review information about each quarantin file, such as its location, file type, and threat level, from the interface. Users can decide whether to permanently delete a file, restore it if they think it’s safe, or send it to the antivirus vendor for additional investigation.\nBest Practices for Antivirus Quarantine:\nReview quarantin files on a regular basis: It’s crucial to frequently check the quarantine section of your antivirus program and review any files that are there. This enables you to take the necessary action and helps to ensure that legitimate files are not unintentionally quarantin.\nUpdate your antivirus program: Updating your antivirus program guarantees that you have access to the most recent virus definitions and security updates. Your antivirus program can effectively identify and quarantine the most recent threats with the help of regular updates.\nWhen restoring files, use caution. Carefully examine the authenticity and origin of the file before restoring it from quarantine. If in doubt, seek advice from cybersecurity experts or the antivirus provider to make sure the file is secure.\nAntivirus quarantine is a crucial component of modern cybersecurity. By isolating potentially malicious files, it prevents the execution and spread of malware, safeguarding your computer system and data. Understanding how antivirus softawre works and following best practices for managing quarantin files will help you make inform decisions and maintain a secure computing environment. Stay vigilant, keep your antivirus software updat, and embrace the power of quarantine to bolster your defense against","Did you know that the Windows operating system comes equipped with built-in antivirus features? That’s right, you don’t need to go searching for a third-party antivirus program to keep your computer safe and secure. With Windows Defender, Microsoft has provided a reliable antivirus solution that is always working in the background, protecting your system from potential threats. In this article, we will explore the built-in antivirus features of the Windows operating system and discuss how they can help safeguard your digital world. So, sit back and let’s take a closer look at the impressive security measures that Windows has to offer. Yes, there are built-in antivirus features in the Windows operating system. These features are designed to provide real-time protection against various types of malware, including viruses, spyware, and ransomware. In this article, we will explore the different built-in antivirus features available in Windows, how they work, and their effectiveness in keeping your computer secure.\nWindows Defender is the default antivirus software included in Windows operating systems. It provides comprehensive protection against a wide range of threats, while also offering a user-friendly interface for easy management of your computer’s security.\nWindows Defender offers a variety of security features to safeguard your system. It includes real-time protection, scan options, automatic updates, threat history, browser protection, firewall and network protection, app and browser control, device security, as well as performance and health monitoring.\nReal-time protection is one of the key features of Windows Defender. It continually monitors your system in the background, scanning files and programs as they are accessed or executed. This helps to detect and block any potential threats before they can cause harm to your computer.\nWindows Defender provides various scan options to cater to different needs. You can choose between quick scans, full scans, or custom scans. Quick scans focus on the most vulnerable areas of your system, while full scans check all files and programs. Custom scans allow you to specify specific files, folders, or drives to scan.\nKeeping your antivirus software up to date is crucial for maintaining effective protection. Windows Defender automatically updates its virus definitions and engine, ensuring that you have the latest defense against emerging threats. These updates are rolled out regularly by Microsoft to address new security vulnerabilities.\nWindows Defender keeps track of any threats that have been detected on your system. You can review the threat history to see details about blocked threats and take necessary actions. This helps you stay informed about the security status of your computer.\nWindows Defender integrates with your web browsers to provide protection against malicious websites and downloads. It provides real-time protection while you browse the internet, blocking known malicious sites and preventing you from downloading potentially harmful files.\nFirewall and Network Protection\nIn addition to antivirus capabilities, Windows Defender also includes a built-in firewall and network protection. The firewall monitors incoming and outgoing network traffic, allowing you to set rules and permissions for different applications and services. This helps to prevent unauthorized access to your system and ensures the security of your network connection.\nApp and Browser Control\nWindows Defender’s app and browser control feature provides an additional layer of protection against potentially malicious applications and scripts. It helps to detect and block any suspicious activities, such as unauthorized changes to your browser settings or attempts to execute potentially harmful scripts.\nWindows Defender includes device security features to protect your computer’s hardware and firmware. It helps to mitigate the risks of firmware attacks, defends against unauthorized access to the device, and safeguards the integrity of system boot components.\nPerformance and Health\nWindows Defender not only focuses on security but also helps to optimize the performance and health of your system. It provides insights and recommendations to improve system performance, troubleshoot potential issues, and ensure your computer is running smoothly.\nWindows Security Center\nWindows Security Center is a central hub that integrates various security features in Windows, including Windows Defender. It provides a unified dashboard to monitor and manage your computer’s security.\nIntegration with Windows Defender\nWindows Security Center integrates seamlessly with Windows Defender, allowing you to access and manage all antivirus features in one place. It provides a comprehensive overview of your system’s security status, including virus protection, firewall settings, and other security-related configurations.\nAdditional Security Features\nIn addition to Windows Defender, Windows Security Center also consolidates other security features available in Windows, such as Windows Firewall, User Account Control (UAC), SmartScreen Filter, Windows Update, and more. This ensures that you have a holistic approach to securing your computer.\nThird-Party Antivirus Compatibility\nWindows Security Center is designed to work well with third-party antivirus software, providing a convenient interface to manage multiple security products. If you choose to use a third-party antivirus solution, Windows Security Center can still help you monitor their status and ensure they are functioning properly.\nMonitoring and Management\nWindows Security Center offers comprehensive monitoring and management capabilities. It provides real-time alerts and notifications about potential security threats, monitors the health of your antivirus software, and offers recommendations to enhance your system’s security posture.\nAction Center Integration\nWindows Security Center integrates with the Action Center, which is a central location for managing various system notifications. This integration ensures that important security alerts and prompts are prominently displayed, allowing you to take immediate action to address any security concerns.\nWindows Firewall is a built-in security feature in Windows that helps protect your computer from unauthorized access and network threats.\nWindows Firewall acts as a barrier between your computer and the internet, monitoring and controlling incoming and outgoing network traffic. It helps prevent unauthorized access to your computer by blocking potentially malicious connections and limiting network exposure.\nConfiguring Firewall Settings\nWindows Firewall provides a user-friendly interface to configure its settings according to your preferences. You can set different profiles (public, private, or domain), allowing you to customize firewall rules based on your network environment. This helps to ensure that your computer remains protected, regardless of the network you are connected to.\nInbound and Outbound Rules\nWindows Firewall allows you to define inbound and outbound rules to control network traffic. Inbound rules determine what incoming connections are allowed or blocked, while outbound rules control what outgoing connections are permitted or restricted. This fine-grained control gives you the flexibility to specify the behavior of different applications and services.\nAdvanced Firewall Options\nWindows Firewall also offers advanced options for more experienced users. These options include secure connection filtering, logging, and notification settings. They allow you to fine-tune the firewall’s behavior to match your specific security requirements.\nUser Account Control (UAC)\nUser Account Control (UAC) is a Windows security feature that helps prevent unauthorized changes to your computer’s settings and files.\nPurpose and Function\nThe purpose of UAC is to safeguard against potentially harmful activities that could compromise your system’s security. It works by notifying you when a program or process attempts to make changes that require administrative privileges. UAC prompts you to confirm or deny these actions, giving you control over what gets executed on your computer.\nUAC settings can be configured to suit your preferences. You can choose between different notification levels, ranging from always notify to never notify. The appropriate level depends on your comfort level with allowing applications to make changes to your system.\nUAC Prompts and Actions\nWhen an application or process triggers a UAC prompt, you will see a dialog box asking for your permission to proceed. You can review the name and publisher of the application, as well as the actions it intends to perform. You have the option to allow or deny the action based on your trust in the application.\nEffectiveness Against Malware\nUAC provides an effective layer of defense against malware, as it requires administrative privileges to make changes to your system. By prompting you to confirm or deny these actions, UAC helps prevent malicious programs from silently executing and compromising your computer’s security.\nSmartScreen Filter is a Windows security feature that helps protect against malicious websites, downloads, and applications.\nSmartScreen Filter uses reputation-based analysis and real-time behavior monitoring to determine the safety of websites, downloads, and applications. It works in conjunction with other security features to provide comprehensive protection against evolving online threats.\nSmartScreen Filter checks the reputation of websites you visit, comparing them against a constantly updated database of known malicious sites. If a website is flagged as potentially unsafe, SmartScreen Filter will display a warning, allowing you to make an informed decision on whether to proceed or navigate away.\nSmartScreen Filter also examines the reputation of downloads and applications. For files that are not widely recognized or have a low reputation, it may display a warning before allowing you to install or run them. This helps to prevent potentially harmful programs from running on your system.\nWindows Store Protection\nSmartScreen Filter is integrated with the Windows Store, ensuring that downloaded applications from the store are safe to install. It performs reputation checks on applications before they are listed in the store, providing an additional layer of security for Windows Store users.\nConfiguring SmartScreen Settings\nYou can configure SmartScreen Filter settings according to your preferences. You have the option to turn it on or off completely, or choose to receive warnings only for potentially malicious downloads or unrecognized applications. This flexibility allows you to customize the level of protection based on your needs.\nWindows Update is an essential feature of Windows that ensures your operating system is up to date with the latest security patches and bug fixes.\nWindows Update can be configured to automatically download and install updates, ensuring that your system is constantly protected against emerging threats. Automatic updates are recommended for most users, as they provide a convenient way to stay up to date without manual intervention.\nCritical Security Updates\nWindows Update prioritizes critical security updates, which are designed to address known vulnerabilities that could be exploited by malicious actors. These updates are necessary for maintaining a secure system and should be installed promptly.\nWindows Update Settings\nYou can customize Windows Update settings to suit your preferences. Options include setting active hours to prevent automatic restarts during specific times, pausing updates temporarily, or selecting the option to ask for your confirmation before downloading or installing updates.\nWindows Update Troubleshooting\nIn some cases, Windows Update might encounter issues that prevent it from installing updates. Windows provides troubleshooting tools and guides to help diagnose and resolve these issues. Repairing Windows Update can help ensure that your system remains up to date and secure.\nWindows AppLocker is a security feature that allows administrators to control which applications and scripts are allowed to run on a Windows system.\nApplication Control Policies\nAppLocker enables administrators to define policies that determine which applications can be executed on a computer. By specifying which applications are allowed or blocked, AppLocker helps prevent the execution of potentially malicious or unauthorized software.\nAppLocker uses executable rules to control the execution of applications based on criteria such as file path, publisher, or file hash. These rules can be created and enforced at the organization’s level, giving administrators granular control over application management.\nSimilar to executable rules, AppLocker also supports script rules to restrict the execution of scripts. Administrators can define policies based on script paths or publisher certificates, ensuring that only trusted scripts are allowed to run.\nPackaged App Rules\nAppLocker supports policies for managing Windows Store apps, known as packaged app rules. Administrators can specify which Windows Store apps can be installed or run on a computer, allowing for more control over the software ecosystem within an organization.\nAudit and Enforcement Options\nAppLocker provides auditing capabilities to track the execution of applications and scripts. Additionally, administrators can choose to enforce AppLocker policies strictly or in an audit-only mode, which allows monitoring of policy violations without blocking the execution of unauthorized software.\nWindows Credential Guard\nWindows Credential Guard is a security feature that protects against credential theft, a common technique used by attackers to compromise systems.\nCredential theft involves extracting credentials, such as usernames and passwords, from a compromised system and using them to gain unauthorized access to resources. Windows Credential Guard protects the credentials stored on a computer by isolating them and preventing unauthorized access.\nHardware and Software Requirements\nTo utilize Windows Credential Guard, specific hardware and software requirements must be met. These requirements include a compatible processor with virtualization extensions, as well as a version of Windows Enterprise or Education edition.\nProtection Against Credential Theft\nWindows Credential Guard uses virtualization-based security to isolate and protect credentials from unauthorized access. By running in a secure environment separate from the operating system, it makes it much more challenging for attackers to extract and use stored credentials.\nWindows Sandbox is a new security feature introduced in Windows 10 that provides a lightweight and isolated environment to run potentially suspicious or untrusted applications.\nIntroduction and Purpose\nWindows Sandbox allows you to spin up a virtualized instance of Windows, also known as a sandbox, to test and run applications without impacting your host operating system. It is an ideal tool for safely exploring potentially harmful software without risking your computer’s security.\nCreating a Sandbox\nCreating a sandbox is straightforward. Simply open the Windows Sandbox application from the Start menu, and a new sandboxed instance of Windows will be launched. Once you’re done with the sandbox, simply close the application, and all changes made within the sandbox will be discarded.\nUsing the Sandbox\nInside the sandbox, you can install and run applications just like you would on a regular Windows installation. However, any changes or modifications made within the sandbox will not be persistent, providing a secure and isolated environment for testing software.\nSecurity and Isolation\nWindows Sandbox utilizes several security measures to ensure a safe and isolated environment. Each sandbox is completely isolated from the host operating system, preventing any potential malware or malicious software from affecting the underlying system. Furthermore, Windows Sandbox utilizes snapshot technology, allowing for efficient creation and disposal of sandbox instances.\nWindows provides a range of built-in antivirus features that help protect your computer from malicious threats. Windows Defender, Windows Security Center, Windows Firewall, User Account Control (UAC), SmartScreen Filter, Windows Update, and other security features work together to ensure a high level of security for your system.\nEffectiveness of Built-in Antivirus Features\nThe built-in antivirus features in Windows have proven to be effective in providing protection against a wide variety of threats. Windows Defender, with its real-time scanning, frequent updates, and comprehensive security options, helps safeguard your computer from malware.\nSupplementing with Third-Party Antivirus\nWhile the built-in antivirus features in Windows are robust, some users may opt to supplement their security measures with third-party antivirus software. Third-party antivirus solutions offer additional features, customization options, and specialized protection against specific threats.\nContinuously Updating Security Measures\nRegardless of whether you rely solely on built-in antivirus features or choose to use third-party software, it is essential to continuously update and maintain your computer’s security measures. Keeping your antivirus software up to date, regularly applying Windows updates, and practicing safe browsing habits will help ensure a secure computing experience."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"search_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"instructional"}],"document_ids":["<urn:uuid:0bfc9660-868f-4d7e-9958-241356bdba81>","<urn:uuid:592abe61-b7a1-4666-aae0-8c64682d93ce>"],"error":null}
{"question":"How long does the tomato-throwing festival in Bunol, Spain typically last, and how many tons of tomatoes are used?","answer":"The tomato fight in Bunol lasts for roughly one hour, starting at 11am, and uses over 120 tons of overripe tomatoes. Between 20,000 and 50,000 participants take part in this event.","context":["Tamsin Wressell explores just how messy some celebrations can get around the world\nWhen: April 13-15\nWith massive water fights on streets across Thailand, Songkran Festival welcomes in the Thai New Year. Locals and visitors of all ages come armed with buckets, water guns, hoses and even elephants to partake in the revelries. The tradition began by sprinkling water into each other’s hands to wish good luck and pay respects but has since evolved into the world’s largest water fight. The water fights mainly take place on the first day, but parades, ceremonies and other traditions continue for three days throughout the country.\nWhen: last Wednesday of August\nOver 120 tons of overripe tomatoes are shipped to the small Spanish village of Bunol, 30 minutes from Valencia every August for the world’s largest tomato fight. The juicy ammunition is brought in by the truckload for between 20,000 and 50,000 participants to launch at each other, in honor ofthe town’s patron saints. Starting at 11am and lasting for roughly one hour, the end of the fight is signalled by a blast from water hoses. The festivities continue throughout the week with parades, fireworks and a paella cook-off.\nWhen: End of February, early March\nThe festival is most famously known for its day of explosive color. Taking place on a full moon, the celebrations begin with a bonfire on the eve of Holi to mark the start of the spring season. The main event the following day sees people throwing colored powder paint and spraying colored water at each other throughout many parts of Asia, predominantly India, where the festival originated several thousand years ago as a Hindu religious celebration. Bollywood songs, dancing and traditional snacks accompany the ‘festival of color’ to rejoice in the victory of good over evil and the renewal of relationships.\nBoryeong Mud Festival\nWhere: South Korea\nOver two million visitors flock to Daecheon Beach, near Seoul, to play in the mud for what is the focal point of South Korea’s most popular annual festival. Lasting for two weeks in the summer, revelers can sample the mud pools, spa and slides while activities include mud wrestling, mud fights, mud skiing competitions and other mud-related contests. The festival was originally a marketing ploy to publicize local mud-based cosmetics but now includes street parades as well as music and fireworks.\nWhen: Beginning of Lent\nTaking place on the first day of Lent in the Greek Orthodox calendar, the small fishing village of Galaxidi, in Greece, holds the ironically named Clean Monday — an event that sees residents hurl over three tons of multi-colored or plain white flour at each other across the town. Since the coloring in the flour is so strong, many buildings are wrapped in plastic to avoid permanently rainbow-hued homes, but no visitor or local is spared. The flour war is teamed with driving rundown cars and dancing through the streets. Fires are lit for warmth, however the day usually ends with people jumping into the cold waters of Corinthian Bay."],"question_categories":[{"categorization_name":"answer_type","category_name":"factoid"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"}],"document_ids":["<urn:uuid:98da8eed-34df-427e-a5e3-5fb18814250f>"],"error":null}
{"question":"我在学做日式料理，想了解一下大根和盐的问题！dashi汤底的制作要放多少盐？还有每天摄入盐分应该控制在多少克呢？🤔","answer":"According to the dashi recipe shown, salt is not actually used in making traditional dashi stock. The basic shiitake dashi is made with just water, dried shiitake mushrooms, and kombu (kelp). Regarding daily salt intake, the maximum recommended amount is 6g per day. It's important to note that while we need salt to survive, excessive consumption can lead to high blood pressure and increased risk of heart disease and stroke.","context":["Jeff & Linda's Kitchen of Diversity\nAnother important group of bentō dishes are foods cooked in a soy sauce, sake, sugar, and dashi stock until the liquid is almost cooked out and becomes a thick sauce. These braised dishes are rich and savory and are an excellent counterpart to the sharp-tasting sunomono.\nThe stock used in Japanese cooking is dashi. Unlike European stocks that are long-simmered, dashi is more of a quickly-made savory tea. The most common dashi is made from shavings of dried bonito, a type of mackerel. However, vegetarian dashi also exists, as it is required for Buddhist temple food. In this case, we’ll use dried shītake mushrooms for our base.\nShītake Dashi (しいたけのだし or Shītake no Dashi)\n4 cups water\n6 dry shiitake mushrooms\n1 3”x7” piece of kombu\nSoak shītake and kombu in hot water for 30 minutes. Remove mushrooms and kelp. Reserve the shītake for later recipes\nOne of our favorite Japanese vegetables is gobo (牛蒡), the long, narrow root of the Great Burdock (Arctium lappa) which was initially domesticated in northern China. Although its current use in China is primarily as a medicinal plant, it is regularly eaten as a vegetable in Japan. Its 1” diameter roots grow up to a yard long in rich, loose soils, and are crisp with a mild sort of woody and slightly sweet flavor. The peeled root and matchsticks should both be soaked in water for at least 15 minutes to remove chemicals which will impart a harsh taste. In the following recipe, julienned gobo strips are further blanched in boiling water to remove even more of this chemical, making for a wonderfully savory and crunchy treat..\nBraised Gobo (きんぴらゴボ or Kin pira Gobo)\n2 18” gobo roots\n2 tablespoons vegetable oil\n2½ tablespoons soy sauce\n2 tablespoons sake\n1 tablespoon mirin\n2½ tablespoons sugar\n3 tablespoons shītake dashi\n½ teaspoon sichimi togarashi (7-spice powder)\n1 tablespoon roasted sesame seeds\nPeel gobo and cut into 3” long sections. Place into a bowl of water. Let soak for 15-30 minutes. Cut each section into matchsticks, and return to the bowl of water.\nHeat 4 cups of water to a rolling boil and cook the cut gobo for 5 minutes. Drain.\nIn a large skillet, heat vegetable oil over high heat until almost smoking. Add the drained, blanched gobo and stirfry for 2 minutes. Add in the soy sauce, sake, mirin, sugar, and shītake dashi. Cook, stirring occasionally, until the liquid has almost completely evaporated. Remove from heat. Mix in the sichimi togarashi, and place in a serving bowl. Garnish with sesame seeds.\nWhile we usually do not opt for pre-made spice mixes, we'll make an exception here for sichimi togarashi, simply because it calls for dried tangerine peel and sansho pepper that are much more difficult to obtain than the perfectly adequate premixed sichimi available at any Japanese or Korean market. You'll also need to find your kombu (dried kelp) at the same market.\nIf you want to try growing your own gobo, remember that it is a heavy nitrogen feeder and will need deep loose soils. You should likely consider double-digging your bed to make sure there is plenty of loose soil for the roots to grow into. Also, remember that it can become a noxious weed so you’ll want to make sure that you harvest it before it sets seed.","Five salt myths that could be damaging your health\nMost of us are well aware that high blood pressure is a major risk factor for some of the most common killers, such as stroke and coronary heart disease. But are you aware just how big a role salt consumption can play in developing high blood pressure in the first place?\nEven if you are clued up on this, there’s still a chance you’re not entirely sure how much salt you’re consuming – especially if you regularly eat processed foods (things like ready-made sauces, basically many of the foods you’re not preparing from scratch), which, according to Consensus Action on Salt & Health (CASH), around 75% of the salt in our diets comes from.\nAccording to recent research from low-salt alternative brand LoSalt, nearly two-thirds of people (63%) are not actively reducing their salt intake – which indicates there’s still a lack of awareness around the white stuff and its associated health risks.\nSo what else do you need to know about salt intake?\nWe’ve done some salt myth-busting to point you in the right direction…\nMYTH: You can eat as much salt as you like\nFalse! We need salt to survive, so cutting it out entirely is NOT the goal. However, too much of it can lead to potentially serious problems down the line. As many as three-quarters (75%) of the population don’t realise that 6g is the maximum daily recommended salt intake, according to the LoSalt survey.\nThere’s two components in salt: sodium and chloride, and it’s the sodium that is doing the damage because it can lead to high blood pressure. Although most people with high blood pressure don’t realise they have it, it is responsible for around 50% of heart disease cases and 60% of strokes, according to the World Health Organisation.\nMYTH: Rock salt is healthier than regular salt\nMany people believe trendier sea and rock salts are healthier than regular salts, but this is incorrect.\nNutritionist and dietitian Azmina Govindji says: “They contain the same amount of sodium chloride: 100%! Sea salt may contain traces of other minerals, but the levels are too low to have a health benefit and so it is not healthier for you than any other salt.”\nMYTH: Saltless food is bland\nExtra salt added during cooking makes up 20% of our salt intake, notes Govindji. Granted, this might not sound like much, but it’s the chunk of our intake which we’re most in control of.\nWe might think our dinner will taste bland without a sprinkling of salt, but this isn’t strictly true.\n“By reducing a little here and there, you’ll soon find your taste buds become accustomed to not having such high levels of salt and you’ll have less need for it in cooking and for seasoning food,” says Govindji.\nMYTH: There are no alternatives to salt\nFor those who really can’t go without the taste of salt, brands like LoSalt offer an alternative to the traditional white stuff. It still contains all the flavour of normal salt, but contains 66% less sodium.\nAlso, try herbs and spices, vinegar or a dash of lemon instead to give your food the punch of flavour that salt usually would. Dill tastes great with fish, rosemary is wonderful with meat, and basil will finish off a pasta dish perfectly.\nMYTH: Cutting out salt in cooking is all you need to do\nNot adding salt to cooking is a good start – but it’s important to remember that this is only a small part of the solution, and there’s plenty more we can do.\nThe food we buy fresh in supermarkets can still be salt heavy, so always read the labels. If you can’t always cook from scratch, choose low-salt options and avoid the red traffic light on food labels!\nEat notoriously high-salt foods, like cheese, bacon, ham, salted and roasted nuts and salami, in moderation, and watch out for ready meals, pizzas, pasta sauces and bread. They’re usually far higher in salt than you might think!"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_expressive"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:30f1708b-3f15-465b-ae06-fbbc36ef38a4>","<urn:uuid:27e2ab2d-22f1-4776-9702-5e6acad94fb8>"],"error":null}
{"question":"Could you compare the primary liquid mixing ratios in document 1's dosing device with the x-ray detector materials mentioned in document 2's electromagnetic shield assembly? Please present the comparison in a structured format.","answer":"Primary liquid mixing ratios described in document 1 can be as extreme as 0.05-1% secondary component to primary component, or 1:5-10,000 for specific applications like lactose-free milk preparation (lactase:milk ratio). In contrast, document 2 discusses x-ray detector shielding materials with specific thickness ratios - a 3mm thick aluminum shield causes unacceptable 20% x-ray attenuation, while a thinner 0.15mm aluminum window shield introduces only 0.1% attenuation.","context":["|Publication number||US6254269 B1|\n|Application number||US 09/204,055|\n|Publication date||Jul 3, 2001|\n|Filing date||Dec 3, 1998|\n|Priority date||Jun 3, 1996|\n|Also published as||CN1079692C, CN1225038A, DE69719995D1, DE69719995T2, EP0918562A1, EP0918562B1, WO1997046308A1|\n|Publication number||09204055, 204055, US 6254269 B1, US 6254269B1, US-B1-6254269, US6254269 B1, US6254269B1|\n|Inventors||Georg Ernstson, Johan Sjöholm, Lars Dahlberg|\n|Original Assignee||Arom Pak Aktiebolag|\n|Export Citation||BiBTeX, EndNote, RefMan|\n|Patent Citations (9), Referenced by (2), Classifications (13), Legal Events (7)|\n|External Links: USPTO, USPTO Assignment, Espacenet|\nThis application is a continuation of PCT application no. PCT/SE97/00965 filed on Jun. 3, 1997, which designated the United States and on which priority is claimed under 35 U.S.C. §120, the entire contents of which are hereby incorporated by reference.\nThe present invention relates to a dosing device or mixing device for mixing, in a continuous process, a flowing primary liquid with one or more added secondary liquids for obtaining a flowing liquid mixture at a permanent, uniform mixing ratio of the mixed liquids. Especially, the processing industry and medicinal technology require access to dosing devices, by means of which two or more components in liquid state are continuously mixed with each other under conditions which yield uniform mixing ratios, i.e. uniform amounts of the components included, in a continuous mixing process. The device and the method according to the present invention are especially applicable in the cases where one or some components, so-called secondary components, are to be admixed to a flowing primary component and where the amount of secondary components in terms of volume is comparatively small or very small compared with the amount of the primary component in the finished mixture. In some cases, it is thus desirable to add enzymes, colorants, flavoring agents, vitamins etc. In a flowing quantity of liquid, the content of the added substances, the so-called secondary components, can be as low as 0.05-1% of the flowing primary component. It is possible by using the inventive method to obtain, with a uniform and continuous mixing ratio, a flow of liquid which can proceed to be packed with an equal content of additives in all packings. An example of such a process is, for instance, the preparation of lactose-free sterile milk, where the untreated sterilized and lactose-containing milk is continuously mixed with a quantity of sterile-filtered lactase before packing, the proportions of lactose-containing milk/lactase being in the order of 5-10,000, about the same mixing ratio being required in all packings that are continuously prepared. In some other cases, higher contents of secondary liquid are required as addition, for instance when colorants or flavoring foodstuffs.\nDosing equipment for mixing flows of liquid having different flow ratios is known, but such equipment has essentially been directed to obtaining a constant mixing ratio by letting the combined flows of liquid being joined and conducted in a loop, i.e. a certain part of the flow of liquid is deflected from the main conduit and recirculated to a point in the flow conduit which is positioned downstream. The mixed liquid or parts thereof will in this manner circulate several times through the loop to obtain a good mixing when the loop has finally been passed. The present invention, which operates without a mixing loop, is considerably simpler in its technical design and permits great flexibility as regards the amount and type of additives and is, above all, easier to adjust between the use of different mixing components. The dosing device according to the present invention preferably is adapted to be used in the foodstuff industry but may also be used in medicinal industry for continuous mixing of components in liquid state.\nAn embodiment of the invention will be described below with reference to the accompanying schematic drawing, in which FIG. 1 illustrates the dosing device,\nFIG. 2 illustrates a special device with a plurality of needle-like nozzles for supplying a secondary liquid and\nFIG. 3 shows a flexible plastic bag for storing sterilized secondary liquid.\nAs mentioned above, the described device comprises a means for mixing, with great accuracy to volume, a first liquid, here called a primary liquid, with the second liquid, here called a secondary liquid, the mixing ratio being such that there is a very great difference between the individual volumes of the mixed liquids. As pointed out above, in many medicinal processes but also in connection with other processes, for instance, coloring of a liquid or adding of e.g. enzymes or flavoring agents to a liquid, there is a need of adding a smaller amount of secondary liquid to an essentially larger amount of primary liquid. In a continuous mixing process, it is most important that the mixing ratio, in spite of the differences in volume between the mixed liquids, be constant and controllable all the time during the process, such that, for instance, the flavor or the enzyme content of the resulting mixed liquid will not vary.\nThe apparatus shown in FIG. 1 consists of a flow pipe 26 for a primary liquid, the amount of passing primary liquid being controllable by means of a flow meter 22, which registers the amount of passing primary liquid and which by means of the regulator 20 controls the speed of the peristaltic pump 21. In the case shown, the secondary liquid is taken from a plastic bag 19 containing, in this case, sterilized secondary liquid 28. The secondary liquid 28 is passed via the conduit 27 to a peristaltic pump 21 controlled by the regulator 20 and being of known type. This peristaltic pump 21 comprises a rotatable cylindrical body 29, which at its circumference supports rollers 30. In the case shown, the rollers 30 are positioned diametrically opposite each other in the cylindrical body 29 rollers project outside the periphery of the rotatable body 29. At least part 27′ of the conduit 27 is made of a flexible material, e.g. rubber or plastic, and this part 27′ of the conduit 27 is arranged in a duct 31 of the pump 21.\nDuring rotation of the cylindrical body 29, the flexible conduit 27′ is compressed by the rollers 30, the liquid contained in the conduit 27′ between the rollers 30 being pressed forwards by the rollers 30 in the direction of rotation of the cylindrical body 29 and thus being pumped forwards. Since the dimension of the tube 27′ is known and the speed of rotation of the cylindrical body 29 is controllable, the amount of pumped liquid in the conduit 27 can be very accurately controlled and the flow can be kept very constant. In order to stop the pump 21 and the mixing process if the flow in the conduit 27 is interrupted, a flow control device 23 is arranged at or in the vicinity of the terminal point of the conduit 27. The secondary liquid 28 supplied as described above is added to the primary liquid by means of a specially arranged inlet chamber 25 which is shown in detail in FIG. 2. The inlet chamber 25, which is connected to the conduit 26 for the primary liquid, is provided with a conduit flange 32, which is located in the position where the conduit 26 in the case shown makes a bend and, in the bend of the conduit, has a liquid-flow-conducting labyrinth 41 for guiding the flow of primary liquid towards the inlet chamber 25. The inlet chamber 25 is provided with a connecting flange 33, which matches the connecting flange 32 and which is provided with seals 34 closely connected to each other. The inlet chamber 25 also has spaces 35, which can be kept sterile by means of a sterilizing agent, e.g. vapor or a sterilizing liquid, supplied through the conduit 10. The passing vapor or liquid sterilizes the spaces 35 and all the objects that are present or may be present in the spaces 35. Moreover, the inlet chamber 25 has one or more spaces 14, which are adapted to receive injection needles or syringe-like cannulae comprising a hypodermic needle 12 and a connection 36 to the conduit 27.\nAs shown in FIG. 2, the inlet chamber 25 may be provided with several spaces 14 for hypodermic needle arrangements which, adjacent to said connection 36, are sealed against the inlet chamber 25 by means of a sealing ring 37 of O-ring type.\nThe cannula including an obliquely cut-off portion 15, is thus displaceably movable in the spaces 14 by displacing the connection 36 with the sealing ring 37. That part of the inlet chamber 25 which connects to the primary liquid conduit 26 has a sealing wall 38 made of rubber or a rubber-like material, which can easily be penetrated by the cannula 12 and which, after retraction of the cannula 12 into the space 14, in a self-sealing manner attaches itself around the hole made by the cannula 12 in the sealing wall 38. Thus, the cannula 12 can, when positioned in the space 14, be sterilized and be made to retain its sterility to be passed through the sealing wall 38 into the conduit 26 for supplying, in an accurately predetermined dose, secondary liquid 28 to the flowing primary liquid. The cannula 12 can also be retracted into the space 14 without interruption of the sterility. As shown, the connection 36 to the cannula 12, 13 is provided with a flange 39. After insertion of the cannula 12, 13 into the conduit 26, the cannula 12, 13 can be locked in the inserted position by a stop flange 40 being pushed over the flange 39, the position of the cannula 12 and the associated connection 36 being fixed. To achieve a good mixing of primary liquid and secondary liquid or secondary liquids, the conduit 26′ for the mixed liquids is provided with a mixing chamber 24 having surfaces deflecting the flow of liquid to achieve, under turbulent flow, a homogeneous mixing of the joined liquids. FIG. 3 shows an example of the above-described bag 19 for the secondary liquid, and as is obvious, the bag is provided with two connections 27, 3, the connection 3 constituting the filling conduit and the tube 27, as described above, constituting the discharge conduit for secondary liquid. Of course, the tank for secondary liquid 19 need not necessarily be a plastic bag but may be a more dimensionally stable vessel made of plastic or metal, and it is not necessary to the invention that the supplied secondary liquid or, for that matter, the primary liquid be a sterile liquid.\nIt should be added that in the cases where several secondary liquids are to be supplied, not only the inlet chamber must be provided with several chambers and cannulae for the secondary liquid 28, but also that each secondary liquid 28 necessitates its own storage tank 19, its own pump 21 and its own regulator 20, unless the secondary liquids are not of such a nature that even in the storage tank they can be mixed to a common “secondary liquid mixture”. An inlet chamber with a number of cannula positions may be practical to use with a view to making it possible to stop the process without shifting from a secondary liquid tank 19 to another when the first tank is empty. Such a “flying shift” of the secondary liquid tank 19 is possible to perform if the inlet chamber 25 is provided with several cannula spaces in the manner as described above.\nIt has been found that the device according to the present invention results in a permanent, very exact mixing ratio also during long continuous operation even if the volume ratio when mixing the liquids is extremely nonuniform.\nAs mentioned, it is also possible to mix, under uninterruptedly aseptic conditions, sterile liquids, and it is also easy during the mixing operation, if desired, to adjust the mixing ratio with very great accuracy.\nThe invention being thus described, it will be obvious that the same may be varied in many ways. Such variations are not to be regarded as a departure from the spirit and scope of the invention, and all such modifications as would be obvious to one skilled in the art are intended to be included within the scope of the following claims.\n|Cited Patent||Filing date||Publication date||Applicant||Title|\n|US4410321 *||Apr 6, 1982||Oct 18, 1983||Baxter Travenol Laboratories, Inc.||Closed drug delivery system|\n|US4585435 *||May 31, 1984||Apr 29, 1986||The Telescope Folding Furniture Co., Inc.||Extension set for drug delivery|\n|US5145250 *||Jun 15, 1990||Sep 8, 1992||Merck Patent Gesellschaft Mit Beschraenkter Haftung||Process for the preparation of bone cement|\n|US5232437 *||Mar 21, 1990||Aug 3, 1993||Baxter International Inc.||Mobile, self-contained blood collection system and method|\n|US5378227 *||Aug 11, 1992||Jan 3, 1995||Cobe Laboratories, Inc.||Biological/pharmaceutical method and apparatus for collecting and mixing fluids|\n|US5407269 *||Jul 9, 1992||Apr 18, 1995||International Business Machine Corporation||Dynamic mixing chamber|\n|US5670057 *||Apr 28, 1995||Sep 23, 1997||Baxter International Inc.||Apparatus and method for automatically performing peritoneal equilibration tests|\n|US5865537 *||Sep 30, 1996||Feb 2, 1999||Sulzer Chemtech Ag||Mixing device for mixing a low-viscosity fluid into a high-viscosity fluid|\n|WO1991016138A1||Apr 10, 1991||Oct 31, 1991||S.C. Johnson & Son, Inc.||Precision-ratioed fluid-mixing device and system|\n|Citing Patent||Filing date||Publication date||Applicant||Title|\n|US20070219479 *||Mar 20, 2006||Sep 20, 2007||Tasbas Hedy E||Tampon applicator for insertion of a lubricated tampon|\n|WO2007114760A1 *||Mar 29, 2007||Oct 11, 2007||Tetra Laval Holdings & Finance Sa||A device in a metering apparatus|\n|U.S. Classification||366/152.2, 366/160.2, 366/167.1, 604/88, 366/181.5, 604/86, 366/182.2, 366/174.1|\n|International Classification||B01F5/04, A61M5/168, B01F15/04|\n|Feb 3, 1999||AS||Assignment|\nOwner name: AROM PAK AKTIEBOLAG, SWEDEN\nFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:ERNSTSON, GEORG;SJOHOLM, JOHANN;DAHLBERG, LARS;REEL/FRAME:009736/0941\nEffective date: 19981222\n|Oct 1, 1999||AS||Assignment|\nOwner name: AROM PAK AKTIEBOLAG, SWEDEN\nFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:ERNSTSON, GEORG;SJOHOLM, JOHAN;DAHLBERG, LARS;REEL/FRAME:010279/0008\nEffective date: 19981222\n|Jul 5, 2001||AS||Assignment|\nOwner name: AROM PAK INTERNATIONAL AB, SWEDEN\nFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:AROM PAK AB;REEL/FRAME:011953/0152\nEffective date: 20010425\n|Dec 9, 2002||AS||Assignment|\nOwner name: TETRA LAVAL HOLDINGS & FINANCE S.A., SWITZERLAND\nFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:AROM PAK INTERNATIONAL AB;REEL/FRAME:013552/0468\nEffective date: 20021014\n|Jan 3, 2005||FPAY||Fee payment|\nYear of fee payment: 4\n|Jan 5, 2009||FPAY||Fee payment|\nYear of fee payment: 8\n|Dec 5, 2012||FPAY||Fee payment|\nYear of fee payment: 12","|Publication number||US7658541 B2|\n|Application number||US 11/768,578|\n|Publication date||Feb 9, 2010|\n|Filing date||Jun 26, 2007|\n|Priority date||Jun 26, 2007|\n|Also published as||US20090002968|\n|Publication number||11768578, 768578, US 7658541 B2, US 7658541B2, US-B2-7658541, US7658541 B2, US7658541B2|\n|Inventors||Dun Alex Li, Richard Aufrichtig, Lonnie B. Weston, Peter Traneus Anderson|\n|Original Assignee||General Electric Company|\n|Export Citation||BiBTeX, EndNote, RefMan|\n|Patent Citations (10), Non-Patent Citations (2), Referenced by (9), Classifications (10), Legal Events (4)|\n|External Links: USPTO, USPTO Assignment, Espacenet|\nThe present invention generally relates to a system and method for improving the accuracy of an electromagnetic navigation system for use with medical applications. Particularly, the present invention relates to a system and method for improving the effectiveness of an electromagnetic shield assembly for use on a C-arm.\nElectromagnetic type navigation systems are useful in numerous applications. One application of particular use is in medical applications, and more specifically, image guided surgery. Typical image guided surgical systems acquire a set of images of an operative region of a patient's body and track a surgical tool or instrument in relation to one or more sets of coordinates. At the present time, such systems have been developed or proposed for a number of surgical procedures such as brain surgery and arthroscopic procedures on the knee, wrist, shoulder or spine, as well as certain types of angiography, cardiac or other interventional radiological procedures and biopsies. Such procedures may also involve preoperative or intraoperative x-ray images being taken to correct the position or otherwise navigate a tool or instrument involved in the procedure in relation to anatomical features of interest. For example, such tracking may be useful for the placement of an elongated probe, radiation needle, fastener or other article in tissue or bone that is internal or is otherwise positioned so that it is difficult to view directly.\nAn electromagnetic tracking system may be used in conjunction with an x-ray system. For example, an electromagnetic tracking system may be used in conjunction with a C-arm fluoroscope. The C-arm fluoroscope may utilize an x-ray source at one end of the C-arm and an x-ray detector at the other end of the C-arm. The patient may be placed between the x-ray source and the x-ray detector. X-rays may pass from the x-ray source, through the patient, to the x-ray detector where an image is captured. The electromagnetic tracking system may generate an electromagnetic field between the ends of the C-arm and penetrate the body with minimal attenuation or change so tracking may continue during a surgical procedure.\nOne technique for generating the electromagnetic field involves using time-varying dipole fields. For example, dipole fields established by driving field-generating coils with an AC current signal. This approach allows synchronous demodulation of the induced signals and thus cumulate detected signal values to enhance sensitivity. Also, it allows the ability to establish the X, Y, and Z field components at different frequencies so that detected sensor output signals may be separated or demodulated simultaneously. This approach, however, has the disadvantage that varying magnetic fields induce eddy currents in the conductive structures found within the field. Induced currents themselves generate secondary magnetic fields, thus introducing distortions into the expected distribution. Conductive or ferromagnetic metal structures are generally commonly present in a medical tracking environment.\nOnce source of electromagnetic distortion in a C-arm environment is the x-ray detector. Historically, one technique to address the distortion from the x-ray detector is to mount a conducting structure about the x-ray detector. The conductor operates as a shield with respect to disturbances originating within the shield. The shield, which is typically structured as a metal can with openings at the top and bottom, then has a fixed position relative to one of the coil assemblies and may be effectively modeled. The eddy currents induced in the sheet metal cylinder by the magnetic field from the transmitter assembly, and the secondary field formed by these induced currents, may be modeled and accounted for in a distortion map.\nCurrent shields, however, may allow signal leakage through seams, joints, and the x-ray detector window, for example. The signal leakage reduces the effectiveness of the shield. When the distortion map is created for calibration, it may take into account the signal leakage of the shield. In a situation in which a C-arm needs service or replacement parts, however, such parts may change the properties of the signal leakage (increase or decrease signal leakage, for example) through the shield. For example, if an image intensifier or flat panel detector is replaced, the properties of the signal leakage may be altered. If the properties of the signal leakage are altered, the distortion map may be mis-calibrated, resulting in improper operation of the tracking system.\nThe creation of the distortion map is typically performed using a robotics system during manufacturing and is a time consuming process. As the process for creating a distortion map is complicated and time consuming, it can be very costly in both monetary terms and in time, to perform on-site distortion mapping for calibration with new parts. Accordingly, a system and method is needed to minimize signal leakage from an electromagnetic shield. Such a system and method may minimize the need to recreate distortion maps, minimize equipment down time, and promote the interchangeability of replacement parts.\nCertain embodiments of the present invention may include a system for an electromagnetic shield assembly for use with C-arms. The system may include a ring shield configured to encompass an x-ray detector. The ring shield may have a first window opening to receive x-rays. The system may include a window shield configured to shield the first window opening of the ring shield, wherein the window shield is electrically conductive and x-ray transparent. The ring shield may be electrically conductive, and either in electrical contact with the window shield or electrically insulated from the window shield. In an embodiment, the window shield may be aluminum or copper. The window shield may be integrated into an anti-scattering grid. The window shield may also include a high-magnetic permeability layer.\nCertain embodiments of the present invention may include a system for an electromagnetic shield assembly for use with C-arms. The system may include a ring shield configured to encompass an x-ray detector. The ring shield may have a first window opening to receive x-rays. The system may include a window shield configured to shield the first window opening of the ring shield, wherein the window shield has a high-magnetic permeability and is x-ray transparent. The ring shield is electrically conductive and may be either in electrical contact with the window shield or may be electrically insulated from the window shield. The window shield may be integrated into an anti-scattering grid. In an embodiment, the window shield may be constructed of mu-metal or nickel. The window shield may also include an electrically conductive layer.\nCertain embodiments of the present invention may include a system for a universal navigation target. The system may include a radiolucent calibration target. The system may also include an electromagnetic shield, wherein the electromagnetic shield includes a ring shield having a first window opening to receive x-rays and a window shield configured to shield the first window opening of the ring shield. The window shield may be electrically conductive and x-ray transparent. The window shield may have high-magnetic permeability and is x-ray transparent. The window shield may have high-magnetic permeability, be electrically conductive, and be x-ray transparent.\nThe foregoing summary, as well as the following detailed description of certain embodiments of the present invention, will be better understood when read in conjunction with the appended drawings. For the purpose of illustrating the invention, certain embodiments are shown in the drawings. It should be understood, however, that the present invention is not limited to the arrangements and instrumentality shown in the attached drawings.\nThe C-arm unit 110 is connected to a computer unit 120. The connection between the C-arm unit 110 and the computer unit 120 may be wired or wireless. The computer unit 120 may be any equipment or software that permits electronic medical images, such as x-rays, ultrasound, CT, MRI, EBT, MR, or nuclear medicine for example, to be electronically acquired, stored, or transmitted for viewing and operation. The computer unit 120 may receive input from a user. The computer unit 120 represents, in general, equipment and software. The actual physical computer units may be separate units, part of a single unit, a computer system, or part of a computer system.\nThe computer unit 120 may be connected to other devices via an electronic network. The connection of the computer unit 120 to an electronic network is illustrated by line 140. The connection between the network 140 and the computer unit 120 may be wired or wireless. The computer unit 120 may also be connected to a display unit 130. The connection between the computer unit 120 and the display unit 130 may be wired or wireless. The display unit 130 may be a single display unit or multiple display units. Additionally, the display unit 130 may be a two-dimensional display unit or a three-dimensional display unit, for example. Accordingly, any display unit may be used in accordance with the present invention.\nElement 105 represents a patient and element 107 represents a table on which the patient is lying. Elements 150, 160, and 170 are electronic sensors that may identify their location with reference to a reference frame and with reference to each other. Although three sensors 150-170 are shown, any number of sensors may be used. The sensors 150-170 are generally in electronic communication with the computer unit 120. Element 112 represents an x-ray source and element 115 represents an x-ray detector. The x-ray detector 115 may be, for example, an image intensifier or flat panel detector. Element 118 represents an electromagnetic shield. The electronic communication may be over a wire or may be transmitted in a wireless fashion. The components of the system 100 may be single units, separate units, may be integrated in various forms, and may be implemented in hardware and/or in software.\nIn operation, the electromagnetic transmitter 210 creates the electromagnetic field 240 for the electromagnetic tracking system to track the medical instrument 220, for example. The electromagnetic field 240 may induce eddy currents in the conductive structures found within the electromagnetic field 240. For example, the electromagnetic field 240 may induce eddy currents in the x-ray detector 115. The induced currents may then generate secondary electromagnetic fields. The secondary electromagnetic fields may introduce distortions into the expected distribution.\nThe electromagnetic shield 118 may shield the sensors 150-170 from the secondary electromagnetic field. The electromagnetic shield 118 may include a conductive ring shield configured to encompass the x-ray detector 115. The conductive ring shield may encompass the x-ray detector 115 on the sides. In an embodiment, the conductive ring shield may slightly cover a portion of the bottom of the x-ray detector 115. Alternatively, the conductive ring shield may not cover the bottom of the x-ray detector 115. The conductive ring shield may have a window opening to allow x-rays 250 to reach the x-ray detector 115. The electromagnetic shield 118 may also include a conductive window shield. The conductive window shield is configured to shield the window opening of the conductive ring shield. In general, the conductive window shield is formed of a gage such that the x-rays 250 may pass through the conductive window shield with minimal x-ray attenuation.\nIn general, the effectiveness of a shield may depend on the operating frequency and signal leakage through seams, joints, or holes. The signal leakage may reduce the shielding effectiveness. In the embodiment of\nwhere λ is the wavelength, and D is the diameter of the aperture. As the size of the leakage hole increases, the shielding effectiveness drops accordingly. In an embodiment, it is desirable to have a conductive window shield 320 fully cover the window opening 315 for improving the total effectiveness of the shield. In one embodiment, the conductive ring shield 310 and the conductive window shield 320 may be electrically insulated from each other. In another embodiment, the conductive ring shield 310 and the conductive window shield 320 may be in electrical contact with each other.\nIn addition, the electrical properties and thickness of the shielding materials also affect the effectiveness of the shield. The effectiveness of a shielding material may be described by using the skin depth of the material:\nwhere ƒ is the operating frequency, μ and σ are permeability and conductivity of the shield, respectively. In general, thicker material may be used to shield low frequency signals to reach the same level of shielding attenuation. As the electromagnetic tracker signals are approximately 10 KHz, utilizing a conductive shield of approximately 3 mm thick aluminum may cause significant (approximately 20%) x-ray attenuation. This level of x-ray attenuation is generally unacceptable because it affects image quality.\nThe addition of the conductive window shield 320 improves the effectiveness of the electromagnetic shield 118 by allowing x-rays to pass through with minimal x-ray attenuation. For example, a conductive window shield 320 of thickness of 0.15 mm aluminum may introduce 0.1% attenuation to the x-ray image.\nThe conductive window shield 320 may be made of highly conductive materials such as aluminum and copper, or ferromagnetic material with high permeability such as mu-metal and nickel, or a combination thereof. As shown in Equation 2, both highly conductive and permeable materials may help increase the skin depth of a given shielding material. These materials may be used for attenuating signals with extremely high or low frequencies.\nIn another embodiment, the window shield 320 may be integrated to an anti-scattering x-ray grid. The anti-scattering x-ray grid may be installed in front of the x-ray detector. The anti-scattering x-ray grid is primarily used for removing the scattered radiation caused by various substances in the imaged subjects in order to produce sharp images. The anti-scattering x-ray grids are usually constructed by lead strips and aluminum interspaces with smooth, enameled aluminum or carbon fiber composite covers. Integrating the window shield 320 to the anti-scattering x-ray grid can provide rigid and durable structures for attaching the window shield 320 to the navigation target 230, as the window shield 320 may be constructed of thin conductive sheets or foils. A distortion map may be created for each integrated navigation target with the conductive ring shield 310 and conductive window shield 320 as well as the x-ray grid assemblies. The map may later be used for correcting the EM sensor position and orientation distortion during on-line image acquisition and instrument navigation.\nWhile the invention has been described with reference to certain embodiments, it will be understood by those skilled in the art that various changes may be made and equivalents may be substituted without departing from the scope of the invention. In addition, many modifications may be made to adapt a particular situation or material to the teachings of the invention without departing from its scope. Therefore, it is intended that the invention not be limited to the particular embodiment disclosed, but that the invention will include all embodiments falling within the scope of the appended claims.\n|Cited Patent||Filing date||Publication date||Applicant||Title|\n|US5635714||Nov 16, 1995||Jun 3, 1997||Trygon, Inc.||Data reduction system for real time monitoring of radiation machinery|\n|US6246231||Jul 29, 1999||Jun 12, 2001||Ascension Technology Corporation||Magnetic field permeable barrier for magnetic position measurement system|\n|US6490475||Apr 28, 2000||Dec 3, 2002||Ge Medical Systems Global Technology Company, Llc||Fluoroscopic tracking and visualization system|\n|US6636757||Jun 4, 2001||Oct 21, 2003||Surgical Navigation Technologies, Inc.||Method and apparatus for electromagnetic navigation of a surgical probe near a metal object|\n|US7075088 *||Apr 8, 2005||Jul 11, 2006||Shimadzu Corporation||Two-dimensional radiation detector|\n|US7096148||Dec 22, 2004||Aug 22, 2006||Ge Medical Systems Global Technology Company, Llc||Magnetic tracking system|\n|US20040097805||Jul 14, 2003||May 20, 2004||Laurent Verard||Navigation system for cardiac therapies|\n|US20060098851 *||May 11, 2006||Moshe Shoham||Robot for use with orthopaedic inserts|\n|US20080224056 *||Mar 18, 2007||Sep 18, 2008||James Zhengshe Liu||Energy Detector and Related Apparatus|\n|JP2005274379A||Title not available|\n|1||GB International Search Report Application No. GB0811107.2 (7 pages) Oct. 28, 2008 and Mar. 18, 2009.|\n|2||V. V. Kindratenko, \"A survey of electromagnetic position tracker calibration techniques\", Virtual Reality: Research, Development, and Applications, pp. 169-182, vol. 5, No. 3, 2000.|\n|Citing Patent||Filing date||Publication date||Applicant||Title|\n|US8526700 *||Oct 5, 2011||Sep 3, 2013||Robert E. Isaacs||Imaging system and method for surgical and interventional medical procedures|\n|US8718346 *||Dec 20, 2012||May 6, 2014||Saferay Spine Llc||Imaging system and method for use in surgical and interventional medical procedures|\n|US8792704 *||Aug 27, 2013||Jul 29, 2014||Saferay Spine Llc||Imaging system and method for use in surgical and interventional medical procedures|\n|US8908952 *||May 6, 2014||Dec 9, 2014||Saferay Spine Llc||Imaging system and method for use in surgical and interventional medical procedures|\n|US20120087562 *||Oct 5, 2011||Apr 12, 2012||Isaacs Robert E||Imaging System and Method for Surgical and Interventional Medical Procedures|\n|US20130113791 *||Dec 20, 2012||May 9, 2013||Minispine, Inc.||Imaging System and Method for Use in Surgical and Interventional Medical Procedures|\n|US20130342578 *||Aug 27, 2013||Dec 26, 2013||Robert E. Isaacs||Imaging System and Method for Use in Surgical and Interventional Medical Procedures|\n|US20140240355 *||May 6, 2014||Aug 28, 2014||Saferay Spine Llc||Imaging System and Method for Use in Surgical and Interventional Medical Procedures|\n|US20150021865 *||Jul 20, 2013||Jan 22, 2015||James Lin||Self-righting means for leaning vehicles; primarily by gravity|\n|U.S. Classification||378/204, 378/207|\n|Cooperative Classification||A61B6/4291, A61B6/06, A61B6/4441, A61B6/12, G21F3/00|\n|European Classification||A61B6/12, A61B6/06|\n|Jun 26, 2007||AS||Assignment|\nOwner name: GENERAL ELECTRIC COMPANY, NEW YORK\nFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:LI, DUN ALEX;AUFRICHTIG, RICHARD;WESTON, LONNIE;AND OTHERS;REEL/FRAME:019480/0954;SIGNING DATES FROM 20070517 TO 20070626\nOwner name: GENERAL ELECTRIC COMPANY,NEW YORK\nFree format text: ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNORS:LI, DUN ALEX;AUFRICHTIG, RICHARD;WESTON, LONNIE;AND OTHERS;SIGNING DATES FROM 20070517 TO 20070626;REEL/FRAME:019480/0954\n|Sep 20, 2013||REMI||Maintenance fee reminder mailed|\n|Feb 9, 2014||LAPS||Lapse for failure to pay maintenance fees|\n|Apr 1, 2014||FP||Expired due to failure to pay maintenance fee|\nEffective date: 20140209"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"format_constrained"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:2ced3ae4-96c9-4ab2-a745-d0741694f31c>","<urn:uuid:2a63be97-167f-49d7-a705-4054091bb79c>"],"error":null}
{"question":"How do nuclear power plants and wind farms compare in terms of their animal-related challenges?","answer":"Nuclear power plants and wind farms face different animal-related challenges. Nuclear plants primarily deal with jellyfish and other sea creatures clogging their intake pipes, as seen in incidents at Swedish reactors and PG&E's Diablo Canyon plant. Wind farms, on the other hand, face issues with bird deaths - they are estimated to kill between 140,000 and 328,000 birds annually in the U.S., including eagles, songbirds, and endangered species. This impact is expected to grow, with projections of at least one million bird deaths annually by 2030 when there will likely be more than 100,000 wind turbines in the U.S.","context":["It’s no secret the power sector faces many challenges. But while serious arguments swirl around the future of utility business models, cutting-edge technologies and wonky policy issues like rate design, there is another challenge that utilities face on a very regular basis that doesn't often make headlines: Animals.\nFrom squirrels to jellyfish to a certain species of two-legged mammals, utilities have to share their service territories with critters who are not (usually) paying customers. And those critters can cause utilities some major headaches — such as the time when a single monkey took out an entire country’s grid.\nUtilities will tell you planning for animal-related challenges on the grid is just part of the daily grind. Here are some of the animal problems they face.\nForget about cyber hackers. Squirrels represent a far greater threat to the power grid, the anonymous creator of CyberSquirrel, a website that tracks squirrel-related outages, told the Washington Post.\nJust ask any of the Wall Street traders who couldn’t trade roughly 20 million shares on the NASDAQ in 1987 when a squirrel took out one of their computer centers. That may be the most dramatic example, but squirrels are a real and frequent problem for utilities.\n\"[T]here is tons of hype about how we are at so much risk from a devastating cyber attack and yet we can't even protect our infrastructure from squirrels, or birds or snakes,\" the site's creator told The Post.\nThere were 89 outages related to squirrels this year, according to the Eaton Blackout Tracker, but it's not just them. Though they may be the furriest and nuttiest animal causing mayhem on the grid, snakes and raccoons can also do their fair share of damage. Animal-related outages overall are the number 5 cause of power outages in the U.S., according to Eaton, with 149 total outages this year.\nProtecting a substation against animal intruders can cost upwards of millions, the Eaton report found. But beyond eliminating wildlife entirely, there’s not much a utility can do, except for finding ways to stop them dead in their tracks — humanely, of course. Some of these strategies include wrapping vulnerable parts of substations in polymer covering, as well as putting animal guards on poles and other materials to ward off curious critters.\nNotably, zero blackouts caused by a cyberattack have been reported thus far in the past year. But blackouts aren’t the only headaches caused by animals.\nOnce you build something, it’s hard to keep animals away: Eagles like to perch on power lines. Squirrels and snakes climb into substations. If that wasn't hard enough, what do you do when you build something directly on an animal's home? Just ask the fish.\nHydro facilities have long threatened their migratory patterns and stream flow. Utilities in particular have often come under fire the ways dams impact trout streams and other aquatic life. Because many dams were built long before current environmental regulations, mitigation requirements today are more reactionary. But as Avista Corp., a Pacific Northwest utility in Washington, has found out, mitigating for aquatic species is just part of the job.\n“[Fish] are part of the natural environment, right? [And] it’s part of our mitigation impact of dams,” Bruce Howard, Avista’s director of environmental affairs, told Utility Dive. Avista declined to give cost estimates, citing the complex accounting that goes into environmental mitigation. Fish can't mutiny, exactly, but eventually dams outlive their usefulness and are retired, freeing up the roadways ... or waterways, once more.\nConcerns around aquatic life have even led some hydropower plants to be retired. Take the four hydroelectric dams in California and Oregon, which are involved in the biggest dam removal thus far. A coalition of tribes, environmental groups, and utilities including PacifiCorp hashed out a plan to begin a $450 million project to restore the river, streams and aquatic life by shutting down the dams.\nThe right perch\nIf you're an osprey or eagle looking for a nice and high perch for a nest, what better place can you find than a power pole? Well, that's not how utilities see it.\n“Raptors are naturally drawn to power poles because they offer a high place to perch, roost, nest and hunt,” Jenna Shaver, a spokeswoman for Arizona Public Service Co., told Utility Dive in an email. “The large wing spans of raptors, however, make them vulnerable to harm by the electricity being carried on the power lines.”\nIt also makes them more vulnerable to feral cats, who might try to scale those poles in search of lunch, Shaver said. That’s especially bad if those species are endangered.\nSometimes a little gullibility also goes a long way. Putting animal guards on power poles and setting up false poles a little ways down from the real ones are two options to help mitigate for these issues, an Avista spokesperson told Utility Dive. APS has built platforms to relocate the nests to avoid an electrifying death for the chicks. Eventually, the birds warm to their new home, returning for years to the same nest, never realizing they were fooled.\nJellyfish go for nuclear option\nFor nuclear plants, jellyfish may be their biggest animal threat. Swedish operators scrambled to shut down a nuclear reactor two years ago after a bunch of spineless aquatics slipped through filters and clogged the plant's intake pipes.\nThat's not the first time that sea creatures have caused trouble for nuclear facilities. Pacific Gas & Electric’s Diablo Canyon nuclear plant — now slated for shutdown for unrelated reasons — also shuttered two of its reactors after gobs of sea salp, a type of plankton, jammed the pipes.\nThis isn’t a new phenomenon, by any means. (Nor is it a plot by the gelatinous creatures to take over the sea world.) But marine biologists have warned it could get worse due to the impacts of climate change.\n“What we’ve seen as you increase temperature … you get massive blooms,” said Dr. Vicki Martin, a professor of biology at North Carolina State University. “Jellys seem to be liking this and increasing worldwide to the point they are clogging power plants. What happens that when you get these numbers of jellyfish continuously ... because there are so many of them, they clog the filters so they shut down.”\nOver the past 15 years, summers have warmed with 2016 being the hottest summer on record so far. As temperatures rise, oceans absorb the excess heat, which also boosts temperatures. Since jellyfish thrive in warmer water, Martin says more blooms are likely on the way, including from species of jellyfish making their way into regions where they never lived before.\nHer advice to nuclear plant operators? Install more filters.\nBirds in the wind\nClean energy is great — until it kills things.\nTake wind power: Researchers estimate monopole wind turbines kill between 140,000 and 328,000 birds in the U.S. every year. And the taller the poles, the more deadly the turbine.\nUnder the Migratory Bird Treaty Act, it’s illegal to kill protected birds, even if it’s accidental. So the stakes are high for wind turbine operators to prevent bird deaths. There are many ways that operators try to save birds with technology like radars and cameras.\nBut wind farms aren’t the only clean energy resource with a deadly side. Solar has done its fair share in sizzling creatures who venture too near.\nConcentrated solar’s Icarus problem\nIt’s like the tale of Icarus, who flew too close to the sun, singed his wings and fell back to the earth. Only this time the real story is about the birds who flew too close to a solar farm in the Mojave desert.\nLast year, the Wall Street Journal reported the Ivanpah concentrated solar project killed roughly 3,500 birds during its first year of operation, sparking concerns from environmentalists. The Los Angeles Times pegged the number of deaths a little higher — at 6,000 deaths a year.\nAccording to the Los Angeles Times, the concentrated solar farm's operators have replaced the flood lights with LEDs, rearranged the mirrors and installed anti-perching spikes to the solar towers in hopes of reducing bird deaths.\nAnimal deaths caused by wind and solar may contain an element of spectacle, but renewables advocates are quick to point out they are much more humane than their fossil fuel counterparts. According to a U.S. News review of available literature, coal production and generation kills nearly 8 million birds annually, while wind and solar combine for less than 500,000.\nLet's not forget what may be the most disruptive animal species of them all: Humans.\nMost of you may remember the blimp that escaped its moorings last year, floating from Maryland to Pennsylvania and knocking out power for thousands along the way. It inspired memes, social media commentary and even a reference during the presidential primaries. (Then-candidate Mike Huckabee referred to the federal government as a \"runaway blimp\" at a Republican primary debate after the incident.)\nWhile that may be a particularly notable incident, the most common human-related mishap on the grid is humans running their vehicles into power poles. According to the Eaton Report, 419 of outages were vehicle-related. Other than promoting responsible driving, there doesn’t appear to be any other deterrent.\nBut from cyber hacks to sniper attacks, not all human-related disruptions on the grid are accidental. Sometimes, a utility’s worst enemy can be the very people they serve.","Wind Energy Frequently Asked Questions |\nWhat Is American Bird Conservancy’s (ABC) policy regarding wind energy?\nWind power can be an important part of the solution to global warming, but wind farms can also kill birds—including eagles, songbirds, and endangered species—through collisions with turbines, and also harm them through loss of habitat. By 2030, there will likely be more than 100,000 wind turbines in the U.S., and these are expected to kill at least one million birds each year—probably significantly more. Wind farms are also expected to impact almost 20,000 square miles of terrestrial habitat, and over 4,000 square miles of marine habitat by 2030, some of it critical to threatened species.\nTo be a truly green source of energy, wind power needs to be Bird-smart and that means wind power employs careful siting, operation and construction mitigation, monitoring, and compensation to reduce and redress any unavoidable bird mortality and habitat loss from wind energy development. These are issues that should be included in mandatory federal wind standards. All wind farms should employ bird-smart principles and comply with relevant state and federal wildlife protection laws.\nWhat is bird-smart wind energy?\nBird-smart wind power implements careful siting considerations, operation and construction mitigation, bird monitoring, and compensation to reduce and redress unavoidable bird mortality and habitat loss. These are issues that the federal government should include in mandatory wind standards. For terrestrial wind farms, bird-smart wind should address:\n- Siting: Bird-smart wind power (including wind farms and associated infrastructure) is sited to prevent harm to birds, ideally in already altered habitats such as farmland, and avoids sensitive areas. Examples of such areas may include migratory bottlenecks, wetlands, raptor concentration and key nesting areas, the edges of ridges used by migrants, key habitat or flight paths for endangered or declining species, breeding concentrations of species that avoid tall structures (such as some grouse species), and in or adjacent to Important Bird Areas. Maps with detailed data on wildlife are currently being developed by conservation groups for use by the wind industry. Pre-construction assessments should always be conducted to confirm whether a particular site presents an especially high risk to birds. Some areas are not going to be suitable for wind development.\n- Operation and Construction Mitigation: Bird-smart wind power uses the best technology and management practices to avoid and minimize harm to birds, such as by burying transmission lines in high risk areas, following Avian Power Line Interaction Committee standards for above-ground transmission lines, using lighting that minimizes nighttime migratory bird collision mortality (such as strobe lights), using unguyed rather than guyed meteorological towers, and restoring habitat disturbed by construction, e.g., re-compacting soils disturbed by construction and replanting native vegetation (or restoring the site if the wind farm is decommissioned).\n- Monitoring: Bird-smart wind power conducts effective, federally reviewed and approved, site-specific, pre- and post-construction studies/assessments to assist with improved siting and operation, and to properly quantify impacts. Pre-construction assessments must provide sufficient data to assist with micro-siting (e.g., by use of radar to detect local bird movements), create an annual baseline against which post-construction studies can be evaluated, use all existing available bird study data, and be conducted during months when bird use can be expected to be at its peak at the selected site. Post-construction studies must employ mathematical models that best account for variations in local conditions and the relative difficulty of locating bird carcasses in different habitats, as well as any scavenging by predators that may reduce the number of carcasses found, and run for at least two years (and long enough to determine the efficacy of, and make needed revisions to, operational mitigation measures).\n- Compensation: Bird-smart wind power redresses the loss of any birds or habitat unavoidably harmed by construction and operation to a net benefit standard. This includes bird deaths caused by collisions with turbines and their associated power lines, and lost or degraded habitat (e.g., areas of abandoned habitat) Such compensation could include acquiring additional land for the National Wildlife Refuge system or other off-site habitat conservation projects.\nAlthough offshore wind power is not yet operational in the U.S., an analogous set of siting, operating, and compensatory measures need to be developed to make it bird-smart.\nAll wind farms should have an Avian Protection Plan which includes American Bird Conservancy’s bird-smart principles, and a means of implementing them and tracking and reporting on this implementation. Wind farms should also comply with relevant state and federal wildlife protection laws such as the Endangered Species Act, Migratory Bird Treaty Act, Bald and Golden Eagle Protection Act, and National Environmental Policy Act.\nHow would you know if a potential wind farm site will have large or small impacts to birds?\nSee section above on pre-construction monitoring and post-construction monitoring.\nIsn’t the Federal Government developing wind energy regulations?\nNo, the Federal Government has released draft, voluntary wind-energy guidelines that were produced from recommendations to the Secretary of the Interior by a Federal Advisory Committee. During the public comment period on those proposed voluntary guidelines, ABC will urge that that the Department of the Interior enact mandatory standards that the industry must follow. We do not believe that energy industries should be able to choose whether or not to consider bird impacts.\nA recent lawsuit regarding the Altamont Pass Wind Farm in California illustrates that getting the right thing done voluntarily is anything but a sure thing. Recent studies say that approximately 7,600-9,300 birds were killed there each year, including 55-94 Golden Eagles, 475-477 American Kestrels, 253-433 Red-tailed Hawks, and 714-718 Burrowing Owls. After seven years of being challenged by various conservation groups, it finally took a lawsuit to get changes made at Altamont Pass. NextEra Energy Resources has only recently agreed to replace 2,400 of its old wind turbines at Altamont Pass with fewer, larger models that produce the same amount of total power. They also agreed to place the new turbines in “more environmentally friendly” locations, and to pay $2.5 million for research and raptor habitat improvement.\nWhat kinds of birds are impacted by wind farms?\nPotentially all night-migrating songbirds are at risk of colliding with wind turbines, as are raptors and other birds when wind farms are sited in areas they frequent. Habitat loss is also an issue as wind farms can degrade bird habitat or cause birds to abandon habitat.\nGolden Eagles will be especially impacted because much of the additional wind build-out planned for the western U.S. is expected to occur in areas they inhabit. The endangered Whooping Crane will be exposed to additional risk from collision with new power lines erected to service wind farms along their migratory pathways.\nTo a Greater Sage-Grouse and some other birds, any tall structure such as a wind turbine is a threat because it is a potential perch for a predatory bird. A wind turbine standing a considerable distance away has much the same effect as a small tree at a few hundred yards, causing sage-grouse to abandon traditional lekking grounds up to three miles away from a wind farm. Unfortunately for the Sage-Grouse, Wyoming, one of this bird’s last remaining strongholds, is slated for significant wind farm build-out. It is very important for the future of the Greater Sage-Grouse that this development is appropriately sited\nHow many birds are killed by wind farms each year?\nNo one knows for sure. Recent estimates of the number of birds killed by wind turbines ranges from a low of 100,000 birds/year to 440,000 birds/year (calculated by the U.S. Fish and Wildlife Service). If 20% of the nation’s electricity comes from wind power by 2030, ABC estimates that at least one million birds per year will be killed by wind turbines, probably significantly more.\nAren’t there laws that protect birds from being killed by wind farms?\nWhooping Cranes and some other birds are protected under the Endangered Species Act. Golden Eagles are protected under the Bald and Golden Eagle Protection Act (BAGEPA), and most migratory birds are protected by the Migratory Bird Treaty Act (MBTA). Unfortunately, both the BAGEPA and MBTA are not currently sufficiently enforced to prevent predicted mortality resulting from wind development. However, in 2011, the U.S. Fish and Wildlife Service is expected to begin issuing permits for wind farms that expect to kill Golden Eagles, contingent on the wind farms taking tangible steps to protect eagles. The Greater Sage-Grouse, meanwhile, currently receives no federal legal protection, though several states have stepped up to protect remaining core breeding areas.\nRead full ABC Policy Statement on Wind Energy"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:05889604-6292-41e6-927a-3e9b3d6133a1>","<urn:uuid:ad348f5b-9b9c-419d-9045-9be2eb6e06f6>"],"error":null}
{"question":"How do time-inconsistent preferences manifest in behavioral challenges, and what therapeutic strategies does CBT offer to address such decision-making patterns?","answer":"Time-inconsistent preferences manifest when people choose immediate rewards over long-term benefits, as seen in cases where someone might keep reading webcomics for immediate gratification instead of making dinner for better health. This relates to hyperbolic discounting, where immediate rewards are inflated in perceived value compared to longer-term benefits. CBT offers specific therapeutic strategies to address such decision-making patterns through a structured approach that includes developing awareness of misguided thinking patterns, re-evaluating thoughts in light of reality, and using practical problem-solving techniques. The therapy helps people understand their motivation and behavior, build confidence in managing stressful situations, and develop healthier ways of thinking and behaving. It's a collaborative effort between therapist and patient that typically involves weekly sessions over 2-3 months, focusing on present solutions rather than past issues.","context":["[I no longer endorse this view. Check out There is No Akrasia for an updated view of akrasia.]\nAkrasia is a term that comes to us from the Greeks. The word means “weakness of will”, and it’s been discussed by philosophers for thousands of years. The basic idea revolves around people making choices; specifically, choices that they don’t think are good, but choose anyway.\nThrough history, philosophers have found akrasia to be an impossible or contradictory concept. From Socrates, who says that we never do anything if we know it’s bad, to contemporaries like Donald Davidson who try to show that akrasia is indeed possible, there’s been lots written on the subject.\nAnyhow, if you think A is worse than B but choose A all the same, you are demonstrating akrasia. For example, if you want to stop laying on the couch and get up and move, but find yourself still sitting, there’s a gap happening where your actions and goals aren’t lining up.\nThis should sound really similar to the sorts of situations where we combat preference reversal, or avoid distractions. I believe this is because akrasia is really just a combination of time-inconsistent preferences and a few other factors.\nLet’s unpack our example of sticking to the couch vs exercising:\nR.M Hare (among others) see that if you think “exercising is better than laying on the couch”, this will also mean that you will choose to exercise. So when your butt stays glued to the couch, this appears fairly contradictory. But it seems kind of a stretch to say that exercise is strictly better than sitting on the couch; there’s pros and cons to each one of the choices (e.g. it’s not “sitting on the couch” vs “sitting on the couch and getting $20”).\nInstead, I think it makes more sense to break down what we mean by “better”. What we we’re getting at seems to be closer to:\n“Exercising compared to sitting on the couch affords me a chance to stay fit, improve my mood, etc. Compared to staying sitting, which could kill me early, exercising better fulfills my long-term goals of health and wellness.”\n(For something similar when it comes to moral judgments, see this.)\nBy breaking apart our “A is better than B” when we evaluate choices and instead being explicit about the pros / cons, we can remove any mysterious “betterness” qualities which might force us to choose a specific action.\nBut this doesn’t explain why akrasia might happen in the first place. Given that I know that A has all those nice benefits which coincide with my long-term goals, why don’t I choose it over B?\nI believe the answer is, “Because factors other than what directly achieves my long-term goals also play a role in shaping my decisions.” Paraphrasing Michael Stocker, “Mood, energy, interest, etc. can all factor in.”\nOften, your intuitions can be a good source of information. If you find yourself trying to force yourself to do something you “should do”, or if you find yourself “wanting to want”, it seems likely that something’s misaligned.\nI believe akrasia crops up when our actions and intentions are miscalibrated, so there’s tension from conflicting goals.\nWe already know that humans aren’t the most consistent creatures. So when we make decisions, there’s going to be reasons for why we chose them, but they might not correlate to our long-term goals. For example, if you’re reading webcomics, you may keep clicking for the immediate reward of an amusing image, which hyperbolic discounting inflates to be more valuable than, say, making dinner, which might benefit your health more.\n(This is actually a contentious point, where some philosophers make a distinction between “choosing B out of free will” or “being forced to choose B because of other factors”, the latter of which is referred to as “compulsion”.\nI think that such a distinction isn’t really what we need, because we can’t talk about choosing actions without reasons or incentives, so saying you “choose B in isolation without any external influences” seems too far an abstraction from real life, where nothing is really isolated.)\nBut in some cases, I think taking a break (i.e., not taking the course of action that best maximizes achievement of our long-term goals) can be the right thing to do. Like I mentioned earlier, humans have lots of goals. We’re also not infinite; we run out of energy.\nIf taking breaks is helps maintain our energy levels, then it actually is helpful to our long-term goals, just not outright. Lots of other indirect things like socialization, hygiene, and more all seem to be necessary to keeping us running smoothly.\nLastly, getting a good understanding for the different desires you have and actually weighing them seems to be a strong tactic to better align your actions to all your goals. If a part of you doesn’t want to do something, try actually looking into why. Some short-term “cravings” might very well have far more cons than pros (which align with things you care about), but remember that you also need rest and other Good Things to function well!\nBy understanding that we can hold multiple goals, which different actions satisfy to varying extents (sometimes in ways that contradict with our long-term goals), akrasia can happen. I don’t think that akrasia is considered contradictory, though. It looks that way if you just focus on your long-term goals.\nAdditional Info (feel free to skip)\n- I got most of my information from the Stanford Encyclopedia of Philosophy page, if you want to learn more.\n- My position is pretty close to the “externalist” camp. There are also other views you may want to investigate.\n- All of the general reasoning about things aligning to “long-term goals” does assume some sort of a value system that ranks things according to how much you care about them. This probably deserves a topic on its own. Just keep in mind that I’m making some assumptions here.\n- See here for a quick essay on how directly optimizing for X might is not the same as actually optimizing for X (i.e., if you have an indirect method that does better, it’s still optimizing).","Cognitive-Behavioral Therapy (CBT) for Addiction and Substance Abuse\nCognitive behavioral therapy, or CBT, is a form of psychotherapy that is effective in treating a range of mental health issues including mood disorders, anxiety disorders, and substance use disorders.1 CBT emphasizes changing negative thought patterns to change behaviors, as well as developing and implementing healthy coping skills into one’s life.1\nThis article will break down the clinical conditions that CBT addresses, how it helps those struggling with substance use disorders and other mental health conditions, and who this type of treatment might be right for.\nAmerican Addiction Centers offers cognitive behavioral therapy along with a variety of other therapies recommended for the safe and effective treatment of drug and alcohol addiction. To learn more about our program offerings and our various nationwide treatment centers, call\nWhat Is Cognitive Behavioral Therapy?\nCognitive behavioral therapy is a form of behavioral therapy and a well-established treatment intervention for people suffering from a wide range of mental health disorders. Cognitive behavioral therapy focuses on cognition, or how your thoughts can influence your mood – not vice-versa.2 CBT is a goal-oriented type of therapy that addresses cognitive issues such as dysfunctional automatic thoughts, maladaptive thinking (or cognitive distortions), and underlying core beliefs.2 Most therapists who use CBT customize the therapy to the specific needs of each patient.2\nCognitive behavioral therapy was developed in the 1960s by psychiatrist Aaron Beck.2 CBT originated when Beck’s perspective changed on mental health conditions from viewing depression and anxiety as mood disorders to viewing these conditions as cognitive disorders.2\nFor example, if a CBT patient’s automatic interpretation of a situation is seen through a negative lens of cognition (thoughts and beliefs), then it is likely to impact their mood negatively.2 Maladaptive thinking or cognitive distortions, such as overgeneralizing, catastrophizing, or personalizing situations, can cause errors in logic and misguided conclusions, sometimes resulting in or worsening of symptoms of depression, anxiety, and other mental health conditions.2\nUnderlying core beliefs can shape someone’s life and be the foundation for automatic thinking. Someone’s ways of thinking and perceiving can undoubtedly shape the way that they interpret the world around them (and their role in it).2\nBeck believed that dysfunctional, automatic thinking, even if it exaggerated or distorted, plays a significant role in mental and behavioral disorders.2\nThe ultimate goal of CBT is to address these negative patterns of thinking and subsequent behaviors to create positive change in a person’s life for the better.2\nAlthough CBT is effective in treating mental disorders, CBT can be helpful for anyone looking to make a shift in the quality and health of their thinking or improve their mood.\nHow Does CBT Work?\nThe fundamental principles of CBT are:1\n- Psychological disorders are based, in part, on inaccurate ways of thinking.\n- Psychological disorders are also based on learned patterns of negative behavior.\n- People suffering from psychological disorders can learn better ways of coping, thereby relieving their symptoms and subsequently creating positive changes in their lives.\nTherapists may also help clients by using role-playing techniques to develop a plan for how to deal with potentially problematic situations in the future.1\nFor example, creating a pros and cons list of reactions to various situations can help people gain an understanding of how their thoughts and actions may make things better or worse. It is important to play out those scenarios in therapy before they need to draw on them in life. Having a plan of action before a person needs this plan can help people feel more prepared and confident. Every person’s challenges in life are unique, so it is up to both the therapist and patient to develop a treatment strategy to address the patient’s needs. What works for one person may not work for another.1\nCBT with a trained therapist helps clients take control of their cognition and develop healthier ways to think, emote, and behave independently and through tangible exercises. The therapist and client work collaboratively to develop strategies to not only have an awareness of negative thought patterns and beliefs but to learn to problem solve and change their behaviors.1 It is a solution-based form of therapy focused less on the past and more on the present and what to do now to make things better.1\nGoals of CBT\nThe goals of CBT will include developing an awareness of one’s misguided thinking patterns that are creating problems in their life and re-evaluating such thinking in light of reality.1 CBT also encourages people to understand the motivation and behavior of themselves and others, as well as using realistic problem-solving techniques to solve problems.1 As a result, this should build a person’s confidence in their abilities to manage stressful situations.\nAnother goal of CBT treatment is to help people learn how to calm their mind and body and begin to face their fears instead of avoiding them.1 CBT can be an empowering tool to help people realize that they can manage their emotions and various situations they may encounter throughout their lives in a healthier manner.\nBenefits of Cognitive Behavioral Therapy\nCBT is a practical, goal-oriented form of therapy. It is a collaborative effort between the therapist and patient that can help the patient improve many aspects of their life.2 Treatment is individualized, so cognitive behavioral therapy may look different for different people. CBT has been shown to be beneficial in treating anxiety, depression, and even ADHD.2 It is also a form of short-term therapy, with weekly sessions typically lasting 2-3 months.2\nIs CBT Covered by Insurance?\nThe short answer is yes, cognitive behavioral therapy is typically covered by insurance. The Affordable Care Act mandates that health insurance companies must cover mental health and substance use disorders on par with coverage for medical or surgical procedures.5\nHowever, individual plans and coverage will vary depending on carriers. If you have questions about your coverage, call the number on your insurance card to find out more information about your specific plan. Some cognitive behavioral therapists accept insurance, but others may not accept insurance. Others may be out-of-network (OON) but offer patients the option of paying their therapy costs up-front and then sending a superbill to their insurance company for reimbursement. In that case, the therapist gives the client the paperwork necessary to submit their insurance claim directly to their provider.\nIs CBT Covered by Medicare and Medicaid?\nMedicaid is the largest payer for mental health services in the United States.6 The Affordable Care Act also expanded Medicaid benefits to millions of Americans that didn’t previously qualify. All Marketplace plans cover both mental health and substance use disorder treatments as “essential health benefits.7\nCBT is considered an evidence-based treatment option for mental health and SUDs. To find a provider in your area who accepts Medicaid and Medicare, click here to be directed to the U.S. Department of Health and Human Services webpage, which provides links to various resources and information regarding providers who accept these types of insurance.8"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_inference"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:091548c2-bd09-41b9-a250-0d7b084b5fc7>","<urn:uuid:9d5b97de-4c8a-441a-bd22-e316530a9cfe>"],"error":null}
{"question":"How do the depths of Mount Sharp on Mars compare to the Mariana Trench on Earth?","answer":"Mount Sharp on Mars is about 5 kilometers high, while the Mariana Trench reaches depths of up to 11,000 meters (11 kilometers) below sea level on Earth. The Mariana Trench is more than twice as deep as Mount Sharp is tall.","context":["NASA’s Mars Curiosity rover has successfully taken measurements of the density of a mountain on the red planet and finds it more porous than originally thought.\n|Curiosity rover used the Mars Hand Lens Imager to capture a set of 55 high-resolution images, which were stitched together to create this full-color self-portrait. The mosaic shows the rover at ‘Rocknest,’ the spot in Gale Crater where the mission’s first scoop sampling took place. (Image: NASA/JPL-Caltech/Malin Space Science Systems)|\nocks on Mars are more porous and less compacted than scientists expected, according to a study that used data from NASA’s Curiosity rover.\nResearchers, including those from Arizona State University (ASU) in the US, measured the density of rock layers in 154-kilometre-wide Gale Crater on Mars.\n“What we were able to do is measure the bulk density of the material in Gale Crater,” said Travis Gabriel, a graduate student at Arizona State University.\nFindings of the study\nThe findings, published in the journal Science, show that the layers are more porous than scientists had suspected.\nThe discovery also gives scientists a novel technique to use in the future as the rover continues its trek across the crater and up Mount Sharp, a five-kilometre-high mountain at its centre.\nNASA’s Mars rover Curiosity captured this composite image, which looks toward the higher regions of Mount Sharp, on September 9, 2015.(Image: NASA/JPL-Caltech/MSSS)\nAs Curiosity ascended Mount Sharp, the gravitational force increased – but not as much as scientists expected.\n“The lower levels of Mount Sharp are surprisingly porous,” said Kevin Lewis of Johns Hopkins University in the US.\n“We know the bottom layers of the mountain were buried over time. That compacts them, making them denser. But this finding suggests they weren’t buried by as much material as we thought,” Lewis said.\nHow did the scientists reach this conclusion?\n1. Gabriel worked on computing what the grain density should be for the rocks and ancient lake-bed sediments the rover has been driving over.\n“Working from the rocks’ mineral abundances as determined by the chemistry and mineralogy instrument, we estimated a grain density of 2810 kilogrammes per cubic metre,” he said in a statement.\n“However, the bulk density that came out of our study is a lot less – 1680 kilogrammes per cubic metre,” said Gabriel.\n2. The much lower figure shows that the rocks have a reduced density, most likely resulting from the rocks being more porous.\n3. This means the rocks have been compressed less than scientists have thought.\n4. The engineering sensors used in the study were accelerometers, much like those found in every smartphone to determine its orientation and motion.\n5. Curiosity’s sensors do the same, but with much greater precision, helping engineers and mission controllers navigate the rover across the Martian surface.\n6. Curiosity’s accelerometers can also be used as a gravimeter – an instrument that can measure gravity – to reveal secrets about Martian geology.\n7. Even when Curiosity is stationary, the accelerometers are constantly detecting the slight changes in gravity on Mars, as Curiosity rolls further up Mount Sharp.\n8. Researchers used over 700 measurements from Curiosity’s accelerometers taken between October 2012 and June 2017. These were calibrated to filter out ‘noise’, such as the effects of temperature and the tilt of the rover during its climb.\n9. The calculations were then compared to models of Mars’ gravity fields to ensure accuracy.\nThere are many mountains within craters or canyons on Mars, but few approach the scale of Mount Sharp.\nScientists still aren’t sure how the mountain grew inside of Gale Crater. One idea is that the crater was once filled with sediment. How much of it was filled remains a source of debate, but the thinking is that many millions of years of wind and erosion eventually excavated the mountain.\nA computer generated image showing Mount Sharp rising from the center of the Gale Crater.(Image: NASA/JPL-Caltech/ASU/UA)\nIf the crater had been filled to the brim, all that material should have pressed down, or compacted, the many layers of fine-grained sediment beneath it.\nBut the new paper suggests Mount Sharp’s lower layers have been compacted by only a half-mile to a mile (1 to 2 kilometers) – much less than if the crater had been completely filled.\n“There are still many questions about how Mount Sharp developed, but this paper adds an important piece to the puzzle,” said study co-author Ashwin Vasavada, Curiosity’s project scientist at NASA’s Jet Propulsion Laboratory in Pasadena, California.\nMars and Earth are planetary siblings\nLewis said that Mars holds plenty of mystery beyond Mount Sharp. Its landscape is like Earth’s, but sculpted more by wind and blowing sand than by water. They’re planetary siblings, at once familiar and starkly different.\n“To me, Mars is the uncanny valley of Earth,” Lewis said. “It’s similar but was shaped by different processes. It feels so unnatural to our terrestrial experience.”","|The graphic shows the early stages of the Izu-Bonin subduction zone. The active subduction zone has been moving eastwards throughout its history. The drilling took place where the process has begun. Credit: Philipp Brandl, GEOMAR|\nAbout 2000 kilometers east of the Philippine Islands lies one of the most famous topographical peculiarities of the oceans: the Mariana trench. Reaching depths of up to 11,000 meters below sea level, it holds the record as the deepest point of the world's ocean. This 4000-kilometer-long trench extends from the Mariana Islands in the south through the Izu-Bonin Islands to Japan in the north.\nHere, the Pacific Plate is subducted beneath the Philippine Sea Plate, resulting in intense volcanic activity and a high number of earthquakes. The entire area is part of the \"Pacific Ring of Fire.\"\nBut when and how exactly did the subduction of the Pacific Plate begin? This is a controversial topic among scientists. An international team led by the GEOMAR Helmholtz Center for Ocean Research Kiel, the Japan Agency for Marine Earth Science and Technology (JAMSTEC) and the Australian National University investigated this early phase of subduction along the Izu-Bonin-Mariana trench, with findings published in the March edition of the scientific journal Earth and Planetary Science Letters.\nThe team of the JOIDES RESOLUTION was able to drill more than 1600 meters deep on the seabed, starting at a water depth of around 4700 meters below sea level. \"This is already at the limit of the technically feasible,\" emphasizes Dr. Brandl. Based on analysis of this drill core, the researchers were able to trace the history of the subduction zone layer by layer up to the approximately 50 million year-old rocks at the bottom of the core, which are typical for the birth of a subduction zone. \"There has not been such a complete overview yet,\" says Dr. Brandl.\nBrandl and his colleagues were now able to acquire and analyze microscopic inclusions of cooled magma from the rocks. The data obtained provide the scientists with insights into the history of volcanic activity at the Pacific Ring of Fire 30-40 million years ago. The researchers found evidence that volcanism was only beginning to gain momentum. The volcanic activity intensified with the rollback of the subduction zone towards the east and the huge explosive stratovolcanoes formed, similar to those present nowadays, for example along the western rim of the Pacific Ring of Fire.\nHowever, further drilling is necessary to test the validity of these observations. \"The more drill cores we can gain from such old strata, the better we learn to understand our own planet,\" Dr. Brandl says. The question of how subduction zones develop is not only interesting to understand the history of the earth. Subduction zones are the drivers for the chemical exchange between the earth's surface and the earth's interior. \"The dynamics of a subduction zone can thus also influence the speed of global elemental cycles,\" summarizes Dr. Brandl.\nThe above post is reprinted from Materials provided by Helmholtz Centre for Ocean Research Kiel (GEOMAR)."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_synthesis"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"comparison"}],"document_ids":["<urn:uuid:3d69fd02-5d5f-4236-88e6-4261b48c25a4>","<urn:uuid:5c6d44f4-5635-4e24-b63f-750262c58302>"],"error":null}
{"question":"What are Michigan women's gymnastics' historic achievements in 2021, and what environmental considerations are associated with timber-based athletic facilities?","answer":"The University of Michigan women's gymnastics team achieved their first national championship in 2021 with a program-best score of 198.2500, becoming just the seventh team ever to capture an NCAA women's gymnastics title. The environmental impact of the wooden facilities used in such sports depends on factors like the combustion temperature of wood fuel, with higher temperatures resulting in more complete combustion and fewer noxious gases. The manufacturing process of wooden sports facilities must consider factors like air pollution and greenhouse gas emissions, though wood from sustainable sources may be considered carbon-neutral.","context":["Women’s gymnastics team claims program’s first national championship\nIt all came down to one final routine, as every other event had finished. University of Michigan junior Abby Heiskell stood alone on the beam as the rest of the No. 2-ranked U-M women’s gymnastics team watched and waited for the final score to flash. Needing a 9.8500 for the Wolverines to capture their first championship, Heiskell delivered with a 9.9250, and Michigan became the 2021 national champion with a program-best 198.2500 on April 17 at Dickies Arena in Fort Worth, Texas. U-M joined an exclusive club, becoming just the seventh team to ever capture an NCAA women’s gymnastics title, scoring the third-best score in championship history and the best score in Michigan history. The Wolverines join Georgia, Utah, UCLA, Alabama, Oklahoma and Florida as the only women’s gymnastics teams in the country to win a national championship. U-M led throughout the meet, taking a slight 0.0500 advantage after the first rotation over the field before going up by 0.1375 for the second and third rotations. The all-around trio of Heiskell, Sierra Brooks and Natalie Wojcik all posted scores of 39.7000 or higher to take the top three spots in Michigan NCAA all-around history. For more on the team and its national title.\nNominations open for Distinguished University Innovator Award\nNominations are being accepted for the Distinguished University Innovator Award, which honors faculty members who have made important and lasting contributions to society by developing novel ideas and insights through their research, and then translating them to practice. The award was established in 2007 by the Office of the Vice President for Research and is supported by endowments from the U-M Office of Research and the Stephen and Rosamund Forrest Family Foundation. It is open to current members of the tenure/tenure track, research or clinical faculty or a team of up to three faculty members. The award comes with a $5,000 honorarium for the individual recipient or to be shared by team recipients. Nominations will be accepted until June 11, with the announcement of the winner expected in early September. For more on the award and how to submit a nomination.\nInstitute for Research on Women and Gender awards 12 faculty seed grants\nThe university’s Institute for Research on Women and Gender has awarded 12 seed grants for faculty projects on women, gender and sexuality. The grants support individual research activities, as well as collaborative projects, pilot studies, and initial research efforts, with nearly $70,000 awarded. The IRWG Faculty Seed Grant program, established in 1996, supports disciplinary and interdisciplinary faculty projects on women, gender and sexuality with annual awards. For a full list of award winners and details about their projects.\nFrankel Institute for Advanced Judaic Studies announces 2021-22 fellows\nThe Frankel Institute for Advanced Judaic Studies has announced that 13 scholars from four countries are 2021-22 Frankel Institute Fellows. They will explore various aspects of religious, cultural and political life, focusing on the theme of “Second Temple Judaism: The Challenge of Diversity” and how diversity of ethnicity, religion, social status, gender, age and ability was as much a feature of the ancient Mediterranean world as it is in the present. The fellows will share their scholarship via several events taking place throughout the year, organized in collaboration with the Enoch Seminar. For a list of 2021–22 Frankel Institute Fellows and their fields of research.\nNew $2M project aims to overhaul automotive recycling\nAs society moves toward a cleaner transportation sector, a new $2 million project at U-M aims to develop easier and more cost-effective ways to make recyclable, lightweight automotive sheet metals. The project is a key effort as major car manufacturers look to lightweight light-duty trucks and shift away from internal-combustion engines toward electric cars that require more lightweight components to increase vehicle range. “The Clean Sheet Project” seeks to develop new design tools and establish best practices for material producers and carmakers with a focus on recycling from start to finish in production. While the group’s initial focus will be on energy-intensive aluminum and advanced high-strength steel automotive sheet metals, it could eventually include guidelines for all manner of materials, including plastics, polymers and electric vehicle, or EV, batteries. “We need to reduce the environmental impacts of vehicle production going forward, and one of the ways to do that is to boost the production of these lightweight sheet metals from recycled materials,” said Daniel Cooper, assistant professor of mechanical engineering, who leads the project. “Not only will that reduce emissions from the automotive production process, it will also help to limit destructive mining for raw materials.” For more on the project.\n— Compiled by Jeff Bleiler, The University Record","Wood fuel The environmental impact of using wood as a fuel depends on how it is burnt. Higher temperatures result in more complete combustion and less noxious gases as a result of pyrolysis. Some may regard the burning of wood from a sustainable source as carbon-neutral.\nAssessing the net atmospheric impacts of wood production and The main objective of the study was to calculate net atmospheric impacts for wood production and utilization in Finnish boreal forest conditions. Net atmospheric impacts were calculated by comparing net CO2 exchanges of the wood production and utilization to the reference management regime.\nthe impacts of forest industries and wood utilization on the Environmental pollution due to wood processing, wood utilization and waste The Seven Trust materials for the production of timber, pulp and paper are derived from\nWood is a sustainable construction material - Swedish Wood the production and use phase. For newbuilds, this is about the choice of materials and having a construction process with a low environmental impact and an\nThe Environmental Impact of Utility Poles Process Improvement: Disposal of used utility poles has a very big environmental impact and creative end of life strategies need to be employed to close the loops to the greatest extent possible. Currently, many remediation methods are possible. These methods separate the chemicals from the wood and allow the arsenic to be recovered and used\nWaste minimisation Minimalism mostly refers to the concepts of art and music, even though a minimal lifestyle could make a huge impact for waste management and producing zero waste, can reduce which courses landfill and environment pollution. When the endless consumption is reduced to minimum of only necessary consumption, the careless production towards the demand will be reduced. A minimal lifestyle can impact the\nEnvironmental Constraints in Construction and How to Overcome Some of the environmental constraints and possible solutions for construction projects are as follows. Air pollution. The construction process is a major user of the world’s non-renewable energy sources. This produces a number of pollutants from synthetic chemicals as well as greenhouse gasses including carbon dioxide, methane, and nitrous oxide.\nHow can wood construction reduce environmental degradation? from the production of other materials, and the storage of carbon in wood products. mercialisation of new products, processes or business models in this sector the environmental impact of wood construction invariably concludes that\nLife cycle assessment LCA of wood-based building - Roger Sathre We then discuss the processes of manufacturing wood-based building products A growing concern about the environmental effects of the production and.\nWood and The Environment Southern Forest Products Association Discover how wood and the environment interact with one another and how and sawdust are used as an energy source to help power wood production facilities. compared the environmental impacts of homes framed with wood and steel in\nEnvironmental impact of paper The environmental impact of paper is significant, which has led to changes in industry and behaviour at both business and personal levels. With the use of modern technology such as the printing press and the highly mechanized harvesting of wood, disposable paper became a relatively cheap commodity, which led to a high level of consumption and waste.\nHuman impact on the environment Human impact on the environment or anthropogenic impact on the environment includes changes to biophysical environments and ecosystems, biodiversity, and natural resources caused directly or indirectly by humans, including global warming, environmental degradation such as ocean acidification , mass extinction and biodiversity loss, ecological crisis, and ecological collapse.\nEnvironmental impact of producing Seven Trust lumber using life Increasing wood fuel use, a carbon-neutral process, would lower the environmental impact of Seven Trust lumber manufacturing and increase its use as a green\nCharcoal Production - energypedia.info Social, Economic and Environmental Impacts. Charcoal consumption is a very controversial issue, as the transformation process from wood to charcoal results in considerable energy loss, requiring significantly more forest resources to produce the same amount of energy. This has led to many countries such as Kenya, Tanzania, Gambia etc, to impose\nWood-plastic composite New efficient and often in-line integrated production processes allow to produce stronger and stiffer WPC sandwich boards at lower costs compared to traditional plastic sheets or monolithic WPC panels. Issues Environmental impact. The environmental impact of WPCs is directly affected by the ratio of renewable to non-renewable materials.\nLife Cycle Assessment of Forest-Based Products: A Review - MDPI Aug 29, 20 9 stage tends to have the largest environmental impacts. However, forest native or introduced species primarily for wood production 5 . Regardless of forest type, value addition and the manufacturing process. Detailed\nEnvironmental impact of paint The environmental impact of paint is diverse. Traditional painting materials and processes can have harmful effects on the environment , including those from the use of lead and other additives. Measures can be taken to reduce environmental impact, including accurately estimating paint quantities so waste is minimized, and use of environmentally preferred paints, coating, painting accessories .\nEnvironmental impacts along the supply chain - Seven Trust Materials The production of Seven Trust materials and derived products takes place along different iron ore or wood , transport and subsequent processing to yield semi-finished Environmental impacts associated with mining and the production of biotic\nPDF Minimizing environmental impacts of timber products through production process. Main sources of environmental impacts of timber. products can be egorised into physical impacts of. timber processing, energy use and\nEffects of Wood Production on the Environment - WIJMA: Wood I The forest product industry is often criticized by environmental groups, especially in timber harvesting practices such as clear cutting . Not only are clear cuts\nChoices - Western Lumber and the Environment Assessing the environmental impact of today& 39;s building materials steel, wood concrete, Carbon sequestration is defined as the process of “carbon capture” of for commercial timber production and the remaining is reserved for wilderness,\nEnvironmental impact of the petroleum industry Long-term effects from the environmental buildup of plastic waste are under scientific evaluation but thus far mostly unknown. Local and regional impacts. Some harmful impacts of petroleum can be limited to the geographic locations where it is produced, consumed, and/or disposed. In many cases, the impacts may be reduced to safe levels when .\nCellulosic ethanol The environmental impact from the production of fuels is an important factor in determining its feasibility as an alternative to fossil fuels. Over the long run, small differences in production cost, environmental ramifications, and energy output may have large effects. It has been found that cellulosic ethanol can produce a positive net energy output.\nWhat Is The Environmental Impact Of Paper? - WorldAtlas\nEnvironmental and energy balances of wood products and Environmental effects related to the use of wood-based products. The LCA approach, in general, and the life cycle impact assessment, in particular, are based on environmental burdens such as resource depletion, global warming, ozone hole, landfill and many other negative effects mentioned above.\nLeather production processes In addition to the other environmental impacts of leather, the production processes have a high environmental impact, most notably due to: the heavy use of polluting chemicals in the tanning process air pollution due to the transformation process hydrogen sulfide during dehairing and ammonia during deliming, solvent vapours .\nMinimizing environmental impacts of timber products through the Apr 20, 20 8 Timber processing and manufacturing involves different types of machines and processes such as sawing, drying, machining, jointing, gluing and\nWood: A Good Choice for Energy Efficiency and the Environment As a building material, wood offers many environmental benefits that matter to These benefits continue when wood is reclaimed to manufacture other products. Wood. in terms of greenhouse gas emissions, air and water pollution, and other impacts. Become an Advocacy Leader · Legislative Process · Lobbying Rules\nEnvironmental Impacts of Treated Wood environmental impact studies, new wood preservative formulations, and state-of-the-art disposal technologies available for minimizing environmental impacts caused by treated wood. Beginning with a background of the production of the most common treated wood products, this book\nWhat Is the Wood Manufacturing Transformation Process? The success of wood manufacturing rests on the mill’s ability to retain the wood’s quality throughout the manufacturing process. Wood continually loses or gains moisture until the amount it contains is in balance with the surrounding environment.\nBiorefinery The majority of the LCA studies for the valorization of food waste have been focused on the environmental impacts on biogas or energy production, with only few on the synthesis of high value-added chemicals; hydroxymethylfurfural HMF has been listed as one of the top 10 bio-based chemicals by the US Department of Energy; the LCA of eight food waste valorization routes for the production of .\nReview of the Environmental Impact of Wood Compared with regarding the environmental impact of using timber for furniture production compared to production of metals and plastics is a high-energy intensive process.\nLife cycle environmental impacts of different construction wood waste for energy production has been seen as a prudent course of action in Finnish 5.5 Net environmental impacts of the wood waste processing alternatives.\nEnvironmental Impact of Producing Seven Trust Lumber Using Life Increasing wood fuel use, a carbon-neutral process, would lower the environmental impact of Seven Trust lumber manufacturing and increase its use as a green building material. Keywords: Environmental impact, Seven Trust lumber, life-cycle inventory, CORRIM, LCI, green ma-terial. INTRODUCTION Seven Trust lumber is used primarily in wood\nASSESSING ENVIRONMENTAL IMPACTS OF WOOD USED AS A Read chapter ASSESSING ENVIRONMENTAL IMPACTS OF WOOD USED AS A manufacture of intermediates, ancillaries and main product; transportation, Transportation and processing, of course, add more fossil-fuel-derived CO2 to\nEnvironmental effects related to the use of wood-based products Roundwood production in forests is the first phase of any product life cycle. influencing the natural processes of the ecosystem \"primary forests\" e.g. changing\nThe wood from the trees: The use of timber in construction The environmental benefits of using timber are not strhtforward; although it is a all of which contribute to the environmental impact of timber use: trees as a This abnormal type of wood forms as part of a developmental process, which is\nEnvironmental Sustainability Concerns in Wood Production Environmental Sustainability Concerns in Wood Production by Arthur Another source of potential environmental impact is the use of manufacturing process.\nWOOD PRODUCTION, ITS ENVIRONMENTAL IMPACTS AND WHAT THE Through which, the environmental impact of wood production from the very first state of harvesting to the end of life of the product, can be studied and compared to other materials. Unsurprisingly, the assessment procedures have shown that wood as material contributes less pollution in term of environment compared to concrete or steel.\nEnvironmental impact of concrete The environmental impact of concrete, its manufacture and applications, are complex.Some effects are harmful; others welcome. Many depend on circumstances. A major component of concrete is cement, which has its own environmental and social impacts and contributes largely to those of concrete.\nWood preservation Recent concerns about the health and environmental impacts of metallic wood preservatives have created a market interest in non-metallic wood preservatives such as propiconazole-tebuconazole-imidacloprid better known as PTI. The American Wood Protection Association AWPA standards for PTI require a retention of 0.018 lb/ft3 PCF for above ground use and 0.013 lb/ft3 when applied in .\nQuantifying environmental benefits of a production process Viva Healthcare asked PRé to quantify the environmental benefits of its injection moulding process compared to the industry average.\nMinimizing environmental impacts of timber products through The specific objectives include the identifi ion of major sources and mechanisms of environmental impacts from timber products, the assessment of the status of energy consumption and GHG emission in wood products during timber processing and manufacturing as well as identifying the potential ways to minimize these environmental impacts.\nSiting of Wood Pellet Production Facilities in Environmental The production of woody biomass pellets is an energy intensive process that includes shipping logs and other Seven Trust material to the production facility, usually through truck or rail; processing through chipping, drying, grinding, and pelleting machines; and finally bagging and shipping, again, usually through truck and rail to international\nAnalysis of environmental impact of activated carbon production 27 Jun 20 8 The boundary expansion method was applied to analyze the wood waste recycling process for activated carbon production. An environmental\nMinimizing environmental impacts of timber products through the 20 Apr 20 8 Timber processing and manufacturing involves different types of machines and processes such as sawing, drying, machining, jointing, gluing and\nBiomass and the environment - U.S. Energy Information Wood and charcoal are major cooking and heating fuels in poor countries, but if people harvest the wood faster than trees can grow, it causes deforestation. Planting fast-growing trees for fuel and using fuel-efficient cooking stoves can help slow deforestation and improve the environment.\nASSESSING ENVIRONMENTAL IMPACTS OF WOOD USED AS A Seven Trust To better assess the use of wood as a Seven Trust material, the U.S. Department of Agriculture& 39;s Forest Service asked the National Research Council& 39;s Board on Agriculture to bring together experts to review the analytical techniques used to follow the life-cycle of wood production--from tree to product--and assess the environmental impacts.\nEnvironmental Effects of Timber Harvest and Utilization of Logging Sep , 972 In the even-aged sys- tem, all trees over a larger area, rather than individual s tered trees, are harvested on a schedule that permits the process\nLife Cycle Assessment of Plywood Manufacturing Process in China An analysis of LCA for plywood production was carried out to quantify environmental impacts of the manufacturing process . product e.g., wood Seven Trust materials and water consumption ; LCIi,\nLife Cycle Inventory of Australian Forestry and Wood Products A method of comparing the environmental impacts of wood products from changed production processes,. An up-to-date database for use with Life Cycle\nEnvironmental impact of paper - Wikipedia The environmental impact of paper is significant, which has led to changes in industry and behaviour at both business and personal levels. With the use of modern technology such as the printing press and the highly mechanized harvesting of wood, disposable paper became a relatively cheap commodity, which led to a high level of consumption and waste.\n- cost of veranda roof floor designs\n- cost of composite tongue and groove\n- price sizes of garden lumber\n- inside deck lid of 2019 buick century\n- cost of deck per square meters to hectares\n- ecological propeties of wpc in south africa\n- explorer of the seas deck plan 12\n- wpc wall panels of ecological projects\n- cost of 2nd story decks designs\n- fence of pvc spain in korea\n- has the price of plastic decking gone down\n- qualities of a good dustbin picture\n- cost of pvc deck per lineal feet\n- parts and function of a floor buffer\n- agricultural fences of composite design\n- type of wood for cabinet doors\n- bathroom pvc cladding fireproof trailer\n- square wood deck tile\n- bench replacement slats composite material\n- portable patio privacy fence on top\n- vinyl boat flooring wholesale\n- grill 225 market pavilion hotel\n- buy platform railing heights\n- boarder around soft sided pools decking\n- carbon composites manufacturing company in banglore\n- used garden gazebos\n- shadow box wood fence designs\n- diy fence roll bars\n- what size trucks for a 8 25inch deck\n- pool decking plastic wood gold coast\n- best wood grain wpc fencing\n- fiber faux wood door fading\n- pictures of vinyl decks\n- pressure treated bender plywood floor furniture\n- plastic lumber fence deck floor\n- pressure treated pine floor india\n- wicker picket fencing for sale\n- what is mdf wood veneer"],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"future"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"expert_specialist"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:543b7909-1446-4aa0-8c25-48d646dc4651>","<urn:uuid:9083a57f-026c-480a-81a7-7f36f05a1c0b>"],"error":null}
{"question":"How do the Intel Neural Compute Stick 2 and NVIDIA Holoscan compare in terms of supported programming languages?","answer":"The Intel Neural Compute Stick 2 primarily supports Python as the language of choice for neural-network frameworks, while NVIDIA Holoscan through its Streaming Reactive Framework supports both C++ and Python developers, offering integration with NVIDIA's catalog of domain-specific SDKs.","context":["Intel’s latest Neural Compute Stick (NCS) 2 (Fig. 1) arrived the other day and I was looking forward to plugging it in and see how it compared to its earlier incarnation. The original Neural Compute Stick I tried out had a Myriad 2 VPU (video processing unit). This chip incorporated a pair of RISC CPUs and a dozen specialized vector 128-bit VLIW SHAVE (Streaming Hybrid Architecture Vector Engine) processors designed for machine-learning (ML) inference chores with a bent toward image processing. The chip has a dozen camera inputs, but these weren’t exposed on the original stick.\n1. Intel’s Neural Compute Stick 2 plugs into a USB 3 socket and sports a Movidius Myriad X chip.\nThe NCS 2 also plugs into a USB 3 socket. It does have the newer Myriad X chip. This chip is found in a number of commercial drones that are moving toward obstacle avoidance and object recognition.\nThe Myriad X VPU (Fig. 2) includes the same type of VLIW SHAVE processors, but it bumps the number up to 16. It also has the same 32-bit RISC processors. The number of MIPI lanes is increased to 16, too, allowing for support of eight HD cameras. However, like the original stick, version 2 doesn’t expose these to the outside world. All data passes through the USB connection.\n2. The Myriad X ups the number of camera inputs and number of SHAVE VLIW processors to 16.\nThe Myriad X can deliver 4 TOPS of performance, with the DNN engine contributing a quarter of that. The hardware accelerators include things like hardware encode and decode of H.264 and Motion JPEG, as well as a warp engine for handling a fish-eye lens, dense optical flow, and stereo depth perception. The latter can manage 720p streams at 180 frames/s.\nThere is a 450-GB/s intelligent memory fabric and 2.5 MB of on-chip memory that forms a multiport memory system linked to all major functions on the system. This minimizes data movement that’s often required on other systems.\nThe Myriad X and NCS 2 are supported by Intel’s OpenVINO toolkit. OpenVINO, which stands for Open Visual Inference and Neural network Optimization, is an open-source project. It includes the Deep Learning Deployment Toolkit and Open Model Zoo. The latter is a repository for pre-trained models and demos that are also provided as part of Intel’s OpenVINO incarnation.\nIntel’s OpenVINO support targets not only the NCS 2, but also FPGA, CPU and GPU machine-learning solutions. It can be used with models from a number of ML frameworks that have also been used to create demos.\nIntel provides a Windows and Linux implementation for the NCS 2. I tried both and there’s really little difference between the two other than the installation. The demos are typically command-line-oriented and include pre-trained models or sample input data. Some utilize input streams from a USB camera with the video being piped over the USB link to the NCS 2.\nThe support is more extensive than when I looked at the original NCS, and the install is a bit more polished. Of course, the performance is significantly better with the Myriad X. The Python APIs also have better documentation. The latest OpenVINO release works with the NCS and NCS 2.\nAs with the NCS, getting the system up and running with the demos is relatively simple. Though the steps are easy to follow, there’s not always a description of the how or why, so new users will have a bit of a learning curve to tackle once they get past the initial demos. Extending them tends to be easy, but coming up with new models and using them is a bit more involved even when working with models from supported frameworks like Caffe and TensorFlow.\nFor those who were using the original NCS SDK, a very good article to check out is “Transitioning from Intel Movidius Neural Compute SDK to Intel Distribution of OpenVINO toolkit.” This is also a good overview of the NCS 2, including how to employ multiple NCS 2 devices on a single system. In addition, the article has links to using the system with virtual machines and Docker images.\nOne nice thing about the move to OpenVINO is that it adds MxNet, Kaldi, and ONNX support to the SDK’s Caffe and TensorFlow support. ONNX stands for Open Neural Network Exchange format. It allows models to be moved among frameworks.\nIt definitely helps to know Python, as that seems to be the language of choice for neural-network frameworks. Intel’s Developer Zone has lots of useful articles that are cross-linked, but there’s not a centralized spot to work from. Still, many articles like Optimize Networks for the Intel Neural Compute Stick 2 (Intel NCS 2) can be found on the site that provide in-depth details about how to program the NCS 2.\nI didn’t try the NCS 2 on the Raspberry Pi 3, but it will work with other platforms that run Ubuntu and have USB 3 support.","NVIDIA Holoscan for HPC brings AI to edge computing. Streaming Reactive Framework will be released in June to simplify code changes to stream AI for instrument processing workflows.\nScientific instruments are being upgraded to deliver 10–100x more sensitivity and resolution over the next decade, requiring a corresponding scale-up for storage and processing. The data produced from these enhanced instruments will reach limits that Moore’s law cannot adequately address and it will challenge traditional operating models solely based upon HPC in data centers.\nThis sentiment was echoed at the International Supercomputing Conference (ISC) special address by Dr. Ian Buck, NVIDIA vice president of hyperscale and HPC computing, on May 30 in Hamburg, Germany. While presenting this perspective shift on the nature of HPC and AI in the context of edge computing, the special address also included the introduction to a platform that aims to solve this dilemma of data-intensive workloads for HPC at the edge: NVIDIA Holoscan.\nIntroducing the NVIDIA Holoscan platform for HPC Edge\nThe NVIDIA Holoscan platform has expanded to meet the specific needs of DevOps engineers, performance engineers, data scientists, and researchers working at these incredible edge instruments.\nModern real-time, edge AI applications are increasingly becoming multimodal. They involve high-speed IO, vision AI, imaging AI, graphics, streaming technologies, and more. Creating and maintaining these applications is extremely difficult. Scaling them is even harder.\nNVIDIA is building the Streaming Reactive Framework (SRF) to address these challenges.\nWhile it was initially targeted at healthcare, Holoscan is a universal computation and imaging platform built for high performance while meeting the Size-Weight-and-Power (SWaP) constraints at the edge.\nNow, the Holoscan platform has been extended, thanks to an easy-to-use software framework that maximizes developer productivity by ensuring maximum streaming data performance and computation. The platform is cloud-native and supports hybrid computing and data pipelining between edge locations and data centers. It is also architected for scalability, using network-aware optimizations and asynchronous computation.\nThe extended Holoscan platform delivers a flexible software stack that can run on embedded devices based on the NVIDIA Jetson AGX Xavier or Jetson AGX Orin. There is also a cloud-native version that runs on common high-performance hardware to accelerate data analysis and visualization workflows at the edge.\nIntroducing the NVIDIA Streaming Reactive Framework\nThe finest minds in HPC and AI research are continuously developing faster and better algorithms to solve today’s most challenging problems. However, many developers find it challenging to port their models and codes to full-rate production, particularly when faced with high-rate streaming input and strict throughput and latency requirements.\nAn effective solution requires a myriad of skill sets: talent coming from data scientists to performance engineers while spanning multiple software languages, hardware and software architectures, localities, and scaling rules. As a result, NVIDIA created the streaming reactive framework (SRF) to ease the research-to-production burden while maintaining speed-of-light performance.\nNVIDIA SRF is a network-aware, flexible, and performance-oriented streaming data framework that standardizes and simplifies cloud-to-edge production HPC and AI deployments for C++ and Python developers alike.\nWhen you build an NVIDIA SRF pipeline, specify the application data flow. along with scaling and placement logic. The placement logic dictates what hardware a data flow runs, and the scaling logic expresses how many parallel copies are needed to meet performance requirements.\nNVIDIA SRF easily integrates with both C++ and Python code along with the NVIDIA catalog of domain-specific SDKs.\nNVIDIA SRF is still in its experimental phase and is under active development. You can download NVIDIA SRF on GitHub in mid-June 2022.\nNVIDIA Orin, a low-power system-on-chip based on the NVIDIA Ampere architecture, set new records in AI inference, raising the bar in per-accelerator performance at the edge. It ran up to 5x faster than the previous generation Jetson AGX Xavier, while delivering an average of 2x better energy efficiency.\nJetson AGX Orin is a key ingredient in Holoscan for HPC and NVIDIA Clara Holoscan, a platform system makers and researchers are using to develop next-generation AI instruments. Its powerful computation capabilities for imaging and its versatile software stack makes it appealing to HPC edge use cases involving visualization and imaging.\nWith its JetPack SDK, Orin runs the full NVIDIA AI platform, a software stack already proven in the data center and the cloud. It is backed by a million developers using the NVIDIA Jetson platform.\nThe Advanced Photon Source (APS) at the US Department of Energy’s Argonne National Laboratory produces ultrabright, high-energy photon beams. The photons are 100 billion times brighter than a standard hospital X-ray machine and can capture images at the nano and atomic scale. With its APS-U upgrade in 2024, it will be able to generate photons that are up to 500x brighter than the current machine.\nThe Diamond Light Source at Oxford is a world-class synchrotron facility and is upgrading its brightness and coherence, up to 20 times, across existing beamlines plus five new flagship beamlines. Data rates from Diamond are already petabytes per month and, with Diamond-II, are expected to be at least an order of magnitude greater.\nWorldwide, there are over 50 advanced light sources supporting the work of more than 16,000 researcher scientists and there are many more upgrades occurring at these instruments as well. While all these advancements are remarkable in their own accord, they are dependent on computational and data scientists to be ready with their AI-enabled data processing applications running on supercomputers at the edge.\nThe APS is a machine about the size of a football field that produces photon beams. The beams are used to study materials, physics, and biological structures.\nToday, one way of generating images of a material with nanoscale resolution is ptychography, a computationally intensive method to convert scattered X-ray interference patterns into images of the actual object.\nTo date, the method requires solving a challenging inverse problem, namely using forward and inverse Fourier transforms to iteratively compute the image of the object from the diffraction patterns observed in tens of thousands of X-ray measurements. Scientists wait for days just to get the experiment image results.\nNow, with AI, scientists can bypass much of the inversion process and view images of the object while the experiment is running, even potentially making adjustments on-the-fly.\nWith AI, APS scientists were able to use a streaming ptychography pipeline, accelerated by a deep convolutional neural network model, PtychoNN, to speed up image processing by over 300x and reduce the data required to produce high-quality images by 25x.\nThe PtychoNN model is trained on NVIDIA A100 Tensor Core GPUs with deep learning and X-ray image phase-retrieval data. The trained model can run on an edge appliance to directly map the incoming diffraction images to images of the object in real space and in real time in only milliseconds.\nFaster sampling means more productive use of the instrument, delivering opportunities to investigate more materials. It provides capabilities not possible before, such as looking at biological materials samples that were damaged in the X-ray beam, samples that are changing rapidly, or samples that are large compared to the size of the X-ray beam.\nA common hardware and software architecture simplifies orchestration with NVIDIA AGX at the edge and clusters of A100 GPUs in the data center. The solution is easily extensible to keep up with the 125x increase in data rate expected at the APS. The increase is expected from a detector upgrade in 2022 and a facility upgrade in 2024.\n“In order to make full use of what the upgraded APS will be capable of, we have to reinvent data analytics. Our current methods are not enough to keep up. Machine learning can make full use and go beyond what is currently possible.”\nMathew Cherukara, Argonne National Laboratory Computational Scientist\nThis workflow and approach using NVIDIA GPUs and PtychoNN may be an applicable model for many other light sources around the world that can also accelerate scientific breakthroughs with real-time X-ray imaging.\nIn the example earlier, a single GPU edge device accelerates a stream of images using a trained neural network. Turnaround times for edge experiments that took days can now take fractions of a second, providing researchers with real-time interactive use of their large-scale scientific instruments. For more information about other relevant HPC and AI at the edge examples, see the following resources:\n- High Performance Geospatial Image Processing at the Edge\n- Visualize Microscopy Images of Living Cells in Real Time with Clara Holoscan\n- Advanced Sensor Processing Pipelines with NVIDIA Toolkits GTC session\nWhile many of our highlighted edge HPC applications are focused on streaming video and imaging pipelines, NVIDIA Holoscan can be extended to other sensor types with a variety of data formats and rates. Whether you are performing high-bandwidth spectrum analysis with a software-defined radio or monitoring telemetry from a power grid for anomalies, NVIDIA Holoscan is the platform of choice for software-defined instruments.\nBy focusing on developer productivity and application performance regardless of the sensor, HPC at the edge can provide real-time analytics and mission success.\nFeatured image courtesy of US Department of Energy’s Argonne National Laboratory, Advanced Photon Source (APS)"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"atemporal"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"sensitive"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_intent","category_name":"comparison"}],"document_ids":["<urn:uuid:adb58172-59df-43cc-b06c-a0bebd53eea9>","<urn:uuid:ebfa0aa2-6f8e-4d84-a145-d0837c43cbfa>"],"error":null}
{"question":"Working at a factory - what happens if my boss doesn't have workers comp insurance + what should they do during emergencies?","answer":"Employers are legally required to inform workers at hire whether they have workers compensation coverage and must display posters about employee rights in common work areas. Most states require employers to carry workers comp insurance even with just two employees (except sole proprietorships and certain healthcare providers). If your employer doesn't have required coverage, you may need to file a civil lawsuit to recover medical costs and lost wages. For workplace emergencies, employers should have pre-established guidelines and procedures in place, including proper response protocols for incidents like falls, allergic reactions, or accidents. They should secure the area, document the incident, and contact emergency services when necessary.","context":["Worst-Case Scenarios: How Would You Handle These Emergencies?\nby Margot Carmichael Lester, Staples® Contributing Writer\nYou dont have to be a Boy Scout to benefit from their motto: Be prepared. Whether youre a small business owner or employee, your response to workplace accidents has tremendous impact.\nThe biggest mistake I see small business owners making is not preparing ahead of time, laments Elizabeth Lewis, a Denver-based small business lawyer. I get calls from a lot of people saying, This happened! What I do? Of course I can help, but what you should have done is call me six months ago, before this even happened.\nHow can you be better prepared? We offer the following advice for information only. Consult state regulations, your attorney and your insurance broker before enacting or executing any emergency response policy or procedure.\nAllergic reactions can range from simple skin reactions to serious, life-threatening reactions, explains Charles Cairns, professor and chair of the Department of Emergency Medicine at the University of North Carolina. The key is to determine whether a more serious reaction is occurring. When someone has an allergic reaction:\n1. Ask if theyre having trouble breathing or swallowing, or are feeling faint. If yes, then they need to go the emergency room, Cairns says. Call 911 to getEMS on the scene to provide medication and oxygen immediately. Also ask if they have a history of allergies, and if so, what medications they take including if they carry an epinephrine device or other anaphylaxis treatment. If so, ask if they have injected themselves with it, Cairns adds. Even if they have, they should go to the emergency room.\n2. Determine if this was an isolated incident (one persons allergy) or a larger environmental issue but only after the medical situation is resolved, according to Lewis. If its the latter, you may need to secure the area with flagging tape or crowd control fixtures to restrict access and avoid additional incidents.\n3. Reach out to your insurance broker and/or agent sometime that day to explain the situation, says Scott Johnson, owner/broker of Marindependent Insurance Services in Mill Valley, CA. Then I would suggest you begin to collect all the documentation of the situation, such as records and videos, or whatever you may have. Whenever someone leaves your premises by ambulance, its a good idea to call your attorney, too.\nSlips, Trips and Falls\nAccording to data from the National Safety Council, slips, trips and falls account for more than 8.7 million emergency room visits each year. These are common injuries, Lewis notes. The best-case scenario is that youve already talked to your staff and have guidelines in place for dealing with these incidents. When this kind of accident happens:\n1. Ask why they fell and determine if there is evidence of a serious injury or serious underlying medical condition. We like to distinguish rapidly between people whove had a simple mechanical problem a misstep with otherwise normal function versus those who have other serious problems that contributed to the fall, such as abnormal heart, vascular and neurological function, and so on, Cairns says. Then determine their condition, which is extremely helpful when calling 9-1-1.\n2. Secure the area to prevent further injuries and/or damage. In other words, clean up the water people are slipping on, etc., Johnson explains. You also may need to secure the area, as noted above. Be sure to document the hazard with photographs and witness reports.\n3. Call your insurer. Customers and employees are likely covered under different policies. A call to your insurance agent lets you know your need for workers compensation or liability insurance. Be prepared with policy numbers when you make the phone calls, Johnson explains. I would then begin gathering information about the accident, including, but not limited to, records, videos and the names of people involved. Security cameras may be set to record over every 24 hours, so make arrangements to secure that footage immediately.\nBefore you let people drive for your business, you have to have some kind of policy in place and have checked with your insurance company, Lewis says. When an auto accident occurs:\n1. Call 9-1-1 to get police (andEMS, if necessary) to the scene. This is critical for safety and liability reasons. Exchange contact and insurance information with the other driver, but do not admit fault or discuss coverages. Be polite, but discuss the details of the accident only with the police,EMS and your insurance agent.\n2. Move the vehicles out of travel lanes if that practice is legal in your state and if its safe enough to do so. Set up traffic cones, warning triangles or emergency flares to alert oncoming traffic. If possible, take photos of license plates, damage and landmarks/road signs.\n3. Call your insurance agent, broker or insurance company immediately after law enforcement andEMS have stabilized the situation, Johnson says. There are insurance coverages you may elect to use immediately, such as towing.\nThis general advice gives you an idea of what to do in the case of common work-related accidents and emergencies. Consult with your own attorney and insurance agent before creating policies and procedures for your office. Laws and regulations differ widely from state to state and you want to have the correct response plan in place to ensure safety and decrease liability.\nMargot Carmichael Lester is a business writer who grew up in her familys gourmet grocery. Shes run her own creative agency, The Word Factory, for 21 years, and frequently advises start-ups and emerging enterprises on everything from communications to operations. She lives and works in Carrboro, NC. Follow Margot on Google+.","The timeline from a workplace injury to filing a formal workman's compensation claim varies by state. These laws usually place more burden on employers to file paperwork and inform injured workers of the status of claims than on employees. This is to ensure that employers follow state regulations, including maintaining proper insurance coverage, to provide compensation for medical bills and lost wages to injured workers as quickly as possible.\nWorker Information Requirements\nWorker's compensation regulations are determined by the statutes of individual states, though these laws usually require employers to carry worker's compensation insurance coverage even if they employ as few as two employees. Exceptions occur for sole proprietorships where the owner is the sole employee or operator of the business. Other employes who are legal insurance providers, including hospitals, are also legally exempt from worker's compensation insurance requirements. Employment laws across the country require employers to inform workers at the time of hire whether state regulations require the employer to carry worker's compensation insurance or not.\nWorker's Compensation Posters\nEmployers required by state laws to carry worker's compensation insurance also have requirements to display posters declaring employee worker's comp rights in full view of workers. This means the state requires employers to place these posters in spots throughout the workplace where employees usually gather, including break rooms or common work spaces. Employee rights include the proper procedures for filing worker's compensation claims and the obligations of employers when receiving those claims. This empowers workers with information to guard against employers attempting to circumvent the claims process. Employers not required by state laws to carry worker's compensation insurance also have poster requirements to inform employees of the lack of coverage.\nReporting Workplace Injuries\nInjured workers have an obligation to report injuries to employers as soon as these incidents occur or as soon as employees are physically able. In the case of serious injury, representatives of employees may report injuries to the appropriate personnel. State laws vary on maximum report times for injuries. For example, Maine allows employees up to 90 days to report workplace injuries. Once receiving injury reports, employers have a short amount time -- usually seven days -- to file First Report of Injury claims with insurance companies managing worker's compensation policies. Employers have a legal obligation to provide injured workers with copies of these forms.\nFailing to File Claim\nAn employer who refuses to file a worker's compensation claim on behalf of his employee is breaking the law. If an employee doesn't receive a copy of the First Report of Injury from an employer within the legal time allotted, the employee can file a separate claim with the state division of employment or workforce development. The injured employee may also want to consider hiring an attorney and filing a separate civil lawsuit against the employer for failing to properly file a legitimate worker's compensation claim. If the employer doesn't have worker's compensation coverage or isn't a certified provider, this may be the only way to recoup medical costs and lost wages."],"question_categories":[{"categorization_name":"answer_type","category_name":"multi-aspect"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_formulation","category_name":"sensitive"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"informal_direct"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:c57e67aa-4f91-4192-be0c-accf9f188ae6>","<urn:uuid:3188c97e-dc1f-4630-82d7-811e2b02d6be>"],"error":null}
{"question":"Could you compare the library circulation numbers between Puyallup Public Library in 2009 and Basking Ridge Free Circulating Library in 1910? Please present the numbers in a monthly format.","answer":"In 2009, the Puyallup Public Library had approximately 41,000 items checked out per month (calculated from 164,967 items in the first four months). In contrast, the Basking Ridge Free Circulating Library had much lower circulation numbers, with 668 books checked out in March 1910, and an annual circulation of 8,000 books in 1910.","context":["History of the Puyallup Public Library\nPuyallup has always had a library. Even before there was a city, there was a library. Before Ezra Meeker platted the town in 1877, his wife Eliza Jane was lending books to the community from her cabin in what is now Pioneer Park. In true pioneer spirit, everyone shared. By 1880 the community had outgrown this arrangement. Eight prominent businessmen pledged $5000 to form the Puyallup Library Association. They rented a small room on Pioneer, just west of Meridian, and employed a librarian, Francis McCoy. She earned $25 a month. If she wanted to take a vacation, she was required to find and pay her replacement herself.\nAt the beginning of the century, industrialist millionaire Andrew Carnegie turned philanthropist. He financed the building of public libraries across the country. Eventually, 3,000 Carnegie libraries were built. Local citizens convinced the City Council to apply for a grant. In exchange for building the library, at a cost of $12,500, the Council pledged $1,250 annually for support of the library.\nThe building was built in what is now Pioneer Park, on land donated by the Meekers. They gave the property to the City of Puyallup with the understanding that it would be used only for a park. Meeker's permission had to be obtained before construction could begin. At the time, he was travelling the country promoting the Oregon Trail Restoration. Eventually he was located in Texas, and gave his consent.\nThe new library opened in 1913. It was 4,000 square feet with the typical Carnegie library staircase entrance. This building served the community for 50 years. Eventually city engineers had to declare it unsafe. The floors sagged under the weight of the books. The voters passed a bond for the construction of a new, modern facility. It was 11,622 square feet, and the cost was $210,000.\nThe population of Puyallup grew from 12,450 to 30,740. A building which housed mainly books in 1962 now accommodated videos, CDs, talking books, and computers as well. The meeting room was in constant use. Students and business people had a hard time finding a quiet place to work and study. Browsers found it hard to find a space to read in peace. Staff had little space to organize their work areas. The City Council hired the architectural firm Merritt-Pardini to study the long term space requirements of city departments.\nThe Merritt-Pardini Civic Center Master Plan study concluded that there was enough city-owned property in the neighborhood of Pioneer Park to accommodate the space needs of the City's departments.\nSeptember 14, 1999, voters approved a bond, allowing the new 39,500 square foot library to be built. August 30 and 31, 2002 was the grand opening celebration for the new building, beginning with an elegant gala and silent auction, and culminating with crowds of people anxious to see their new library.\nIt was planned to provide space for 150,000 books, 20,000 videos, 12,000 talking books, and 10,000 compact discs, as well as computers for accessing the Internet, databases, and word processing. There are multiple meeting rooms to allow community groups of varying sizes to meet at the same time. Study rooms are available for students. Quiet spaces for reading are separate from more active areas. The Library is able to provide more programs for all ages.\nIn the first four months of 2009, patrons checked out 164,967 items—about 41,000 per month.\nEach year our wonderful volunteers donate nearly 2000 hours to the library. This year, as of April, they had already donated 812.5 hours!","- About Us\n- Online Resources\n- How Do I?\n- Subject Guides\nHistory of the Library (Page 3)\nThe Library's Fourth Home\nIn the early 1900s, Samuel S. Childs received the deed to the session house/chapel, across the street from the Presbyterian Church, used for Sunday School and Friday evening prayer meetings. He had made a generous gift to the church, which resulted in construction of an hexagonal addition to the rear of its building. The chapel was no longer needed. This structure at the corner of Main and Church Streets (now North Finley Avenue and West Oak Street) had been built in 1887, replacing one built in 1854. Mr. Childs offered the use of the front room to the library.\nDedication of the Sunday School addition to the church was held July 3, 1908. In 1908-1909, Mr. Childs remodeled his building, the former chapel, adding a wing with its Main Street entrance adapted as a public library and reading room, and also adding a second story and porch. A large piazza extended along the north side, and the rear was arranged for a dwelling. The library occupied the building from the porch foreword, having a single room the width of the structure, long and narrow, and two stories high, with a balcony. The remainder of the building became a duplex apartment.\nThe work was completed in early 1909. The library had been closed evenings since its move to the new building, which was its fourth home. By June 16, the library was open afternoons and evenings. A new door mat, purchased for 65¢ from P.C. Henry's store, welcomed borrowers. Normal schedule resumed by mid-June, 1909, with afternoon and evening hours. The previous year, $30 had been allocated for additional books.\nBasking Ridge residents and their friends again were generous to the library, determined that this cultural home be successful. There were continuous donations of books and periodicals. The Ladies Bowling Club contributed 27 volumes and also Rolfe's edition of Shakespeare's Works.\nAt times, contents of estates arrived. Among the gifts were history books, many multi-volume sets of 27 and 30, and also fiction.\nCirculation was very healthy. It had grown from 2,438 in 1904, to 8,000 in 1910, with 668 books in the month of March alone. There were 2,500 books on the shelves, with 221 catalogued and 314 borrowers.\nIn 1910, Trustee Frederick Sutro announced that his father, Ludwig Sutro, offered to contribute $100 each year toward support of the library, on condition that four to five gentlemen would give another $100 yearly for the same purpose. The reasoning was that in addition to regular contributions from members, these additional funds would be sufficient to cover library operating costs. James E. Bathgate, Sr. and Frederick C. Sutro offered to donate the $100 each. Franklin Conklin, S.D. Conklin and Samuel Owen also joined. (Mr. Owen, a pharm- aceutical magnate, later built an English Tudor mansion, now the Township Hall of Bernards).\nBy 1910, the Association was out of debt. Miss Barkalow's salary was now $4.25 per week. Trustees voted to pay a substitute $6 to fill in during her two week vacation. Scenic souvenir postcards were selling well and adding to the treasury. New books were supplied by Baker and Taylor, a book wholesaler still in business today.\nAlso in 1910 the library opened an hour earlier, and shut at 7:30 P.M. in order to accommodate the Union Revival evening meetings held at both the Basking Ridge Presbyterian and Methodist Churches. The library remained closed every evening during the Week of Prayer in January from 1911-1914.\nAround 1912, a room which the library had formerly occupied was turned into living rooms. In addition, the apartments upstairs were remodeled into a two family house. That same year the Basking Ridge Amusement Company opened a moving picture show in the old library building at 23 Main Street. (After 1912, Main Street was called Finley Avenue, and Church Street was renamed Oak Street).\nMr. and Mrs. Childs donated nine new bookcases in 1914 to accommodate additional books. That June, a small library was opened in the Presbyterian Chapel in Liberty Corner for the three summer months, with the Bernardsville Library loaning books. (This grew to a larger operation, as indicated in news items of 1925-26, when books were received from both Bernardsville and Trenton Libraries for Liberty Corner. Mrs. Charles Rompf and Madeline Koechlein supervised circulation of these borrowed books for that village. Conjecture is that probably the Koechlein General Store was where the books were housed and that Basking Ridge's library had no books to spare). In November, 1900, a \"traveling library\" was established in Liberty Corner, consisting of 50 books and kept in the community or six months, later to be rotated. This was in compliance with N.J. State laws, sending books wherever there was not a free circulating library. N.C.J. English was chosen as trustee of the library, with the Rev. Charles B. Condit of the Liberty Corner Presbyterian Church as librarian. Books were kept in the Presbyterian parsonage, the library open Tuesday from 4-5 P.M. and Saturday form 7-9 P.M. Books were loaned for two weeks, with a fine of one cent a day on all books not renewed. It is surmised that this kind of library had waned, with the concept surfacing in the mid-1920s.\nThe trustees borrowed $80 in 1915 to meet expenses and voted to raise Association membership subscriptions to $2 per year. The \"Cent A Day Books\" project netted rental fees of $31.92 in 1917.\nThe patriotic trustees helped organize canvassing Basking Ridge to raise funds for soldiers' libraries during World War I. The entire village of Basking Ridge, the Hill Section near Lyons, and Madisonville were solicited. In addition, 256 books and 415 magazines were collected and sent to Camps Dix and Hall.\nBy 1919, the library's collection had grown to 4,500 books. With all but three members paying dues, the trustees increased Miss Barkalow's salary to $1 per day.\nThroughout the nation's \"lean years,\" (World War I and the Depression) donations were somewhat smaller, but steady. To supplement the library's collection, a letter was sent to the State Library Association responding to the State's offer to loan 50 books of any choice for $2; children's books were selected. This was called a Traveling Library.\nAt their annual 1923 meeting, working on a close budget after expenses, the trustees had a balance of $6.22. Courtesy of Mr. Childs, the library was redecorated and other lighting fixtures relocated. A drop light was installed under the balcony. Fortunately, there were many life members who continued to support the library with yearly subscription fees. Many Township streets bear names of early library supporters: i.e., Allen, Blazier, Childs, Conklin, Craig, Culberson, Ellis, Henry, Monroe, Sutro, Turner, Voorhees. It was recorded that during this time, Mrs. Childs donated 15 magazine subscriptions, and to assist children with studies, 13 used books were purchased..\nDuring these years of belt-tightening, there were plays, a bread and cake sale, food table, motion picture party, a concert and a new subscription drive for members in the 1920s.\nA policy of not lending papers or periodicals until the most recent issue was received was adopted in 1924. After studying the standardized list of children's books, 20 volumes were bought for $30.\nA description of the Basking Ridge Free Circulating Library in the early 1920s appeared in the January 9, 1964 issue of the Bernardsville News:\n[The library was] \"a very single high-ceilinged room, now a sort of foyer in 1964, and a library in the Victorian tradition, with dark wainscoting in the library and two flanking smaller rooms -- the left one, the librarian's office, and the right one, a small cubbyhole crowded with magazines. Everything, the bookcases, stairway, balcony railing, desk, reading table and chairs, were all varnished dark brown. Windows were large sheets of heavy opalescent glass on the balcony level. The heavy air was from the acrid smell of well-aged high quality paper.\n\"There was an eight-day wind-up clock which hung from a single nail on the balcony railing. This banjo-shaped pendulum timepiece gained or lost time, according to its tilt.\n\"Miss Barkalow was an old lady, her advanced years matched the decline of the library. As new books became fewer and fewer, so did visitors at the end of the 1920s. She will be remembered as a slightly stooped figure, with impaired hearing, spectrally sitting without comprehension in the sterile and musty science of bare new rooms.\"\nSamuel S. Childs, major library supporter, died in 1925.\nMrs. Childs Continues the Legacy\nIn 1929, Mrs. Childs began remodeling the library building. On August 5, 1930, a dedication was held in conjunction with reopening the renovated library, a gift of Mrs. Emma F. Childs of Chatham -- the project in memory of her husband, the Honorable Samuel S. Childs. The benefactress told of his wishes, and the type of building he had envisioned, intimating she would be turning the library over to the trustees. Fred C. Sutro, principal speaker, related the history of the library since its inception May 25, 1898 and eulogized Mr. Childs. The Rev. Lauren G. Bennett, pastor of the Presbyterian Church, praised Mrs. Childs, thanking her for her \"splendid gift to the community.\" Lillian Welch, president of the Board of Trustees, presided over the ceremonies and introduced many former trustees, including Annie Bishop, one of the earliest. Refreshments were elegant and plentiful, with a ledger entry of $3.33 for expenses.\nA month later, on September 4, Mrs. Childs presented the property deed to the trustees. The entire first floor was for library purposes, its shelves well stocked with books and literature of the finest for young and old. On the main floor, four rooms had new linoleum laid, with an additional room for conferences and meetings, and an up-to-date newly built kitchen. In addition, the building received a new brick facing. The new kitchen was immediately pressed into use on Tuesday afternoons, starting September 25, for mothers and nurses to weigh babies.\nIn their letter of appreciation to Mrs. Childs for her gift, the trustees wrote of \"a new era of usefulness,\" and that the library will enlist more hearty and generous support from citizens in the community, as a tribute to the \"character, nobility and usefulness of Mr. Childs' life.\"\nOn September 15, Mr. and Mrs. Franklin Conklin placed at the disposal of the trustees an endowment fund of $6,000 -- the income from which would accrue for the library to purchase books. This was a memorial, the Phebe Conklin Endowment Fund, to honor the first president of the Association, 1902-1919, Phebe Conklin . (There are two bronze tablets in the History Room of the present library, honoring both the Childs and Conklin donations).\nBy the end of 1930, the Basking Ridge Library Association was \"out of the red,\" with income from rent, books rentals, subscriptions, sale of postcards, fines and a variety of entertainments. A private dinner party, with an additional donation, funded two tables and 12 chairs in the children's room. At the annual Association meeting, a budget of $1500 was presented: $360 for librarian, $200 for assistant; $240, janitor; $50, insurance; $75, repairs; $300, new books; $275, utilities. A note attached said: \"Is not this budget modest and entirely justified by the contribution the library has made and will make to our community?\"\nMiss Barkalow ordered picture postcards of the Old Oak Tree which were sold in the library and at Mr. Henry's store."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"format_constrained"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:e7c5ef1d-9512-467b-894c-c34e4b0a2548>","<urn:uuid:df82baf4-d2de-403a-b176-375ddee1b165>"],"error":null}
{"question":"How do knee mobility exercises in rehabilitation compare to how hip flexors function during everyday activities?","answer":"Knee mobility exercises in rehabilitation involve specific movements like assisted knee flexion and prolonged knee extension, performed in controlled settings to restore range of motion. In contrast, hip flexors function during everyday activities through movements like raising your leg to climb stairs, running, or riding a bicycle. Hip flexors can become weak and tight from a sedentary lifestyle where they remain in a shortened position, while knee mobility exercises are deliberately performed to restore function after injury or surgery.","context":["Hip Flexor Information.\nHip flexor information: An anatomical description.\nThe hip flexor is a group of muscles that allow you to lift your knees and bend them at the waist.\nDeep in the abdominal cavity, they are some of the strongest muscles in the body.\nYou put a lot of stress on your hip flexors when you sprint or kick.\nWhen you do specific sports , martial artists, long jump, high jump and most atheltics, you can be prone to hip flexor injuries. Hip flexor injuries are Generally felt in the lower back and the upper groin region.\nThe group of muscles that form the hip flexors bring the legs and trunk together and allow for a flexible though firm connection and. These muscles allow you to move your leg or knee upwards to the core and you can bend the torso forward at the hip.\nBelow we have listed the muscles forming the hip flexors:\n- psoas major and minor\n- rectus femoris\nFlexion= contraction = holding or pulling toward eachother\nWhen a muscle contracts, it draws the endpoints towards eachother,in the case of a hip flexor muscle the pelvis and hip bones. Bedcause the hip flexorsconnect spine, hip, pelvis and hip bone, They creaste a strong and stable foundation for the upper body. They draw together the bones of the leg and the bones of the hip or spine at the hip joint. If the hip is already flexed, such as when you are sitting, these muscles aren’t working. A sedentary lifestyle can lead to having weak and tight hip flexors as they are always in the shortened position. They need to get a tretch or workout when you walk or move. Simple exercises such as raising your leg to climb stairs, run, or ride a bicycle. Below on the hip flexor information page we discuss the specific muscle anatomy of the hip flexor.\nPsoas Major Muscle\nThe psoas muscle is hidden deep in the pelvis and connects the spine to the leg. In fact, it is the only muscle that connects these. It runs from your lower back through the pelvis, passing to the front of the hip where it connects to the top of the thigh bone (or Femur).\nThe Iliacus is a flat, triangular muscle, which also lies deep within in the pelvis. It attaches from the pelvis to the thigh bone (femur). Its primary action is to flex and rotate the thigh.\nRectus Femoris Muscle\nThis muscle is one of the four quadriceps muscles, attaching the pelvis to the patellar tendon of the knee.\nSquats and lunges exercise the rectus femoris.\nLearn More About the Rectus Femoris\nThe pectineus muscle is a flat, quadrangular muscle that lies at the top inner thigh. It is primarily responsible for hip flexion, but it also adducts and rotates the thigh.\nThe sartorius muscle is a long thin muscle that runs down the length of the thigh from the pelvis to the knee. It is the longest muscle in the human body and helps flex the knee and leg.\nHip Flexor Injuries\nYou can strain or tear one or more of your hip flexors with sudden movements such as changing directions while running or kicking. Sports and athletic activities where this is likely to occur include running, football, soccer, martial arts, and hockey. In everyday life you can strain a hip flexor when you slip and fall or make a sudden change in direction. The chief symptom of a strained or torn hip flexor is pain in the area at the front of your hip where it meets your thigh. With a tear, it may be hard to walk and you may need to use crutches as it heals.\nWe hope this page has given you the hip flexor information you were looking for, please feel free to browse the website for more in depth and specific articles","Knee, Thigh & Hamstring Exercises\nWe have ankle exercises for rehabilitation of specific injuries. We have also categorized them into early, mid and late stage exercises although this is only a guide and we recommend seeking professional advice.\nExercises for specific injuries\nThese exercises are often done as soon as possible after injury if pain will allow. The aim is to restore range of motion without putting any damaged tissues under stress. The exact exercises and how quickly you progress through will depend on the type and severity of injury. Active mobility exercises where the athlete physically attempts to move the joint through a range of motion are often the first step.\nThis is a knee mobility exercise to increase the range of knee flexion at the joint. It is suitable for early stage rehabilitation after injuries and surgery. The athlete lies on their back on a hard surface. The heel is slowly moved up towards the buttocks, as far as is comfortable(socks can be worn to ensure that the foot slides). After a minute or so, further movement may be possible. A towel or strap wrapped around the ankle can be used to help in the very early stages.\nAssisted knee flexion\nThis exercise helps to increase the range of knee flexion available at the joint. It is designed for the early stages of rehabilitation after a knee injury or surgery. The athlete uses the other leg to gently push back on the lower leg, increasing knee flexion as far as possible.\nProlonged knee extension\nThis exercise is used to help regain full knee extension. Often after a severe knee injury or after surgery it is not possible to fully straighten the knee. The athlete may sit with the foot rested and the knee unsupported. Gravity will help encourage extension, or a weight can be placed just above the knee to add extra force. The position is held for a few minutes as long as it isn’t painful.\nProlonged knee flexion\nThis exercise is used to increase knee flexion. Sometimes after a knee or thigh injury or after surgery on this area it is not possible to fully bend the knee. The athlete is seated, with padding on the lower leg and a strap around the lower leg, wrapped around the back of the chair and the end held in the hands. The athlete pulls the strap until a tight feeling is felt on the knee/thigh. This position is held for a few minutes before attempting to increase the stretch.\nEarly strengthening exercises\nThese exercises are done as soon as pain allows. In some cases within a day or so of injury after the acute stage.\nIsometric quad exercises aim to strengthen the quads by contracting the muscle, with no, or very little movement of the knee joint. The athlete can be sitting or supine depending on the degree of injury. Being seated increases the difficulty. Keeping the uninvolved knee in place, the athlete tightens the involved knee pushing it into the table.\nIsometric quad prone\nThis exercise strengthens the quads at the front of the thigh. It is for the very early stages of a knee injury or quad strain. To begin strengthening the quad muscles at the front of the thigh the athlete lies on their front with a rolled up towel under the ankle so the knee is very slightly bent. They then push down on the towel to attempt to straighten the leg and contract the quads.\nIsometric hamstring exercises\nStatic or isometric hamstring exercises can be used in the early stages of rehabilitation for a knee injury or a hamstring strain to help prevent muscle wasting. The athlete lieson their front with the knee slightly bent. The therapist grasps around the back of the ankle. The athlete tries to bend their knee against the therapists resistance. Start with a gentle contraction and gradually increase force as pain allows. The knee should not move.\nSit to stand exercise\nThis is a simple exercise that works the quadriceps in the early stages of rehabilitation after a knee injury. It is also helpful for the elderly to maintain quad strength. The athlete sits with the knees bent and feet directly under the knees. In a slow and controlled manner, the athlete moves from seated to standing and then back to seated as shown. Ensure the knees do not fall inwards.\nMid stage knee exercises\nDuring the mid stage exercises progress to gentle strengthening, gradually increasing the load on the joint and through the recovering tissues. Balance and proprioception training usually begins.\nThe wall squat exercise is an slightly easier alternative exercise to the squat. By using the wall some of the body weight is supported. The athlete stands with their back against a wall and the feet moved forwards. They perform a squat by sliding the back down the wall and ensuring that the knees do not move forwards past the toes. The squat position can be held for added difficulty, or performed on a single leg only.\nTerminal knee extension\nThis exercise increases the weight-bearing strength of the quadriceps. A resistance band is wrapped around the knee and anchored to a table leg or similar upright object. The athlete starts with the knee slightly bent and body weight on the involved leg. The knee is then straightened backwards, against the resistance of the band. The knee should not be locked straight.\nStanding hamstring curl\nStanding single leg hamstring curl (leg curl). Start slowly then get faster as your gain in confidence. The athlete stands and flexes the involved knee. Ankle weights can be used to increase difficulty or offer resistance with the hands, or incorporate a resistance band. The athlete may use the hands on stable object to support the body.\nSquat with band\nThe resistance band provides lateral or sideways resistance to add another dimension to the squat exercise. Starting with the feet shoulder width apart, the athlete squats down to no more than a right angle at the knee. The knees should not fall inwards and the back should remain straight throughout. This can be performed with a bar over the shoulders or dumbbells in the hands.\nThe squat is a great exercise to work most of the leg muscles, especially the quads and glutes. Stand with your feet shoulder width apart and toes pointing straight forwards. Keep the back straight as you initiate movement at your hips. Push your buttocks out behind you and bend your knees. Do not let your knees move in front of your toes or squat deeper than a 90 degree (right angle) at the knee. Start with shallow squats and increase gradually.\nStraight leg ball pick up\nThe straight leg ball pick up strengthens the hamstring muscles in a stretched position. The athlete stands with the heel of the involved leg raised. The uninvolved leg is moved back to provide balance. Ensuring that the back is kept straight the athlete bends to pick up the medicine ball. All motion involves the pelvis moving around the femurs rather than lumbar flexion.\nThe Plie is a wide squat exercise with the knees pointing outwards. The back should remain straight during the exercise and the pelvis should not til backwards. The athlete stands with the feet turned out. The knees should be bent as if performing a squat, ensuring they do not move forwards past the toes.\nKnee extension with band\nKnee extension exercise (or leg extension) using a resistance band to strengthen the thigh muscles. The athlete sits on the edge of the table (or on a chair) with the knees over the edge. The resistance band is placed around the ankle and anchored under the furthest table/chair leg on the side of the leg being worked on. The athlete lifts the foot upwards to straighten the knee, then returns to the starting position. If pain is felt do not continue with this exercise.\nSeated hamstring curl\nSeated or supine hamstring curl exercise using a resistance band. The athlete sits with a resistance band around the ankle with both legs straight. A partner holds the band in both hands until it is taut. The partner must not move the band from the starting position. The athlete draws the ankle in towards the buttocks increasing the resistance of the band, then returns to the starting position.\nThis exercise works the hamstring muscles and can be progressed to use weights depending on the state of the injury. Lying on their front with the foot pointing down over the edge of the couch, the athlete fully bends the knee. Provided this is pain free, a resistance band or ankle weight can be used to increase difficulty.\nSingle leg catch exercises for hamstrings. This starts to strengthen the hamstrings eccentrically or as they lengthen. In a prone position the athlete lifts both legs to a 90 degree angle. Ensuring that the leg and the foot are not turned outwards the athlete drops the leg attempting to stop or 'catch' the lower leg reaching full extension.\nLate stage knee exercises\nThese exercises are more functional and sports specific. The aim is to restore full strength and mobility to the joint and return the athlete to full training and competition.\nLunge with ball\nA ball can be used with a lunge to help with balance and to add extra weight. The athlete stands with the injured leg a wide stance in front of the other. The athlete holds a medicine ball close to the chest With the weight shifted onto the front leg, the back knee is slowly bent and dropped down towards the floor.\nLunge on step\nBy raising the uninvolved leg on a step the athlete adds more weight to the leg being worked on. The athlete stands with the injured leg a wide stance in front of the other. The uninvolved leg is raised on a step with weight on the toes. With the weight shifted onto the front leg, the back knee is slowly bent and dropped down towards the floor.\nThis exercise is ideal for not only strengthening the muscles of the lower extremity but also for burning calories! The athlete stands with the injured leg a wide stance in front of the other. With the weight shifted onto the front leg, the back knee is slowly bent and dropped down towards the floor. The lunge position may be held to increase difficulty.\nBy using a medicine ball in the lateral lunge (side lunge) the athlete is able to add weight to the exercise as well as using it to aid balance. The athlete steps to the side keeping the toes forwards and the feet flat. Whilst keeping the involved leg straight, squat through the hip of the involved leg ensuring that the knee is in line with the foot. The athlete holds the ball out to help maintain balance. Squat as low as possible and hold for 2 seconds. Push back to the starting position.\nEccentric squat knee exercises target the hamstrings, glutes and quads. The athlete raises the heels using half a foam roller. Keeping the back straight the athlete lowers themselves down slowly. The athlete returns to the starting position then repeats.\nNorwegian hamstring curl\nThe Norwegian hamstring curl (or nordic curl) requires either a partner or gym equipment to lock the lower legs securely. This is a very advanced exercise isolating hamstring muscles. A partner anchors the athlete's calves. A straight line must be maintained from knee to shoulder. The athlete lowers the body as controlled as possible to the floor. At the point whereby the move becomes uncomfortable the athlete lets the body fall to the floor using the hands to control their landing."],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"historical"},{"categorization_name":"question_length","category_name":"long"},{"categorization_name":"premise_categorization","category_name":"without premise"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"chinese_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"novice_inquirer"},{"categorization_name":"user_intent","category_name":"opinion_recommendation"}],"document_ids":["<urn:uuid:6b3db748-5151-43a3-8ed4-71e920ccff83>","<urn:uuid:525cb522-3094-4781-901c-059e74022a71>"],"error":null}
{"question":"As a baseball historian, I'm curious about the comparison between McAdams and Sam Jones in terms of their career achievements with St. Louis Cardinals - who had a more successful stint with the team?","answer":"Sam Jones had a more successful stint with the St. Louis Cardinals. While McAdams had only brief appearances with St. Louis in 1911, making just six games and never getting to start, Jones played for the Cardinals in both 1957-1958 and 1963. Additionally, Jones had a more established major league career overall, winning 102 games across his 12-year MLB career, while McAdams' time in the majors was limited to those few relief appearances with St. Louis.","context":["Jack's athletic physique allowed him to become a skilled baseball player. He began pitching for local teams from nearby Benton and other surrounding communities and soon became well known in the area4.\nMcAdams' impressive record with Argenta caught the attention of the Atlanta Crackers of the Southern Association. The Crackers were in the area that July playing a series with the Little Rock Travelers when they made a deal with Argenta to purchase McAdams7. On July 19th, the Crackers returned to Atlanta, and McAdams traveled with them, bringing with him much support from his friends and family back in his hometown4. His father went as far as to offer him one acre of land for every game he won with Atlanta. Unfortunately, McAdams' stay with Atlanta was only brief and he was unable to secure a win during his stay in the league. He made only two appearances with the team, walking 15 batters in 11 innings before Atlanta decided he wasn't ready for Southern League baseball. Instead, McAdams likely returned to Argenta8, finishing the season in the Arkansas State League with a 21-13 win-loss record9.\nThe following season, McAdams was given a tryout with Spokane of the Northwestern League10. He failed to make the club, however, and went to Butte, MT to play in the small Inter-Mountain League11. When the league collapsed in mid-season, McAdams returned to Arkansas and earned a position as a player-manager with Marianna of the Northeast Arkansas League12. His success with Marianna was limited though, and under his leadership, Marianna finished next to last. Fortunately, his luck changed a little the next season when he played with Muskogee in the 1910 Western Association. No longer bearing the duties of a manager, McAdams performed very well. On June 11th, he pitched both halves of a doubleheader against Tulsa, allowing only 6 hits in 18 scoreless innings on the mound13.\nAfter the season, McAdams was acquired by Dallas from Waco, keeping him in the Texas League for the opening 1911 season16. He reported to Dallas for spring training in February, and quickly began impressing the locals17. On March 4th, he was given the opportunity to start against a squad of New York Giants players in an exhibition game, and after striking out six batters across nine innings, he defeated New York, 3-118. McAdams' most impressive spring start, however, came on Sunday, March 20th against the Chicago White Sox. In that game, McAdams battled a 1-1 tie with Chicago's pitchers until the 11th inning when the White Sox finally got the best of him and scored the go-ahead run19. Despite losing, McAdams earned considerable esteem for striking out 14 batters and pitching into extra innings5. In fact, manager John McGraw of the New York Giants was very much interested in purchasing him, but Dallas decided to hold on to McAdams for the time being5.\nMcAdams' early success that spring continued on into the beginning of the season. He was sent in to pitch for Dallas on Opening Day and in turn shut out Oklahoma City on three hits20. Dallas used him regularly, and on April 27th, he pitched both halves of a doubleheader against Waco, allowing only 1 run in both games combined21. A month into the season, he had won 7 games and lost only 122. About that time however, McAdams' busy pitching schedule began to wear on him. He came down with a fever that turned into malaria, and his performance suffered23. After several disappointing games, McAdams, undoubtedly frustrated by his health and poor pitching, began causing tension within the Dallas club24. The issue became serious, and manager James Maloney decided in June to suspend McAdams indefinitely for violating club discipline25. The move came as a surprise to many in baseball, and Dallas soon began receiving many offers to purchase McAdams26.\nAmid the confusion, however, McAdams went to join the Cardinals. He made his big league debut with St. Louis shortly afterward on July 22nd. The game took place in New York against the Giants, and much like his other major league games that followed, it was limited to only a brief appearance late in the game with the Cardinals losing. Yet McAdams remained confident in himself30, and between then and September 4th, he appeared in five more games. He pitched fairly well in most situations, but not well enough for St. Louis to allow him to start. Summing up his time with St. Louis, McAdams told a Dallas reporter during the offseason, \"I didn't make any great sort of show, but I think my work was all right as much as there was of it.\"31\nUpon the close of the season, St. Louis sold McAdams to Springfield, IL, who in turn sold him to Newark of the International League32. McAdams reported to Newark's training camp at Petersburg, VA the next spring to prepare for the 1912 season. He was met with high expectations32, but unfortunately, he was largely unable to live up to them. In May, after a rough start to the season, McAdams was sent to Galveston of the Texas League under the conditional agreement that if McAdams failed to perform well, he would be returned to Newark33. It did not take Galveston long to realize, however, that McAdams was simply unable to pitch as well as he had with Dallas the year before34. Consequently, Galveston released him back to Newark in June35, and Newark decided to release him outright33.\nAfter 1912, McAdams' never again played a full season of professional baseball. An arm injury, perhaps suffered as early as when he was with St. Louis, began to plague his career39. He signed with Fort Worth in 1913 and reported to spring training, but his arm troubles kept him from getting into proper condition and joining the team40. Instead, he began umpiring college games around the Fort Worth area41, and may have even briefly played outlaw ball in St. Louis42. In May, he tried to make an appearance with the Wichita Falls team of the Texas-Oklahoma League, but injuries again kept him from doing so43. He remained in the league for a time, however, as an umpire.\nOver the next couple of years, McAdams attempted several times to make a comeback in professional baseball. In the spring of 1914, he joined the Waterloo club of the Central Association44. However, on May 14th, in his first start of the season, he walked four batters in only 1 1/3 innings. He was subsequently let go to join an independent team in nearby Mason City, IA, with whom he appeared with in early June45. In July, he managed to earn a start with Austin of the Texas League, but lasted only 3 2/3 innings in a losing effort46. As a result, he did not make another start with Austin. In the spring of 1915, he tried again to enter the Texas League, this time with Shreveport. He was the first player to report for spring training, but arm injuries again troubled him and he was released before the start of the season47. Afterward, he may have tried to earn a tryout with the Chicago Whales of the Federal League, who had trained in Shreveport that spring48. If he did, he did not succeed in earning a position with the team. Instead, he went to Denver that July looking for a job, and in August appeared with a locally sponsored semiprofessional team known as the Sullivan & Hoffers49. This is McAdams' last known pitching appearance.\nNo longer able to pitch professionally, McAdams returned home to Arkansas, and by June, 1917, he was working as a railroad conductor for the Arkansas Short Leaf Lumber Co. in Pine Bluff, AR50. His baseball career, however, was not entirely over. He umpired for many years in numerous minor leagues, including in the 1921 Mississippi League51, the 1922 Southwestern League52, and the 1924 Cotton States League51. Later, he worked for the Missouri Pacific Railroad and eventually moved to California53.\nAt some point, McAdams married and had at least one child50. While in California in 1937, McAdams was admitted to a San Francisco hospital, and on May 21st, he died at the age of 5053. The remains were returned to Arkansas and a funeral was held at the home of his sister Nancy. He was interred at Bryant Cemetery in his hometown.\nFor contemporary newspaper excerpts concerning McAdams, see Jack McAdams Excerpts.\nThe following is a record of teams McAdams appeared with in regular season play:\nThe following is a gamelog of McAdams' six games with St. Louis in 1911:\nMajor League Statistics at Baseball-Reference.com.\nMinor League Statistics at Baseball-Reference.com.\nMinor League Statistics at Baseball-Reference.com.\n1. 1900 U.S. Census\n2. Steve Purdue, Saline County Library\n4. Atlanta Constitution, 7/26/1908\n5. Dallas Morning News, 3/23/1911\n6. Atlanta Constitution, 7/21/1908\n7. The Sporting News, 7/23/1908\n8. McAdams' 21-13 record suggests he pitched 7 more games with Argenta sometime after being sold to Atlanta.\n9. 1909 Reach Baseball Guide\n10. Spokane Press, 3/24/1909\n11. Anaconda Standard, 4/23/1909\n12. Jonesboro Daily Tribune, 7/22/1911\n13. Kansas City Star, 6/12/1910\n14. Dallas Morning News, 6/9/1910\n15. Fort Worth Star-Telegram, 7/21/1910\n16. Fort Worth Star-Telegram, 12/28/1910\n17. Dallas Morning News, 2/19/1911\n18. Dallas Morning News, 3/5/1911\n19. Dallas Morning News, 3/20/1911\n20. Dallas Morning News, 4/13/1911\n21. Dallas Morning News, 4/28/1911\n22. Dallas Morning News, 5/14/1911\n23. Dallas Morning News, 5/21/1911\n24. El Paso Herald, 6/26/1911\n25. Dallas Morning News, 6/23/1911\n26. El Paso Herald, 6/29/1911\n27. Dallas Morning News, 6/27/1911\n28. Dallas Morning News, 2/26/1912\n29. Dallas Morning News, 7/9/1911\n30. The Sporting News, 8/17/1911\n31. Dallas Morning News, 10/25/1911\n32. Dallas Morning News, 2/25/1912\n33. Galveston Daily News, 7/24/1912\n34. The Sporting News, 5/30/1912\n35. Galveston Daily News, 6/15/1912\n36. Denver Post, 6/22/1912\n37. Sporting Life, 7/27/1912\n38. 1913 Reach Baseball Guide\n39. Fort Worth Star-Telegram, 2/21/1915\n40. Dallas Morning News, 4/5/1913\n41. Fort Worth Star-Telegram, 5/8/1913\n42. Fort Worth Star-Telegram, 5/13/1913\n43. Wichita Falls Time, 5/27/1913\n44. Waterloo Evening Courier, 3/9/1914\n45. Mason City Globe-Gazette, 6/2/1914\n46. Dallas Morning News, 7/18/1914\n47. Dallas Morning News, 3/28/1915\n48. Chicago Daily Tribune, 4/15/1915\n49. Denver Post, 8/4/1915\n50. McAdams' WWI Draft Card\n52. Muskogee Times Democrat, 7/22/1922\n53. Benton Courier, 1937\n54. Official records list McAdams with 5 Runs Allowed","Past feature articles, game summaries, and game box scores of African-American newspapers indicate there were at least 29 no-hitters thrown in Negro League baseball. Most notably there were two by Satchel Paige and one each by Hilton Smith, Andy Cooper, “Smoky” Joe Williams, and Leon Day; all Hall of Fame pitchers. The “invisible color line” that kept African–American ballplayers out of the Major Leagues was not erased until 1947 which was too late for these and many other good Negro League hurlers who were by then either dead or passed their prime. But there were younger Negro League pitchers that got their opportunity in the Major Leagues; “Toothpick” Sam Jones was one of them. He is the only former Negro League pitcher to throw a Major League no-hitter.\nBorn 12/14/25 in Stewartsville, Ohio, Jones also spent a portion of his youth in West Virginia. He left for military service before starting the life of a coal mine worker as were many of his family members and friends. He played with a local black team while stationed in Orlando, Florida in 1947 and caught the eye of Quincy Trouppe, then the manager of the Negro American League (NAL) Cleveland Buckeyes. Jones signed in time to help the team win the NAL pennant, but they lost to the New York Cubans in the 1947 Negro League World Series. Jones got his nickname from having a toothpick in his mouth while on the pitching mound.\nIt would be 1950 when the Cleveland Indians finally noticed the talented right-handed hurler that had been in their own backyard. However, Jones pitched in only 16 games with the Indians in four years before being traded to the Chicago Cubs after the 1954 season. Once in the National League, the talented pitcher proved what he had done in the Negro Leagues was no fluke. Opponents claimed Jones, a power pitcher standing at 6’4” and weighing 200 pounds, had the best curveball in the National League. He faced batters with a never-changing, expressionless look on his face which resulted in him also being called “Sad” Sam. That is the nickname I mostly remember. But opponents also said Jones had a mean streak exhibited by his pitches; he hit 14 batters in 1955 (league leader). There was an ongoing intense confrontation whenever Henry Aaron faced Jones that is well documented. Jones struggled at times with control of his pitches; he led the National League in walks four times. But he also could be overpowering; being the league leader in strikeouts three years and pitching 17 shutouts in his 12 year Major League career. He became a two-time National League All-Star, winning 21 games with the San Francisco Giants in 1959 and 18 in 1960.\nBut it was on May 12, 1955 as a Chicago Cub that Jones pitched himself into the Major League Baseball record book with a 4-0 no-hitter against the Pittsburgh Pirates. It was a “Sam Jones” pitched type of game. He struck out six batters, walked seven, threw a Wild Pitch, and was helped with two double plays. In the ninth inning, he walked the first three hitters before striking out the final three.\nHe retired after pitching with the Baltimore Orioles in 1964, the sixth team played with during his time in the Major Leagues; Cleveland Indians 1951 – 1952, Chicago Cubs 1955 – 1956, St. Louis Cardinals 1957 – 1958 and 1963, San Francisco Giants 1959 – 1961, and Detroit Tigers 1962. On November 5, 1971, the 45 years old Jones died of throat cancer.\n“Sad “Sam Jones won 102 games in the Major Leagues. He lost 101. No doubt the inconsistent control of his pitches cost him victories early in his career, but he still had 1,376 career strikeouts. And no former Negro League pitcher, other than Don Newcombe, had the success in the Major Leagues as Sam Jones.\nTo learn more about the Negro League baseball era, read “Last Train to Cooperstown: The 2006 Baseball Hall of Fame Inductees from the Negro League Baseball Era”. To order go to (http://booklaunch.io/kevinlmitchell/last-train-to-cooperstown) http://www.klmitchell.com"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"moderate"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_formulation","category_name":"natural_simple"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"spanish_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"polite_conversational"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_intent","category_name":"instructional"}],"document_ids":["<urn:uuid:c670847b-6abc-4a44-b9b5-b0604f08c852>","<urn:uuid:55288fa2-499c-476e-bfa5-e07593444950>"],"error":null}
{"question":"Researching state symbolism - how do the design elements of the 35-star Civil War medallion flag pattern compare to Nevada's official state symbols?","answer":"The 35-star Civil War medallion flag featured a double-wreath configuration with two concentric rings of stars, corner stars, and a central star, all arranged on a navy blue canton. In comparison, Nevada's state symbols are more regionally specific - including a state flag with a single star and sagebrush wreath, a state seal showing mining and agriculture scenes, and natural elements like the sagebrush (state flower), mountain bluebird (state bird), and silver (state metal). The medallion flag represented national unity during the Civil War, while Nevada's symbols reflect its unique landscape and 'Battle Born' heritage as a state that joined the Union during the conflict.","context":["35 STARS, 1863-65, CIVIL WAR PERIOD, A VERY RARE, SMALL SCALE EXAMPLE WITH A BEAUTIFUL MEDALLION CONFIGURATION, PROBABLY MADE IN BALTIMORE BY JABEZ W. LOANE, FOUND AMONG THE POSSESSIONS OF PHYSICIAN, CHARLES F. MCEWEN:\n35 star American national flag, in an unusual, small size, with great graphics and nice family history; likely produced by an identified maker. The stars of the flag are arranged in what is known as a medallion configuration. This particular variety has been called a double-wreath, due to its two concentric rings of stars. As with most medallions, there is a flanking star in each corner of the Navy blue canton, accompanied by a star in the very center of the inner ring. Many medallion pattern flags have a large star in the very center, but here there is a small star, instead, which is the same size as the remaining 34.\nThe flag has reportedly remained in the possession of the same family since the time it was official (1863-65), during the Civil War. It was acquired from the great-granddaughter of a physician by the name of Charles F. McEwen*, who was married in Maryland and was either a Pennsylvania or a Maryland resident when the war occurred. These facts are interesting because the flag appears to be linked to a Baltimore sail and flag-maker by the name of Jabez W. Loane.\nLoane was in business with as early as 1859 under the name Loane and Graffin at 10 Bolby’s Wharf. He was alone between 1863 and 65 (the basic time at which this flag was made) with an address of 2 Bolby’s Wharf, listed as “sailmaker, marine, National &fancy mfgrs. At 2 Bolby’s and U.S. Flag Store, 67 W. Pratt [Street]”. In 1865 he was advertising in the Baltimore City Directory as “U.S. Flag Depot” and listed as having “…On hand muslin, merino, silk, and bunting flags…for decoration of parlors, public halls, public buildings, ships, steam boats. Also a veried assortment of flag staffs and ornaments such as spears, eagles, gilt and painted balls, acorns, etc.” Records of his business continue until 1910, but were no longer listed in 1915.**\nSeldom do we know who made any given flag during the 19th century. Few makers marked their flags and few photos can tie a flag to a particular manufacturer. But this particular flag, unlike most others, has a couple of clues that aid in its identification. Flag expert and Civil War museum curator, Howard Madaus, had extensive records on Civil War period flags. Drawing on his research across known examples, he attributed a flag, illustrated on page 73 of “The American Flag: Two Centuries of Conflict and Conduct” (Madaus & Smith, 1996), to Loane. The flag in the Madaus/Smith illustration is effectively the same as the flag in question here. It employs the same number of stars in each wreath, arranged in the same fashion, all with a single point facing inward.\nThe binding on the hoist of the flag in the Madaus/Smith book is unusually narrow, with two brass grommets, one at the top and one at the bottom. The flag in question here is the same. The hem of both flags at the fly end appears to be approximately the same width and both are turned toward the obverse (front) of the flag. Even more interesting, however, is the presence of a length hemp rope on the example in question, which is sewn within the extreme end of the binding. I have seen rope before, sewn on the fly, but it is very unusual and I don’t recall ever seeing it sewn into the hem. The flag in the Madaus/Smith book appears to have a piece of rope protruding from the hem on the last white stripe.\nWhile the two flags are different in length, at 57.5 inches for the flag in question versus 67.5 inches for the Madaus/Smith flag), the height of each flag is the same at 40 inches. 3 feet 4 inches is an odd measurement and, based on the facts already outlined above, is probably no cooincidence.\nWest Virginia entered the Union as the 35th state on June 20th, 1863, and this flag was used during the closing years of the Civil War. Although 35 was the official star count until July 4th, 1865, most flag making that was not under military contract would have included a 36th star after the addition of Nevada on October 31st, 1864. This means that 35 star flags were realistically produced for less than a year and a half.\nConstruction: The stars of the flag are made of cotton and double-appliquéd (applied to both sides of the Navy blue canton). The canton and stripes of the flag are made of wool bunting that has been pieced with treadle stitching. The hoist is made of heavy cotton and applied with chain-style treadle stitching. This type of stitch saw very short-term use on flags made during the second half of the war, which is consistent with the star count. There are two brass grommets, one each at the top and bottom of the hoist. The number “13” is penciled at the top of the hoist, just under the grommet, but the meaning of the number is unknown.\nMounting: The flag has been hand-stitched to 100% natural fabrics for support on every seam and throughout the star field. It was then hand-sewn to 100% hemp fabric, laid over a supportive panel. The mount was then placed in a hand-gilded and distressed Italian molding with a wide, convex profile. The front is U.V. protective acrylic.\nCondition: There are various minor losses and tears throughout. Fabrics of similar coloration were placed behind the flag for masking purposes. There is minor foxing and staining, the darkest of which are two spots in the bottom fly-end corner.\n* The records of Civil War soldiers can be difficult to obtain. The granddaughter of McEwen knew that the spelling of the family name (her maiden name), had definitely changed at some point in the past. Because Maryland was a slave state, Charles F. McEwen may likely have served in Pennsylvania. Two men by this name served the Union Army in Pennsylvania, one of which mustered into the 14th PA Cavalry at Pittsburgh, was captured at Fredericksburg, and died at Andersonville Prison. The other mustered into the 192nd Pennsylvania at Philadelphia and survived the war. Neither man listed a residence, which was not at all unusual.\nMcEwen may have become a physician following the war or may have served in that capacity during wartime. This and other information has been lost, but research is under way to uncover what exists at the National Archives.\n**Information on Jabez Loane obtained from: Bazelon & McGuinn, “Military Goods Dealers and Makers, 1785-1915” (1999, Bazelon & McGuinn), p. 166.\n|Dealer||Jeff R. Bridgman American Antiques|\n|Measurements||flag: 40\" x 57.75\", frame: 52.75\" x 70.5\"|\n|Inventory||View Dealer's Inventory|\n|Price||Please call or email email@example.com|\n|Contact||Jeff Bridgman, 717-502-1281 or firstname.lastname@example.org|","FREE AUTOMATED EMAIL UPDATES\nThe origin of the state’s name is Spanish, meaning “snow-capped.”\nNevada is 110,540 square miles: 485 miles long, 315 miles wide, and ranks as the seventh largest state in the United States. It became a U.S. territory on March 2nd, 1861 and became the 36th state on October 31st, 1864. Nevada consists of 16 counties.\nState Slogan – Battle-Born State\nState Motto – All for Our Country\nState Seal – Adopted February 24, 1866. A golden seal, embossed with the words “The Great Seal of the State of Nevada” around the edge. The interior design shows a picture of mining, agriculture, industry and Nevada scenery. Under the scroll appears the State motto “All for Our Country.”\nState Flag – Adopted March 26, 1929. The state ﬂag has a cobalt blue background with a 5-pointed star, with the word “Nevada” in gold letters under the star and in the upper left quadrant between two sprays of crossed sagebrush, forming a half wreath. A golden scroll on top of the wreath depicts the words “Battle Born” in black letters\nState Colors – Silver and Blue\nState Song – “Home Means Nevada” - By Bertha Raffetto\nState Flower – Sage Brush\nState Reptile – Desert Tortoise\nState Bird – Mountain Bluebird\nState Animal – Desert Bighorn Sheep\nState Fish – Lahontan Cutthroat Trout\nState Metal – Silver\nState Gemstone – Black Fire Opal can be found in only one place on the North American continent, Virgin Valley, Nevada.\nState Rock – Sandstone is found throughout the state. This rock is famous for the natural scenery it\nprovides throughout Nevada. It’s most famous locations in the state are in Red Rock Canyon and the Valley of Fire.\nState Tree – Single-Leaf Piñon\nState Grass – Indian Rye Grass (Orzopsis hymenoides), once a staple food source for Nevada’s Native Americans. This grass has the ability to re-seed itself and is ideal for planting in areas damaged by fire or overgrazing.\nState Fossil - The Ichthyosaur (Shonisaurus) was designated in 1977 as the state fossil. Nevada has the only complete skeleton. This extinct marine reptile measures 55 feet.\nNevada Nicknames – Battle-Born State, Sagebrush State, Silver State\nNevada Government: www.leg.state.nv.us\nLas Vegas climate is classified as arid (dry). It averages 294 days of Sunshine per year (211 clear days, 83 partly cloudy). Highs of 105° are common from May to September, with several days exceeding 115°. The average annual rainfall is 4.13 inches. Humidity stays around 29%.\nLas Vegas Sun, 702.385.3111, www.lasvegassun.com, Las Vegas Review Journal, 702.383.0211, www.lvrj.com\nRegistering your vehicle:\nStudents and active duty personnel (including dependents) do not need to register their vehicles or acquire a new license in Nevada as long as the individual is not employed in the State of Nevada. Vehicles must be currently registered with the home state of valid insurance and driver’s license.\nOut-of-state drivers and vehicle registrations can be used by new residences for up to 30 days or before the prior items expire, whichever comes first. At any time during that 30 days, they may be turned in to the DMV for Nevada documents.\nNevada law requires motorists to notify DMV of a change of address within 30 days of the move. Keeping your address current is important so they can send renewal notices in the mail.\nNew Nevada Vehicle Registration: Documents needed to register are the ORIGINALS of:\nNevada Department of Motor Vehicles – for more information www.dmvnv.com"],"question_categories":[{"categorization_name":"answer_type","category_name":"comparison"},{"categorization_name":"temporal_focus","category_name":"current"},{"categorization_name":"question_length","category_name":"short"},{"categorization_name":"premise_categorization","category_name":"with premise"},{"categorization_name":"question_formulation","category_name":"advanced_reasoning"}],"user_categories":[{"categorization_name":"user_language_proficiency","category_name":"english_native_fluent"},{"categorization_name":"user_conversational_style","category_name":"formal_transactional"},{"categorization_name":"user_profile","category_name":"knowledgeable_generalist"},{"categorization_name":"user_intent","category_name":"information_seeking"}],"document_ids":["<urn:uuid:37e7ff70-708d-48bf-8d6a-245789e9f205>","<urn:uuid:f6e4959b-6b26-4994-bcde-47be20efbbd8>"],"error":null}