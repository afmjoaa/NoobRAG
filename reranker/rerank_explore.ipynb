{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-28T12:47:36.114611Z",
     "start_time": "2025-04-28T12:47:36.112787Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import random\n",
    "\n",
    "# ------------------------------\n",
    "# 1. Reranker Model: MixedBread Reranker\n",
    "# ------------------------------\n",
    "\n",
    "class MixedBreadReranker(nn.Module):\n",
    "    def __init__(self, model_name=\"mixedbread-ai/mxbai-rerank-large-v1\"):\n",
    "        super().__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.hidden_size = self.encoder.config.hidden_size\n",
    "        self.scorer = nn.Linear(self.hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, sentences):\n",
    "        \"\"\"\n",
    "        MixedBread expects inputs like: 'query: ... passage: ...'\n",
    "        \"\"\"\n",
    "        inputs = [f\"query: {query} passage: {sent}\" for sent in sentences]\n",
    "        tokenized = self.tokenizer(inputs, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        tokenized = {k: v.to(next(self.parameters()).device) for k, v in tokenized.items()}\n",
    "        output = self.encoder(**tokenized)\n",
    "        cls_emb = output.last_hidden_state[:, 0, :]  # [CLS] token embedding\n",
    "        scores = self.scorer(cls_emb).squeeze(-1)\n",
    "        return scores  # shape: (batch_size,)\n",
    "\n",
    "# ------------------------------\n",
    "# 2. Differentiable Top-k (Gumbel Softmax Approximation)\n",
    "# ------------------------------\n",
    "\n",
    "def differentiable_top_k(scores, max_k, tau=0.5):\n",
    "    probs = F.gumbel_softmax(scores, tau=tau, hard=False)\n",
    "    sorted_probs, indices = torch.sort(probs, descending=True)\n",
    "    mask = torch.zeros_like(probs)\n",
    "    for i in range(max_k):\n",
    "        mask[indices[i]] = sorted_probs[i]\n",
    "    return mask / (mask.sum() + 1e-9)\n",
    "\n",
    "# ------------------------------\n",
    "# 3. Custom Dataset with Metadata\n",
    "# ------------------------------\n",
    "\n",
    "class RerankerDataset(Dataset):\n",
    "    def __init__(self, data_samples):\n",
    "        self.samples = []\n",
    "        for sample in data_samples:\n",
    "            query = sample[\"query\"]\n",
    "            doc = sample[\"document\"]\n",
    "            teacher_scores = sample[\"teacher_scores\"]\n",
    "\n",
    "            sentences = sent_tokenize(doc)\n",
    "            for i, sent in enumerate(sentences):\n",
    "                self.samples.append({\n",
    "                    \"query\": query,\n",
    "                    \"sentence\": sent,\n",
    "                    \"teacher_score\": teacher_scores[i] if i < len(teacher_scores) else random.uniform(0, 1),\n",
    "                    \"metadata\": {\n",
    "                        \"sentence_index\": i,\n",
    "                        \"document\": doc\n",
    "                    }\n",
    "                })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return {\n",
    "        \"queries\": [x[\"query\"] for x in batch],\n",
    "        \"sentences\": [x[\"sentence\"] for x in batch],\n",
    "        \"teacher_scores\": torch.tensor([x[\"teacher_score\"] for x in batch], dtype=torch.float32),\n",
    "        \"metadata\": [x[\"metadata\"] for x in batch]\n",
    "    }\n",
    "\n",
    "# ------------------------------\n",
    "# 4. Training Loop\n",
    "# ------------------------------\n",
    "\n",
    "def train_reranker(model, dataset, max_k=3, tau=0.5, epochs=3, batch_size=8, lr=2e-5, device='cuda'):\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for batch in dataloader:\n",
    "            query = batch[\"queries\"][0]  # assume batch shares the same query\n",
    "            sentences = batch[\"sentences\"]\n",
    "            teacher_scores = batch[\"teacher_scores\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred_scores = model(query, sentences)\n",
    "            mask = differentiable_top_k(pred_scores, max_k, tau)\n",
    "            loss = F.mse_loss(pred_scores * mask, teacher_scores * mask)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"[Epoch {epoch+1}] Loss: {epoch_loss / len(dataloader):.4f}\")\n",
    "\n",
    "# ------------------------------\n",
    "# 5. Inference with Metadata\n",
    "# ------------------------------\n",
    "\n",
    "def rerank_inference(model, query, document, max_k=3, tau=0.5):\n",
    "    sentences = sent_tokenize(document)\n",
    "    metadata = [{\"sentence_index\": i, \"document\": document} for i in range(len(sentences))]\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        scores = model(query, sentences)\n",
    "        print(scores)\n",
    "        mask = differentiable_top_k(scores, max_k, tau)\n",
    "        _, indices = torch.topk(mask, max_k)\n",
    "        selected_sents = [sentences[i] for i in indices.tolist()]\n",
    "        selected_meta = [metadata[i] for i in indices.tolist()]\n",
    "    return selected_sents, selected_meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Loss: 0.1598\n",
      "[Epoch 2] Loss: 0.1196\n",
      "[Epoch 3] Loss: 0.0145\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# 6. Run Example\n",
    "# ------------------------------\n",
    "\n",
    "example_data = [\n",
    "        {\n",
    "            \"query\": \"What are hybrid retrieval systems?\",\n",
    "            \"document\": (\"Hybrid systems combine sparse and dense retrieval. \"\n",
    "                         \"They are useful in large-scale QA. \"\n",
    "                         \"Some models use rerankers to select top documents.\"),\n",
    "            \"teacher_scores\": [0.8, 0.6, 0.9]\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"What is Gumbel softmax?\",\n",
    "            \"document\": (\"Gumbel softmax allows differentiable sampling. \"\n",
    "                         \"It helps in training discrete selections. \"\n",
    "                         \"Widely used in end-to-end reranking tasks.\"),\n",
    "            \"teacher_scores\": [0.7, 0.85, 0.75]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "dataset = RerankerDataset(example_data)\n",
    "model = MixedBreadReranker()\n",
    "train_reranker(model, dataset, max_k=2, tau=0.7, epochs=3, batch_size=4, lr=2e-5, device='cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-28T12:39:44.701645Z",
     "start_time": "2025-04-28T12:37:18.210044Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Inference Example ---\n",
      "tensor([0.9369, 0.6435, 0.8630, 0.7269, 0.9350, 0.5094, 0.5182, 0.5132, 0.5036,\n",
      "        0.5399])\n",
      "Selected Sentences:\n",
      "• It is used in models like Gumbel Rerank.\n",
      "• This is crucial for end-to-end training.\n",
      "• The weather today is sunny with clear skies.\n",
      "\n",
      "Metadata:\n",
      "{'sentence_index': 2, 'document': 'Gumbel softmax allows smooth approximations of argmax. This is crucial for end-to-end training. It is used in models like Gumbel Rerank. The technique allows for differentiable selection.It is widely applied in machine learning models to enable continuous gradient flow. Additionally, Gumbel softmax provides a more efficient way to train models with discrete outputs. The weather today is sunny with clear skies. I went to the market to buy some fresh vegetables. Many people enjoy hiking in the mountains during the summer. The football game last night was very exciting. Art and culture play an important role in shaping society.'}\n",
      "{'sentence_index': 1, 'document': 'Gumbel softmax allows smooth approximations of argmax. This is crucial for end-to-end training. It is used in models like Gumbel Rerank. The technique allows for differentiable selection.It is widely applied in machine learning models to enable continuous gradient flow. Additionally, Gumbel softmax provides a more efficient way to train models with discrete outputs. The weather today is sunny with clear skies. I went to the market to buy some fresh vegetables. Many people enjoy hiking in the mountains during the summer. The football game last night was very exciting. Art and culture play an important role in shaping society.'}\n",
      "{'sentence_index': 5, 'document': 'Gumbel softmax allows smooth approximations of argmax. This is crucial for end-to-end training. It is used in models like Gumbel Rerank. The technique allows for differentiable selection.It is widely applied in machine learning models to enable continuous gradient flow. Additionally, Gumbel softmax provides a more efficient way to train models with discrete outputs. The weather today is sunny with clear skies. I went to the market to buy some fresh vegetables. Many people enjoy hiking in the mountains during the summer. The football game last night was very exciting. Art and culture play an important role in shaping society.'}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Inference Example ---\")\n",
    "q = \"Explain Gumbel softmax in reranking.\"\n",
    "d = (\n",
    "    \"Gumbel softmax allows smooth approximations of argmax. \"\n",
    "    \"This is crucial for end-to-end training. \"\n",
    "    \"It is used in models like Gumbel Rerank. \"\n",
    "    \"The technique allows for differentiable selection.\"\n",
    "    \"It is widely applied in machine learning models to enable continuous gradient flow. \"\n",
    "    \"Additionally, Gumbel softmax provides a more efficient way to train models with discrete outputs. \"\n",
    "    # Irrelevant sentences:\n",
    "    \"The weather today is sunny with clear skies. \"\n",
    "    \"I went to the market to buy some fresh vegetables. \"\n",
    "    \"Many people enjoy hiking in the mountains during the summer. \"\n",
    "    \"The football game last night was very exciting. \"\n",
    "    \"Art and culture play an important role in shaping society.\"\n",
    ")\n",
    "sents, meta = rerank_inference(model, q, d)\n",
    "print(\"Selected Sentences:\")\n",
    "for s in sents:\n",
    "    print(\"•\", s)\n",
    "print(\"\\nMetadata:\")\n",
    "for m in meta:\n",
    "    print(m)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-28T12:47:41.164363Z",
     "start_time": "2025-04-28T12:47:39.620806Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
